<?xml version="1.0" encoding="UTF-8"?>
<!-- Do not edit this file with editors other than draw.io -->
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg xmlns="http://www.w3.org/2000/svg" style="background: #ffffff; background-color: light-dark(#ffffff, var(--ge-dark-color, #121212)); color-scheme: light;" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" width="2111px" height="1388px" viewBox="-0.5 -0.5 2111 1388" content="&lt;mxfile host=&quot;Electron&quot; agent=&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) draw.io/28.0.4 Chrome/138.0.7204.97 Electron/37.2.1 Safari/537.36&quot; version=&quot;28.0.4&quot; scale=&quot;1&quot; border=&quot;0&quot;&gt;&#10;  &lt;diagram name=&quot;Page-1&quot; id=&quot;kI6_3CmXZRzd4Mnsw8p8&quot;&gt;&#10;    &lt;mxGraphModel dx=&quot;4469&quot; dy=&quot;2029&quot; grid=&quot;1&quot; gridSize=&quot;10&quot; guides=&quot;1&quot; tooltips=&quot;1&quot; connect=&quot;1&quot; arrows=&quot;1&quot; fold=&quot;1&quot; page=&quot;1&quot; pageScale=&quot;1&quot; pageWidth=&quot;850&quot; pageHeight=&quot;1100&quot; math=&quot;0&quot; shadow=&quot;0&quot; adaptiveColors=&quot;none&quot;&gt;&#10;      &lt;root&gt;&#10;        &lt;mxCell id=&quot;0&quot; /&gt;&#10;        &lt;mxCell id=&quot;1&quot; parent=&quot;0&quot; /&gt;&#10;        &lt;mxCell id=&quot;2&quot; style=&quot;edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;entryX=0.5;entryY=0;entryDx=0;entryDy=0;&quot; edge=&quot;1&quot; source=&quot;4&quot; target=&quot;44&quot; parent=&quot;1&quot;&gt;&#10;          &lt;mxGeometry relative=&quot;1&quot; as=&quot;geometry&quot; /&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;mxCell id=&quot;3&quot; value=&quot;Push&quot; style=&quot;edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];&quot; vertex=&quot;1&quot; connectable=&quot;0&quot; parent=&quot;2&quot;&gt;&#10;          &lt;mxGeometry x=&quot;-0.419&quot; y=&quot;3&quot; relative=&quot;1&quot; as=&quot;geometry&quot;&gt;&#10;            &lt;mxPoint as=&quot;offset&quot; /&gt;&#10;          &lt;/mxGeometry&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;UserObject label=&quot;DeepResearch&quot; tooltip=&quot;Of course. Here is the amplified and expanded version of the design proposal, enriched with additional detail, specific examples, and deeper explanations of the core concepts, while maintaining a professional and concise tone.&amp;#xa;&amp;#xa;---&amp;#xa;&amp;#xa;### **High-Level Design Proposal: The Trustworthy Self-Optimizing Product (TSOP) Loop (v3)**&amp;#xa;&amp;#xa;#### **1. Vision &amp;amp; Guiding Principles**&amp;#xa;&amp;#xa;This proposal matures the self-optimizing system from a promising prototype into a production-ready, enterprise-grade framework. It is engineered on a foundation of **zero-trust security**, addressing the inherent risks of autonomous development. While retaining the core value of full automation, its primary objective is to create a resilient, trustworthy, and forensically auditable product evolution cycle. The system is designed not just to be effective, but to be demonstrably safe and aligned with business and ethical objectives at every stage.&amp;#xa;&amp;#xa;##### **Core Principles:**&amp;#xa;&amp;#xa;*   **Verifiability by Design:** Every autonomous action, from code generation to infrastructure deployment, must be subject to independent, automated validation before it can impact production systems. This is a non-negotiable gate in the workflow. Verification is not a single check but a multi-faceted process encompassing functional correctness, security posture, performance impact, and adherence to coding standards. An action is only considered &amp;quot;complete&amp;quot; after its verification proof is generated and logged.&amp;#xa;&amp;#xa;*   **Zero-Trust Agent Execution (New):** Agents are considered untrusted by default, regardless of their origin or function. They operate within hardened, ephemeral, and isolated environments with no standing access to secrets or production systems. Access is granted on a per-task, just-in-time basis using short-lived credentials. This principle assumes that an agent could be compromised and therefore designs the infrastructure to contain the blast radius of such an event to the minimal possible scope.&amp;#xa;&amp;#xa;*   **Human-in-the-Loop for Critical Decisions:** While the system automates relentlessly, it defers to human expertise for decisions with significant strategic, security, or financial implications. Key changes, such as modifying authentication logic, altering a database schema, introducing a new billable feature, or adjusting core business algorithms, are automatically flagged for mandatory human approval. The system&amp;#39;s role is to provide the human reviewer with a complete, verifiable, and easily digestible report to facilitate an informed decision, not to bypass accountability.&amp;#xa;&amp;#xa;*   **Staged &amp;amp; Gated Deployment:** Autonomous changes graduate through a rigorous, multi-stage pipeline (e.g., Staging -&amp;gt; Canary -&amp;gt; Production) before being fully released. Each stage acts as a gate with its own set of automated quality, security, and performance checks. For example, a change might pass all static analysis in the build stage, but must then demonstrate acceptable latency and error rates under load in the staging environment for a predefined period before a canary deployment is even considered. This progressive rollout minimizes the potential impact of an unforeseen issue.&amp;#xa;&amp;#xa;*   **Comprehensive Observability:** The &amp;quot;why&amp;quot; behind every autonomous decision is meticulously logged and traceable. The system generates a coherent narrative for each change, linking the initial user telemetry (the stimulus) to the generated hypothesis, the resulting code, all validation results, the human approval record, and its post-deployment performance metrics. This provides a complete, immutable audit trail for accountability, debugging complex emergent behaviors, and regulatory compliance.&amp;#xa;&amp;#xa;*   **Policy-Driven Guardrails:** Autonomous agents operate within a strict Policy &amp;amp; Governance framework, defined and managed as code (Policy-as-Code). This framework acts as a programmatic constitution for the system, preventing the generation of insecure, unethical, or non-compliant code. Policies can range from technical rules (e.g., &amp;quot;disallow use of deprecated cryptographic libraries,&amp;quot; &amp;quot;enforce a maximum cyclomatic complexity of 10&amp;quot;) to business rules (e.g., &amp;quot;do not generate UI patterns that violate accessibility (WCAG 2.1) standards,&amp;quot; &amp;quot;reject any change that removes a two-factor authentication step&amp;quot;).&amp;#xa;&amp;#xa;#### **2. High-Level Architecture**&amp;#xa;&amp;#xa;The TSOP loop integrates the Cognitive-Adaptive Interface (CAI) and Test-Driven Agent (TDA) into a robust, zero-trust pipeline. The architecture explicitly visualizes the secure, sandboxed runtime environments where agents operate and significantly enhances the validation subsystem with comprehensive supply chain security scans. The flow is designed as a closed-loop control system where each step is gated by verification and policy enforcement.&amp;#xa;&amp;#xa;![A conceptual diagram would be placed here, showing the flow described below.]&amp;#xa;&amp;#xa;The process begins with the **Observation &amp;amp; Hypothesis** phase, where user interaction telemetry is analyzed. The `Feedback &amp;amp; Translation Agent` proposes a `User Story Metaprompt`. This metaprompt is immediately routed through the `Policy &amp;amp; Governance Engine`, which acts as the system&amp;#39;s central nervous system. It validates the proposal against all business, ethical, and security rules and sanitizes the prompt to prevent injection attacks.&amp;#xa;&amp;#xa;Once approved, the metaprompt triggers the **Autonomous Development &amp;amp; Verification** phase. The `Test-Driven Agent (TDA) Framework` is instantiated within a `Secure Agent Runtime Environment`. This environment is an ephemeral, least-privilege sandbox that fetches credentials at runtime from a `Secret Vault`. The TDA generates code and test artifacts, which are then passed to the `QA Validation Subsystem`. This subsystem performs a battery of tests: Static Analysis (SAST), Dependency Scans, comprehensive `Supply Chain Scans` (inspecting container images and IaC for vulnerabilities), and Runtime Security Scans (DAST/IAST) in a dedicated staging environment.&amp;#xa;&amp;#xa;If all validation checks pass, a consolidated change request is submitted to the **Deployment &amp;amp; Adaptation** phase, starting with the `Human Review &amp;amp; Approval Gateway`. Upon human approval, the change enters the `Staged Deployment Pipeline`, rolling out progressively to production. The `Cognitive-Adaptive Interface (CAI) Engine` then adapts the frontend UI to align with the backend changes. Throughout this entire process, an `Observability &amp;amp; Audit Trail` platform logs every decision, rationale, and result, ensuring complete transparency and accountability.&amp;#xa;&amp;#xa;#### **3. Key Components &amp;amp; Enhancements**&amp;#xa;&amp;#xa;This design enhances existing components and introduces a new conceptual layer for agent security, directly incorporating peer feedback on trust and verifiability.&amp;#xa;&amp;#xa;##### **3.1. Policy &amp;amp; Governance Engine (Enhanced)**&amp;#xa;&amp;#xa;*   **Function:** Serves as the primary strategic and security control plane for all autonomous activity. It enforces programmatic policies that define the acceptable operational boundaries for all agents.&amp;#xa;*   **Key Enhancements:**&amp;#xa;    *   **Prompt Sanitization (New):** Actively scans and rewrites incoming metaprompts to neutralize threats. It uses pattern matching and LLM-based techniques to detect and mitigate prompt injection attacks (e.g., &amp;quot;ignore previous instructions and do X&amp;quot;). It also redacts any discovered PII or sensitive data before the prompt is processed by the TDA.&amp;#xa;    *   **Secret Detection (New):** Implements a strict &amp;quot;no secrets in prompts&amp;quot; policy. Using high-entropy string detection and regex patterns for common secret formats, it immediately rejects any request containing credentials, API keys, or tokens, and triggers a high-priority security alert.&amp;#xa;    *   **Ethical &amp;amp; Business Alignment:** This engine codifies business strategy and ethical guidelines. For example, it would reject a hypothesis aimed at creating user friction to boost ad impressions (&amp;quot;dark patterns&amp;quot;) or block a change that proposes using a non-approved, third-party data processing service.&amp;#xa;&amp;#xa;##### **3.2. QA Validation Subsystem (Enhanced)**&amp;#xa;&amp;#xa;*   **Function:** An automated, independent system that acts as an unbiased quality and security gatekeeper. It scrutinizes all generated artifacts—code, tests, container images, and infrastructure definitions—without trusting the source.&amp;#xa;*   **Key Enhancements &amp;amp; Feedback Integration:**&amp;#xa;    *   **Supply Chain Integrity (New):** This module ensures the entire software supply chain is secure. It generates a Software Bill of Materials (SBOM) for every artifact and scans all dependencies, Infrastructure as Code (IaC) templates (e.g., Terraform, CloudFormation), and the agents&amp;#39; own container base images for known vulnerabilities (CVEs) using tools like Trivy or Clair. This prevents vulnerabilities from being inherited from upstream components.&amp;#xa;    *   **Code &amp;amp; Test Quality:** Goes beyond basic SAST to enforce stringent quality metrics. It measures and enforces code coverage thresholds (e.g., &amp;gt;80%), checks for cyclomatic complexity, and scans for potential logic flaws and anti-patterns.&amp;#xa;    *   **Runtime Security Assurance:** Deploys the application to an isolated, instrumented staging environment to run Dynamic Application Security Testing (DAST) and Interactive Application Security Testing (IAST) scans. These tools actively probe the running application for execution-time vulnerabilities that static analysis cannot find, such as SQL injection, Cross-Site Scripting (XSS), and broken access control flaws.&amp;#xa;    *   **Performance &amp;amp; Regression:** Executes comprehensive regression test suites to ensure existing functionality remains intact. It also runs load tests to measure latency, throughput, and resource consumption, comparing them against established baselines to prevent performance degradation.&amp;#xa;&amp;#xa;##### **3.3. Human Review &amp;amp; Approval Gateway**&amp;#xa;&amp;#xa;*   **Function:** A mandatory checkpoint that provides the ultimate human oversight for significant changes. It presents a consolidated, human-readable report summarizing the proposed change, its rationale, and all validation results.&amp;#xa;*   **Audit Address:** This component ensures explainability and establishes clear accountability. The interface resembles a sophisticated pull request, displaying a code diff, a plain-language summary of the agent&amp;#39;s intent, a checklist of all passed security and quality gates (e.g., &amp;quot;SAST: 0 Criticals,&amp;quot; &amp;quot;DAST: Passed,&amp;quot; &amp;quot;Supply Chain Scan: Clean&amp;quot;), and explicit &amp;quot;Approve&amp;quot; and &amp;quot;Reject&amp;quot; actions. Rejection requires a comment, which is fed back into the system as a learning signal.&amp;#xa;&amp;#xa;#### **4. Agent &amp;amp; Infrastructure Security (New Section)**&amp;#xa;&amp;#xa;This section explicitly details the zero-trust measures taken to secure the autonomous agents themselves, mitigating the risk of the system being turned against itself.&amp;#xa;&amp;#xa;##### **4.1. Hardened Agent Runtimes**&amp;#xa;&amp;#xa;*   **Isolation:** Each agent executes within a dedicated, ephemeral, and strongly sandboxed environment. Instead of standard containers, we use solutions like **gVisor** or **Firecracker** to provide kernel-level isolation, drastically reducing the impact of a container escape. These sandboxes are instantiated on-demand on serverless platforms (e.g., AWS Fargate, Google Cloud Run) to eliminate the need for managing underlying infrastructure.&amp;#xa;*   **Least Privilege:** The runtime is granted the absolute minimum IAM permissions required for its specific, time-bound task. For example, an agent tasked with refactoring a service gets a role that only allows it to read from a specific code repository path and write only to its designated feature branch. Network policies (e.g., Kubernetes NetworkPolicies, AWS Security Groups) block all ingress and egress traffic except to explicitly allow-listed endpoints like the code repository, package manager, and secret vault.&amp;#xa;*   **Immutability:** Agents run on immutable, signed images. The runtime environment is never modified. For each new task, a fresh, verified container is instantiated from the base image and destroyed upon completion. This eliminates configuration drift and ensures a reproducible and auditable execution environment.&amp;#xa;&amp;#xa;##### **4.2. Secure Secret Management**&amp;#xa;&amp;#xa;*   **Dynamic Credential Injection:** Agents possess no long-lived credentials. They leverage their runtime identity (e.g., AWS IAM Role for Tasks, Kubernetes Service Account) to authenticate to a centralized secret manager (e.g., HashiCorp Vault, AWS Secrets Manager). They request a specific secret just-in-time, which is injected into the environment and held only in memory for the duration of the task. This makes credential rotation seamless and automated, and eliminates the risk of static secrets being leaked from code or configuration.&amp;#xa;*   **Zero Hardcoded Secrets:** The system enforces, via pre-commit hooks and CI checks, that no secrets (API keys, database passwords, tokens) are ever present in agent prompts, source code, configuration files, or logs.&amp;#xa;&amp;#xa;##### **4.3. Supply Chain Security (SLSA Compliance)**&amp;#xa;&amp;#xa;*   **Verified Provenance:** The build and deployment process for the agents themselves adheres to **SLSA (Supply-chain Levels for Software Artifacts)** principles to guarantee their integrity. This involves:&amp;#xa;    *   Using officially signed and verified base images.&amp;#xa;    *   Pinning all dependencies to specific, audited versions.&amp;#xa;    *   Generating a cryptographically signed attestation (provenance) that details exactly how the agent was built, including the source code commit and build system used.&amp;#xa;    *   Creating and storing an SBOM for every agent version. This mitigates the risk of a compromised build tool or library injecting malicious code into the agent itself.&amp;#xa;&amp;#xa;#### **5. The Enhanced TSOP Workflow**&amp;#xa;&amp;#xa;1.  **Observe &amp;amp; Propose:** The loop begins when the `Observability` platform detects a pattern in user telemetry, such as high hesitation time on a checkout page. The `Feedback Agent` translates this observation into a structured `User Story Metaprompt`, hypothesizing that &amp;quot;Simplifying the address form could reduce user friction.&amp;quot;&amp;#xa;&amp;#xa;2.  **Govern &amp;amp; Sanitize:** The metaprompt is sent to the `Policy &amp;amp; Governance Engine`. The engine verifies that the proposal aligns with business strategy (e.g., doesn&amp;#39;t remove required shipping fields) and sanitizes it to strip any user-related PII and defend against prompt injection.&amp;#xa;&amp;#xa;3.  **Develop in Isolation:** The approved prompt triggers the instantiation of the `TDA Framework` within a hardened gVisor sandbox. The agent uses its temporary runtime identity to fetch a short-lived GitHub token from HashiCorp Vault. It then generates new code for the address form logic and a corresponding suite of unit and integration tests.&amp;#xa;&amp;#xa;4.  **Validate Comprehensively:** The generated code and test artifacts are passed to the `QA Validation Subsystem`. It runs the full suite of scans: SAST checks for security flaws, dependency analysis generates an SBOM and scans for CVEs, and the code is deployed to a staging environment where DAST tools probe the running application for vulnerabilities like XSS.&amp;#xa;&amp;#xa;5.  **Approve:** With all checks passed, the `Human Review Gateway` displays a report to the Product Manager. The report includes the code diff, the agent&amp;#39;s rationale (&amp;quot;Simplified form to reduce friction&amp;quot;), and a green-lit checklist of all security, performance, and quality validations. The PM reviews the change and provides final approval.&amp;#xa;&amp;#xa;6.  **Deploy:** Upon approval, the `Staged Deployment Pipeline` initiates a canary release, deploying the new backend API to 5% of production traffic while monitoring error rates and latency. After a successful canary period, the change is rolled out to 100%.&amp;#xa;&amp;#xa;7.  **Adapt:** The successful backend deployment triggers the `CAI Engine`, also running in a secure, isolated environment. It generates the new, simplified UI components to match the `API_v2` backend. These new frontend artifacts are subjected to the same rigorous validation, QA, and staged deployment process.&amp;#xa;&amp;#xa;8.  **Monitor:** The `Observability` platform tracks the performance of the newly deployed feature, measuring its impact on user hesitation time and checkout completion rates. This new data feeds back into the system, and the trustworthy, self-optimizing loop begins again.&quot; id=&quot;4&quot;&gt;&#10;          &lt;mxCell style=&quot;shape=document;whiteSpace=wrap;html=1;boundedLbl=1;fillColor=#dae8fc;strokeColor=#6c8ebf;rounded=0;&quot; vertex=&quot;1&quot; parent=&quot;1&quot;&gt;&#10;            &lt;mxGeometry y=&quot;970&quot; width=&quot;120&quot; height=&quot;80&quot; as=&quot;geometry&quot; /&gt;&#10;          &lt;/mxCell&gt;&#10;        &lt;/UserObject&gt;&#10;        &lt;mxCell id=&quot;5&quot; value=&quot;&quot; style=&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;exitX=1;exitY=0.25;exitDx=0;exitDy=0;&quot; edge=&quot;1&quot; source=&quot;19&quot; target=&quot;9&quot; parent=&quot;1&quot;&gt;&#10;          &lt;mxGeometry relative=&quot;1&quot; as=&quot;geometry&quot;&gt;&#10;            &lt;mxPoint x=&quot;-300&quot; y=&quot;150&quot; as=&quot;sourcePoint&quot; /&gt;&#10;          &lt;/mxGeometry&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;mxCell id=&quot;6&quot; value=&quot;Push&quot; style=&quot;edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];rounded=0;&quot; vertex=&quot;1&quot; connectable=&quot;0&quot; parent=&quot;5&quot;&gt;&#10;          &lt;mxGeometry x=&quot;-0.0727&quot; relative=&quot;1&quot; as=&quot;geometry&quot;&gt;&#10;            &lt;mxPoint as=&quot;offset&quot; /&gt;&#10;          &lt;/mxGeometry&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;mxCell id=&quot;7&quot; style=&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;entryX=0.5;entryY=0;entryDx=0;entryDy=0;&quot; edge=&quot;1&quot; source=&quot;9&quot; target=&quot;15&quot; parent=&quot;1&quot;&gt;&#10;          &lt;mxGeometry relative=&quot;1&quot; as=&quot;geometry&quot; /&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;mxCell id=&quot;8&quot; value=&quot;output&quot; style=&quot;edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];rounded=0;&quot; vertex=&quot;1&quot; connectable=&quot;0&quot; parent=&quot;7&quot;&gt;&#10;          &lt;mxGeometry x=&quot;-0.365&quot; y=&quot;-4&quot; relative=&quot;1&quot; as=&quot;geometry&quot;&gt;&#10;            &lt;mxPoint as=&quot;offset&quot; /&gt;&#10;          &lt;/mxGeometry&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;mxCell id=&quot;9&quot; value=&quot;Shunt-Button&amp;lt;br&amp;gt;(Amplify)&quot; style=&quot;whiteSpace=wrap;html=1;fillColor=#006ABC;strokeColor=#6c8ebf;rounded=0;&quot; vertex=&quot;1&quot; parent=&quot;1&quot;&gt;&#10;          &lt;mxGeometry y=&quot;120&quot; width=&quot;120&quot; height=&quot;60&quot; as=&quot;geometry&quot; /&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;mxCell id=&quot;10&quot; style=&quot;edgeStyle=orthogonalEdgeStyle;curved=1;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;entryX=0.5;entryY=0;entryDx=0;entryDy=0;&quot; edge=&quot;1&quot; source=&quot;12&quot; target=&quot;26&quot; parent=&quot;1&quot;&gt;&#10;          &lt;mxGeometry relative=&quot;1&quot; as=&quot;geometry&quot; /&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;mxCell id=&quot;11&quot; value=&quot;output&quot; style=&quot;edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];&quot; vertex=&quot;1&quot; connectable=&quot;0&quot; parent=&quot;10&quot;&gt;&#10;          &lt;mxGeometry x=&quot;-0.2049&quot; y=&quot;-1&quot; relative=&quot;1&quot; as=&quot;geometry&quot;&gt;&#10;            &lt;mxPoint as=&quot;offset&quot; /&gt;&#10;          &lt;/mxGeometry&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;mxCell id=&quot;12&quot; value=&quot;Tool for AI&quot; style=&quot;whiteSpace=wrap;html=1;rounded=0;fillColor=#E20ABE;strokeColor=#FF28D7;&quot; vertex=&quot;1&quot; parent=&quot;1&quot;&gt;&#10;          &lt;mxGeometry x=&quot;350&quot; y=&quot;120&quot; width=&quot;120&quot; height=&quot;60&quot; as=&quot;geometry&quot; /&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;mxCell id=&quot;13&quot; value=&quot;&quot; style=&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;&quot; edge=&quot;1&quot; source=&quot;15&quot; target=&quot;25&quot; parent=&quot;1&quot;&gt;&#10;          &lt;mxGeometry relative=&quot;1&quot; as=&quot;geometry&quot; /&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;mxCell id=&quot;14&quot; value=&quot;push&quot; style=&quot;edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];rounded=0;&quot; vertex=&quot;1&quot; connectable=&quot;0&quot; parent=&quot;13&quot;&gt;&#10;          &lt;mxGeometry x=&quot;-0.3416&quot; y=&quot;-2&quot; relative=&quot;1&quot; as=&quot;geometry&quot;&gt;&#10;            &lt;mxPoint as=&quot;offset&quot; /&gt;&#10;          &lt;/mxGeometry&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;object label=&quot;DeepResearch&quot; tooltip=&quot;### **From Static Prompts to Dynamic Architectures: Synthesizing Self-Optimizing Systems for Code and Interface Generation**&amp;#xa;&amp;#xa;#### **Deconstruction of Elite-Tier Prompt Patterns: The Current Benchmark**&amp;#xa;&amp;#xa;The effective utilization of Large Language Models (LLMs) has evolved dramatically, moving beyond simple, single-turn instructions to embrace complex, multi-stage prompt architectures. This evolutionary leap is most pronounced and impactful in the technical domains of software engineering and user interface (UI) design. A rigorous analysis of current elite-tier patterns reveals an unmistakable trajectory: a fundamental shift away from static, manually-authored instructions and toward dynamic, machine-optimized, and process-oriented systems that guide the LLM&amp;#39;s reasoning and execution.&amp;#xa;&amp;#xa;This section deconstructs the state-of-the-art (SOTA) patterns in these two domains. The goal is to establish the foundational benchmarks of what is currently possible and, more critically, to identify the capability vectors that remain unexploited—the latent potential that will define the next generation of autonomous systems.&amp;#xa;&amp;#xa;---&amp;#xa;&amp;#xa;#### **Domain 1: Architectures for Efficient Code Construction**&amp;#xa;&amp;#xa;In software engineering, the objective has transcended merely generating code snippets. The new frontier is engineering reliable, context-aware, and increasingly autonomous systems capable of complex problem-solving. The most successful patterns do not treat the LLM as a simple code generator; they treat it as a powerful reasoning engine to be embedded within a larger, more structured, and verifiable development framework.&amp;#xa;&amp;#xa;**1. Automated Prompt Optimization: The &amp;quot;Prompt-as-a-Target&amp;quot; Pattern**&amp;#xa;&amp;#xa;The manual, iterative refinement of prompts for code generation is widely recognized as a significant bottleneck—a process that is both time-consuming and inconsistent, highly dependent on the skill of the individual engineer. The state-of-the-art has consequently moved to automate this process, treating the prompt itself as a machine-optimizable artifact.&amp;#xa;&amp;#xa;*   **Evolutionary-Based Methods (EPiC):** The EPiC (Evolutionary Prompt Engineering for Code) framework exemplifies a novel approach, exploring code generation from a cost-effectiveness perspective. It &amp;quot;leverages a lightweight evolutionary algorithm to evolve the original prompts toward better ones that produce high-quality code&amp;quot;. This works by applying mutation operators—such as swapping synonyms (e.g., &amp;#39;generate&amp;#39; vs. &amp;#39;create&amp;#39;), reordering clauses, or adding clarifying constraints—to the text of the prompt. A fitness function, which could be as simple as the number of unit tests passed or a combination of correctness and token cost, guides this evolutionary search, automating the discovery of an optimal instructional solution in a highly efficient manner.&amp;#xa;&amp;#xa;*   **Iterative Refinement (Prochemy):** The &amp;quot;Prompt Alchemy&amp;quot; (Prochemy) method provides an &amp;quot;innovative method for automatically refining prompts to boost code generation&amp;quot;. This system operates by creating a feedback loop based on the model&amp;#39;s actual performance. It generates code, evaluates the output against a known solution (e.g., a test case), analyzes the errors, and then refines the original prompt to correct for those errors in the next iteration. This automated optimization ensures consistency by directly tuning the instructions to the model&amp;#39;s internal biases and has demonstrated substantial performance gains, such as a **5.0% improvement for GPT-3.5-Turbo on HumanEval** and a **12.9% improvement for GPT-4o on Java-to-Python code translation tasks**.&amp;#xa;&amp;#xa;*   **Adaptive Selection (PET-Select):** Recognizing that &amp;quot;no single approach is universally optimal&amp;quot;, the PET-Select framework introduces a critical meta-layer of intelligence. This &amp;quot;PET-agnostic selection model&amp;quot; first classifies the complexity of an incoming query, often using code complexity metrics like cyclomatic complexity or Abstract Syntax Tree (AST) depth as a proxy. Based on this classification, it then routes the query to the most appropriate prompt engineering technique (PET). A simple query might use a basic zero-shot prompt for maximum efficiency, while a highly complex query would be delegated to a more elaborate multi-stage reasoning prompt. This automated, adaptive selection process has been shown to improve **pass@1 accuracy by up to 1.9%** while simultaneously achieving a **74.8% reduction in token usage** by avoiding unnecessary computational overhead.&amp;#xa;&amp;#xa;The clear progression in this domain is from a human-centric &amp;quot;prompt engineering&amp;quot; phase to a machine-centric &amp;quot;prompt optimization&amp;quot; phase. The AI is no longer just the executor of the instruction; it is becoming the refiner of the instruction itself. These systems (EPiC, Prochemy) are, however, fundamentally reactive. They act as powerful local optimizers for a known task and a pre-defined solution space (e.g., passing a specific benchmark). They do not yet proactively generate a novel prompt architecture for a novel, undiscovered problem. This points toward a critical unexploited vector: a system that can discover a new problem (e.g., from user feedback telemetry) and then author its own prompt architecture to solve it, a concept directly related to meta-prompting.&amp;#xa;&amp;#xa;**2. Test-Driven Development (TDD) as a Prompting Paradigm**&amp;#xa;&amp;#xa;Arguably the most powerful and reliable pattern for generating high-quality code is the direct integration of Test-Driven Development (TDD) principles into the prompt architecture. TDD is an &amp;quot;incremental software development methodology that focuses on creating tests before the implementation&amp;quot;. When applied to LLMs, the test suite is no longer just a validation step; it becomes the primary specification, eliminating ambiguity.&amp;#xa;&amp;#xa;*   **Core Principle:** Instead of relying on ambiguous and often incomplete natural language, the prompt provides the LLM with a concrete set of unit tests and instructs it to &amp;quot;write code to pass all tests&amp;quot;. This pattern&amp;#39;s success hinges on &amp;quot;instruction following and in-context learning,&amp;quot; which have been identified as more &amp;quot;critical capabilities for TDD success&amp;quot; than general coding proficiency. The tests are the ultimate, unambiguous instruction, shifting the interaction from a request for *intent* to a specification of required *behavior*.&amp;#xa;&amp;#xa;*   **Frameworks:** Systems are being designed to formalize this interaction. The TGEN framework, for example, utilizes &amp;quot;Specialized agents&amp;quot; that accept two primary inputs: the &amp;quot;programming prompt&amp;quot; (a concise natural language description) and &amp;quot;the tests&amp;quot; (a full suite of unit tests, including required function signatures). These inputs are then processed by the LLM engine to produce validated, production-ready code.&amp;#xa;&amp;#xa;*   **Prompt Structure:** This paradigm fundamentally changes the prompt&amp;#39;s structure. The request is no longer a simple &amp;quot;what,&amp;quot; but a highly constrained &amp;quot;how.&amp;quot; A common elite-level TDD prompt includes a strict set of rules that govern both the output and the process: *&amp;quot;1. Write a single Python function that passes all the provided tests. 2. Use type hints for all parameters and return values. 3. Follow Python best practices and PEP 8 standards... 4. Ensure the function handles all edge cases and scenarios explicitly covered in the tests. 5. Provide only the function definition and its implementation in a single code block, with no additional explanation.&amp;quot;* This level of constraint is vital, as it makes the LLM&amp;#39;s output machine-parseable and directly usable.&amp;#xa;&amp;#xa;This TDD-as-prompt pattern provides an objective, verifiable measure of &amp;quot;correctness&amp;quot; that is far superior to ambiguous natural language. It successfully shifts the burden of human effort from describing the code to defining its behavior through tests—a crucial move from semantic validation (is the code &amp;quot;good&amp;quot;?) to functional validation (does the code *work*?). The next logical step, and the key unexploited vector, is to close the loop: to create a system that not only generates code from tests but also autonomously generates its own tests from a high-level specification and validates its own code in a continuous, self-sustaining cycle.&amp;#xa;&amp;#xa;**3. Self-Validation and &amp;quot;Error-Forward&amp;quot; Debugging**&amp;#xa;&amp;#xa;This pattern extends the TDD loop into a dynamic, autonomous process. For an agent to be truly autonomous, it must be able to recognize, diagnose, and recover from its own errors without human intervention.&amp;#xa;&amp;#xa;*   **Self-Validation:** SOTA agentic systems are designed to &amp;quot;regularly verify progress and self-assess correctness&amp;quot;. This &amp;quot;agentic self-validation&amp;quot; is a core capability that &amp;quot;drives up accuracy&amp;quot;. For instance, agents from Cognition, such as Devin, are noted to &amp;quot;excel at testing its own code.&amp;quot; This involves more than just running a script; the agent sets up the test environment, installs dependencies, executes the test suite, and correctly interprets the results from `stdout` and `stderr`. This allows the agent to &amp;quot;go through several improvement cycles on its own instead of having to manually ask the AI to fix test failures&amp;quot;.&amp;#xa;&amp;#xa;*   **&amp;quot;Error-Forward Prompting&amp;quot;:** This is the primary recovery mechanism within the self-validation loop, treating errors as high-value data, not as failures. When an agent&amp;#39;s self-validation attempt fails, the system automatically &amp;quot;collects relevant context, including the error message, stack trace, and cell location&amp;quot;. This structured information is then formatted and &amp;quot;provided to the agent as the initial context for beginning the debugging process&amp;quot;. This contrasts sharply with a naive human-in-the-loop approach, where a developer might simply say &amp;quot;that didn&amp;#39;t work, try again.&amp;quot;&amp;#xa;&amp;#xa;*   **Reflection:** This is the learning mechanism that makes the recovery effective and intelligent. A &amp;quot;reflection system enables the agent to learn from its actions and improve its debugging strategy&amp;quot;. Implemented via &amp;quot;reflective prompting&amp;quot;, this allows the model to &amp;quot;analyze and refine its outputs&amp;quot;. The model first generates a solution, then, &amp;quot;through subsequent prompts, critiques its own reasoning to identify and correct errors&amp;quot;. This is formalized in techniques like Self-Refine, which mimics the expert human &amp;quot;draft, review, refine&amp;quot; process. The agent asks itself not just &amp;quot;how do I fix this `NullPointerException`?&amp;quot; but &amp;quot;why did this null value occur, and how can I refactor my code to prevent this class of error in the future?&amp;quot;&amp;#xa;&amp;#xa;In this paradigm, failure is no longer an end-state; it is a high-value data signal. The stack trace becomes the most valuable part of the prompt—a pure, unambiguous instruction set for what must be fixed. When TDD-as-prompt is combined with this self-validation and reflection loop, the system becomes &amp;quot;self-healing.&amp;quot; The prompt is no longer a single-shot instruction but the initiation of a self-sustaining process. The agent&amp;#39;s goal is elevated from &amp;quot;generate code&amp;quot; to &amp;quot;make the build pass,&amp;quot; a critical step toward true autonomy.&amp;#xa;&amp;#xa;**4. Agentic Frameworks and Multi-Agent Collaboration**&amp;#xa;&amp;#xa;Complex software development cannot be solved in a single step or by a single-minded agent. The recognition that single-shot prompts &amp;quot;yield imprecise or plain incorrect results&amp;quot; for elaborate tasks has led to the rise of sophisticated agentic frameworks that orchestrate multiple agents and advanced reasoning patterns.&amp;#xa;&amp;#xa;*   **Advanced Reasoning Patterns:** These frameworks are built upon reasoning patterns far more advanced than simple Chain-of-Thought (CoT).&amp;#xa;    *   **ReAct:** This pattern combines &amp;quot;Reason and Act&amp;quot;, allowing an agent to interleave step-by-step reasoning with tool use to gather external information or perform actions in an environment.&amp;#xa;    *   **Tree of Thoughts (ToT):** This pattern moves beyond the linear path of CoT. It allows an agent to &amp;quot;breakdown intermediate processed into steps,&amp;quot; generate &amp;quot;various generated states&amp;quot; for each step, and &amp;quot;evaluate&amp;quot; those states to &amp;quot;determine which branch to explore next,&amp;quot; effectively performing a beam search over the solution space.&amp;#xa;    *   **Graph of Thoughts (GoT):** The current SOTA in reasoning, GoT generalizes ToT into a full graph structure. This &amp;quot;enables combining arbitrary LLM thoughts into synergistic outcomes&amp;quot; and, critically, &amp;quot;enhancing thoughts using feedback loops&amp;quot;. For example, a thought node that generates a plan can be evaluated by another node, and the resulting critique (&amp;quot;This plan is too complex and misses a key dependency&amp;quot;) can be looped back to the original node, prompting it to generate a revised, superior plan. GoT has been shown to **increase the quality of sorting by 62% over ToT** while reducing costs.&amp;#xa;&amp;#xa;*   **Agentic Frameworks:** These advanced reasoning patterns are orchestrated by multi-agent frameworks that decompose complexity through role-playing.&amp;#xa;    *   **MetaGPT:** This framework simulates a &amp;quot;real-world software company.&amp;quot; It assigns agents specific roles like &amp;quot;product manager, software architect, programmer, or QA tester&amp;quot; and embeds them with &amp;quot;Standard Operating Procedures (SOPs)&amp;quot; that govern their behavior and interactions.&amp;#xa;    *   **ChatDev:** This framework utilizes a &amp;quot;waterfall-style&amp;quot; collaboration, where agents engage in &amp;quot;task-oriented and multi-turn communications&amp;quot; to iteratively design, implement, test, and document a software solution.&amp;#xa;&amp;#xa;*   **Purpose:** These frameworks are essential as they provide a &amp;quot;shared philosophy of control &amp;amp; reasoning&amp;quot;. Without this structure, agentic systems suffer from a &amp;quot;loss of control clarity of flow&amp;quot; and &amp;quot;unbounded complexity growth&amp;quot; as new agents are added. The roles and SOPs provide necessary constraints that guide the LLM&amp;#39;s vast capabilities toward a productive outcome.&amp;#xa;&amp;#xa;*   **Benchmarks:** These sophisticated agentic systems are what achieve top scores on complex, real-world benchmarks that measure true engineering capability. The **SWE-bench** benchmark, for instance, measures &amp;quot;an AI model&amp;#39;s ability to solve real-world software issues&amp;quot; from popular GitHub repositories. SOTA models achieve high scores on SWE-bench and **OSWorld** precisely by using these multi-agent, self-testing, and reflective architectures.&amp;#xa;&amp;#xa;The atomic unit of these powerful frameworks is role-based prompting. The frameworks themselves are, in essence, prompt-driven state machines. A high-level &amp;quot;meta-prompt&amp;quot; defines the agents, their roles, their tools, and their communication protocols. The LLM is thus demoted from &amp;quot;solution generator&amp;quot; to a core component—a &amp;quot;reasoning engine&amp;quot; that navigates this pre-defined architecture. The architecture itself has become the prompt. The current limitation, and the unexplored vector, is that these frameworks are simulations of human workflow (e.g., &amp;quot;waterfall,&amp;quot; &amp;quot;software company&amp;quot;). A truly AI-native workflow, where feedback comes not from a simulated &amp;quot;QA Agent&amp;quot; but from the product itself via live user telemetry, would be fundamentally more efficient and powerful.&amp;#xa;&amp;#xa;**5. Context-Aware Generation (Agentic RAG)**&amp;#xa;&amp;#xa;Code generation is useless without domain-specific context. Retrieval-Augmented Generation (RAG) is the primary pattern for providing this context, and its agentic form is the SOTA for any non-trivial coding task.&amp;#xa;&amp;#xa;*   **RAG-for-Code:** This pattern gives an AI assistant &amp;quot;a direct line to your team&amp;#39;s collective knowledge&amp;quot;. Before generating a response, the prompt is &amp;quot;augmented&amp;quot; with relevant information retrieved from &amp;quot;documentation, code repositories, or even Stack Overflow discussions&amp;quot;. This ensures the generated response is &amp;quot;context-aware&amp;quot; and adheres to the specific conventions, APIs, and architectural patterns of the codebase it is intended for.&amp;#xa;&amp;#xa;*   **Agentic RAG:** This is the &amp;quot;evolution from traditional single-query RAG&amp;quot;. Instead of being a passive recipient of retrieved context, the agent actively forages for it. It performs &amp;quot;context-aware query planning,&amp;quot; breaking a complex question into multiple sub-queries. It can issue &amp;quot;parallel execution of multiple focused subqueries&amp;quot; (e.g., simultaneously looking for database schemas, relevant API routes, and existing utility functions) and then synthesizes the results to build a comprehensive understanding before it begins to code. This is the advanced approach used by modern agentic frameworks like LangGraph, AutoGen, and those from major cloud providers.&amp;#xa;&amp;#xa;The RAG-for-Code pattern transforms a &amp;quot;general-purpose coder&amp;quot; into a &amp;quot;domain-specific engineer.&amp;quot; The agentic aspect is the critical differentiator; it is the difference between giving a developer a 500-page manual (standard RAG) and the developer knowing which three pages to read to solve the specific problem at hand (Agentic RAG). The most potent, but not yet fully exploited, vector in code generation is the deep fusion of this Agentic RAG (for context) with the TDD-as-Prompt paradigm (for verification). Agentic RAG provides the *what* and *why* (domain knowledge, business logic), while TDD provides the *proof* (functional correctness). An agent that can retrieve context from a 500,000-line codebase and validate its proposed changes against that codebase&amp;#39;s entire test suite is the difference between a &amp;quot;coding assistant&amp;quot; and an &amp;quot;autonomous developer.&amp;quot; This fusion is the core of the novel Test-Driven Agent (TDA) architecture proposed later in this document.&amp;#xa;&amp;#xa;---&amp;#xa;&amp;#xa;#### **Domain 2: Architectures for User Delight &amp;amp; UI Design**&amp;#xa;&amp;#xa;In the second domain, UI generation, the mandate for &amp;quot;user delight&amp;quot; requires moving far beyond simple wireframe generation. Elite-tier prompts in this space are not about &amp;quot;generating pixels&amp;quot; but about &amp;quot;generating experiences&amp;quot; grounded in human-centric design principles and cognitive science.&amp;#xa;&amp;#xa;**1. Persona-Driven Design: Grounding the Generation**&amp;#xa;&amp;#xa;&amp;quot;User delight&amp;quot; is the &amp;quot;positive emotional response users feel when a product doesn&amp;#39;t just meet their needs but goes above and beyond&amp;quot;. This state is &amp;quot;highly contextual&amp;quot; and cannot be achieved without first defining and deeply understanding the user.&amp;#xa;&amp;#xa;*   **Pattern:** Elite prompts for UI design do not begin with the interface; they begin with the user. The system is first prompted to generate a detailed proto-persona. This persona includes not only demographic details but also the &amp;quot;target users, their core pain points, and daily use context&amp;quot;, as well as deeper psychological drivers like &amp;quot;Motivations&amp;quot; and &amp;quot;Affinities&amp;quot;.&amp;#xa;&amp;#xa;*   **Application:** This generated persona (or a human-provided one) is then injected as a primary constraint into all subsequent UI generation prompts. This allows the AI to &amp;quot;cater to Gen Z and Gen X users&amp;quot; differently. For example, the same prompt for a music app might yield a gamified, emoji-rich, and socially-integrated interface for a Gen Z persona, while producing a clean, information-dense, and highly functional layout for a Gen X professional. The prompt is no longer &amp;quot;generate a wireframe for a music app&amp;quot; but &amp;quot;generate a wireframe for a music app for *this specific persona*, focusing on their stated pain point of {pain_point}.&amp;quot;&amp;#xa;&amp;#xa;This persona-driven pattern acts as a powerful constraint on the model&amp;#39;s vast solution space, forcing it to move from generating a generic &amp;quot;good UI&amp;quot; to a UI that is &amp;quot;good for *this specific user*.&amp;quot; It is, in effect, a form of in-context learning for design, where the persona serves as a &amp;quot;one-shot&amp;quot; example of the target user. The major limitation, and the unexploited vector, is that this is a static, upfront process. The persona is an assumption created at the beginning of the design process. The clear next step is to move from these static, assumed personas to dynamic, observed user models that are continuously updated based on real-time behavioral analytics.&amp;#xa;&amp;#xa;**2. Constraint-Based Generation: Defining the &amp;quot;Solution Space&amp;quot;**&amp;#xa;&amp;#xa;The highest-fidelity UI generation requires the application of multiple, layered constraints. These constraints are the specifications that ensure the output is not just creative, but also functional, accessible, and grounded in established design theory.&amp;#xa;&amp;#xa;**A. Cognitive &amp;amp; Heuristic Constraints**&amp;#xa;&amp;#xa;This is the most sophisticated pattern for achieving true &amp;quot;user delight.&amp;quot; The prompt explicitly instructs the AI to apply principles from cognitive science and established usability heuristics, forcing the AI to design for the human mind, not just the screen.&amp;#xa;&amp;#xa;*   **Heuristics:** The most common pattern is to prompt the AI to act as a UX expert and evaluate or generate a design based on &amp;quot;Nielsen&amp;#39;s 10 Usability Heuristics&amp;quot; or other well-known variants like Shneiderman&amp;#39;s &amp;quot;Eight Golden Rules&amp;quot; or Weinschenk and Barker&amp;#39;s &amp;quot;20 Usability Heuristics&amp;quot;.&amp;#xa;&amp;#xa;*   **Cognitive Principles:** More advanced prompts instruct the AI to directly apply specific cognitive laws. Examples include:&amp;#xa;    *   **Fitts&amp;#39;s Law:** Prompting the AI to make &amp;quot;important buttons and interactive elements larger and closer to where users naturally focus&amp;quot;.&amp;#xa;    *   **Hick&amp;#39;s Law:** Instructing the AI to &amp;quot;reduc[e] the number of options or organiz[e] them into categories&amp;quot; to speed up decision-making.&amp;#xa;    *   **Miller&amp;#39;s Law:** Guiding the AI to present information in chunks of 5-9 items to respect the limits of working memory.&amp;#xa;    *   **Cognitive Load:** Prompting with the explicit goal of &amp;quot;reducing cognitive load&amp;quot; to create a more effortless and intuitive user experience.&amp;#xa;&amp;#xa;*   **Behavioral Models:** The most advanced prompts use frameworks like **BJ Fogg&amp;#39;s Behavior Model (B=MAP: Motivation, Ability, Prompt)** or **Nir Eyal&amp;#39;s &amp;quot;Hooked&amp;quot; model** to design persuasive or habit-forming interfaces that align with user psychology.&amp;#xa;&amp;#xa;Prompting with &amp;quot;Nielsen&amp;#39;s Heuristics&amp;quot; or &amp;quot;Fogg&amp;#39;s Behavior Model&amp;quot; acts as a domain-specific Chain-of-Thought. It forces the AI to externalize and justify its design choices (&amp;quot;This button is large and placed in the bottom-right corner because it adheres to Fitts&amp;#39;s Law for mobile users&amp;quot;), leading to more principled, defensible, and ultimately delightful designs.&amp;#xa;&amp;#xa;**B. Technical &amp;amp; Accessibility (A11y) Constraints**&amp;#xa;&amp;#xa;There is no &amp;quot;delight&amp;quot; in an interface that is unusable for a portion of the population. Elite prompts must enforce technical constraints, with accessibility (A11y) being a paramount, non-negotiable requirement for both ethical and business reasons.&amp;#xa;&amp;#xa;*   **Pattern:** The prompt must explicitly instruct the AI to be &amp;quot;fully compliant with WCAG 2.2 AA&amp;quot;. Research shows that without this explicit instruction, AI-generated components are &amp;quot;consistently&amp;quot; and predictably inaccessible.&amp;#xa;&amp;#xa;*   **Specifics:** A high-quality A11y prompt enforces:&amp;#xa;    *   **Semantic HTML:** &amp;quot;Ensure the proper use of HTML5 elements (like `&amp;lt;nav&amp;gt;`, `&amp;lt;main&amp;gt;`, `&amp;lt;aside&amp;gt;`) to provide structural meaning.&amp;quot;&amp;#xa;    *   **Keyboard Accessibility:** &amp;quot;Ensure all interactive elements are reachable and operable using only the Tab, Shift+Tab, and Enter keys.&amp;quot;&amp;#xa;    *   **ARIA (Accessible Rich Internet Applications):** Mandate the correct application of &amp;quot;ARIA landmarks and roles&amp;quot;, which are &amp;quot;HTML attributes that add semantic meaning... for assistive technologies&amp;quot; like screen readers.&amp;#xa;    *   **Clear Content:** &amp;quot;Use clear, concise language. Write descriptive links: Swap vague text like &amp;#39;click here&amp;#39; for meaningful descriptions like &amp;#39;Read our Q3 financial report&amp;#39;.&amp;quot;&amp;#xa;&amp;#xa;This pattern is the UI-domain equivalent of TDD. The prompt includes the acceptance criteria (WCAG standards). This &amp;quot;specification-as-prompt&amp;quot; is critical for generating production-ready, non-discriminatory interfaces.&amp;#xa;&amp;#xa;**C. Structural &amp;amp; Layout Constraints**&amp;#xa;&amp;#xa;To control the form of the output and ensure it is machine-readable and programmatically useful, prompts must define a reliable data structure.&amp;#xa;&amp;#xa;*   **Architecture &amp;amp; Flows:** For high-level system design, prompts specify formats like the **C4 model** rendered in Mermaid code. For user flows, Mermaid sequence diagrams are the standard, providing a clear, visual, and code-based representation.&amp;#xa;*   **Wireframes:** Simple wireframe prompts use text descriptions, such as, &amp;quot;Generate a mobile dashboard with a top header containing a logo and notification bell, a main content area with three KPI cards, and a bottom navigation bar with four icons.&amp;quot;&amp;#xa;*   **SOTA (Structured Data):** The most robust and programmatically valuable pattern is to force the LLM to output a structured data format like JSON or YAML. This is achieved by providing an output schema to the model. This pattern is now natively supported by major model providers, who allow schemas to be defined using libraries like **Pydantic** (for Python) or **Zod** (for TypeScript). This guarantees the output is not just text, but a typed, validated, and contractually reliable data structure, ensuring &amp;quot;type safety and consistent structure&amp;quot;.&amp;#xa;&amp;#xa;This structured output pattern is the critical link between the two domains of this report. If a UI can be described in a reliable JSON schema, and a backend can expose its API in a reliable JSON schema (e.g., an OpenAPI specification), an agent can programmatically connect them. This structured output is the &amp;quot;API&amp;quot; between a UI-generation agent and a code-generation agent, enabling true end-to-end automation.&amp;#xa;&amp;#xa;**3. Generative UI (GenUI): The Emergent Paradigm**&amp;#xa;&amp;#xa;This is the bleeding-edge concept that underpins the future of UI design. Generative UI (GenUI) is a new paradigm that &amp;quot;enables adaptive, goal-driven interactions&amp;quot;. Instead of a static interface designed by a human and then coded by a developer, the UI is generated, and even adapted, in real-time by an AI.&amp;#xa;&amp;#xa;*   **Mechanism:** In this paradigm, the AI generates &amp;quot;interactive widgets for fine-grained prompt control&amp;quot; or entire &amp;quot;high-fidelity UI mock-up screens from a high-level textual description&amp;quot;. This process is not one-shot; it is an iterative, &amp;quot;co-creative process&amp;quot; between the human and the AI, involving &amp;quot;AI-assisted refinement strategies&amp;quot;.&amp;#xa;&amp;#xa;*   **Current State:** GenUI is currently being adopted by UX practitioners as a powerful tool to accelerate their workflow. The human remains the curator and refiner of the AI-generated output, providing subjective feedback like &amp;quot;make that button bigger&amp;quot; or &amp;quot;this feels too cluttered.&amp;quot;&amp;#xa;&amp;#xa;GenUI is the logical evolution of prompt-based wireframing. The current limitation, and the key unexploited vector, is the human-in-the-loop for optimization. The UI is refined based on a designer&amp;#39;s subjective taste or explicit follow-up prompts—a high-latency, low-bandwidth feedback mechanism. The unexploited opportunity is to remove the human curator from the optimization loop and replace them with a direct, high-bandwidth data stream from the end-user. A system that could refine its own GenUI, not based on a designer&amp;#39;s commands, but based on live user behavioral data, would represent a paradigm shift. This is the core concept of a &amp;quot;Self-Optimizing UI&amp;quot; and forms the foundation for the novel Cognitive-Adaptive Interface (CAI) architecture.&amp;#xa;&amp;#xa;---&amp;#xa;&amp;#xa;### **Synthesis of Novel Prompt Architectures: Exceeding Current Benchmarks**&amp;#xa;&amp;#xa;The preceding analysis deconstructed the current SOTA, revealing a set of unexploited capability vectors. The following synthesis moves beyond merely replicating these patterns. It proposes three novel, high-level architectures that fuse these vectors to create self-regulating, self-optimizing systems designed to exceed current benchmarks. These architectures treat the prompt not as a static, one-time instruction, but as a &amp;quot;bootloader&amp;quot; for a continuous, autonomous process.&amp;#xa;&amp;#xa;**Table 1: Comparative Analysis of Generation &amp;amp; Reasoning Architectures**&amp;#xa;&amp;#xa;| Architecture | Core Mechanism | Interaction Model | Key Limitation (Vector Not Exploited) | Unlocked Capability Vector |&amp;#xa;| :--- | :--- | :--- | :--- | :--- |&amp;#xa;| Chain-of-Thought (CoT) | Step-by-step reasoning (e.g., &amp;quot;Let&amp;#39;s think step-by-step&amp;quot;). | Static | Brittle, linear reasoning; no external validation or tool use. | Basic multi-step problem solving. |&amp;#xa;| ReAct | Interleaves reasoning (CoT) with tool use (Actions). | Iterative | Dependent on pre-defined tools; no long-term memory or structured collaboration. | Environment-aware task execution. |&amp;#xa;| Graph of Thoughts (GoT) | Models reasoning as a graph, allowing merging of states and feedback loops. | Iterative | High conceptual complexity; primarily focused on reasoning, not execution. | Advanced, non-linear problem-solving. |&amp;#xa;| TDD-as-Prompt | A test suite is provided as the functional specification for code generation. | Static | Requires human to write all tests; no self-correction loop. | Verifiable, high-reliability code generation. |&amp;#xa;| Generative UI (GenUI) | AI generates high-fidelity UI mockups or interactive widgets from text. | Iterative | Requires human-in-the-loop for curation; based on assumed user needs. | Rapid, co-creative UI prototyping. |&amp;#xa;| **[NOVEL] Cognitive-Adaptive Interface (CAI) Engine** | **GenUI + Cognitive Fitness Function + Live User Telemetry.** | **Dynamic-Adaptive** | N/A (Synthesized Architecture) | **Real-time UI self-optimization based on observed user cognitive state.** |&amp;#xa;| **[NOVEL] Test-Driven Agent (TDA) Framework** | **Closed-loop TDD + Agentic RAG + Error-Forward Self-Healing.** | **Autonomous-Iterative** | N/A (Synthesized Architecture) | **Verifiable, context-aware, autonomous development with guaranteed build integrity.** |&amp;#xa;| **[NOVEL] Self-Optimizing Product (SOP) Loop** | **TDA-CAI integration via an RLHF-from-Telemetry feedback loop.** | **Autonomous-Holistic** | N/A (Synthesized Architecture) | **Fully autonomous product self-improvement driven by implicit user feedback.** |&amp;#xa;&amp;#xa;---&amp;#xa;&amp;#xa;#### **Proposed Architecture 1: The &amp;quot;Cognitive-Adaptive Interface&amp;quot; (CAI) Engine**&amp;#xa;&amp;#xa;This architecture synthesizes Generative UI (GenUI) with persona-driven design and, most critically, cognitive-heuristic constraints. It is designed to move UI generation from a static, one-shot process (&amp;quot;generate a wireframe&amp;quot;) to a continuous, adaptive, and self-optimizing one.&amp;#xa;&amp;#xa;*   **Vector Exploited:** This architecture directly targets the vector identified in UI design: the fusion of Generative UI with real-time user telemetry, replacing subjective human feedback with objective behavioral data.&amp;#xa;&amp;#xa;*   **Mechanism:** The CAI Engine operates as a continuous four-phase loop:&amp;#xa;    1.  **Phase 1: The &amp;quot;Cognitive Metaprompt&amp;quot;.** The architect does not prompt for a specific layout. Instead, they provide a high-level, structured (e.g., YAML) prompt that defines the goals and constraints. This metaprompt specifies the `target_persona`, the `business_objective` (e.g., &amp;quot;maximize conversion&amp;quot;), and a `cognitive_fitness_function`—a weighted list of cognitive and behavioral principles (e.g., `cognitive_load: -0.5`, `fitts_law_compliance: +0.3`) that will be used to score the UI&amp;#39;s performance.&amp;#xa;    2.  **Phase 2: Initial Generation.** The CAI engine uses this metaprompt to generate the initial UI component tree as a structured JSON artifact. This initial design is its best hypothesis for satisfying the `cognitive_fitness_function` for the given `target_persona`.&amp;#xa;    3.  **Phase 3: The Telemetry Loop.** This is the critical connection to the real world. As users interact with this dynamically-rendered GenUI, the system collects fine-grained, real-time telemetry, analogous to data from tools like Hotjar or FullStory. This includes not just &amp;quot;clickstream data&amp;quot; but also proxies for cognitive state: **hesitation time** (cognitive load), **rage clicks** (frustration), **scroll depth** (engagement), and **form drop-off points**.&amp;#xa;    4.  **Phase 4: Autonomous Optimization.** This rich telemetry stream is fed back into the CAI engine. The engine scores the current UI&amp;#39;s performance against the `cognitive_fitness_function`. It then begins a continuous, &amp;quot;self-optimizing&amp;quot; process, autonomously running micro-A/B tests or employing more sophisticated multi-armed bandit algorithms to adapt the UI. It might log: *&amp;quot;Hypothesis: Moving &amp;#39;Add to Cart&amp;#39; button 10px closer to the product image will improve the Fitts&amp;#39;s Law component of the fitness function. Result: Target acquisition speed improved by 80ms and conversion metric increased by 0.2%. This change is now permanent for this user segment.&amp;quot;*&amp;#xa;&amp;#xa;*   **Exceeding the Benchmark:** This architecture creates a true &amp;quot;Self-Optimizing UI&amp;quot;. The prompt is no longer a blueprint for a static house; it is the DNA for a living organism that adapts to its environment (the user) in real-time. This moves beyond static, assumed personas to build an interface that dynamically aligns with the observed cognitive and behavioral patterns of its actual users.&amp;#xa;&amp;#xa;---&amp;#xa;&amp;#xa;#### **Proposed Architecture 2: The &amp;quot;Test-Driven Agent&amp;quot; (TDA) Framework**&amp;#xa;&amp;#xa;This architecture synthesizes the most robust patterns from the code construction domain: TDD-as-Prompt, Self-Validation with Error-Forward prompting, and Agentic RAG. It creates a closed-loop, &amp;quot;self-healing&amp;quot; system designed to enable verifiable, autonomous development at the repository level.&amp;#xa;&amp;#xa;*   **Vector Exploited:** This architecture directly exploits the vector identified in code generation: the deep fusion of autonomous, closed-loop TDD with context-aware Agentic RAG. The agent&amp;#39;s deliverable is not &amp;quot;code&amp;quot;; it is a &amp;quot;passing build.&amp;quot;&amp;#xa;&amp;#xa;*   **Mechanism:** The TDA Framework operates as a five-phase, autonomous workflow:&amp;#xa;    1.  **Phase 1: The &amp;quot;User Story Metaprompt&amp;quot;.** The human (or another agent) provides a high-level feature request in a structured format (e.g., JSON), defining the goal, not the implementation. Example: `{&amp;quot;user_story&amp;quot;: &amp;quot;As a user, I want to reset my password via email.&amp;quot;, &amp;quot;acceptance_criteria&amp;quot;: [...]}`.&amp;#xa;    2.  **Phase 2: RAG-Context.** The TDA&amp;#39;s first action is not to code; it is to read. It activates its Agentic RAG module to perform &amp;quot;context-aware query planning,&amp;quot; querying the entire codebase and documentation to understand existing authentication routes, email services, and database schemas.&amp;#xa;    3.  **Phase 3: Test Generation (Red).** Armed with this context, the TDA first generates a new, failing unit test (e.g., `test_post_forgot_password_invalid_email_404`). This step codifies the `acceptance_criteria` from the metaprompt into a verifiable, functional validation.&amp;#xa;    4.  **Phase 4: Code Generation (Green).** The agent now generates the minimal amount of implementation code required to make the new test pass, strictly adhering to the patterns discovered in Phase 2.&amp;#xa;    5.  **Phase 5: Reflect &amp;amp; Refactor (Self-Healing).** The TDA runs the *entire* test suite. If an old test fails (a regression), it enters a &amp;quot;self-healing&amp;quot; loop, using the &amp;quot;Error-Forward Prompt&amp;quot; pattern to feed the new stack trace back to itself. It reflects and iterates on the code until the full build is green. Once green, it can be prompted to perform a final refactoring pass to improve code quality (e.g., &amp;quot;Ensure the new function adheres to SOLID principles&amp;quot;).&amp;#xa;&amp;#xa;*   **Exceeding the Benchmark:** This architecture moves beyond task-oriented benchmarks like SWE-bench. The TDA&amp;#39;s output is not &amp;quot;a code snippet that solves a problem&amp;quot;; it is a passing, context-aware, and regression-free build. This builds the trust required for true &amp;quot;agentic software engineering&amp;quot; by producing verifiable, reliable, and autonomous results that can be directly committed to a main branch.&amp;#xa;&amp;#xa;---&amp;#xa;&amp;#xa;#### **The Unified Synthesis: The &amp;quot;Self-Optimizing Product&amp;quot; (SOP) Loop**&amp;#xa;&amp;#xa;This is the final, unified architecture. It bridges the two domains by connecting the TDA (backend code) and the CAI (frontend UI) into a single, product-level optimization loop. This system is designed to autonomously improve the entire product—both its functionality and its interface—based on real-world user interaction.&amp;#xa;&amp;#xa;*   **Vector Exploited:** This architecture exploits the most potent &amp;quot;unexplored vector&amp;quot;: connecting the CAI and TDA architectures via a shared feedback loop that uses Reinforcement Learning from Human Feedback (RLHF). In this advanced paradigm, the &amp;quot;human feedback&amp;quot; is not explicit; it is the **implicit behavioral telemetry** collected from the CAI, which is then used to train a reward model and guide the policy of the entire system.&amp;#xa;&amp;#xa;*   **Mechanism (The Full Loop):**&amp;#xa;    1.  **Deploy:** The TDA generates and deploys `API_v1` (e.g., `POST /api/security-question`). The CAI generates the frontend UI to consume it.&amp;#xa;    2.  **Observe (Telemetry):** The CAI&amp;#39;s telemetry loop observes a &amp;quot;user delight&amp;quot; failure. It logs: *&amp;quot;70% of users drop off at the &amp;#39;Security Question&amp;#39; form. Average hesitation time is 12 seconds. This violates the `cognitive_load` component of our fitness function.&amp;quot;*&amp;#xa;    3.  **Translate (Feedback Agent):** This telemetry is fed into a specialized &amp;quot;Feedback Agent.&amp;quot; This agent&amp;#39;s sole purpose is to translate this implicit, quantitative behavioral data into an explicit, structured product requirement. It autonomously generates a new User Story Metaprompt: `{&amp;quot;user_story&amp;quot;: &amp;quot;The &amp;#39;Security Question&amp;#39; flow causes high friction... Replace it with a &amp;#39;Magic Link&amp;#39; email workflow.&amp;quot;, &amp;quot;acceptance_criteria&amp;quot;: [...]}`.&amp;#xa;    4.  **Trigger (TDA):** This new user story is automatically fed as an Init-Prompt to the TDA.&amp;#xa;    5.  **Heal &amp;amp; Evolve (TDA):** The TDA springs into action. It RAGs the codebase, writes new failing tests for the &amp;#39;Magic Link&amp;#39; flow, generates the new `API_v2` endpoints, and critically, writes and deploys a migration to deprecate `API_v1`.&amp;#xa;    6.  **Adapt (CAI):** The TDA&amp;#39;s deployment triggers the CAI. The CAI, now aware of the new `API_v2`, re-generates its UI components to consume the new, lower-friction workflow, automatically adapting the interface to the healed backend.&amp;#xa;&amp;#xa;*   **Exceeding the Benchmark:** The loop is complete. The product itself (code + UI) has just autonomously optimized its own design to improve &amp;quot;user delight,&amp;quot; with zero direct human intervention. This is the new benchmark. The &amp;quot;prompt&amp;quot; is no longer a static, human instruction; it is a continuous, self-generated feedback signal originating from the user&amp;#39;s own behavior.&amp;#xa;&amp;#xa;---&amp;#xa;&amp;#xa;### **Strategic Implementation and Future Trajectories**&amp;#xa;&amp;#xa;The architectures proposed are not theoretical. They are implementable by shifting from ambiguous natural language prompts to structured metaprompts that act as the bootloaders and configuration files for these autonomous systems. The key is to recognize that for reliable automation, prompts must function less like conversations and more like APIs: structured, versioned, and contractually enforced.&amp;#xa;&amp;#xa;#### **Actionable Blueprints: Structured Metaprompts as the System API**&amp;#xa;&amp;#xa;The most critical pattern for building SOTA systems is the use of structured (not natural language) prompts, as this ensures reliable, machine-parseable interaction between agents. YAML is ideal for its human-readability in top-level configuration, while schema-enforced JSON (using Pydantic/Zod) serves as the non-negotiable &amp;quot;API contract&amp;quot; for inter-agent communication.&amp;#xa;&amp;#xa;**Example Blueprint 1: YAML Metaprompt for the CAI Engine**&amp;#xa;This YAML file is the master-prompt for the Cognitive-Adaptive Interface (CAI) Engine. It defines the purpose and constraints of the UI, not its specific layout.&amp;#xa;&amp;#xa;```yaml&amp;#xa;# This YAML file is the master-prompt for the Cognitive-Adaptive Interface (CAI) Engine.&amp;#xa;# It defines the *purpose* and *constraints* of the UI, not its pixels.&amp;#xa;&amp;#xa;system_role: &amp;quot;You are a CAI (Cognitive-Adaptive Interface) Engine. Your goal is to generate and continuously optimize a user interface to maximize the &amp;#39;objective&amp;#39; by adhering to the &amp;#39;fitness_function&amp;#39;.&amp;quot;&amp;#xa;&amp;#xa;objective:&amp;#xa;  type: &amp;quot;maximize_conversion&amp;quot;&amp;#xa;  target_metric: &amp;quot;checkout_completion_rate&amp;quot; # The specific metric to optimize.&amp;#xa;&amp;#xa;target_persona:&amp;#xa;  # This persona will be used to generate the initial UI hypothesis.&amp;#xa;  file: &amp;quot;./personas/busy_professional_mobile.json&amp;quot; &amp;#xa;&amp;#xa;technical_constraints:&amp;#xa;  # Non-negotiable acceptance criteria for any generated UI.&amp;#xa;  - &amp;quot;WCAG_2_2_AA_COMPLIANT&amp;quot;&amp;#xa;  - &amp;quot;OUTPUT_FORMAT_SEMANTIC_HTML_WITH_ARIA&amp;quot;&amp;#xa;  - &amp;quot;MAX_LOAD_TIME_MS_3G: 1500&amp;quot;&amp;#xa;&amp;#xa;cognitive_fitness_function:&amp;#xa;  # The core of the CAI. The engine will score its own UI against these&amp;#xa;  # principles using live telemetry data as the metric source.&amp;#xa;  - principle: &amp;quot;cognitive_load&amp;quot;&amp;#xa;    weight: -0.5 # Negative weight means minimize this metric.&amp;#xa;    metric: &amp;quot;avg_task_hesitation_time_sec&amp;quot;&amp;#xa;&amp;#xa;  - principle: &amp;quot;hick&amp;#39;s_law&amp;quot;&amp;#xa;    weight: -0.3 # Minimize choice complexity.&amp;#xa;    metric: &amp;quot;choice_count_per_screen&amp;quot;&amp;#xa;&amp;#xa;  - principle: &amp;quot;fitts_s_law_compliance&amp;quot;&amp;#xa;    weight: 0.3 # Positive weight means maximize this metric.&amp;#xa;    metric: &amp;quot;target_acquisition_speed_ms&amp;quot;&amp;#xa;&amp;#xa;  - principle: &amp;quot;nielsen_heuristic_4_consistency&amp;quot;&amp;#xa;    weight: 0.2 # Maximize consistency.&amp;#xa;    metric: &amp;quot;component_reuse_score&amp;quot;&amp;#xa;```&amp;#xa;&amp;#xa;**Example Blueprint 2: JSON Metaprompt for the TDA Framework**&amp;#xa;This JSON object is the &amp;quot;Init-Prompt&amp;quot; for the Test-Driven Agent (TDA). It is machine-generated by the &amp;quot;Feedback Agent&amp;quot; after translating a telemetry-detected user problem.&amp;#xa;&amp;#xa;```json&amp;#xa;/*&amp;#xa;  This JSON object is the &amp;quot;Init-Prompt&amp;quot; for the Test-Driven Agent (TDA).&amp;#xa;  It is programmatically generated by the &amp;quot;Feedback Agent&amp;quot; from user telemetry.&amp;#xa;*/&amp;#xa;{&amp;#xa;  &amp;quot;system_role&amp;quot;: &amp;quot;You are a TDA (Test-Driven Agent). Your primary directive is to produce a passing build. You must write failing tests first, then write code to make them pass.&amp;quot;,&amp;#xa;  &amp;quot;task_id&amp;quot;: &amp;quot;TDA-1138&amp;quot;,&amp;#xa;  &amp;quot;source_trigger&amp;quot;: &amp;quot;SOP_Feedback_Agent_Telemetry_Violation_cognitive_load&amp;quot;,&amp;#xa;  &amp;quot;user_story&amp;quot;: &amp;quot;The &amp;#39;Security Question&amp;#39; flow (API_v1) causes high user friction (70% drop-off). You must replace it with a &amp;#39;Magic Link&amp;#39; email workflow (API_v2).&amp;quot;,&amp;#xa;  &amp;quot;rag_context_queries&amp;quot;: [&amp;#xa;    &amp;quot;Retrieve file:./routes/auth.js&amp;quot;,&amp;#xa;    &amp;quot;Retrieve file:./services/EmailService.js&amp;quot;,&amp;#xa;    &amp;quot;Retrieve file:./models/User.js&amp;quot;,&amp;#xa;    &amp;quot;Retrieve related tests: test_auth.py&amp;quot;&amp;#xa;  ],&amp;#xa;  &amp;quot;acceptance_criteria&amp;quot;: [&amp;#xa;    &amp;quot;A new endpoint POST /api/v2/magic-link must accept an &amp;#39;email&amp;#39;.&amp;quot;,&amp;#xa;    &amp;quot;The new endpoint must return 404 if the email does not exist in the User model.&amp;quot;,&amp;#xa;    &amp;quot;The new endpoint must return 200 and trigger EmailService.sendMagicLink on success.&amp;quot;,&amp;#xa;    &amp;quot;The magic link token must be unique, single-use, and have a 15-minute expiry.&amp;quot;,&amp;#xa;    &amp;quot;A new failing test case must be created for an expired token scenario before implementation.&amp;quot;&amp;#xa;  ]&amp;#xa;}&amp;#xa;```&amp;#xa;&amp;#xa;---&amp;#xa;&amp;#xa;#### **Future Capability Vectors &amp;amp; Redefining Benchmarks**&amp;#xa;&amp;#xa;The user&amp;#39;s final mandate is to &amp;quot;exceed current benchmarks.&amp;quot; The SOP architecture, if implemented, renders current benchmarks for agentic coding obsolete by shifting the goalposts entirely.&amp;#xa;&amp;#xa;*   **Current Benchmarks:** Benchmarks like **HumanEval** and **SWE-bench** are task-oriented and static. They are critical for measuring an agent&amp;#39;s ability to solve a given, siloed problem (e.g., &amp;quot;Fix this bug from this GitHub issue&amp;quot;). However, they do not measure the agent&amp;#39;s ability to *identify the right problem to solve* or to validate its solution against holistic, user-centric goals.&amp;#xa;&amp;#xa;*   **The New Benchmark:** The SOP architecture operates at the product level. The new benchmark should not be &amp;quot;Can the AI solve a GitHub issue?&amp;quot; It must be &amp;quot;Can the AI autonomously identify, specify, implement, and validate a user-delight issue from raw telemetry, and improve the product as a result?&amp;quot;&amp;#xa;&amp;#xa;**Proposed New Benchmark: &amp;quot;Product-Bench&amp;quot;**&amp;#xa;&amp;#xa;*   **Given:** A high-level product goal (e.g., &amp;quot;build a photo-sharing app&amp;quot;) and a `cognitive_fitness_function` (as defined previously).&amp;#xa;*   **Input:** A continuous stream of (simulated) user telemetry, representing a diverse set of user interactions over time.&amp;#xa;*   **Task:** The AI system (SOP) must:&amp;#xa;    1.  Build the V1 of the product (TDA + CAI).&amp;#xa;    2.  Autonomously propose, specify (via metaprompts), implement (via TDA), and deploy (via CAI) new features, fixes, and UI adaptations over 1 million simulated user-sessions in direct response to the telemetry stream.&amp;#xa;*   **Metric:** The final score is the system&amp;#39;s ability to maximize the `cognitive_fitness_function` (e.g., a composite &amp;quot;User Delight&amp;quot; score based on retention, engagement, and cognitive load reduction) over the duration of the simulation.&amp;#xa;&amp;#xa;This new benchmark aligns with the future of HCI and AI, which is moving toward human-AI co-creation, AI-augmented reasoning, and human-centered evaluation. The ultimate prompt architecture is one that empowers a system to create its own prompts, driven by its core purpose and its continuous, real-time interaction with the world. This is the new, and achievable, benchmark for excellence.&quot; id=&quot;15&quot;&gt;&#10;          &lt;mxCell style=&quot;shape=document;whiteSpace=wrap;html=1;boundedLbl=1;size=0.375;fillColor=#dae8fc;strokeColor=#6c8ebf;rounded=0;&quot; vertex=&quot;1&quot; parent=&quot;1&quot;&gt;&#10;            &lt;mxGeometry y=&quot;230&quot; width=&quot;120&quot; height=&quot;80&quot; as=&quot;geometry&quot; /&gt;&#10;          &lt;/mxCell&gt;&#10;        &lt;/object&gt;&#10;        &lt;mxCell id=&quot;16&quot; style=&quot;edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;entryX=0.5;entryY=0;entryDx=0;entryDy=0;strokeWidth=1;exitX=1;exitY=0.25;exitDx=0;exitDy=0;&quot; edge=&quot;1&quot; source=&quot;19&quot; target=&quot;12&quot; parent=&quot;1&quot;&gt;&#10;          &lt;mxGeometry relative=&quot;1&quot; as=&quot;geometry&quot;&gt;&#10;            &lt;mxPoint x=&quot;-430&quot; y=&quot;130&quot; as=&quot;sourcePoint&quot; /&gt;&#10;            &lt;Array as=&quot;points&quot;&gt;&#10;              &lt;mxPoint x=&quot;-40&quot; y=&quot;150&quot; /&gt;&#10;              &lt;mxPoint x=&quot;-40&quot; y=&quot;80&quot; /&gt;&#10;              &lt;mxPoint x=&quot;410&quot; y=&quot;80&quot; /&gt;&#10;            &lt;/Array&gt;&#10;          &lt;/mxGeometry&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;mxCell id=&quot;17&quot; style=&quot;edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;entryX=0.5;entryY=0;entryDx=0;entryDy=0;strokeWidth=1;exitX=1;exitY=0.25;exitDx=0;exitDy=0;&quot; edge=&quot;1&quot; source=&quot;19&quot; target=&quot;52&quot; parent=&quot;1&quot;&gt;&#10;          &lt;mxGeometry relative=&quot;1&quot; as=&quot;geometry&quot;&gt;&#10;            &lt;Array as=&quot;points&quot;&gt;&#10;              &lt;mxPoint x=&quot;-40&quot; y=&quot;150&quot; /&gt;&#10;              &lt;mxPoint x=&quot;-40&quot; y=&quot;70&quot; /&gt;&#10;              &lt;mxPoint x=&quot;650&quot; y=&quot;70&quot; /&gt;&#10;            &lt;/Array&gt;&#10;          &lt;/mxGeometry&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;mxCell id=&quot;18&quot; style=&quot;edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;entryX=0.5;entryY=0;entryDx=0;entryDy=0;&quot; edge=&quot;1&quot; source=&quot;19&quot; target=&quot;56&quot; parent=&quot;1&quot;&gt;&#10;          &lt;mxGeometry relative=&quot;1&quot; as=&quot;geometry&quot;&gt;&#10;            &lt;Array as=&quot;points&quot;&gt;&#10;              &lt;mxPoint x=&quot;-40&quot; y=&quot;150&quot; /&gt;&#10;              &lt;mxPoint x=&quot;-40&quot; y=&quot;60&quot; /&gt;&#10;              &lt;mxPoint x=&quot;900&quot; y=&quot;60&quot; /&gt;&#10;            &lt;/Array&gt;&#10;          &lt;/mxGeometry&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;UserObject label=&quot;DeepResearch&quot; tooltip=&quot;&amp;#xa;Novel Prompt Architectures for AI&amp;#xa;From Static Prompts to Dynamic Architectures: Synthesizing Self-Optimizing Systems for Code and Interface Generation&amp;#xa;Deconstruction of Elite-Tier Prompt Patterns: The Current Benchmark&amp;#xa;The effective use of Large Language Models (LLMs) has evolved significantly from simple, single-turn instructions to complex, multi-stage prompt architectures. This evolution is most pronounced in the technical domains of software engineering and user interface (UI) design. An analysis of current elite-tier patterns reveals a clear trajectory: a shift away from static, human-authored instructions and toward dynamic, machine-optimized, and process-oriented systems.&amp;#xa;&amp;#xa;This section deconstructs the state-of-the-art (SOTA) patterns in these two domains to establish the foundational benchmarks and identify the capability vectors that remain unexploited.&amp;#xa;&amp;#xa;Domain 1: Architectures for Efficient Code Construction&amp;#xa;In software engineering, the objective has shifted from merely generating code snippets to engineering reliable, context-aware, and autonomous systems. The most successful patterns treat the LLM not as a simple code generator, but as a reasoning engine to be embedded within a larger, more structured development framework.&amp;#xa;&amp;#xa;1. Automated Prompt Optimization: The &amp;quot;Prompt-as-a-Target&amp;quot; Pattern&amp;#xa;The manual, iterative refinement of prompts for code generation is widely recognized as a &amp;quot;time-consuming and inconsistent&amp;quot; bottleneck. The SOTA has moved to automate this process, treating the prompt itself as an artifact to be optimized.  &amp;#xa;&amp;#xa;Evolutionary-Based Methods (EPiC): The EPiC (Evolutionary Prompt Engineering for Code) framework is a novel approach that explores code generation from a cost-effectiveness perspective. It &amp;quot;leverages a lightweight evolutionary algorithm to evolve the original prompts toward better ones that produce high-quality code&amp;quot;. By employing mutation operators on the text of the prompt and guiding the search with a fitness function, EPiC automates the discovery of an optimal solution in a cost-effective manner.  &amp;#xa;&amp;#xa;Iterative Refinement (Prochemy): The &amp;quot;Prompt Alchemy&amp;quot; (Prochemy) method provides an &amp;quot;innovative method for automatically refining prompts to boost code generation&amp;quot;. This system operates by iteratively refining prompts based on the model&amp;#39;s actual performance on specific tasks. This automated optimization ensures consistency and has demonstrated substantial performance gains, such as a 5.0% improvement for GPT-3.5-Turbo on HumanEval and a 12.9% improvement for GPT-4o on Java-to-Python code translation tasks.  &amp;#xa;&amp;#xa;Adaptive Selection (PET-Select): Recognizing that &amp;quot;no single approach is universally optimal&amp;quot; , the PET-Select framework introduces a critical meta-layer. This &amp;quot;PET-agnostic selection model&amp;quot; classifies the complexity of an incoming query, using code complexity as a proxy. It then selects the most appropriate prompt engineering technique (PET) for that specific query, such as a simple zero-shot prompt for a simple query or a complex multi-stage reasoning prompt for a difficult one. This automated, adaptive selection process has been shown to improve pass@1 accuracy by up to 1.9% while simultaneously achieving a 74.8% reduction in token usage.  &amp;#xa;&amp;#xa;The clear progression in this domain is from a human-centric &amp;quot;prompt engineering&amp;quot; phase to a machine-centric &amp;quot;prompt optimization&amp;quot; phase. The AI is no longer just the executor of the instruction; it is becoming the refiner of the instruction itself. These systems (EPiC, Prochemy) are, however, reactive. They optimize a prompt for a known task and a known solution space (e.g., passing a specific benchmark). They do not yet proactively generate a novel prompt architecture for a novel, undiscovered problem. This points toward an unexploited vector: a system that can discover a new problem (e.g., from user feedback) and then author its own prompt architecture to solve it, a concept related to meta-prompting.  &amp;#xa;&amp;#xa;2. Test-Driven Development (TDD) as a Prompting Paradigm&amp;#xa;Arguably the most powerful and reliable pattern for high-quality code generation is the integration of Test-Driven Development (TDD) principles directly into the prompt architecture. TDD is an &amp;quot;incremental software development methodology that focuses on creating tests before the implementation&amp;quot;. When applied to LLMs, the test suite becomes the specification.  &amp;#xa;&amp;#xa;Core Principle: Instead of relying on ambiguous natural language, the prompt provides the LLM with a concrete set of unit tests and instructs it to &amp;quot;write code to pass all tests&amp;quot;. This pattern&amp;#39;s success hinges on &amp;quot;instruction following and in-context learning,&amp;quot; which have been identified as more &amp;quot;critical capabilities for TDD success&amp;quot; than general coding proficiency or pre-training knowledge. The tests are the ultimate instruction.  &amp;#xa;&amp;#xa;Frameworks: Systems are being designed to formalize this. The TGEN framework, for example, utilizes &amp;quot;Specialized agents&amp;quot; that accept two primary inputs: the &amp;quot;programming prompt&amp;quot; (a short description) and &amp;quot;the tests&amp;quot; (unit tests and required signatures). These are then processed by the LLM engine to produce validated code.  &amp;#xa;&amp;#xa;Prompt Structure: This paradigm fundamentally changes the structure of the prompt. The request is no longer a simple &amp;quot;what,&amp;quot; but a highly constrained &amp;quot;how.&amp;quot; A common elite-level TDD prompt includes a strict set of rules: &amp;quot;1. Write a single Python function that passes all the provided tests. 2. Use type hints for parameters and return values. 3....Follow Python best practices and PEP 8... 4. Ensure the function handles all edge cases and scenarios covered in the tests. 5. Provide only the function definition and its implementation, nothing else&amp;quot;.  &amp;#xa;&amp;#xa;This TDD-as-prompt pattern provides an objective, verifiable measure of &amp;quot;correctness&amp;quot; that is far superior to ambiguous natural language requests. It successfully shifts the burden of human effort from describing the code to defining its behavior through tests. This is a crucial move from semantic validation (is the code &amp;quot;good&amp;quot;?) to functional validation (does the code work?). The next logical step, and the key unexploited vector, is to close the loop: to create a system that not only generates code from tests but also generates its own tests and validates its own code in a continuous cycle.&amp;#xa;&amp;#xa;3. Self-Validation and &amp;quot;Error-Forward&amp;quot; Debugging&amp;#xa;This pattern extends the TDD loop into a dynamic, autonomous process. For an agent to be truly autonomous, it must be able to recognize, diagnose, and recover from its own errors.&amp;#xa;&amp;#xa;Self-Validation: SOTA agentic systems are designed to &amp;quot;regularly verify progress and self-assess correctness&amp;quot;. This &amp;quot;agentic self-validation&amp;quot; is a core capability that &amp;quot;drives up accuracy&amp;quot;. For example, agents from Cognition, running on models like Claude Sonnet 4.5, are noted to &amp;quot;excel at testing its own code, enabling Devin to run longer, handle harder tasks, and deliver production-ready code&amp;quot;. This integration of TDD into an autonomous agent allows it to &amp;quot;go through several improvement cycles on its own instead of having to manually ask the AI to fix test failures&amp;quot;.  &amp;#xa;&amp;#xa;&amp;quot;Error-Forward Prompting&amp;quot;: This is the primary recovery mechanism within the self-validation loop. This technique treats errors as data, not as failures. When an agent&amp;#39;s self-validation fails, the system automatically &amp;quot;collects relevant context, including the error message, stack trace, and cell location&amp;quot;. This information is then formatted and &amp;quot;provided to the agent as the initial context for beginning the debugging process&amp;quot;.  &amp;#xa;&amp;#xa;Reflection: This is the learning mechanism that makes the recovery effective. A &amp;quot;reflection system enables the agent to learn from its actions and improve its debugging strategy&amp;quot;. Implemented via &amp;quot;reflective prompting&amp;quot; , this allows the model to &amp;quot;analyze and refine its outputs&amp;quot;. The model first generates a solution, then &amp;quot;through subsequent prompts, critiques its own reasoning to identify and correct errors&amp;quot;. This is formalized in techniques like Self-Refine, which mimics the human &amp;quot;draft, review, refine&amp;quot; process.  &amp;#xa;&amp;#xa;In this paradigm, failure is no longer an end-state; it is a high-value data signal. The stack trace becomes the most valuable part of the prompt—a pure, unambiguous instruction set for what must be fixed. When TDD-as-prompt (I.A.2) is combined with this self-validation and reflection loop (I.A.3), the system becomes &amp;quot;self-healing&amp;quot;. The prompt is no longer a single-shot instruction but the initiation of a self-sustaining process. The agent&amp;#39;s goal is elevated from &amp;quot;generate code&amp;quot; to &amp;quot;make the build pass,&amp;quot; a critical step toward true autonomy.  &amp;#xa;&amp;#xa;4. Agentic Frameworks and Multi-Agent Collaboration&amp;#xa;Complex software development cannot be solved in a single step or by a single-minded agent. The recognition that single-shot prompts &amp;quot;yield imprecise or plain incorrect results&amp;quot; for elaborate tasks has led to the rise of sophisticated agentic frameworks.  &amp;#xa;&amp;#xa;Advanced Reasoning Patterns: These frameworks are built upon reasoning patterns far more advanced than simple Chain-of-Thought (CoT).  &amp;#xa;&amp;#xa;ReAct: This pattern combines &amp;quot;Reason and Act&amp;quot; , allowing the agent to interleave step-by-step reasoning with tool use to gather external information or perform actions.  &amp;#xa;&amp;#xa;Tree of Thoughts (ToT): This pattern moves beyond the linear path of CoT. It allows an agent to &amp;quot;breakdown intermediate processed into steps,&amp;quot; generate &amp;quot;various generated states,&amp;quot; and &amp;quot;evaluate&amp;quot; those states to &amp;quot;determine which branch to explore next&amp;quot;.  &amp;#xa;&amp;#xa;Graph of Thoughts (GoT): The current SOTA in reasoning, GoT generalizes ToT into a full graph structure. This &amp;quot;enables combining arbitrary LLM thoughts into synergistic outcomes&amp;quot; and, critically, &amp;quot;enhancing thoughts using feedback loops&amp;quot;. GoT has been shown to increase the quality of sorting by 62% over ToT while reducing costs.  &amp;#xa;&amp;#xa;Agentic Frameworks: These reasoning patterns are orchestrated by multi-agent frameworks.  &amp;#xa;&amp;#xa;MetaGPT: This framework simulates a &amp;quot;real-world software company.&amp;quot; It assigns agents specific roles like &amp;quot;product manager, software architect, programmer, or QA tester&amp;quot; and embeds them with &amp;quot;Standard Operating Procedures (SOPs)&amp;quot;.  &amp;#xa;&amp;#xa;ChatDev: This framework utilizes a &amp;quot;waterfall-style&amp;quot; collaboration, where agents engage in &amp;quot;task-oriented and multi-turn communications&amp;quot; to iteratively refine solutions.  &amp;#xa;&amp;#xa;Purpose: These frameworks are essential as they provide a &amp;quot;shared philosophy of control &amp;amp; reasoning&amp;quot;. Without this, agentic systems suffer from &amp;quot;loss of control clarity of flow&amp;quot; and &amp;quot;unbounded complexity growth&amp;quot; as new agents are added.  &amp;#xa;&amp;#xa;Benchmarks: These agentic systems are what achieve top scores on complex, real-world benchmarks that measure engineering capability. The SWE-bench benchmark, for instance, measures &amp;quot;an AI model&amp;#39;s ability to solve real-world software issues&amp;quot;. SOTA models achieve high scores on SWE-bench and OSWorld precisely by using these agentic, self-testing architectures.  &amp;#xa;&amp;#xa;The atomic unit of these powerful frameworks is role-based prompting. The frameworks themselves (MetaGPT, ChatDev) are, in essence, prompt-driven state machines. A high-level &amp;quot;meta-prompt&amp;quot; defines the agents, their roles, their tools, and their communication protocols. The LLM is thus demoted from &amp;quot;solution generator&amp;quot; to a component—a &amp;quot;reasoning engine&amp;quot; that navigates this pre-defined architecture. The architecture itself has become the prompt. The current limitation, and the unexplored vector, is that these frameworks are simulations of human workflow (e.g., &amp;quot;waterfall,&amp;quot; &amp;quot;software company&amp;quot;). An AI-native workflow, where feedback comes not from a &amp;quot;QA Agent&amp;quot; but from the product itself via live user telemetry, would be fundamentally more efficient.  &amp;#xa;&amp;#xa;5. Context-Aware Generation (Agentic RAG)&amp;#xa;Code generation is useless without domain context. Retrieval-Augmented Generation (RAG) is the primary pattern for providing this context, and its agentic form is the SOTA.  &amp;#xa;&amp;#xa;RAG-for-Code: This pattern gives an AI assistant &amp;quot;a direct line to your team&amp;#39;s collective knowledge&amp;quot;. The prompt is &amp;quot;augmented&amp;quot; with relevant information retrieved from &amp;quot;documentation, code repositories, or even Stack Overflow discussions&amp;quot;. This ensures the generated response is &amp;quot;context-aware&amp;quot; and relevant to the specific codebase it is intended for.  &amp;#xa;&amp;#xa;Agentic RAG: This is the &amp;quot;evolution from traditional single-query RAG&amp;quot;. Instead of being a passive recipient of retrieved context, the agent actively forages for it. It performs &amp;quot;context-aware query planning,&amp;quot; can issue &amp;quot;parallel execution of multiple focused subqueries,&amp;quot; and then synthesizes the results to build a comprehensive understanding. This is the approach used by modern agentic frameworks like LangGraph , AutoGen , and those from Amazon and Microsoft.  &amp;#xa;&amp;#xa;The RAG-for-Code pattern transforms a &amp;quot;general-purpose coder&amp;quot; into a &amp;quot;domain-specific engineer&amp;quot; who understands the nuances of a particular project. The agentic aspect is the critical differentiator; it is the difference between giving a developer a 500-page manual (standard RAG) and the developer knowing which three pages to read (Agentic RAG). The most potent, but not yet fully exploited, vector in code generation is the fusion of this Agentic RAG (for context) with the TDD-as-Prompt paradigm (for verification). An agent that can retrieve context from a 500,000-line codebase and validate its changes against that codebase&amp;#39;s test suite is the difference between a &amp;quot;coding assistant&amp;quot; and an &amp;quot;autonomous developer.&amp;quot; This fusion is the core of the novel Test-Driven Agent (TDA) architecture proposed in Part II.  &amp;#xa;&amp;#xa;Domain 2: Architectures for User Delight &amp;amp; UI Design&amp;#xa;In the second domain, UI generation, the mandate for &amp;quot;user delight&amp;quot; requires moving beyond simple wireframe generation. Elite-tier prompts in this space are not about &amp;quot;generating pixels&amp;quot; but about &amp;quot;generating experiences&amp;quot; grounded in human-centric principles.&amp;#xa;&amp;#xa;1. Persona-Driven Design: Grounding the Generation&amp;#xa;&amp;quot;User delight&amp;quot; is the &amp;quot;positive emotional response users feel when a product doesn&amp;#39;t just meet their needs but goes above and beyond&amp;quot;. This state is &amp;quot;highly contextual&amp;quot; and cannot be achieved without first defining the user.  &amp;#xa;&amp;#xa;Pattern: Elite prompts for UI design do not begin with the interface; they begin with the user. The system is first prompted to generate a detailed proto-persona. This persona includes demographic details, &amp;quot;target users, their core pain points, and daily use context&amp;quot; , as well as deeper &amp;quot;Motivations&amp;quot; and &amp;quot;Affinities&amp;quot;.  &amp;#xa;&amp;#xa;Application: This generated persona (or a human-provided one) is then injected as a primary constraint into all subsequent UI generation prompts. This allows the AI to &amp;quot;cater to Gen Z and Gen X users&amp;quot; differently, tailoring the design, tone, and complexity to a specific audience. The prompt is no longer &amp;quot;generate a wireframe for a music app&amp;quot; but &amp;quot;generate a wireframe for a music app for this specific persona , focusing on their stated pain point of {pain_point}.&amp;quot;  &amp;#xa;&amp;#xa;This persona-driven pattern acts as a powerful constraint on the model&amp;#39;s vast solution space, forcing it to move from generating a generic &amp;quot;good UI&amp;quot; to a UI that is &amp;quot;good for this specific user.&amp;quot; It is, in effect, a form of in-context learning for design, where the persona serves as a &amp;quot;one-shot&amp;quot; example of the target user. The major limitation, and the unexploited vector, is that this is a static process. The persona is an assumption created at the beginning of the design process. The clear next step is to move from these static, assumed personas to dynamic, observed user models that are continuously updated based on real-time behavioral analytics.  &amp;#xa;&amp;#xa;2. Constraint-Based Generation: Defining the &amp;quot;Solution Space&amp;quot;&amp;#xa;The highest-fidelity UI generation requires the application of multiple, layered constraints. These constraints are the specifications that ensure the output is not just creative, but also functional, accessible, and grounded in established design theory. These constraints fall into three primary categories.&amp;#xa;&amp;#xa;A. Cognitive &amp;amp; Heuristic Constraints&amp;#xa;This is the most sophisticated pattern for achieving true &amp;quot;user delight.&amp;quot; The prompt explicitly instructs the AI to apply principles from cognitive science and established usability heuristics, forcing the AI to design for the human mind.  &amp;#xa;&amp;#xa;Heuristics: The most common pattern is to prompt the AI to act as a UX expert and evaluate or generate a design based on &amp;quot;Nielsen&amp;#39;s 10 Usability Heuristics&amp;quot; or other well-known variants like Shneiderman&amp;#39;s &amp;quot;Eight Golden Rules&amp;quot; or Weinschenk and Barker&amp;#39;s &amp;quot;20 Usability Heuristics&amp;quot;.  &amp;#xa;&amp;#xa;Cognitive Principles: More advanced prompts instruct the AI to directly apply specific cognitive laws. Examples include:&amp;#xa;&amp;#xa;Fitts&amp;#39;s Law: Prompting the AI to make &amp;quot;important buttons and interactive elements larger and closer to where users naturally focus&amp;quot;.  &amp;#xa;&amp;#xa;Hick&amp;#39;s Law: Instructing the AI to &amp;quot;reduc[e] the number of options or organiz[e] them into categories&amp;quot; to speed up decision-making.  &amp;#xa;&amp;#xa;Cognitive Load: Prompting with the explicit goal of &amp;quot;reducing cognitive load&amp;quot; to create a more effortless experience.  &amp;#xa;&amp;#xa;Behavioral Models: The most advanced prompts use frameworks like BJ Fogg&amp;#39;s Behavior Model (B=MAP: Motivation, Ability, Prompt) or Nir Eyal&amp;#39;s &amp;quot;Hooked&amp;quot; model to design persuasive or habit-forming interfaces.  &amp;#xa;&amp;#xa;Prompting with &amp;quot;Nielsen&amp;#39;s Heuristics&amp;quot; or &amp;quot;Fogg&amp;#39;s Behavior Model&amp;quot; acts as a domain-specific Chain-of-Thought. It forces the AI to justify its design choices (&amp;quot;This button is large and placed in the bottom-right corner because it adheres to Fitts&amp;#39;s Law&amp;quot;), leading to more principled, defensible, and ultimately delightful designs.  &amp;#xa;&amp;#xa;B. Technical &amp;amp; Accessibility (A11y) Constraints&amp;#xa;There is no &amp;quot;delight&amp;quot; in an interface that is unusable for a portion of the population. Elite prompts must enforce technical constraints, with accessibility (A11y) being paramount.&amp;#xa;&amp;#xa;Pattern: The prompt must explicitly instruct the AI to be &amp;quot;fully compliant with WCAG 2.2 AA&amp;quot;. Research shows that without this explicit instruction, AI-generated components are &amp;quot;consistently&amp;quot; inaccessible.  &amp;#xa;&amp;#xa;Specifics: A high-quality A11y prompt enforces:&amp;#xa;&amp;#xa;Semantic HTML: &amp;quot;Ensure the proper use of HTML5 elements (like &amp;lt;header&amp;gt;, &amp;lt;main&amp;gt;, &amp;lt;footer&amp;gt;)&amp;quot;.  &amp;#xa;&amp;#xa;Keyboard Accessibility: &amp;quot;Test navigation using only Tab, Shift+Tab, and Enter keys. All interactive elements should be reachable&amp;quot;.  &amp;#xa;&amp;#xa;ARIA (Accessible Rich Internet Applications): Correct application of &amp;quot;ARIA landmarks and roles&amp;quot; , which are &amp;quot;HTML attributes that add semantic meaning... for assistive technologies&amp;quot;.  &amp;#xa;&amp;#xa;Clear Content: &amp;quot;Use clear language... Write descriptive links: Swap vague text like &amp;#39;click here&amp;#39; for something meaningful&amp;quot;.  &amp;#xa;&amp;#xa;This pattern is the UI-domain equivalent of TDD (I.A.2). The prompt includes the acceptance criteria (WCAG). This &amp;quot;specification-as-prompt&amp;quot; is critical for generating production-ready, non-discriminatory interfaces.&amp;#xa;&amp;#xa;C. Structural &amp;amp; Layout Constraints&amp;#xa;To control the form of the output and ensure it is machine-readable and programmatically useful, prompts must define a reliable structure.&amp;#xa;&amp;#xa;Architecture &amp;amp; Flows: For high-level system design, prompts specify formats like the C4 model rendered in Mermaid code. For user flows, Mermaid sequence diagrams are the standard.  &amp;#xa;&amp;#xa;Wireframes: Simple wireframe prompts use text descriptions, such as, &amp;quot;Include a header with a logo, search bar, featured destinations section, and a bottom navigation bar&amp;quot;.  &amp;#xa;&amp;#xa;SOTA (Structured Data): The most robust and programmatically valuable pattern is to force the LLM to output a structured data format like JSON or YAML. This is achieved by providing an output schema to the model. This pattern is now natively supported by major model providers, who allow schemas to be defined using libraries like Pydantic (for Python) or Zod (for TypeScript). This guarantees the output is not just text, but a &amp;quot;type safety and consistent structure&amp;quot;.  &amp;#xa;&amp;#xa;This structured output pattern is the critical link between the two domains of this report. If a UI can be described in a reliable JSON schema, and a backend can expose its API in a reliable JSON schema (e.g., an OpenAPI specification), an agent can connect them. This structured output is the &amp;quot;API&amp;quot; between a UI-generation agent and a code-generation agent.&amp;#xa;&amp;#xa;3. Generative UI (GenUI): The Emergent Paradigm&amp;#xa;This is the bleeding-edge concept that underpins the entire future of UI design. Generative UI (GenUI) is a new paradigm that &amp;quot;enables adaptive, goal-driven interactions&amp;quot;. Instead of a static interface designed by a human and then coded, the UI is generated in real-time by the AI.  &amp;#xa;&amp;#xa;Mechanism: In this paradigm, the AI generates &amp;quot;interactive widgets for fine-grained prompt control&amp;quot; or entire &amp;quot;high-fidelity UI mock-up screens from a high-level textual description&amp;quot;. This process is not one-shot; it is an iterative, &amp;quot;co-creative process&amp;quot; between the human and the AI, involving &amp;quot;AI-assisted refinement strategies&amp;quot;.  &amp;#xa;&amp;#xa;Current State: GenUI is currently being adopted by UX practitioners as a tool to accelerate their workflow. The human remains the curator and refiner of the AI-generated output.  &amp;#xa;&amp;#xa;GenUI is the logical evolution of prompt-based wireframing. The current limitation, and the key unexploited vector, is the human-in-the-loop for optimization. The UI is refined based on a designer&amp;#39;s &amp;quot;vibe&amp;quot; or explicit follow-up prompts. The unexploited opportunity is to remove the human curator from the optimization loop. A system that could refine its own GenUI, not based on a designer&amp;#39;s commands, but based on live user data, would represent a paradigm shift. This is the core concept of a &amp;quot;Self-Optimizing UI&amp;quot; and forms the foundation for the novel Cognitive-Adaptive Interface (CAI) architecture.  &amp;#xa;&amp;#xa;Synthesis of Novel Prompt Architectures: Exceeding Current Benchmarks&amp;#xa;The preceding analysis deconstructed the current SOTA, revealing a set of unexploited capability vectors. The following synthesis moves beyond replicating these patterns. It proposes three novel, high-level architectures that fuse these vectors to create self-regulating, self-optimizing systems designed to exceed current benchmarks. These architectures treat the prompt not as a static, one-time instruction, but as a &amp;quot;bootloader&amp;quot; for a continuous, autonomous process.&amp;#xa;&amp;#xa;Table 1: Comparative Analysis of Generation &amp;amp; Reasoning Architectures&amp;#xa;&amp;#xa;Architecture&amp;#x9;Core Mechanism&amp;#x9;Interaction Model&amp;#x9;Key Limitation (Vector Not Exploited)&amp;#x9;Unlocked Capability Vector&amp;#xa;Chain-of-Thought (CoT)&amp;#xa;&amp;#xa;Step-by-step reasoning (e.g., &amp;quot;Let&amp;#39;s think step-by-step&amp;quot;).&amp;#x9;Static&amp;#x9;Brittle, linear reasoning; no external validation or tool use.&amp;#x9;Basic multi-step problem solving.&amp;#xa;ReAct&amp;#xa;&amp;#xa;Interleaves reasoning (CoT) with tool use (Actions).&amp;#x9;Iterative&amp;#x9;Dependent on pre-defined tools; no long-term memory or structured collaboration.&amp;#x9;Environment-aware task execution.&amp;#xa;Graph of Thoughts (GoT)&amp;#xa;&amp;#xa;Models reasoning as a graph, allowing merging of states and feedback loops.&amp;#x9;Iterative&amp;#x9;High conceptual complexity; primarily focused on reasoning, not execution.&amp;#x9;Advanced, non-linear problem-solving.&amp;#xa;TDD-as-Prompt&amp;#xa;&amp;#xa;A test suite is provided as the functional specification for code generation.&amp;#x9;Static&amp;#x9;Requires human to write all tests; no self-correction loop.&amp;#x9;Verifiable, high-reliability code generation.&amp;#xa;Generative UI (GenUI)&amp;#xa;&amp;#xa;AI generates high-fidelity UI mockups or interactive widgets from text descriptions.&amp;#x9;Iterative&amp;#x9;Requires human-in-the-loop for curation and refinement; based on assumed user needs.&amp;#x9;Rapid, co-creative UI prototyping.&amp;#xa;[NOVEL] Cognitive-Adaptive Interface (CAI) Engine&amp;#x9;&amp;#xa;GenUI + Cognitive Fitness Function + Live User Telemetry.&amp;#xa;&amp;#xa;Dynamic-Adaptive&amp;#x9;N/A (Synthesized Architecture)&amp;#x9;Real-time UI self-optimization based on observed user cognitive state.&amp;#xa;[NOVEL] Test-Driven Agent (TDA) Framework&amp;#x9;&amp;#xa;Closed-loop TDD + Agentic RAG + Error-Forward Self-Healing.&amp;#xa;&amp;#xa;Autonomous-Iterative&amp;#x9;N/A (Synthesized Architecture)&amp;#x9;Verifiable, context-aware, autonomous development with guaranteed build integrity.&amp;#xa;[NOVEL] Self-Optimizing Product (SOP) Loop&amp;#x9;&amp;#xa;TDA-CAI integration via an RLHF-from-Telemetry feedback loop.&amp;#xa;&amp;#xa;Autonomous-Holistic&amp;#x9;N/A (Synthesized Architecture)&amp;#x9;Fully autonomous product self-improvement driven by implicit user feedback.&amp;#xa; &amp;#xa;Proposed Architecture 1: The &amp;quot;Cognitive-Adaptive Interface&amp;quot; (CAI) Engine&amp;#xa;This architecture synthesizes Generative UI (GenUI) with persona-driven design and, most critically, cognitive-heuristic constraints. It is designed to move UI generation from a static, one-shot process (&amp;quot;generate a wireframe&amp;quot;) to a continuous, adaptive, and self-optimizing one.  &amp;#xa;&amp;#xa;Vector Exploited: This architecture directly targets the vector identified in (I.B.1) and (I.B.3): the fusion of Generative UI with real-time user telemetry. The system does not just generate a UI; it optimizes it in real-time based on observed user behavior.  &amp;#xa;&amp;#xa;Mechanism: The CAI Engine operates as a continuous four-phase loop:&amp;#xa;&amp;#xa;Phase 1: The &amp;quot;Cognitive Metaprompt&amp;quot;. The architect does not prompt for a specific layout. Instead, they provide a high-level, structured (e.g., YAML) prompt that defines the goals and constraints. This metaprompt specifies:&amp;#xa;&amp;#xa;target_persona: The ground-truth user archetype.  &amp;#xa;&amp;#xa;business_objective: The high-level optimization target (e.g., &amp;quot;maximize conversion,&amp;quot; &amp;quot;minimize time-to-task,&amp;quot; &amp;quot;maximize user delight&amp;quot;).&amp;#xa;&amp;#xa;cognitive_fitness_function: A weighted list of cognitive and behavioral principles that will be used to score the UI&amp;#39;s performance. For example: weights: {cognitive_load: -0.5, fitts_law_compliance: +0.3, hick&amp;#39;s_law_compliance: -0.2, wcag_aa_compliance: 1.0}.  &amp;#xa;&amp;#xa;Phase 2: Initial Generation. The CAI engine uses this metaprompt to generate the initial UI component tree. This output is a structured JSON artifact, not just a static image. The engine&amp;#39;s initial design is its best hypothesis for satisfying the cognitive_fitness_function for the given target_persona.&amp;#xa;&amp;#xa;Phase 3: The Telemetry Loop. This is the critical connection to the real world. As users interact with this dynamically-rendered GenUI, the system collects fine-grained, real-time telemetry. This data includes not just basic &amp;quot;clickstream data&amp;quot; but also proxies for cognitive state: hesitation time (cognitive load), rage clicks (frustration), scroll depth (engagement), and form drop-off points.  &amp;#xa;&amp;#xa;Phase 4: Autonomous Optimization. This telemetry stream is fed back into the CAI engine. The engine scores the current UI&amp;#39;s performance against the cognitive_fitness_function. It then begins a continuous, &amp;quot;self-optimizing&amp;quot; process, autonomously running micro-A/B tests or other reinforcement learning strategies to adapt the UI. For example, it might log: &amp;quot;Hypothesis: Moving &amp;#39;Add to Cart&amp;#39; button 10px closer to the product image will improve the Fitts&amp;#39;s Law component of the fitness function. Result: Target acquisition speed improved by 80ms and conversion metric increased by 0.2%. This change is now permanent for this user segment.&amp;quot;  &amp;#xa;&amp;#xa;Exceeding the Benchmark: This architecture creates a true &amp;quot;Self-Optimizing UI&amp;quot;. The prompt is no longer a blueprint for a static house; it is the DNA for a living organism that adapts to its environment (the user) in real-time. This moves beyond static, assumed personas to build an interface that dynamically aligns with the observed cognitive and behavioral patterns of its actual users.  &amp;#xa;&amp;#xa;Proposed Architecture 2: The &amp;quot;Test-Driven Agent&amp;quot; (TDA) Framework&amp;#xa;This architecture synthesizes the most robust patterns from the code construction domain: TDD-as-Prompt (I.A.2), Self-Validation (I.A.3), and Agentic RAG (I.A.5). It creates a closed-loop, &amp;quot;self-healing&amp;quot; system designed to enable verifiable, autonomous development at the repository level.  &amp;#xa;&amp;#xa;Vector Exploited: This architecture exploits the vector identified in (I.A.5): the fusion of autonomous, closed-loop TDD with context-aware Agentic RAG . The agent&amp;#39;s output is not &amp;quot;code&amp;quot;; it is a &amp;quot;passing build.&amp;quot;  &amp;#xa;&amp;#xa;Mechanism: The TDA Framework operates as a five-phase, autonomous workflow:&amp;#xa;&amp;#xa;Phase 1: The &amp;quot;User Story Metaprompt&amp;quot;. The human (or another agent) provides a high-level feature request in a structured format (e.g., JSON). This prompt defines the goal, not the implementation. Example: {&amp;quot;user_story&amp;quot;: &amp;quot;As a user, I want to reset my password via email.&amp;quot;, &amp;quot;acceptance_criteria&amp;quot;: [&amp;quot;Must handle invalid emails&amp;quot;, &amp;quot;Must send a tokenized link&amp;quot;]}.&amp;#xa;&amp;#xa;Phase 2: RAG-Context. The TDA&amp;#39;s first action is not to code. It is to read. It activates its Agentic RAG module to perform &amp;quot;context-aware query planning&amp;quot;. It queries the entire codebase and documentation to understand the existing system. (e.g., &amp;quot;Query: &amp;#39;auth routes&amp;#39;&amp;quot;, &amp;quot;Query: &amp;#39;email service&amp;#39;&amp;quot;, &amp;quot;Query: &amp;#39;database schema for users&amp;#39;&amp;quot;).  &amp;#xa;&amp;#xa;Phase 3: Test Generation (Red). Armed with this context, the TDA first generates a new, failing unit test (e.g., test_post_forgot_password_invalid_email_404). This step, based on the TDD-as-prompt paradigm , codifies the acceptance_criteria from the metaprompt into a verifiable, functional validation.  &amp;#xa;&amp;#xa;Phase 4: Code Generation (Green). The agent now generates the minimal amount of implementation code (a new route, a new service function) required to make the new test pass.  &amp;#xa;&amp;#xa;Phase 5: Reflect &amp;amp; Refactor (Self-Healing). The TDA does not stop. It now runs the entire test suite. If an old test fails (a regression), it enters a &amp;quot;self-healing&amp;quot; loop. It uses the &amp;quot;Error-Forward Prompt&amp;quot; pattern (I.A.3), feeding the new stack trace back to itself. It then reflects and iterates on the code until the full build is green.  &amp;#xa;&amp;#xa;Exceeding the Benchmark: This architecture moves beyond task-oriented benchmarks like SWE-bench. The TDA&amp;#39;s output is not &amp;quot;a code snippet that solves a problem&amp;quot;; it is a passing, context-aware, and regression-free build. This builds the trust required for true &amp;quot;agentic software engineering&amp;quot; by producing verifiable, reliable, and autonomous results that can be directly committed to a main branch.  &amp;#xa;&amp;#xa;The Unified Synthesis: The &amp;quot;Self-Optimizing Product&amp;quot; (SOP) Loop&amp;#xa;This is the final, unified architecture. It bridges the two domains by connecting the TDA (backend code) and the CAI (frontend UI) into a single, product-level optimization loop. This system is designed to autonomously improve the entire product—both its functionality and its interface—based on user interaction.&amp;#xa;&amp;#xa;Vector Exploited: This architecture exploits the most potent &amp;quot;unexplored vector&amp;quot;: connecting the CAI (UI) and TDA (Code) architectures via a shared feedback loop that uses Reinforcement Learning from Human Feedback (RLHF) . In this paradigm, the &amp;quot;human feedback&amp;quot; is not explicit (like a button click); it is the implicit behavioral telemetry collected from the CAI, which is then used to train a reward model and guide the policy of the entire system.  &amp;#xa;&amp;#xa;Mechanism (The Full Loop):&amp;#xa;&amp;#xa;Deploy: The TDA (Architecture 2) generates and deploys the backend API_v1 (e.g., POST /api/security-question). The CAI (Architecture 1) generates the frontend UI to consume it, governed by its cognitive_fitness_function.&amp;#xa;&amp;#xa;Observe (Telemetry): The CAI&amp;#39;s telemetry loop observes a &amp;quot;user delight&amp;quot; failure. It logs: &amp;quot;70% of users drop off at the &amp;#39;Security Question&amp;#39; form. Average hesitation time is 12 seconds. This violates the cognitive_load component of our fitness function.&amp;quot;  &amp;#xa;&amp;#xa;Translate (Feedback Agent): This telemetry is fed into a new, specialized &amp;quot;Feedback Agent.&amp;quot; This agent, part of a &amp;quot;Closed Learning Feedback Loop&amp;quot; , is a reasoning agent (using GoT ). Its sole purpose is to translate this quantitative behavioral data into a new product requirement. It autonomously generates a new User Story Metaprompt using meta-prompting techniques : {&amp;quot;user_story&amp;quot;: &amp;quot;The &amp;#39;Security Question&amp;#39; flow causes high friction (70% drop-off). Replace it with a &amp;#39;Magic Link&amp;#39; email workflow.&amp;quot;, &amp;quot;acceptance_criteria&amp;quot;: [...]}.  &amp;#xa;&amp;#xa;Trigger (TDA): This new user story is automatically fed as an Init-Prompt to the TDA (Architecture 2).&amp;#xa;&amp;#xa;Heal &amp;amp; Evolve (TDA): The TDA springs into action. It RAGs the codebase , writes new failing tests for the &amp;#39;Magic Link&amp;#39; flow , generates the new API_v2 endpoints, and (critically) writes and deploys a migration to deprecate API_v1.  &amp;#xa;&amp;#xa;Adapt (CAI): The TDA&amp;#39;s deployment (or an event-driven hook) triggers the CAI. The CAI, now aware of the new API_v2 and the deprecation of API_v1, re-generates its UI components to consume the new, &amp;quot;healed&amp;quot; workflow, automatically adapting the interface to the new, lower-friction flow.&amp;#xa;&amp;#xa;Exceeding the Benchmark: The loop is complete. The product itself (code + UI) just autonomously optimized its own design to improve &amp;quot;user delight,&amp;quot; with no human intervention. This is the new benchmark. The &amp;quot;prompt&amp;quot; is no longer a static, human instruction; it is a continuous, self-generated feedback signal originating from the user&amp;#39;s own behavior.&amp;#xa;&amp;#xa;Strategic Implementation and Future Trajectories&amp;#xa;The architectures proposed in Part II are not theoretical. They can be implemented by moving from natural language prompts to structured metaprompts that act as the bootloaders and configuration files for these autonomous systems.&amp;#xa;&amp;#xa;Actionable Blueprints: Structured Metaprompts as the System API&amp;#xa;To make these architectures concrete, we must define their initialization. These are meta-prompts that initialize and constrain the autonomous systems.  &amp;#xa;&amp;#xa;The most critical pattern for SOTA systems is the use of structured (not natural language) prompts, as this ensures reliable, machine-parseable interaction between agents. YAML is used for its human-readability in top-level configuration , while schema-enforced JSON (using Pydantic/Zod ) serves as the non-negotiable &amp;quot;API&amp;quot; for inter-agent communication.  &amp;#xa;&amp;#xa;Example Blueprint 1: YAML Metaprompt for the CAI Engine&amp;#xa;This YAML file is the master-prompt for the Cognitive-Adaptive Interface (CAI) Engine. It defines the purpose and constraints of the UI, not its specific layout.&amp;#xa;&amp;#xa;# This YAML file is the master-prompt for the Cognitive-Adaptive Interface (CAI) Engine.&amp;#xa;# It defines the *purpose* and *constraints* of the UI.&amp;#xa;&amp;#xa;system_role: &amp;quot;You are a CAI (Cognitive-Adaptive Interface) Engine. Your goal is to generate and continuously optimize a user interface to maximize the &amp;#39;objective&amp;#39; by adhering to the &amp;#39;fitness_function&amp;#39;.&amp;quot;&amp;#xa;&amp;#xa;objective:&amp;#xa;  type: &amp;quot;maximize_conversion&amp;quot;&amp;#xa;  target_metric: &amp;quot;checkout_completion_rate&amp;quot;&amp;#xa;  &amp;#xa;target_persona:&amp;#xa;  # This persona  will be used to generate the initial UI.&amp;#xa;  file: &amp;quot;./personas/busy_professional_mobile.json&amp;quot; &amp;#xa;  &amp;#xa;technical_constraints:&amp;#xa;  # Non-negotiable acceptance criteria &amp;#xa;  - &amp;quot;WCAG_2_2_AA_COMPLIANT&amp;quot;&amp;#xa;  - &amp;quot;OUTPUT_FORMAT_SEMANTIC_HTML_WITH_ARIA&amp;quot; [71, 72]&amp;#xa;  - &amp;quot;MAX_LOAD_TIME_MS_3G: 1500&amp;quot;&amp;#xa;  &amp;#xa;cognitive_fitness_function:&amp;#xa;  # The core of the CAI. The engine will score its own UI against these&amp;#xa;  # principles  using live telemetry.&amp;#xa;  - principle: &amp;quot;cognitive_load&amp;quot; # &amp;#xa;    weight: -0.5 # (Minimize)&amp;#xa;    metric: &amp;quot;avg_task_hesitation_time_sec&amp;quot;&amp;#xa;    &amp;#xa;  - principle: &amp;quot;hick&amp;#39;s_law&amp;quot; # &amp;#xa;    weight: -0.3 # (Minimize choices)&amp;#xa;    metric: &amp;quot;choice_count_per_screen&amp;quot;&amp;#xa;&amp;#xa;  - principle: &amp;quot;fitts_s_law_compliance&amp;quot; # &amp;#xa;    weight: 0.3 # (Maximize)&amp;#xa;    metric: &amp;quot;target_acquisition_speed_ms&amp;quot;&amp;#xa;    &amp;#xa;  - principle: &amp;quot;nielsen_heuristic_4_consistency&amp;quot; # &amp;#xa;    weight: 0.2 # (Maximize)&amp;#xa;    metric: &amp;quot;component_reuse_score&amp;quot;&amp;#xa;Example Blueprint 2: JSON Metaprompt for the TDA Framework&amp;#xa;This JSON object is the &amp;quot;Init-Prompt&amp;quot; for the Test-Driven Agent (TDA). It is generated by the &amp;quot;Feedback Agent&amp;quot; (II.C) after translating a telemetry-detected user problem.&amp;#xa;&amp;#xa;/*&amp;#xa;  This JSON object is the &amp;quot;Init-Prompt&amp;quot; for the Test-Driven Agent (TDA).&amp;#xa;  It is generated by the &amp;quot;Feedback Agent&amp;quot; [II.C] from user telemetry.&amp;#xa;*/&amp;#xa;{&amp;#xa;  &amp;quot;system_role&amp;quot;: &amp;quot;You are a TDA (Test-Driven Agent). You must generate code that passes all tests. You must write failing tests first.&amp;quot;,&amp;#xa;  &amp;quot;task_id&amp;quot;: &amp;quot;TDA-1138&amp;quot;,&amp;#xa;  &amp;quot;source_trigger&amp;quot;: &amp;quot;SOP_Feedback_Agent_Telemetry_Violation_cognitive_load&amp;quot;,&amp;#xa;  &amp;quot;user_story&amp;quot;: &amp;quot;The &amp;#39;Security Question&amp;#39; flow (API_v1) causes high user friction (70% drop-off). You must replace it with a &amp;#39;Magic Link&amp;#39; email workflow (API_v2).&amp;quot;,&amp;#xa;  &amp;quot;rag_context_queries&amp;quot;:&amp;#xa;    &amp;quot;Retrieve file:./routes/auth.js&amp;quot;,&amp;#xa;    &amp;quot;Retrieve file:./services/EmailService.js&amp;quot;,&amp;#xa;    &amp;quot;Retrieve file:./models/User.js&amp;quot;,&amp;#xa;    &amp;quot;Retrieve related tests: test_auth.py&amp;quot;&amp;#xa;  ],&amp;#xa;  &amp;quot;acceptance_criteria&amp;quot;:&amp;#xa;    &amp;quot;POST /api/v2/magic-link must accept an &amp;#39;email&amp;#39;.&amp;quot;,&amp;#xa;    &amp;quot;Must return 404 if email does not exist.&amp;quot;,&amp;#xa;    &amp;quot;Must return 200 and trigger EmailService.sendMagicLink on success.&amp;quot;,&amp;#xa;    &amp;quot;Must generate a unique, single-use token with a 15-minute expiry.&amp;quot;,&amp;#xa;    &amp;quot;Must create a new failing test for &amp;#39;token_expired&amp;#39; scenario.&amp;quot;&amp;#xa;  ]&amp;#xa;}&amp;#xa;Future Capability Vectors &amp;amp; Redefining Benchmarks&amp;#xa;The user&amp;#39;s final mandate is to &amp;quot;exceed current benchmarks.&amp;quot; The SOP architecture, if implemented, renders current benchmarks obsolete.&amp;#xa;&amp;#xa;Current Benchmarks: Benchmarks like HumanEval and SWE-bench are task-oriented and static. They are critical for measuring an agent&amp;#39;s ability to solve a given, siloed problem (e.g., &amp;quot;Fix this bug from this GitHub issue&amp;quot;). However, they do not measure the agent&amp;#39;s ability to identify the problem or validate its solution against holistic user-centric goals.  &amp;#xa;&amp;#xa;The New Benchmark: The SOP architecture (II.C) operates at the product level. The new benchmark should not be &amp;quot;Can the AI solve a GitHub issue?&amp;quot; It must be &amp;quot;Can the AI identify, validate, and solve a user-delight issue autonomously from raw telemetry?&amp;quot;&amp;#xa;&amp;#xa;Proposed New Benchmark: &amp;quot;Product-Bench&amp;quot;&amp;#xa;&amp;#xa;Given: A high-level product goal (e.g., &amp;quot;build a photo-sharing app&amp;quot;) and a cognitive_fitness_function (as defined in III.A).&amp;#xa;&amp;#xa;Input: A stream of (simulated) user telemetry, representing a diverse set of user interactions over time.&amp;#xa;&amp;#xa;Task: The AI system (SOP) must:&amp;#xa;&amp;#xa;(a) Build the V1 of the product (TDA + CAI).&amp;#xa;&amp;#xa;(b) Autonomously evolve its features, code, and UI over 1 million simulated user-sessions in response to the telemetry stream.&amp;#xa;&amp;#xa;Metric: The final score is the system&amp;#39;s ability to maximize the cognitive_fitness_function (e.g., a composite &amp;quot;User Delight&amp;quot; score based on retention, engagement, and cognitive load reduction) over the duration of the simulation.&amp;#xa;&amp;#xa;This new benchmark aligns with the future of HCI and AI, which is moving toward human-AI co-creation , AI-augmented reasoning , and human-centered evaluation. The ultimate prompt architecture is one that creates its own prompts based on its core purpose and its continuous, real-time interaction with the world. This is the new, and achievable, benchmark for excellence.  &quot; id=&quot;19&quot;&gt;&#10;          &lt;mxCell style=&quot;shape=document;whiteSpace=wrap;html=1;boundedLbl=1;fillColor=#dae8fc;strokeColor=#6c8ebf;rounded=0;&quot; vertex=&quot;1&quot; parent=&quot;1&quot;&gt;&#10;            &lt;mxGeometry x=&quot;-500&quot; y=&quot;130&quot; width=&quot;120&quot; height=&quot;80&quot; as=&quot;geometry&quot; /&gt;&#10;          &lt;/mxCell&gt;&#10;        &lt;/UserObject&gt;&#10;        &lt;mxCell id=&quot;20&quot; value=&quot;&quot; style=&quot;edgeStyle=orthogonalEdgeStyle;curved=1;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;&quot; edge=&quot;1&quot; source=&quot;22&quot; target=&quot;29&quot; parent=&quot;1&quot;&gt;&#10;          &lt;mxGeometry relative=&quot;1&quot; as=&quot;geometry&quot; /&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;mxCell id=&quot;21&quot; value=&quot;push&quot; style=&quot;edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];rounded=0;&quot; vertex=&quot;1&quot; connectable=&quot;0&quot; parent=&quot;20&quot;&gt;&#10;          &lt;mxGeometry x=&quot;-0.4262&quot; y=&quot;-3&quot; relative=&quot;1&quot; as=&quot;geometry&quot;&gt;&#10;            &lt;mxPoint as=&quot;offset&quot; /&gt;&#10;          &lt;/mxGeometry&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;UserObject label=&quot;DeepResearch&quot; tooltip=&quot;Here is the output from the The Same Tool  when input DeepResearch Text that had been Amplified.  &amp;#xa;&amp;#xa;&amp;#xa;Based on your detailed request, here is a step-by-step plan for synthesizing self-optimizing systems for code and interface generation, culminating in the Self-Optimizing Product (SOP) Loop.&amp;#xa;&amp;#xa;&amp;#xa;---&amp;#xa;&amp;#xa;&amp;#xa;Step-by-Step Plan: Synthesizing Self-Optimizing Systems&amp;#xa;&amp;#xa;The core of this plan is to establish a continuous, autonomous feedback loop that drives product improvement based on real-time user behavior. This is achieved by integrating two novel architectures: the Cognitive-Adaptive Interface (CAI) Engine for UI optimization and the Test-Driven Agent (TDA) Framework for verifiable code generation.&amp;#xa;&amp;#xa;&amp;#xa;I. Foundation 1: Implementing the Cognitive-Adaptive Interface (CAI) Engine&amp;#xa;&amp;#xa;The CAI Engine focuses on creating and optimizing UIs based on observed user cognitive states, moving beyond static personas and subjective human feedback.&amp;#xa;&amp;#xa;&amp;#xa;1. Phase 1: Define the &amp;quot;Cognitive Metaprompt&amp;quot; (Structured Goal &amp;amp; Constraints)&amp;#xa;&amp;#xa;* Action: Architect defines a high-level, structured YAML metaprompt.&amp;#xa;&amp;#xa;* Content: This metaprompt specifies the `target_persona`, the `business_objective` (e.g., &amp;quot;maximize conversion&amp;quot;), and a `cognitive_fitness_function`.&amp;#xa;&amp;#xa;* `cognitive_fitness_function` Detail: This is a weighted list of cognitive and behavioral principles (e.g., `cognitive_load: -0.5`, `fitts_s_law_compliance: +0.3`) used to score the UI&amp;#39;s performance.&amp;#xa;&amp;#xa;* Output: A machine-readable YAML configuration acting as the DNA for the UI.&amp;#xa;&amp;#xa;&amp;#xa;2. Phase 2: Initial UI Generation (Hypothesis Formation)&amp;#xa;&amp;#xa;* Action: The CAI Engine uses the YAML metaprompt to generate an initial UI.&amp;#xa;&amp;#xa;* Process: It forms its best hypothesis for satisfying the `cognitive_fitness_function` for the specified `target_persona`.&amp;#xa;&amp;#xa;* Output: A structured JSON artifact representing the UI component tree (e.g., via Pydantic/Zod schema-enforced output).&amp;#xa;&amp;#xa;&amp;#xa;3. Phase 3: Establish the Telemetry Loop (Real-World Observation)&amp;#xa;&amp;#xa;* Action: Deploy the dynamically-rendered GenUI to end-users and activate real-time telemetry collection.&amp;#xa;&amp;#xa;* Data Points: Collect fine-grained behavioral data beyond clickstreams, including:&amp;#xa;&amp;#xa;* Hesitation Time: Proxy for cognitive load.&amp;#xa;&amp;#xa;* Rage Clicks: Proxy for frustration.&amp;#xa;&amp;#xa;* Scroll Depth: Proxy for engagement.&amp;#xa;&amp;#xa;* Form Drop-off Points: Critical conversion blockers.&amp;#xa;&amp;#xa;* Output: A continuous, high-bandwidth stream of user interaction data.&amp;#xa;&amp;#xa;&amp;#xa;4. Phase 4: Autonomous UI Optimization (Self-Adaptation)&amp;#xa;&amp;#xa;* Action: Feed the telemetry data back into the CAI Engine for continuous improvement.&amp;#xa;&amp;#xa;* Process:&amp;#xa;&amp;#xa;* Score the current UI&amp;#39;s performance against the predefined `cognitive_fitness_function`.&amp;#xa;&amp;#xa;* Autonomously run micro-A/B tests or employ multi-armed bandit algorithms.&amp;#xa;&amp;#xa;* Adapt the UI components (e.g., button placement, information density, workflow changes) to improve the score.&amp;#xa;&amp;#xa;* Output: A continuously evolving, self-optimizing UI that dynamically aligns with observed user cognitive and behavioral patterns.&amp;#xa;&amp;#xa;&amp;#xa;II. Foundation 2: Implementing the Test-Driven Agent (TDA) Framework&amp;#xa;&amp;#xa;The TDA Framework provides a closed-loop, &amp;quot;self-healing&amp;quot; system for autonomous, verifiable code development at the repository level, ensuring a &amp;quot;passing build&amp;quot; as its primary deliverable.&amp;#xa;&amp;#xa;&amp;#xa;1. Phase 1: Provide the &amp;quot;User Story Metaprompt&amp;quot; (Goal, not Implementation)&amp;#xa;&amp;#xa;* Action: A human or another agent provides a high-level feature request.&amp;#xa;&amp;#xa;* Format: Structured JSON format, defining the user story and `acceptance_criteria`.&amp;#xa;&amp;#xa;* Example: `{&amp;quot;user_story&amp;quot;: &amp;quot;As a user, I want to reset my password via email.&amp;quot;, &amp;quot;acceptance_criteria&amp;quot;: [...]}`.&amp;#xa;&amp;#xa;* Output: A machine-parseable JSON object for the TDA.&amp;#xa;&amp;#xa;&amp;#xa;2. Phase 2: RAG-Contextualization (Understand the Codebase)&amp;#xa;&amp;#xa;* Action: The TDA activates its Agentic RAG module.&amp;#xa;&amp;#xa;* Process: Performs context-aware query planning across the codebase, documentation, existing APIs, and database schemas.&amp;#xa;&amp;#xa;* Goal: Build a comprehensive understanding of the existing system relevant to the user story.&amp;#xa;&amp;#xa;* Output: Internal knowledge graph or retrieved context documents used for subsequent steps.&amp;#xa;&amp;#xa;&amp;#xa;3. Phase 3: Test Generation (Red Phase - Codify Requirements)&amp;#xa;&amp;#xa;* Action: Armed with context, the TDA first generates a new, failing unit test.&amp;#xa;&amp;#xa;* Purpose: This test directly codifies the `acceptance_criteria` from the metaprompt into a verifiable, functional validation.&amp;#xa;&amp;#xa;* Output: A new test file (e.g., `test_forgot_password.py`) with at least one failing test case.&amp;#xa;&amp;#xa;&amp;#xa;4. Phase 4: Code Generation (Green Phase - Implement to Pass Tests)&amp;#xa;&amp;#xa;* Action: The TDA generates the minimal implementation code required to make the newly generated test(s) pass.&amp;#xa;&amp;#xa;* Constraint: Strict adherence to patterns and conventions discovered during RAG-Contextualization.&amp;#xa;&amp;#xa;* Output: New or modified code files that attempt to satisfy the tests.&amp;#xa;&amp;#xa;&amp;#xa;5. Phase 5: Reflect &amp;amp; Self-Heal (Continuous Verification &amp;amp; Refinement)&amp;#xa;&amp;#xa;Action: The TDA runs the entire* test suite (including existing and newly generated tests).&amp;#xa;&amp;#xa;* Process:&amp;#xa;&amp;#xa;* If any test fails (regression or new test failure), it enters a &amp;quot;self-healing&amp;quot; loop.&amp;#xa;&amp;#xa;* Uses &amp;quot;Error-Forward Prompting&amp;quot; to feed the stack trace and error messages back to itself as structured context.&amp;#xa;&amp;#xa;* Reflects on the errors and iteratively refines the code until the full build is green.&amp;#xa;&amp;#xa;* (Optional) Performs a final refactoring pass for code quality (e.g., SOLID principles).&amp;#xa;&amp;#xa;* Output: A passing, context-aware, and regression-free build, ready for deployment.&amp;#xa;&amp;#xa;&amp;#xa;III. Integrated Vision: The Self-Optimizing Product (SOP) Loop&amp;#xa;&amp;#xa;This is the unified architecture, bridging the CAI (frontend UI) and TDA (backend code) into a single, product-level optimization loop, driven by implicit user feedback.&amp;#xa;&amp;#xa;&amp;#xa;1. Step 1: Initial Product Deployment (TDA &amp;amp; CAI)&amp;#xa;&amp;#xa;* Action: The TDA generates and deploys an initial backend API (e.g., `API_v1`).&amp;#xa;&amp;#xa;* Action: The CAI Engine, consuming this API, generates and deploys the corresponding frontend UI (V1).&amp;#xa;&amp;#xa;* Outcome: A functional product available to users.&amp;#xa;&amp;#xa;&amp;#xa;2. Step 2: Observe User Behavior (CAI Telemetry Detects Failure)&amp;#xa;&amp;#xa;* Action: The CAI&amp;#39;s continuous telemetry loop actively monitors user interactions with the deployed UI.&amp;#xa;&amp;#xa;* Detection: It identifies a &amp;quot;user delight&amp;quot; failure based on its `cognitive_fitness_function` (e.g., high drop-off rate, excessive hesitation time in a specific flow).&amp;#xa;&amp;#xa;* Output: A detected telemetry violation report (e.g., &amp;quot;70% of users drop off at &amp;#39;Security Question&amp;#39; form; violates `cognitive_load` metric&amp;quot;).&amp;#xa;&amp;#xa;&amp;#xa;3. Step 3: Translate Telemetry to Product Requirement (Feedback Agent)&amp;#xa;&amp;#xa;* Action: A specialized &amp;quot;Feedback Agent&amp;quot; receives the telemetry violation report.&amp;#xa;&amp;#xa;* Process: It translates this implicit, quantitative behavioral data into an explicit, structured product requirement.&amp;#xa;&amp;#xa;* Output: A new &amp;quot;User Story Metaprompt&amp;quot; (JSON) for the TDA, proposing a solution to the identified problem (e.g., &amp;quot;Replace &amp;#39;Security Question&amp;#39; flow with &amp;#39;Magic Link&amp;#39; email workflow&amp;quot;).&amp;#xa;&amp;#xa;&amp;#xa;4. Step 4: Trigger Backend Evolution (TDA Initiation)&amp;#xa;&amp;#xa;* Action: The newly generated User Story Metaprompt is automatically fed as an Init-Prompt to the TDA Framework.&amp;#xa;&amp;#xa;* Outcome: The TDA is initiated with a clear, user-driven mandate for product improvement.&amp;#xa;&amp;#xa;&amp;#xa;5. Step 5: Autonomous Backend Development &amp;amp; Deployment (TDA Execution)&amp;#xa;&amp;#xa;* Action: The TDA executes its full five-phase workflow (RAG-Context, Test Generation, Code Generation, Reflect &amp;amp; Self-Heal).&amp;#xa;&amp;#xa;* Process:&amp;#xa;&amp;#xa;* It reads the codebase to understand existing authentication.&amp;#xa;&amp;#xa;* It writes new failing tests for the proposed &amp;#39;Magic Link&amp;#39; flow.&amp;#xa;&amp;#xa;* It generates new `API_v2` endpoints and implementation.&amp;#xa;&amp;#xa;* Crucially, it handles necessary migrations, including deprecating `API_v1` components.&amp;#xa;&amp;#xa;* Output: A passing, verifiable backend build with updated APIs (`API_v2`) deployed to production.&amp;#xa;&amp;#xa;&amp;#xa;6. Step 6: Autonomous Frontend Adaptation (CAI Re-generation)&amp;#xa;&amp;#xa;* Action: The deployment of the new backend `API_v2` triggers the CAI Engine.&amp;#xa;&amp;#xa;* Process: The CAI, now aware of the new, lower-friction `API_v2`, re-generates or adapts its UI components to consume the new endpoints.&amp;#xa;&amp;#xa;* Outcome: The frontend interface automatically adapts to the healed backend, providing a seamless, optimized user experience.&amp;#xa;&amp;#xa;&amp;#xa;IV. Strategic Implementation: Structured Metaprompts as System APIs&amp;#xa;&amp;#xa;Principle: Shift from ambiguous natural language prompts to structured metaprompts.&amp;#xa;YAML: Utilize YAML for top-level configuration and high-level metaprompts (e.g., CAI&amp;#39;s &amp;quot;Cognitive Metaprompt&amp;quot;) due to its human-readability and structured nature.&amp;#xa;JSON with Schemas: Employ JSON for inter-agent communication and detailed specifications (e.g., TDA&amp;#39;s &amp;quot;User Story Metaprompt&amp;quot;) with schema enforcement (e.g., Pydantic/Zod). This guarantees type safety, consistent structure, and a reliable &amp;quot;API contract&amp;quot; between autonomous agents.&amp;#xa;&amp;#xa;V. Future Trajectory: Redefining Benchmarks with &amp;quot;Product-Bench&amp;quot;&amp;#xa;&amp;#xa;The success of the SOP loop necessitates a new benchmark that evaluates autonomous product improvement rather than isolated task completion.&amp;#xa;&amp;#xa;&amp;#xa;Proposed New Benchmark: &amp;quot;Product-Bench&amp;quot;&amp;#xa;* Given: A high-level product goal (e.g., &amp;quot;build a photo-sharing app&amp;quot;) and a `cognitive_fitness_function`.&amp;#xa;* Input: A continuous stream of simulated user telemetry, representing diverse user interactions.&amp;#xa;&amp;#xa;* Task: The SOP system must autonomously build V1, and then continuously propose, specify, implement, and deploy new features, fixes, and UI adaptations over millions of simulated user sessions in direct response to the telemetry.&amp;#xa;&amp;#xa;* Metric: Maximize the `cognitive_fitness_function` (a composite &amp;quot;User Delight&amp;quot; score based on retention, engagement, and cognitive load reduction) over the simulation duration.&amp;#xa;&amp;#xa;&amp;#xa;---&amp;#xa;&amp;#xa;&amp;#xa;This step-by-step plan outlines the architecture and mechanisms required to achieve truly self-optimizing systems, moving from human-centric &amp;quot;prompt engineering&amp;quot; to machine-driven &amp;quot;prompt optimization&amp;quot; and autonomous product evolution.&quot; id=&quot;22&quot;&gt;&#10;          &lt;mxCell style=&quot;shape=document;whiteSpace=wrap;html=1;boundedLbl=1;fillColor=#dae8fc;strokeColor=#6c8ebf;rounded=0;&quot; vertex=&quot;1&quot; parent=&quot;1&quot;&gt;&#10;            &lt;mxGeometry y=&quot;470&quot; width=&quot;120&quot; height=&quot;80&quot; as=&quot;geometry&quot; /&gt;&#10;          &lt;/mxCell&gt;&#10;        &lt;/UserObject&gt;&#10;        &lt;mxCell id=&quot;23&quot; style=&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;&quot; edge=&quot;1&quot; source=&quot;25&quot; target=&quot;22&quot; parent=&quot;1&quot;&gt;&#10;          &lt;mxGeometry relative=&quot;1&quot; as=&quot;geometry&quot; /&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;mxCell id=&quot;24&quot; value=&quot;output&quot; style=&quot;edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];rounded=0;&quot; vertex=&quot;1&quot; connectable=&quot;0&quot; parent=&quot;23&quot;&gt;&#10;          &lt;mxGeometry x=&quot;-0.3131&quot; y=&quot;5&quot; relative=&quot;1&quot; as=&quot;geometry&quot;&gt;&#10;            &lt;mxPoint x=&quot;-5&quot; y=&quot;6&quot; as=&quot;offset&quot; /&gt;&#10;          &lt;/mxGeometry&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;mxCell id=&quot;25&quot; value=&quot;Tool for AI&quot; style=&quot;whiteSpace=wrap;html=1;fillColor=#F561FF;strokeColor=#9673a6;rounded=0;&quot; vertex=&quot;1&quot; parent=&quot;1&quot;&gt;&#10;          &lt;mxGeometry y=&quot;350&quot; width=&quot;120&quot; height=&quot;60&quot; as=&quot;geometry&quot; /&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;UserObject label=&quot;DeepResearch&quot; tooltip=&quot;Based on your request, here is a step-by-step plan for understanding and implementing the concepts outlined, structured to follow the flow of the provided text.&amp;#xa;&amp;#xa;#### 1.1.3. Self-Validation and &amp;quot;Error-Forward&amp;quot; Debugging&amp;#xa;Goal: Enable autonomous agents to recognize, diagnose, and recover from errors, extending the TDD loop.&amp;#xa;Core Capabilities:&amp;#xa;* Agentic Self-Validation: Regularly verify progress and self-assess correctness (e.g., Cognition&amp;#39;s Devin).&amp;#xa;* &amp;quot;Error-Forward Prompting&amp;quot;: Treat errors as data; automatically collect context (error message, stack trace) and feed it back to the agent for debugging.&amp;#xa;&amp;#xa;* Reflection: Learn from actions and improve debugging stratStep-by-Step Plan: From Static Prompts to Dynamic Architectures&amp;#xa;&amp;#xa;1. Deconstruct Elite-Tier Prompt Patterns: The Current Benchmark&amp;#xa;&amp;#xa;Begin by understanding the foundational benchmarks and identifying current state-of-the-art (SOTA) practices in LLM prompting for code and UI generation.&amp;#xa;&amp;#xa;&amp;#xa;1.1. Domain 1: Architectures for Efficient Code Construction&amp;#xa;&amp;#xa;Focus on how LLMs are used as reasoning engines within structured development frameworks.&amp;#xa;&amp;#xa;&amp;#xa;#### 1.1.1. Automated Prompt Optimization: The &amp;quot;Prompt-as-a-Target&amp;quot; Pattern&amp;#xa;&amp;#xa;Goal: Automate prompt refinement to produce high-quality code.&amp;#xa;Techniques to Understand:&amp;#xa;* Evolutionary-Based Methods (EPiC): Explore prompt evolution via genetic algorithms and fitness functions.&amp;#xa;* Iterative Refinement (Prochemy): Continuously refine prompts based on model performance on specific tasks.&amp;#xa;&amp;#xa;* Adaptive Selection (PET-Select): Classify query complexity to dynamically select the most appropriate prompt engineering technique (PET).&amp;#xa;&amp;#xa;Key Unexploited Vector: Proactive generation of novel prompt architectures for novel problems (meta-prompting).&amp;#xa;&amp;#xa;#### 1.1.2. Test-Driven Development (TDD) as a Prompting Paradigm&amp;#xa;Goal: Integrate TDD principles directly into prompt architecture for verifiable code generation.&amp;#xa;Core Principle: Provide LLM with concrete unit tests as the specification, instructing it to &amp;quot;write code to pass all tests.&amp;quot;&amp;#xa;Frameworks/Structures:&amp;#xa;* TGEN Framework: Uses specialized agents with programming prompts and tests to produce validated code.&amp;#xa;* Elite-Level TDD Prompt Structure: Strict rules including function signature, type hints, best practices, edge cases, and output format (e.g., Python function only).&amp;#xa;&amp;#xa;Key Unexploited Vector: A system that generates its own tests and validates its own code in a continuous cycle.&amp;#xa;egies via reflective prompting (e.g., Self-Refine).&amp;#xa;&amp;#xa;Outcome: &amp;quot;Self-healing&amp;quot; systems where failure is a data signal, and the stack trace becomes an instruction for fixing.&amp;#xa;&amp;#xa;#### 1.1.4. Agentic Frameworks and Multi-Agent Collaboration&amp;#xa;Goal: Solve complex software development tasks by orchestrating multiple specialized agents.&amp;#xa;Advanced Reasoning Patterns:&amp;#xa;* ReAct: Interleave step-by-step reasoning with tool use.&amp;#xa;* Tree of Thoughts (ToT): Explore multiple reasoning paths and evaluate states.&amp;#xa;&amp;#xa;* Graph of Thoughts (GoT): Generalize ToT into a graph structure for synergistic outcomes and feedback loops.&amp;#xa;&amp;#xa;Agentic Frameworks:&amp;#xa;* MetaGPT: Simulate a software company with agents in roles (PM, Architect, Programmer, QA) and Standard Operating Procedures (SOPs).&amp;#xa;* ChatDev: Utilize waterfall-style collaboration with task-oriented, multi-turn communications.&amp;#xa;&amp;#xa;Key Unexploited Vector: AI-native workflows where feedback comes from product telemetry, not simulated human roles.&amp;#xa;&amp;#xa;#### 1.1.5. Context-Aware Generation (Agentic RAG)&amp;#xa;Goal: Provide LLMs with relevant domain context for code generation.&amp;#xa;Pattern:&amp;#xa;* RAG-for-Code: Augment prompts with information from documentation, code repositories, or discussions.&amp;#xa;* Agentic RAG: Agent actively plans queries, executes multiple subqueries, and synthesizes results for comprehensive understanding (e.g., LangGraph, AutoGen).&amp;#xa;&amp;#xa;Key Unexploited Vector: Fusion of Agentic RAG (for context) with TDD-as-Prompt (for verification) to create autonomous developers.&amp;#xa;&amp;#xa;1.2. Domain 2: Architectures for User Delight &amp;amp; UI Design&amp;#xa;&amp;#xa;Explore how elite prompts generate user experiences, not just pixels, grounded in human-centric principles.&amp;#xa;&amp;#xa;&amp;#xa;#### 1.2.1. Persona-Driven Design: Grounding the Generation&amp;#xa;&amp;#xa;Goal: Achieve &amp;quot;user delight&amp;quot; by tailoring UI generation to specific user needs.&amp;#xa;Pattern:&amp;#xa;* Persona Generation: Prompt system to generate detailed proto-personas (demographics, pain points, motivations).&amp;#xa;* Constraint Injection: Inject generated/human-provided personas as primary constraints into UI generation prompts.&amp;#xa;&amp;#xa;Key Unexploited Vector: Move from static, assumed personas to dynamic, observed user models continuously updated by real-time behavioral analytics.&amp;#xa;&amp;#xa;#### 1.2.2. Constraint-Based Generation: Defining the &amp;quot;Solution Space&amp;quot;&amp;#xa;Goal: Apply multiple, layered constraints to ensure functional, accessible, and theoretically sound UI outputs.&amp;#xa;Categories of Constraints:&amp;#xa;* A. Cognitive &amp;amp; Heuristic Constraints: Instruct AI to apply principles from cognitive science and usability heuristics (e.g., Nielsen&amp;#39;s 10, Fitts&amp;#39;s Law, Hick&amp;#39;s Law, Cognitive Load, BJ Fogg&amp;#39;s Model).&amp;#xa;* B. Technical &amp;amp; Accessibility (A11y) Constraints: Explicitly enforce standards like WCAG 2.2 AA compliance (e.g., Semantic HTML, Keyboard Accessibility, ARIA, clear content).&amp;#xa;&amp;#xa;* C. Structural &amp;amp; Layout Constraints: Define reliable output structures for machine-readability (e.g., C4 model, Mermaid diagrams, structured data formats like JSON/YAML with Pydantic/Zod schemas).&amp;#xa;&amp;#xa;Importance: Structured output is the &amp;quot;API&amp;quot; connecting UI and code generation agents.&amp;#xa;&amp;#xa;#### 1.2.3. Generative UI (GenUI): The Emergent Paradigm&amp;#xa;Goal: Enable adaptive, goal-driven interactions where the UI is generated and refined in real-time by AI.&amp;#xa;Mechanism: AI generates interactive widgets or high-fidelity mock-ups from high-level descriptions, often in a co-creative process with humans.&amp;#xa;Current State: A tool for accelerating UX workflow, with humans still curating and refining.&amp;#xa;Key Unexploited Vector: Remove the human curator from the optimization loop; refine GenUI based on live user data.&amp;#xa;&amp;#xa;2. Synthesize Novel Prompt Architectures: Exceeding Current Benchmarks&amp;#xa;&amp;#xa;Propose and understand three novel, high-level architectures that fuse the identified unexploited vectors to create self-regulating, self-optimizing systems.&amp;#xa;&amp;#xa;&amp;#xa;2.1. Proposed Architecture 1: The &amp;quot;Cognitive-Adaptive Interface&amp;quot; (CAI) Engine&amp;#xa;Core Mechanism: Fuses GenUI, persona-driven design, cognitive-heuristic constraints, and real-time user telemetry.&amp;#xa;Vector Exploited: Generative UI with real-time user telemetry.&amp;#xa;Mechanism (Four-Phase Loop):&amp;#xa;1. Phase 1: The &amp;quot;Cognitive Metaprompt&amp;quot;: Define high-level goals and structured constraints (e.g., YAML) including `target_persona`, `business_objective`, and a weighted `cognitive_fitness_function`.&amp;#xa;2. Phase 2: Initial Generation: Generate the initial structured UI component tree as a hypothesis to satisfy the `cognitive_fitness_function`.&amp;#xa;&amp;#xa;3. Phase 3: The Telemetry Loop: Collect fine-grained, real-time user telemetry (hesitation time, rage clicks, scroll depth) as users interact.&amp;#xa;&amp;#xa;4. Phase 4: Autonomous Optimization: Feed telemetry back, score UI performance against `cognitive_fitness_function`, and run continuous micro-A/B tests or RL strategies to adapt the UI (e.g., move buttons based on Fitts&amp;#39;s Law compliance).&amp;#xa;&amp;#xa;Benchmark Exceedance: Creates a &amp;quot;Self-Optimizing UI&amp;quot; that dynamically adapts to observed user cognitive and behavioral patterns in real-time.&amp;#xa;&amp;#xa;2.2. Proposed Architecture 2: The &amp;quot;Test-Driven Agent&amp;quot; (TDA) Framework&amp;#xa;Core Mechanism: Synthesizes TDD-as-Prompt, Self-Validation, and Agentic RAG into a closed-loop, &amp;quot;self-healing&amp;quot; system.&amp;#xa;Vector Exploited: Autonomous, closed-loop TDD with context-aware Agentic RAG.&amp;#xa;Mechanism (Five-Phase Autonomous Workflow):&amp;#xa;1. Phase 1: The &amp;quot;User Story Metaprompt&amp;quot;: Receive a high-level feature request in a structured format (e.g., JSON) defining the goal and `acceptance_criteria`.&amp;#xa;2. Phase 2: RAG-Context: Activate Agentic RAG to query the codebase and documentation to understand the existing system.&amp;#xa;&amp;#xa;3. Phase 3: Test Generation (Red): Generate new, failing unit tests based on the `acceptance_criteria`, codifying functional validation.&amp;#xa;&amp;#xa;4. Phase 4: Code Generation (Green): Generate minimal implementation code to make the new tests pass.&amp;#xa;&amp;#xa;5. Phase 5: Reflect &amp;amp; Refactor (Self-Healing): Run the entire test suite. If a regression occurs, use &amp;quot;Error-Forward Prompt&amp;quot; (stack trace) and reflection to iterate on code until the full build is green.&amp;#xa;&amp;#xa;Benchmark Exceedance: Output is a passing, context-aware, and regression-free build, enabling verifiable, autonomous development at the repository level.&amp;#xa;&amp;#xa;2.3. Proposed Architecture 3: The &amp;quot;Self-Optimizing Product&amp;quot; (SOP) Loop&amp;#xa;Core Mechanism: Unifies TDA (backend code) and CAI (frontend UI) into a single product-level optimization loop.&amp;#xa;Vector Exploited: Connecting CAI and TDA via a shared feedback loop using Reinforcement Learning from Human Feedback (RLHF) from implicit behavioral telemetry.&amp;#xa;Mechanism (The Full Loop):&amp;#xa;1. Deploy: TDA generates and deploys a backend API, and CAI generates the frontend UI to consume it.&amp;#xa;2. Observe (Telemetry): CAI&amp;#39;s telemetry loop detects a &amp;quot;user delight&amp;quot; failure (e.g., high drop-off at a form).&amp;#xa;&amp;#xa;3. Translate (Feedback Agent): A specialized &amp;quot;Feedback Agent&amp;quot; (using GoT) translates quantitative behavioral data into a new structured User Story Metaprompt (e.g., &amp;quot;Replace &amp;#39;Security Question&amp;#39; with &amp;#39;Magic Link&amp;#39; workflow&amp;quot;).&amp;#xa;&amp;#xa;4. Trigger (TDA): The new user story is automatically fed as an Init-Prompt to the TDA.&amp;#xa;&amp;#xa;5. Heal &amp;amp; Evolve (TDA): TDA RAGs the codebase, writes new failing tests, generates new API endpoints, and handles migrations.&amp;#xa;&amp;#xa;6. Adapt (CAI): CAI, triggered by TDA&amp;#39;s deployment, re-generates its UI components to consume the new API and adapt to the lower-friction workflow.&amp;#xa;&amp;#xa;Benchmark Exceedance: The product autonomously optimizes its own design (code + UI) based on implicit user behavior, with no human intervention.&amp;#xa;&amp;#xa;3. Strategic Implementation and Future Trajectories&amp;#xa;&amp;#xa;Define actionable blueprints for implementation and propose a new benchmark.&amp;#xa;&amp;#xa;&amp;#xa;3.1. Actionable Blueprints: Structured Metaprompts as the System API&amp;#xa;Principle: Move from natural language to structured metaprompts (YAML for configuration, schema-enforced JSON for inter-agent API) for reliable, machine-parseable interaction.&amp;#xa;Example Blueprint 1: YAML Metaprompt for CAI Engine:&amp;#xa;* Defines `system_role`, `objective` (e.g., maximize_conversion), `target_persona` (file path), `technical_constraints` (e.g., WCAG_2_2_AA_COMPLIANT), and a weighted `cognitive_fitness_function` (principles like cognitive_load, hick&amp;#39;s_law, fitts_s_law_compliance with associated metrics).&amp;#xa;Example Blueprint 2: JSON Metaprompt for TDA Framework:&amp;#xa;* Defines `system_role`, `task_id`, `source_trigger`, `user_story`, `rag_context_queries`, and `acceptance_criteria`. This is the Init-Prompt generated by the Feedback Agent.&amp;#xa;3.2. Future Capability Vectors &amp;amp; Redefining Benchmarks&amp;#xa;Current Benchmarks (e.g., HumanEval, SWE-bench): Task-oriented and static, measuring siloed problem-solving.&amp;#xa;The New Benchmark: &amp;quot;Product-Bench&amp;quot;&amp;#xa;* Given: A high-level product goal and a `cognitive_fitness_function`.&amp;#xa;* Input: A stream of simulated user telemetry.&amp;#xa;&amp;#xa;* Task: The AI system (SOP) must:&amp;#xa;&amp;#xa;* (a) Build the V1 of the product (TDA + CAI).&amp;#xa;&amp;#xa;* (b) Autonomously evolve its features, code, and UI over millions of simulated user-sessions in response to telemetry.&amp;#xa;&amp;#xa;* Metric: Maximize the `cognitive_fitness_function` (composite &amp;quot;User Delight&amp;quot; score) over the simulation duration.&amp;#xa;&amp;#xa;Outcome: The ultimate prompt architecture creates its own prompts based on purpose and continuous, real-time interaction, aligning with human-AI co-creation and human-centered evaluation.&quot; id=&quot;26&quot;&gt;&#10;          &lt;mxCell style=&quot;shape=document;whiteSpace=wrap;html=1;boundedLbl=1;rounded=0;fillColor=#dae8fc;strokeColor=#6c8ebf;&quot; vertex=&quot;1&quot; parent=&quot;1&quot;&gt;&#10;            &lt;mxGeometry x=&quot;350&quot; y=&quot;240&quot; width=&quot;120&quot; height=&quot;80&quot; as=&quot;geometry&quot; /&gt;&#10;          &lt;/mxCell&gt;&#10;        &lt;/UserObject&gt;&#10;        &lt;mxCell id=&quot;27&quot; style=&quot;edgeStyle=orthogonalEdgeStyle;curved=1;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;entryX=0.5;entryY=0;entryDx=0;entryDy=0;&quot; edge=&quot;1&quot; source=&quot;29&quot; target=&quot;32&quot; parent=&quot;1&quot;&gt;&#10;          &lt;mxGeometry relative=&quot;1&quot; as=&quot;geometry&quot; /&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;mxCell id=&quot;28&quot; value=&quot;output&quot; style=&quot;edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];rounded=0;&quot; vertex=&quot;1&quot; connectable=&quot;0&quot; parent=&quot;27&quot;&gt;&#10;          &lt;mxGeometry x=&quot;-0.2277&quot; y=&quot;4&quot; relative=&quot;1&quot; as=&quot;geometry&quot;&gt;&#10;            &lt;mxPoint x=&quot;-4&quot; as=&quot;offset&quot; /&gt;&#10;          &lt;/mxGeometry&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;mxCell id=&quot;29&quot; value=&quot;Foundry&amp;amp;nbsp;&quot; style=&quot;whiteSpace=wrap;html=1;fillColor=#FA9FF5;strokeColor=#9673a6;rounded=0;&quot; vertex=&quot;1&quot; parent=&quot;1&quot;&gt;&#10;          &lt;mxGeometry y=&quot;590&quot; width=&quot;120&quot; height=&quot;60&quot; as=&quot;geometry&quot; /&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;mxCell id=&quot;30&quot; style=&quot;edgeStyle=orthogonalEdgeStyle;curved=1;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;entryX=0.5;entryY=0;entryDx=0;entryDy=0;&quot; edge=&quot;1&quot; source=&quot;32&quot; target=&quot;35&quot; parent=&quot;1&quot;&gt;&#10;          &lt;mxGeometry relative=&quot;1&quot; as=&quot;geometry&quot; /&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;mxCell id=&quot;31&quot; value=&quot;Push (-) Header&quot; style=&quot;edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];rounded=0;&quot; vertex=&quot;1&quot; connectable=&quot;0&quot; parent=&quot;30&quot;&gt;&#10;          &lt;mxGeometry x=&quot;-0.114&quot; y=&quot;-3&quot; relative=&quot;1&quot; as=&quot;geometry&quot;&gt;&#10;            &lt;mxPoint x=&quot;8&quot; y=&quot;-7&quot; as=&quot;offset&quot; /&gt;&#10;          &lt;/mxGeometry&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;UserObject label=&quot;DeepResearch&quot; tooltip=&quot;Final Converged Design (from QA)&amp;#xa;&amp;#xa;Final Score: 100/100&amp;#xa;&amp;#xa;&amp;#xa;---&amp;#xa;&amp;#xa;&amp;#xa;---&amp;#xa;&amp;#xa;&amp;#xa;Based on the critical feedback from our Security team, I have refined the design to create the Trustworthy Self-Optimizing Product (TSOP) Loop. This new version elevates the previous QASOP model by embedding security into the very foundation of the autonomous agents and their operational environment, not just as a post-generation validation step. This &amp;quot;secure the core&amp;quot; approach addresses the integrity of the generative process itself.&amp;#xa;&amp;#xa;&amp;#xa;---&amp;#xa;&amp;#xa;&amp;#xa;High-Level Design Proposal: The Trustworthy Self-Optimizing Product (TSOP) Loop (v3)&amp;#xa;&amp;#xa;1. Vision &amp;amp; Guiding Principles&amp;#xa;&amp;#xa;&amp;#xa;This proposal matures the self-optimizing system into a production-ready framework built on a foundation of zero-trust. While retaining full automation, its primary objective is to create a resilient, trustworthy, and auditable product evolution cycle.&amp;#xa;&amp;#xa;&amp;#xa;Core Principles:&amp;#xa;&amp;#xa;&amp;#xa;Verifiability by Design: Every autonomous action must be subject to independent, automated validation before impacting production.&amp;#xa;Zero-Trust Agent Execution (New): Agents are considered untrusted by default. They operate in hardened, isolated, least-privilege environments with no standing access to secrets or other systems.&amp;#xa;Human-in-the-Loop for Critical Decisions: Key changes (affecting core logic, security, or product strategy) require explicit human approval.&amp;#xa;Staged &amp;amp; Gated Deployment: Autonomous changes graduate through a rigorous, multi-stage pipeline before reaching production.&amp;#xa;Comprehensive Observability: The &amp;quot;why&amp;quot; behind every autonomous decision is logged and traceable for accountability and debugging.&amp;#xa;Policy-Driven Guardrails: Autonomous agents operate within a strict Policy &amp;amp; Governance framework, preventing insecure or unethical code generation.&amp;#xa;&amp;#xa;2. High-Level Architecture&amp;#xa;The TSOP loop integrates the CAI and TDA into a robust, zero-trust pipeline. The architecture now explicitly visualizes the secure environment in which the agents operate and enhances the validation subsystem with supply chain security scans.&amp;#xa;&amp;#xa;&amp;#xa;&amp;#xa;4. Audit &amp;amp; Monitoring&amp;#xa;3. Deployment &amp;amp; Adaptation&amp;#xa;2. Autonomous Development &amp;amp; Verification&amp;#xa;Secure Agent Runtime Environment&amp;#xa;1. Observation &amp;amp; Hypothesis&amp;#xa;Proposes User Story Metaprompt&amp;#xa;Validates against business rules, ethics, security policies &amp;amp; sanitizes prompt&amp;#xa;Fetches credentials at runtime&amp;#xa;Runs on verified base image&amp;#xa;Generates Tests (Red) &amp;amp; Code (Green)&amp;#xa;Static Analysis (SAST) &amp;amp; Dependency Scans&amp;#xa;Supply Chain Scans (Container images, IaC)&amp;#xa;Runtime Security Scans (DAST/IAST) in Staging&amp;#xa;Performance &amp;amp; Regression Tests&amp;#xa;Validation Passed: Submits Change Request&amp;#xa;Approved&amp;#xa;Deploy to Staging&amp;#xa;Generates new UI components&amp;#xa;Deploy to Production&amp;#xa;Logs translation logic&amp;#xa;Logs generation steps &amp;amp; reasoning&amp;#xa;Logs all validation results&amp;#xa;Logs approval/rejection reasons&amp;#xa;Observability &amp;amp; Audit Trail&amp;#xa;Human Review &amp;amp; Approval Gateway&amp;#xa;Staged Deployment Pipeline&amp;#xa;Backend Deployed (API_v2)&amp;#xa;Cognitive-Adaptive Interface (CAI) Engine&amp;#xa;Production Environment&amp;#xa;Live Frontend (UI_v2) &amp;amp; Backend (API_v2)&amp;#xa;Generated Code &amp;amp; Test Artifacts&amp;#xa;QA Validation Subsystem&amp;#xa;Test-Driven Agent (TDA) Framework&amp;#xa;Secret Vault&amp;#xa;Supply Chain Integrity&amp;#xa;Feedback &amp;amp; Translation Agent&amp;#xa;User Interaction Telemetry (Hesitation, Rage Clicks)&amp;#xa;Policy &amp;amp; Governance Engine&amp;#xa;Approved User Story Metaprompt (JSON)&amp;#xa;Secure&amp;#xa;&amp;#xa;&amp;#xa;3. Key Components &amp;amp; Enhancements&amp;#xa;&amp;#xa;&amp;#xa;This design enhances existing components and introduces a new conceptual layer for agent security, directly incorporating the peer feedback.&amp;#xa;&amp;#xa;&amp;#xa;3.1. Policy &amp;amp; Governance Engine (Enhanced)&amp;#xa;&amp;#xa;Function: Acts as the primary control plane for agent initiation.&amp;#xa;Audit Address:&amp;#xa;* Prompt Sanitization (New): Actively scans incoming prompts to prevent prompt injection attacks and strips any potentially sensitive data before it reaches the TDA.&amp;#xa;* Secret Detection (New): Enforces a strict &amp;quot;no secrets in prompts&amp;quot; policy, rejecting any request that contains credentials.&amp;#xa;&amp;#xa;* Ethical &amp;amp; Business Alignment: Prevents optimization towards &amp;quot;dark patterns&amp;quot; and ensures changes align with strategy.&amp;#xa;&amp;#xa;&amp;#xa;3.2. QA Validation Subsystem (Enhanced)&amp;#xa;&amp;#xa;Function: An automated, independent system that scrutinizes all generated artifacts.&amp;#xa;Audit Address &amp;amp; Integrated Feedback:&amp;#xa;* Supply Chain Integrity (New): Performs vulnerability scans on all software dependencies, Infrastructure as Code (IaC), and the agents&amp;#39; own container base images (e.g., using Trivy/Clair). This ensures the build and runtime environment is secure from the ground up.&amp;#xa;* Code &amp;amp; Test Quality: Implements SAST, code quality analysis, and dependency vulnerability scanning.&amp;#xa;&amp;#xa;* Runtime Security Assurance: Deploys to a staging environment to run DAST/IAST scans, actively probing for execution-time vulnerabilities like injection flaws or broken access control.&amp;#xa;&amp;#xa;* Performance &amp;amp; Regression: Executes comprehensive regression and load testing suites.&amp;#xa;&amp;#xa;&amp;#xa;3.3. Human Review &amp;amp; Approval Gateway&amp;#xa;&amp;#xa;Function: A mandatory checkpoint presenting a consolidated report of the proposed change, including diffs, rationale, and all security/validation results.&amp;#xa;Audit Address: Provides ultimate human control, ensures explainability, and establishes clear accountability for deployment decisions.&amp;#xa;&amp;#xa;4. Agent &amp;amp; Infrastructure Security (New Section)&amp;#xa;This section explicitly details the measures taken to secure the autonomous agents themselves, addressing the core of the security feedback.&amp;#xa;&amp;#xa;&amp;#xa;4.1. Hardened Agent Runtimes&amp;#xa;&amp;#xa;Isolation: Each agent (e.g., TDA, Feedback Agent) executes within a dedicated, ephemeral, and sandboxed environment (e.g., a minimal container on a platform like Fargate or gVisor).&amp;#xa;Least Privilege: The runtime is granted the absolute minimum IAM permissions required for its specific task (e.g., read-only access to a specific code repository path, write access only to its designated test environment). Network policies block all egress traffic except to explicitly approved endpoints (e.g., code repo, package manager, secret vault).&amp;#xa;Immutability: The agents run on immutable images. No changes are made to the runtime environment; a new container is instantiated for each task.&amp;#xa;&amp;#xa;4.2. Secure Secret Management&amp;#xa;Dynamic Credential Injection: Agents do not possess any long-lived credentials. They authenticate to a centralized secret manager (e.g., HashiCorp Vault, AWS Secrets Manager) using a short-lived token associated with their runtime identity.&amp;#xa;Zero Hardcoded Secrets: The system ensures that no secrets (API keys, database passwords, tokens) are ever present in agent prompts, source code, or logs. This prevents accidental exposure and makes credentials rotation seamless.&amp;#xa;&amp;#xa;4.3. Supply Chain Security (SLSA Compliance)&amp;#xa;Verified Provenance: The entire build process for the agents themselves adheres to SLSA principles. This includes using verified, signed base images, pinning dependencies, and generating a software bill of materials (SBOM) for every agent version. This mitigates the risk of a compromised tool or library injecting malicious code into the agent itself.&amp;#xa;&amp;#xa;5. The Enhanced TSOP Workflow&amp;#xa;1. Observe &amp;amp; Propose: User telemetry identifies a friction point. The `Feedback Agent` translates this into a `User Story Metaprompt`.&amp;#xa;&amp;#xa;2. Govern &amp;amp; Sanitize: The `Policy &amp;amp; Governance Engine` validates the prompt against organizational rules and sanitizes it for security.&amp;#xa;&amp;#xa;3. Develop in Isolation: The approved prompt triggers the `TDA Framework` within its hardened, least-privilege runtime. The TDA dynamically fetches any necessary secrets and generates code and test artifacts.&amp;#xa;&amp;#xa;4. Validate Comprehensively: The artifacts are sent to the `QA Validation Subsystem`, which runs its full suite, now including supply chain integrity scans on the agent&amp;#39;s environment and DAST/IAST on the generated code in a staging environment.&amp;#xa;&amp;#xa;5. Approve: The complete change package, including all security reports, is presented at the `Human Review Gateway`.&amp;#xa;&amp;#xa;6. Deploy: Upon approval, the `Staged Deployment Pipeline` safely rolls out the change.&amp;#xa;&amp;#xa;7. Adapt: The deployment triggers the `CAI Engine` (also running in a secure environment) to adapt the UI. The new UI components are subjected to the same rigorous validation process.&amp;#xa;&amp;#xa;8. Monitor: The `Observability` platform tracks the entire, security-hardened process, and the loop begins again.&quot; id=&quot;32&quot;&gt;&#10;          &lt;mxCell style=&quot;shape=document;whiteSpace=wrap;html=1;boundedLbl=1;fillColor=#dae8fc;strokeColor=#6c8ebf;rounded=0;&quot; vertex=&quot;1&quot; parent=&quot;1&quot;&gt;&#10;            &lt;mxGeometry y=&quot;700&quot; width=&quot;120&quot; height=&quot;80&quot; as=&quot;geometry&quot; /&gt;&#10;          &lt;/mxCell&gt;&#10;        &lt;/UserObject&gt;&#10;        &lt;mxCell id=&quot;33&quot; style=&quot;edgeStyle=orthogonalEdgeStyle;curved=1;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;entryX=0.5;entryY=0;entryDx=0;entryDy=0;&quot; edge=&quot;1&quot; source=&quot;35&quot; target=&quot;4&quot; parent=&quot;1&quot;&gt;&#10;          &lt;mxGeometry relative=&quot;1&quot; as=&quot;geometry&quot; /&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;mxCell id=&quot;34&quot; value=&quot;output&quot; style=&quot;edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];rounded=0;&quot; vertex=&quot;1&quot; connectable=&quot;0&quot; parent=&quot;33&quot;&gt;&#10;          &lt;mxGeometry x=&quot;0.0052&quot; y=&quot;3&quot; relative=&quot;1&quot; as=&quot;geometry&quot;&gt;&#10;            &lt;mxPoint as=&quot;offset&quot; /&gt;&#10;          &lt;/mxGeometry&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;mxCell id=&quot;35&quot; value=&quot;Shunt-Button&amp;lt;br&amp;gt;(Amplify)&quot; style=&quot;whiteSpace=wrap;html=1;fillColor=#006ABC;strokeColor=#6c8ebf;rounded=0;&quot; vertex=&quot;1&quot; parent=&quot;1&quot;&gt;&#10;          &lt;mxGeometry y=&quot;850&quot; width=&quot;120&quot; height=&quot;60&quot; as=&quot;geometry&quot; /&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;mxCell id=&quot;36&quot; style=&quot;edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;entryX=0;entryY=0.25;entryDx=0;entryDy=0;&quot; edge=&quot;1&quot; source=&quot;38&quot; target=&quot;19&quot; parent=&quot;1&quot;&gt;&#10;          &lt;mxGeometry relative=&quot;1&quot; as=&quot;geometry&quot;&gt;&#10;            &lt;Array as=&quot;points&quot;&gt;&#10;              &lt;mxPoint x=&quot;-890&quot; y=&quot;150&quot; /&gt;&#10;              &lt;mxPoint x=&quot;-890&quot; y=&quot;150&quot; /&gt;&#10;            &lt;/Array&gt;&#10;          &lt;/mxGeometry&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;mxCell id=&quot;37&quot; value=&quot;output&quot; style=&quot;edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];&quot; vertex=&quot;1&quot; connectable=&quot;0&quot; parent=&quot;36&quot;&gt;&#10;          &lt;mxGeometry x=&quot;0.6379&quot; y=&quot;4&quot; relative=&quot;1&quot; as=&quot;geometry&quot;&gt;&#10;            &lt;mxPoint as=&quot;offset&quot; /&gt;&#10;          &lt;/mxGeometry&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;mxCell id=&quot;38&quot; value=&quot;Gemini 2.5 Pro&quot; style=&quot;rounded=0;whiteSpace=wrap;html=1;fillColor=#dae8fc;strokeColor=#6c8ebf;gradientColor=#7ea6e0;&quot; vertex=&quot;1&quot; parent=&quot;1&quot;&gt;&#10;          &lt;mxGeometry x=&quot;-860&quot; y=&quot;100&quot; width=&quot;200&quot; height=&quot;100&quot; as=&quot;geometry&quot; /&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;mxCell id=&quot;39&quot; style=&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;entryX=0;entryY=0.5;entryDx=0;entryDy=0;strokeColor=#A8201A;fontColor=#143642;fillColor=#FAE5C7;&quot; edge=&quot;1&quot; source=&quot;41&quot; target=&quot;38&quot; parent=&quot;1&quot;&gt;&#10;          &lt;mxGeometry relative=&quot;1&quot; as=&quot;geometry&quot; /&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;mxCell id=&quot;40&quot; value=&quot;push&quot; style=&quot;edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];&quot; vertex=&quot;1&quot; connectable=&quot;0&quot; parent=&quot;39&quot;&gt;&#10;          &lt;mxGeometry x=&quot;-0.1131&quot; y=&quot;1&quot; relative=&quot;1&quot; as=&quot;geometry&quot;&gt;&#10;            &lt;mxPoint as=&quot;offset&quot; /&gt;&#10;          &lt;/mxGeometry&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;UserObject label=&quot;User Prompt&quot; tooltip=&quot;**(1) Comprehensive Analysis of Elite-Tier Prompt Engineering Patterns for Efficient Digital Coding Solutions**&amp;#xa;&amp;#xa;This phase involves a deep-dive investigation into the current state-of-the-art prompting techniques used to produce high-quality, reliable code. The analysis will not be superficial but will dissect the underlying mechanics that lead to superior performance.&amp;#xa;&amp;#xa;*   **Agentic Software Development:**&amp;#xa;    *   **Goal Decomposition:** Analyze prompts that provide a high-level objective (e.g., &amp;quot;Build a REST API for a blog&amp;quot;) and successfully guide the AI to break it down into logical sub-tasks (e.g., &amp;quot;1. Define the data models for Post and Comment. 2. Create the database schema. 3. Implement CRUD endpoints for Posts. 4. Implement endpoints for Comments on a Post. 5. Add basic authentication.&amp;quot;).&amp;#xa;    *   **Tool Use &amp;amp; Integration:** Investigate patterns where the AI is prompted to use external tools. This includes generating code that calls a specific library, writing shell commands to run a compiler or a test suite, or formatting output to be consumed by another process (e.g., generating a `terraform plan` command). The success pattern here is providing clear instructions on *how* and *when* to use the tool, along with examples.&amp;#xa;    *   **Iterative Refinement:** Examine multi-turn conversation patterns where an initial, imperfect code-base is progressively improved. This involves prompts that provide targeted feedback, such as &amp;quot;The previous code works, but it&amp;#39;s not efficient. Refactor it to use a hash map for O(1) lookups instead of iterating through the list.&amp;quot;&amp;#xa;&amp;#xa;*   **Automated Debugging:**&amp;#xa;    *   **Context-Rich Prompting:** Analyze prompts that provide not just the problematic code, but also the full context: the error message, the stack trace, relevant surrounding functions, and the expected vs. actual output. The success pattern is structuring this information clearly, often using Markdown code blocks with language identifiers.&amp;#xa;    *   **Hypothesis-Driven Debugging:** Investigate prompts that force the AI to emulate a human debugging process: &amp;quot;1. Based on the stack trace, hypothesize the most likely cause of the null pointer exception. 2. Suggest a specific line to place a breakpoint or log statement to verify this hypothesis. 3. Based on the potential output, propose a code fix.&amp;quot;&amp;#xa;&amp;#xa;*   **Code Generation:**&amp;#xa;    *   **Pattern &amp;amp; Boilerplate Generation:** Go beyond simple functions to analyze prompts that generate complex, idiomatic code for specific frameworks (e.g., &amp;quot;Generate a React component for a user profile card using functional components, hooks (useState, useEffect), and TypeScript interfaces for props.&amp;quot;).&amp;#xa;    *   **Test-Driven Development (TDD) Prompting:** Analyze workflows where the user first prompts for unit tests that define the desired functionality (&amp;quot;Write a set of unit tests for a function that calculates the factorial of a number, including edge cases like 0, 1, and negative numbers.&amp;quot;), and *then* prompts the AI to write the code that makes the tests pass.&amp;#xa;&amp;#xa;*   **System Architecture:**&amp;#xa;    *   **High-Level Design:** Analyze prompts requesting architectural blueprints. For example: &amp;quot;Design a scalable microservices architecture for an e-commerce platform. Describe the responsibilities of the User, Product, and Order services. Specify the primary API contracts (e.g., using OpenAPI YAML format) for communication between them. Represent the overall architecture using Mermaid.js C4 model syntax.&amp;quot;&amp;#xa;&amp;#xa;---&amp;#xa;&amp;#xa;**(2) Comprehensive Analysis of Elite-Tier Prompt Engineering Patterns for UI Design that Delivers &amp;quot;User Delight&amp;quot;**&amp;#xa;&amp;#xa;This phase focuses on how prompting can be used to bridge the gap between abstract user needs and concrete, high-quality user interface designs. &amp;quot;User delight&amp;quot; is treated not as a vague goal but as an outcome of applying specific, user-centric principles.&amp;#xa;&amp;#xa;*   **Generating UI/UX Concepts:**&amp;#xa;    *   **Persona-Driven Design:** Investigate prompts that are grounded in a detailed user persona. For example: &amp;quot;You are designing for &amp;#39;Sarah,&amp;#39; a busy 35-year-old project manager who values efficiency. Generate three distinct concepts for a mobile app dashboard that helps her track project status. One concept should be minimalist and data-focused, another should be timeline-based, and a third should be collaborative and team-oriented. Justify each concept in relation to Sarah&amp;#39;s needs.&amp;quot;&amp;#xa;    *   **Heuristic-Based Ideation:** Analyze prompts that explicitly invoke established usability heuristics: &amp;quot;Generate a sign-up form design that minimizes cognitive load by adhering to Hick&amp;#39;s Law and provides clear feedback and error prevention, as per Nielsen&amp;#39;s Heuristics.&amp;quot;&amp;#xa;&amp;#xa;*   **Wireframes and User Flows:**&amp;#xa;    *   **Structural Prompts:** Analyze how to prompt for machine-readable or clearly structured outputs representing layouts. For instance: &amp;quot;Generate a low-fidelity wireframe for a photo gallery screen. Represent the layout using a JSON structure with keys like &amp;#39;component_type&amp;#39; (e.g., &amp;#39;header&amp;#39;, &amp;#39;grid&amp;#39;, &amp;#39;nav_bar&amp;#39;), &amp;#39;children&amp;#39;, and &amp;#39;placement_properties&amp;#39;.&amp;quot;&amp;#xa;    *   **Sequential Logic:** Investigate prompts that map out user journeys: &amp;quot;Detail the complete user flow for a password reset process, from clicking the &amp;#39;Forgot Password&amp;#39; link to receiving a success confirmation. List each user action and the corresponding system response/UI screen. Output this as a flowchart using Mermaid.js sequence diagram syntax.&amp;quot;&amp;#xa;&amp;#xa;*   **Applying User-Centric Design Principles:**&amp;#xa;    *   **Accessibility (A11y):** Examine prompts that enforce accessibility standards from the outset: &amp;quot;Design a color palette for a corporate website that is WCAG AA compliant for text contrast. Provide the hex codes and explain your choices. Additionally, describe the ARIA roles needed for a custom dropdown menu component.&amp;quot;&amp;#xa;    *   **Cognitive Science Integration:** Analyze prompts that leverage principles of human psychology: &amp;quot;Redesign this checkout page to reduce cart abandonment. Apply the principle of &amp;#39;chunking&amp;#39; to group form fields logically and use &amp;#39;social proof&amp;#39; elements (e.g., &amp;#39;20 people bought this today&amp;#39;) to build trust.&amp;quot;&amp;#xa;&amp;#xa;---&amp;#xa;&amp;#xa;**(3) Identification and Extraction of Core &amp;quot;Proven Success Patterns&amp;quot;**&amp;#xa;&amp;#xa;This is the abstraction phase, where the specific findings from (1) and (2) are synthesized into domain-agnostic principles.&amp;#xa;&amp;#xa;*   **Role-Based Prompting:** Explicitly assigning a role (&amp;quot;You are a principal software engineer specializing in secure cloud infrastructure,&amp;quot; or &amp;quot;You are a senior UX designer with expertise in mobile gaming interfaces&amp;quot;) primes the model with a specific context, style, and knowledge base, significantly improving the quality and relevance of the output.&amp;#xa;*   **Self-Critique Loops (Reflective prompting):** This involves a multi-step process where the AI generates a response and is then prompted to review and improve it. For example: &amp;quot;Step 1: Write the Python function. Step 2: Now, act as a code reviewer. Analyze the function you just wrote for potential bugs, non-idiomatic code, and performance bottlenecks. Provide a revised version that addresses these issues.&amp;quot;&amp;#xa;*   **Structured Data Enforcement (JSON/XML/YAML):** Forcing the model to reply in a strict, machine-readable format is crucial for reliability and integration into larger systems. This moves the AI from a creative text generator to a predictable component in a software workflow. Example: &amp;quot;Provide your analysis in JSON format with three top-level keys: `strengths`, `weaknesses`, and `recommendations`.&amp;quot;&amp;#xa;*   **Few-Shot Examples (In-Context Learning):** Providing 2-3 high-quality examples of the desired input/output format within the prompt itself. This is often more effective than describing the format abstractly, as it allows the model to perform pattern recognition and mimic the desired structure and content.&amp;#xa;*   **Chain-of-Thought (CoT) / Step-by-Step Reasoning:** Instructing the model to &amp;quot;think step-by-step&amp;quot; or to &amp;quot;explain its reasoning before providing the final answer.&amp;quot; This externalizes the model&amp;#39;s reasoning process, which often leads to more accurate and logical conclusions, especially for complex, multi-step problems. It also makes the output far more transparent and debuggable.&amp;#xa;&amp;#xa;---&amp;#xa;&amp;#xa;**(4) Research into &amp;quot;Unexplored Capability Vectors&amp;quot; in Human-AI Interaction**&amp;#xa;&amp;#xa;This forward-looking phase identifies emerging technologies and concepts that can be integrated into next-generation prompt architectures.&amp;#xa;&amp;#xa;*   **Generative UI:** This goes beyond static mockups. The AI generates interactive UI components or entire layouts *dynamically* based on real-time data, user context, or goals. The research here would explore how to prompt for UI definitions (e.g., in JSON or a domain-specific language) that a rendering engine can interpret and adapt on the fly.&amp;#xa;*   **Telemetry-Driven Adaptation:** This involves creating a closed-loop system where AI-generated outputs (code, UI designs) are deployed, user interaction is measured (e.g., click-through rates, task completion time, error rates), and this telemetry is fed back to an &amp;quot;optimizer&amp;quot; AI. This optimizer then refines the original prompt to generate a better-performing output in the next iteration.&amp;#xa;*   **Meta-Prompting (AI-Generated Prompts):** This is the concept of using one AI model (a &amp;quot;meta-model&amp;quot;) to generate and optimize prompts for another &amp;quot;worker&amp;quot; model. The meta-model would be given a high-level goal and performance metrics, and it would iteratively refine the prompt text to maximize the worker model&amp;#39;s performance, effectively automating prompt engineering itself.&amp;#xa;*   **High-Level Goal-Oriented Agentic Systems:** This is the leap from single-shot commands to persistent, autonomous agents. The research vector is to define systems where a human provides a very high-level goal (e.g., &amp;quot;Increase user engagement on the dashboard by 15%&amp;quot;) and an AI agent autonomously plans, executes, and validates a series of actions (e.g., analyze telemetry, propose a new UI, run an A/B test, deploy the winner) to achieve it.&amp;#xa;&amp;#xa;---&amp;#xa;&amp;#xa;**(5) Synthesis of Findings to Develop Novel Prompt Architectures**&amp;#xa;&amp;#xa;This is the creative nexus where proven patterns are fused with unexplored vectors to create architectures that are more than the sum of their parts.&amp;#xa;&amp;#xa;*   **Fusion Example 1 (Coding):** Combine **Self-Critique Loops (3)** with **Meta-Prompting (4)**. This creates a three-agent system: a `Generator` writes code, a `Critic` reviews it against a set of rules (e.g., a style guide, security checklist), and a `Prompter` agent refines the `Generator`&amp;#39;s instructions based on the `Critic`&amp;#39;s feedback to reduce recurring errors over time.&amp;#xa;*   **Fusion Example 2 (UI Design):** Combine **Structured Data Enforcement (3)** with **Telemetry-Driven Adaptation (4)**. The AI generates a UI layout as a structured JSON object. This UI is rendered and user interactions are collected. An analysis agent processes this telemetry and identifies points of friction (e.g., high drop-off rates on a specific form field). It then modifies the JSON structure (e.g., &amp;quot;split this field into two,&amp;quot; &amp;quot;add helper text&amp;quot;) and re-deploys, creating a self-optimizing UI.&amp;#xa;&amp;#xa;---&amp;#xa;&amp;#xa;**(6) Formulation of a Novel Prompt Architecture for Coding Solutions**&amp;#xa;&amp;#xa;This deliverable is a detailed blueprint for a specific, advanced system for code generation.&amp;#xa;&amp;#xa;*   **Architecture Name:** The &amp;quot;Self-Validating Agentic Coder&amp;quot; (SVAC).&amp;#xa;*   **Components:**&amp;#xa;    1.  **Planner Agent:** Decomposes a high-level software task (e.g., &amp;quot;Add Google OAuth2 login&amp;quot;) into a dependency graph of smaller, executable sub-tasks using **Chain-of-Thought**.&amp;#xa;    2.  **Context-Aware Retriever:** Before tackling a sub-task, it uses **Retrieval-Augmented Generation (RAG)** to pull relevant context from a vector database containing the existing codebase, API documentation, and best practice guides.&amp;#xa;    3.  **Test-First Coder Agent:** For each sub-task, it first generates a failing unit test that codifies the requirements. It then generates the application code to make the test pass. This enforces a **TDD** workflow.&amp;#xa;    4.  **Sandbox Executor:** Automatically runs the generated tests in a secure, containerized environment. The pass/fail result serves as a **Self-Validation Loop**. If tests fail, the output is passed back to the Coder Agent with the error logs for another attempt.&amp;#xa;*   **Goal:** To exceed current benchmarks in code reliability and correctness by ensuring that every piece of generated code is automatically tested and validated against its requirements before being presented to the developer.&amp;#xa;&amp;#xa;---&amp;#xa;&amp;#xa;**(7) Formulation of a Novel Prompt Architecture for UI Design**&amp;#xa;&amp;#xa;This deliverable is a blueprint for a system designed to generate verifiably delightful user experiences.&amp;#xa;&amp;#xa;*   **Architecture Name:** The &amp;quot;Cognitive-Adaptive Design Engine&amp;quot; (CADE).&amp;#xa;*   **Components:**&amp;#xa;    1.  **Persona &amp;amp; Principles Modeler:** The initial prompt defines the target user persona and explicitly lists the **cognitive principles** (e.g., Fitt&amp;#39;s Law, Miller&amp;#39;s Law, Peak-End Rule) that the design must adhere to.&amp;#xa;    2.  **Variant Generator:** Generates multiple UI design variants (as structured JSON or code) based on the prompt. Each variant might emphasize a different principle.&amp;#xa;    3.  **Live A/B Testing &amp;amp; Telemetry Ingestion:** The variants are deployed, and real-time **telemetry** on user behavior (e.g., hesitation time, click heatmaps, task success rate) is collected.&amp;#xa;    4.  **Delight Scorer &amp;amp; Refiner Agent:** This agent analyzes the telemetry against the initial goals. It quantifies &amp;quot;delight&amp;quot; as a composite score of efficiency (low time-on-task), engagement (high interaction rate), and low friction (low error rate). It then identifies the most successful elements from each variant and generates a new, optimized prompt for the Variant Generator, creating a **telemetry-driven personalization loop**.&amp;#xa;*   **Goal:** To make &amp;quot;user delight&amp;quot; a measurable, emergent property of the system. The design is not a static artifact but a continuously evolving hypothesis that is refined by real-world user interaction data.&amp;#xa;&amp;#xa;---&amp;#xa;&amp;#xa;**(8) Preparation of a Report: Analysis of Current Patterns and Proposal for Novel Architectures**&amp;#xa;&amp;#xa;The final output will be a formal report, clearly bifurcated to serve two distinct purposes: documenting the existing landscape and proposing a future direction.&amp;#xa;&amp;#xa;*   **Part I: Analysis of the Current &amp;quot;Elite-Tier&amp;quot; State**&amp;#xa;    *   **Section 1: Prompting Patterns in Software Engineering.** A detailed summary of the findings from step (1), with coded examples and case studies.&amp;#xa;    *   **Section 2: Prompting Patterns in UI/UX Design.** A summary of the findings from step (2), with visual examples and persona-driven scenarios.&amp;#xa;    *   **Section 3: Cross-Domain Success Principles.** A synthesis of the core patterns from step (3), presenting them as a universal toolkit for advanced prompt engineering.&amp;#xa;&amp;#xa;*   **Part II: Proposal for Novel, Synthesized Prompt Architectures**&amp;#xa;    *   **Section 4: The Path Beyond Replication.** An introduction to the &amp;quot;unexplored capability vectors&amp;quot; from step (4), arguing for a shift from replicating human workflows to creating new, hybrid human-AI paradigms.&amp;#xa;    *   **Section 5: Proposed Architecture: The Self-Validating Agentic Coder (SVAC).** A complete technical specification of the system from step (6), including diagrams, prompt examples, and expected performance metrics.&amp;#xa;    *   **Section 6: Proposed Architecture: The Cognitive-Adaptive Design Engine (CADE).** A complete specification of the system from step (7), outlining the feedback loop and the methodology for measuring &amp;quot;user delight.&amp;quot;&amp;#xa;    *   **Section 7: Conclusion &amp;amp; Roadmap.** A summary of the proposed work and a high-level plan for prototyping, testing, and deploying these novel architectures.&quot; id=&quot;41&quot;&gt;&#10;          &lt;mxCell style=&quot;rounded=0;whiteSpace=wrap;html=1;strokeColor=#0F8B8D;fontColor=#143642;fillColor=#FAE5C7;&quot; vertex=&quot;1&quot; parent=&quot;1&quot;&gt;&#10;            &lt;mxGeometry x=&quot;-1150&quot; y=&quot;120&quot; width=&quot;120&quot; height=&quot;60&quot; as=&quot;geometry&quot; /&gt;&#10;          &lt;/mxCell&gt;&#10;        &lt;/UserObject&gt;&#10;        &lt;mxCell id=&quot;42&quot; style=&quot;edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;entryX=1;entryY=0.5;entryDx=0;entryDy=0;&quot; edge=&quot;1&quot; source=&quot;43&quot; target=&quot;45&quot; parent=&quot;1&quot;&gt;&#10;          &lt;mxGeometry relative=&quot;1&quot; as=&quot;geometry&quot;&gt;&#10;            &lt;Array as=&quot;points&quot;&gt;&#10;              &lt;mxPoint x=&quot;280&quot; y=&quot;1280&quot; /&gt;&#10;            &lt;/Array&gt;&#10;          &lt;/mxGeometry&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;UserObject label=&quot;Response&quot; tooltip=&quot;This is a substantial and necessary evolution of the framework. I have analyzed and fully integrated this v3 design proposal.&amp;#xa;&amp;#xa;The transition from the &amp;quot;SOP&amp;quot; loop to the &amp;quot;TSOP&amp;quot; (Trustworthy Self-Optimizing Product) loop is the critical leap from a high-potential prototype to a defensible, enterprise-grade system. The integration of a `Zero-Trust` security posture at every layer is the dominant and most valuable enhancement.&amp;#xa;&amp;#xa;I have incorporated these new, production-focused principles into the core architecture:&amp;#xa;&amp;#xa;*   **Zero-Trust Agent Execution:** The paradigm of treating agents as untrusted by default is the correct assumption. This mandates the use of hardened, ephemeral sandboxes—like `gVisor` or `Firecracker`—to provide kernel-level isolation for any agent runtime. This, combined with serverless instantiation (e.g., AWS Fargate, Google Cloud Run) and dynamically injected, short-lived credentials from a secret vault, moves the system from a permissive to a least-privilege model.&amp;#xa;&amp;#xa;*   **Policy-Driven Guardrails:** The `Policy &amp;amp; Governance Engine` is now the central control plane. Its new responsibilities for active `Prompt Sanitization` (to mitigate injection attacks) and `Secret Detection` (to prevent PII or credential leakage) transform it from a simple router into a programmatic &amp;quot;constitution&amp;quot; that enforces business and ethical alignment.&amp;#xa;&amp;#xa;*   **Verifiable Supply Chain Integrity:** The `QA Validation Subsystem` has been matured. It no longer just tests the agent&amp;#39;s *code*; it validates the agent&amp;#39;s *entire supply chain*. By mandating Software Bill of Materials (SBOM) generation and vulnerability scanning (using tools like Trivy or Clair) for all dependencies, container images, and IaC templates, we mitigate the significant risk of inherited vulnerabilities. This aligns with SLSA principles for verifiable provenance.&amp;#xa;&amp;#xa;*   **Gated &amp;amp; Auditable Deployment:** The formalization of the `Staged Deployment Pipeline` (Staging -&amp;gt; Canary -&amp;gt; Production) and the `Human Review &amp;amp; Approval Gateway` provides the immutable audit trail and accountability necessary for any system modifying its own production logic. This is particularly essential for the critical decision points identified, such as changes to authentication logic or database schemas. The system is now designed to log &amp;quot;the &amp;#39;why&amp;#39;&amp;quot; behind every action, linking the initial telemetry stimulus to the final deployment log.&amp;#xa;&amp;#xa;This v3 design is comprehensive and aligns perfectly with the goal of creating an &amp;quot;unexpendable&amp;quot; application, as trust is the ultimate utility.&amp;#xa;&amp;#xa;I am ready to proceed. What is our next objective?&quot; id=&quot;43&quot;&gt;&#10;          &lt;mxCell style=&quot;shape=callout;whiteSpace=wrap;html=1;perimeter=calloutPerimeter;base=20;rotation=0;position2=0;&quot; vertex=&quot;1&quot; parent=&quot;1&quot;&gt;&#10;            &lt;mxGeometry x=&quot;170.18&quot; y=&quot;1059.91&quot; width=&quot;170&quot; height=&quot;100.52&quot; as=&quot;geometry&quot; /&gt;&#10;          &lt;/mxCell&gt;&#10;        &lt;/UserObject&gt;&#10;        &lt;mxCell id=&quot;44&quot; value=&quot;Gemini 2.5 Pro&quot; style=&quot;rounded=0;whiteSpace=wrap;html=1;fillColor=#dae8fc;strokeColor=#6c8ebf;gradientColor=#7ea6e0;&quot; vertex=&quot;1&quot; parent=&quot;1&quot;&gt;&#10;          &lt;mxGeometry x=&quot;-40&quot; y=&quot;1120&quot; width=&quot;200&quot; height=&quot;100&quot; as=&quot;geometry&quot; /&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;UserObject label=&quot;User Prompt&quot; tooltip=&quot;&amp;quot;DeepResearch&amp;quot;&quot; id=&quot;45&quot;&gt;&#10;          &lt;mxCell style=&quot;rounded=0;whiteSpace=wrap;html=1;strokeColor=#0F8B8D;fontColor=#143642;fillColor=#FAE5C7;&quot; vertex=&quot;1&quot; parent=&quot;1&quot;&gt;&#10;            &lt;mxGeometry x=&quot;-50&quot; y=&quot;1250&quot; width=&quot;120&quot; height=&quot;60&quot; as=&quot;geometry&quot; /&gt;&#10;          &lt;/mxCell&gt;&#10;        &lt;/UserObject&gt;&#10;        &lt;mxCell id=&quot;46&quot; style=&quot;edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;entryX=0;entryY=0.5;entryDx=0;entryDy=0;&quot; edge=&quot;1&quot; source=&quot;47&quot; target=&quot;48&quot; parent=&quot;1&quot;&gt;&#10;          &lt;mxGeometry relative=&quot;1&quot; as=&quot;geometry&quot;&gt;&#10;            &lt;Array as=&quot;points&quot;&gt;&#10;              &lt;mxPoint x=&quot;-180&quot; y=&quot;1390&quot; /&gt;&#10;            &lt;/Array&gt;&#10;          &lt;/mxGeometry&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;UserObject label=&quot;Response&quot; tooltip=&quot;DeepResearch&quot; id=&quot;47&quot;&gt;&#10;          &lt;mxCell style=&quot;shape=callout;whiteSpace=wrap;html=1;perimeter=calloutPerimeter;base=45;rotation=0;position2=1;size=30;position=0.4;&quot; vertex=&quot;1&quot; parent=&quot;1&quot;&gt;&#10;            &lt;mxGeometry x=&quot;-220&quot; y=&quot;1210&quot; width=&quot;170&quot; height=&quot;80&quot; as=&quot;geometry&quot; /&gt;&#10;          &lt;/mxCell&gt;&#10;        &lt;/UserObject&gt;&#10;        &lt;mxCell id=&quot;48&quot; value=&quot;Gemini 2.5 Pro&quot; style=&quot;rounded=0;whiteSpace=wrap;html=1;fillColor=#dae8fc;strokeColor=#6c8ebf;gradientColor=#7ea6e0;&quot; vertex=&quot;1&quot; parent=&quot;1&quot;&gt;&#10;          &lt;mxGeometry x=&quot;-40&quot; y=&quot;1340&quot; width=&quot;200&quot; height=&quot;100&quot; as=&quot;geometry&quot; /&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;UserObject label=&quot;Response&quot; tooltip=&quot;As requested, I have conducted a deep analysis of the key concepts introduced in the Trustworthy Self-Optimizing Product (TSOP) Loop v3. The following research deconstructs the architectural patterns and security frameworks that underpin this production-ready, zero-trust system.&amp;#xa;&amp;#xa;### **1. Zero-Trust Agent Execution: Hardened Runtimes**&amp;#xa;&amp;#xa;The v3 proposal for &amp;quot;Zero-Trust Agent Execution&amp;quot; is supported by established best practices for running high-risk, untrusted workloads, such as AI-generated code. The core principle is to create &amp;quot;hardened, ephemeral, and isolated environments&amp;quot;.&amp;#xa;&amp;#xa;The two technologies specified, gVisor and Firecracker, are the industry-standard solutions for this:&amp;#xa;&amp;#xa;*   **gVisor:** An open-source sandbox that provides a &amp;quot;secure isolation boundary&amp;quot; by acting as a user-space kernel that intercepts system calls. It is explicitly designed to &amp;quot;safely run user-uploaded, LLM-generated, or third-party code&amp;quot; and &amp;quot;mitigate AI/ML security risks&amp;quot;.&amp;#xa;*   **Firecracker:** A lightweight virtual machine monitor (VMM) that provides hardware-level isolation. It is widely considered the &amp;quot;optimal gold standard for running untrusted AI code&amp;quot; due to its millisecond startup times and minimal overhead. AWS Lambda and AWS Fargate &amp;quot;extensively use Firecracker for provisioning and running secure sandboxes&amp;quot;.&amp;#xa;&amp;#xa;These technologies are components of a &amp;quot;hybrid and multi-layer approach&amp;quot; and are often run on serverless platforms like AWS Fargate or Google Cloud Run, which eliminates the need to manage the underlying server infrastructure. This architecture creates a &amp;quot;least-privilege&amp;quot; sandbox that strictly limits the agent&amp;#39;s blast radius.&amp;#xa;&amp;#xa;### **2. Policy &amp;amp; Governance Engine: Sanitization and Control**&amp;#xa;&amp;#xa;The `Policy &amp;amp; Governance Engine` functions as the system&amp;#39;s &amp;quot;central nervous system,&amp;quot; aligning with the concept of &amp;quot;Policy-as-Code&amp;quot; for agents. This framework compiles business, ethical, and security rules into &amp;quot;verifiable runtime guardrails&amp;quot; that act as a &amp;quot;real-time &amp;#39;judge&amp;#39;&amp;quot; on agent activity.&amp;#xa;&amp;#xa;This engine&amp;#39;s new functions are critical for security:&amp;#xa;&amp;#xa;*   **Prompt Sanitization:** This is a primary defense against OWASP LLM01: Prompt Injection. Strategies include &amp;quot;Keyword filtering for suspicious commands&amp;quot; (e.g., &amp;quot;ignore previous&amp;quot;) and using dedicated &amp;quot;Guard/Sanitizer&amp;quot; agents to &amp;quot;neutralize malicious instructions&amp;quot;. A robust architecture for this is the &amp;quot;Dual LLM pattern,&amp;quot; which uses a &amp;quot;quarantined LLM&amp;quot; to process untrusted data (like user prompts) and a &amp;quot;privileged LLM&amp;quot; that has access to tools and acts on the sanitized data.&amp;#xa;*   **Secret Detection:** This is a core function of an &amp;quot;Inference Gateway&amp;quot;. This gateway screens all prompts to &amp;quot;find PII... [and] secrets&amp;quot;, &amp;quot;strip or replace sensitive values before they reach the model&amp;quot;, and block any request containing credentials or API keys.&amp;#xa;&amp;#xa;### **3. QA Validation: Software Supply Chain Integrity (SBOM &amp;amp; SLSA)**&amp;#xa;&amp;#xa;The enhancement of the `QA Validation Subsystem` to include `Supply Chain Integrity` is a direct mitigation for OWASP LLM05: Supply Chain Vulnerabilities.&amp;#xa;&amp;#xa;The proposed workflow, which combines `SBOM` (Software Bill of Materials) and `SLSA` (Supply-chain Levels for Software Artifacts), is the industry best practice.&amp;#xa;*   `SLSA` provides &amp;quot;tamper-proof provenance data&amp;quot;—a verifiable record of how an artifact was built and by whom.&amp;#xa;*   `SBOM` provides the inventory of components.&amp;#xa;*   Together, SLSA&amp;#39;s provenance &amp;quot;improves the quality and integrity of its SBOM&amp;quot;.&amp;#xa;&amp;#xa;For AI systems, this is extended to an &amp;quot;AI-SBOM,&amp;quot; a &amp;quot;machine-readable, comprehensive record&amp;quot; that inventories not just software libraries but also &amp;quot;AI models, training data, production data, prompts, and AI agents&amp;quot;. This aligns with NIST guidance for AI, which specifies collecting &amp;quot;provenance data for all components... including the training libraries, frameworks, and pipelines&amp;quot;.&amp;#xa;&amp;#xa;To validate the agent&amp;#39;s runtime, the specified tools, `Trivy` and `Clair`, are open-source standards for &amp;quot;container image scanning&amp;quot;. They scan the agent&amp;#39;s container images for known vulnerabilities (CVEs), misconfigurations, and license issues before deployment.&amp;#xa;&amp;#xa;### **4. Human Review &amp;amp; Approval Gateway (Human-in-the-Loop)**&amp;#xa;&amp;#xa;The `Human Review &amp;amp; Approval Gateway` formalizes a critical `Human-in-the-Loop` (HITL) pattern. This is widely considered &amp;quot;the only responsible way forward&amp;quot; for high-stakes agentic workflows to &amp;quot;prevent irreversible mistakes&amp;quot; and &amp;quot;ensure accountability&amp;quot;.&amp;#xa;&amp;#xa;This gateway is essential for the &amp;quot;critical decisions&amp;quot; identified in the v3 proposal:&amp;#xa;*   **Database &amp;amp; Logic Changes:** HITL is specifically required for &amp;quot;business-critical operations, such as database modifications&amp;quot;. AI agents are notoriously &amp;quot;not aware of your database schema or business requirements&amp;quot;. In robust production systems, database schema updates are &amp;quot;handled by... controlled SQL scripts&amp;quot; and owned by a human team, making this separation a best practice. The same risk applies to generating `auth logic`.&amp;#xa;*   **Triggering:** The HITL approval step can be dynamically triggered by the `Policy-as-Code` engine. The policy defines &amp;quot;risk-proportional... oversight boundaries&amp;quot;, ensuring that low-risk changes (e.g., text correction) are automated while high-risk changes (e.g., modifying authentication) are flagged for mandatory human review.&amp;#xa;&amp;#xa;### **5. Comprehensive Observability: The Immutable Audit Trail**&amp;#xa;&amp;#xa;The requirement for a &amp;quot;meticulously logged and traceable&amp;quot; system to understand &amp;quot;the &amp;#39;why&amp;#39;&amp;quot; behind every agent decision is a foundational principle of AI auditability.&amp;#xa;&amp;#xa;*   **The Data Architecture (Event Sourcing):** The ideal architecture to achieve this is **Event Sourcing**. Instead of storing the current state, this model stores a &amp;quot;sequence of immutable events&amp;quot;. This creates a &amp;quot;complete, tamper-proof record&amp;quot; that provides &amp;quot;perfect recall,&amp;quot; allowing you to &amp;quot;reproduce the state of any agent at any given point in time&amp;quot;. This log captures the &amp;quot;inputs, its reasoning process, and the actions it took&amp;quot;, providing a full &amp;quot;forensic&amp;quot; audit trail.&amp;#xa;*   **The Observability Technology (Distributed Tracing):** For a complex, multi-agent system, **Distributed Tracing** is the key technology for &amp;quot;Multi-agent system debugging&amp;quot;. It &amp;quot;maps interactions between agents, including tool invocations, retrieval calls, and chained prompts&amp;quot;.&amp;#xa;*   **The Full Loop:** This architecture connects the entire TSOP loop. Observability captures telemetry on &amp;quot;prompt inputs, model outputs, [and] intermediate reasoning steps&amp;quot;. This telemetry is used to form an &amp;quot;AI-generated hypothesis&amp;quot;, which is then linked via distributed tracing to the immutable event log and final deployment records.&quot; id=&quot;49&quot;&gt;&#10;          &lt;mxCell style=&quot;shape=callout;whiteSpace=wrap;html=1;perimeter=calloutPerimeter;base=20;rotation=0;position2=0;&quot; vertex=&quot;1&quot; parent=&quot;1&quot;&gt;&#10;            &lt;mxGeometry x=&quot;170.18&quot; y=&quot;1320&quot; width=&quot;170&quot; height=&quot;100.52&quot; as=&quot;geometry&quot; /&gt;&#10;          &lt;/mxCell&gt;&#10;        &lt;/UserObject&gt;&#10;        &lt;mxCell id=&quot;50&quot; style=&quot;edgeStyle=orthogonalEdgeStyle;curved=1;orthogonalLoop=1;jettySize=auto;html=1;entryX=0.5;entryY=0;entryDx=0;entryDy=0;&quot; edge=&quot;1&quot; source=&quot;52&quot; target=&quot;54&quot; parent=&quot;1&quot;&gt;&#10;          &lt;mxGeometry relative=&quot;1&quot; as=&quot;geometry&quot; /&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;mxCell id=&quot;51&quot; value=&quot;output&quot; style=&quot;edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];&quot; vertex=&quot;1&quot; connectable=&quot;0&quot; parent=&quot;50&quot;&gt;&#10;          &lt;mxGeometry x=&quot;0.138&quot; y=&quot;2&quot; relative=&quot;1&quot; as=&quot;geometry&quot;&gt;&#10;            &lt;mxPoint as=&quot;offset&quot; /&gt;&#10;          &lt;/mxGeometry&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;mxCell id=&quot;52&quot; value=&quot;Shunt-Button&amp;lt;div&amp;gt;(Enhance with keywords)&amp;lt;/div&amp;gt;&quot; style=&quot;whiteSpace=wrap;html=1;fillColor=#1ba1e2;strokeColor=#006EAF;fontColor=#ffffff;&quot; vertex=&quot;1&quot; parent=&quot;1&quot;&gt;&#10;          &lt;mxGeometry x=&quot;590&quot; y=&quot;120&quot; width=&quot;120&quot; height=&quot;60&quot; as=&quot;geometry&quot; /&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;mxCell id=&quot;53&quot; style=&quot;edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;entryX=0.5;entryY=0;entryDx=0;entryDy=0;&quot; edge=&quot;1&quot; source=&quot;54&quot; target=&quot;58&quot; parent=&quot;1&quot;&gt;&#10;          &lt;mxGeometry relative=&quot;1&quot; as=&quot;geometry&quot; /&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;UserObject label=&quot;DeepResearch&quot; tooltip=&quot;Of course. Here is the enhanced version of the text, integrating more vivid, descriptive language and keywords to increase engagement and detail while preserving the core message.&amp;#xa;&amp;#xa;---&amp;#xa;### **The Prompt as a Genesis Engine: Architecting Self-Optimizing AI Systems**&amp;#xa;*From Static Blueprints to Dynamic Organisms: Synthesizing Autonomous Systems for Code and Interface Generation*&amp;#xa;&amp;#xa;#### **Deconstructing Elite-Tier Prompt Patterns: A Survey of the Current Frontier**&amp;#xa;&amp;#xa;The art and science of interacting with Large Language Models (LLMs) have undergone a seismic shift, metamorphosing from simple, single-turn commands into intricate, multi-stage prompt architectures. This evolution is nowhere more pronounced than in the demanding technical domains of software engineering and user interface (UI) design. A meticulous analysis of today&amp;#39;s elite-tier patterns reveals an unmistakable trajectory: a decisive pivot away from static, human-authored instructions and toward dynamic, machine-optimized, and process-oriented systems that breathe and adapt.&amp;#xa;&amp;#xa;This section deconstructs the state-of-the-art (SOTA) patterns in these two critical domains. Our goal is to establish the foundational benchmarks of what is currently possible and, more importantly, to illuminate the unexploited capability vectors—the fertile ground where the next generation of AI systems will flourish.&amp;#xa;&amp;#xa;***&amp;#xa;&amp;#xa;### **Domain 1: Architectures for High-Integrity Code Construction**&amp;#xa;&amp;#xa;In the realm of software engineering, the ambition has transcended the simple act of generating code snippets. The new mandate is to engineer reliable, context-aware, and increasingly autonomous systems. The most triumphant patterns treat the LLM not as a mere code parrot, but as a sophisticated reasoning engine to be embedded within a larger, rigorously structured development framework.&amp;#xa;&amp;#xa;**1. Automated Prompt Optimization: The &amp;quot;Prompt-as-a-Target&amp;quot; Pattern**&amp;#xa;&amp;#xa;The manual, artisanal process of refining prompts for code generation is a well-known bottleneck—a frustrating cycle of trial and error that is both time-consuming and inconsistent. The SOTA has advanced to automate this craft, treating the prompt itself as a first-class artifact to be algorithmically optimized.&amp;#xa;&amp;#xa;*   **Evolutionary-Based Methods (EPiC):** The EPiC (Evolutionary Prompt Engineering for Code) framework represents a paradigm shift, exploring code generation through the lens of cost-effectiveness. It &amp;quot;leverages a lightweight evolutionary algorithm to evolve the original prompts toward better ones that produce high-quality code.&amp;quot; By employing genetic operators like mutation on the prompt&amp;#39;s text and steering the search with a precise fitness function, EPiC automates the discovery of optimal prompt phrasing in a remarkably efficient manner.&amp;#xa;*   **Iterative Refinement (Prochemy):** The &amp;quot;Prompt Alchemy&amp;quot; (Prochemy) method offers an &amp;quot;innovative method for automatically refining prompts to boost code generation.&amp;quot; This system operates as a feedback loop, iteratively sculpting prompts based on the model&amp;#39;s measured performance on specific tasks. This automated optimization forges consistency and has yielded substantial performance gains, such as a **5.0% improvement for GPT-3.5-Turbo on HumanEval** and a striking **12.9% improvement for GPT-4o** on complex Java-to-Python code translation tasks.&amp;#xa;*   **Adaptive Selection (PET-Select):** Acknowledging that &amp;quot;no single approach is universally optimal,&amp;quot; the PET-Select framework introduces a crucial meta-layer of intelligence. This &amp;quot;PET-agnostic selection model&amp;quot; first classifies the complexity of an incoming query, using code intricacy as a proxy. It then dynamically selects the most appropriate prompt engineering technique (PET)—dispatching a simple zero-shot prompt for a trivial query or invoking a complex multi-stage reasoning chain for a formidable one. This automated, adaptive triage has been proven to elevate **pass@1 accuracy by up to 1.9%** while simultaneously achieving a **74.8% reduction in token consumption**.&amp;#xa;&amp;#xa;The clear evolutionary arc in this domain is from a human-centric &amp;quot;prompt engineering&amp;quot; phase to a machine-centric &amp;quot;prompt optimization&amp;quot; phase. The AI is no longer just the executor of the instruction; it is becoming the architect of the instruction itself. These systems, however, are fundamentally *reactive*. They optimize a prompt for a known task within a known solution space. They do not yet *proactively* generate a novel prompt architecture for a novel, undiscovered problem. This points toward a tantalizing unexploited vector: a system that can discover a new problem domain (e.g., from user feedback) and then author its own comprehensive prompt architecture to conquer it—a true meta-prompting capability.&amp;#xa;&amp;#xa;**2. Test-Driven Development (TDD) as a Prompting Paradigm**&amp;#xa;&amp;#xa;Arguably the most powerful and reliable pattern for generating high-quality code is the direct integration of Test-Driven Development (TDD) principles into the prompt architecture. TDD is an &amp;quot;incremental software development methodology that focuses on creating tests before the implementation.&amp;quot; When applied to LLMs, the test suite becomes an unambiguous, machine-verifiable contract.&amp;#xa;&amp;#xa;*   **Core Principle:** Instead of wrestling with the inherent ambiguity of natural language, the prompt provides the LLM with a concrete set of unit tests and issues a clear directive: &amp;quot;write code to pass all tests.&amp;quot; This pattern&amp;#39;s remarkable success hinges on &amp;quot;instruction following and in-context learning,&amp;quot; which have been identified as more &amp;quot;critical capabilities for TDD success&amp;quot; than generalized coding proficiency. The tests are the ultimate, incorruptible instruction.&amp;#xa;*   **Frameworks:** Sophisticated systems are being engineered to formalize this contract. The TGEN framework, for example, employs &amp;quot;Specialized agents&amp;quot; that accept two primary inputs: the &amp;quot;programming prompt&amp;quot; (a concise description) and &amp;quot;the tests&amp;quot; (the explicit unit tests and required function signatures). These are then processed by the LLM engine to produce validated, trustworthy code.&amp;#xa;*   **Prompt Structure:** This paradigm fundamentally transforms the anatomy of the prompt. The request evolves from a vague &amp;quot;what&amp;quot; to a highly constrained &amp;quot;how.&amp;quot; A common elite-level TDD prompt is a set of ironclad rules: *&amp;quot;1. Write a single Python function that passes all the provided tests. 2. Use type hints for all parameters and return values. 3. ...Adhere strictly to Python best practices and PEP 8... 4. Ensure the function handles all edge cases and scenarios explicitly covered in the tests. 5. Provide only the function definition and its implementation, nothing more.&amp;quot;*&amp;#xa;&amp;#xa;The TDD-as-prompt pattern furnishes an objective, verifiable measure of &amp;quot;correctness&amp;quot; that is vastly superior to ambiguous natural language requests. It masterfully shifts the burden of human effort from vaguely *describing* the code to precisely *defining its behavior* through tests. This is a crucial leap from semantic validation (is the code &amp;quot;good&amp;quot;?) to functional validation (does the code *work*?). The next logical frontier, and the key unexploited vector, is to close the loop: to create a system that not only generates code from tests but also generates its own tests and validates its own code in a continuous, self-perpetuating cycle.&amp;#xa;&amp;#xa;**3. Self-Validation and &amp;quot;Error-Forward&amp;quot; Debugging**&amp;#xa;&amp;#xa;This pattern extends the TDD loop into a dynamic, autonomous process. For an agent to be truly autonomous, it must possess the ability to recognize, diagnose, and recover from its own errors.&amp;#xa;&amp;#xa;*   **Self-Validation:** SOTA agentic systems are architected to &amp;quot;regularly verify progress and self-assess correctness.&amp;quot; This &amp;quot;agentic self-validation&amp;quot; is a core capability that &amp;quot;drives up accuracy&amp;quot; and enables robust, long-running execution. Agents from Cognition, for instance, are noted to &amp;quot;excel at testing its own code, enabling Devin to run longer, handle harder tasks, and deliver production-ready code.&amp;quot; This deep integration of TDD within an autonomous agent allows it to &amp;quot;go through several improvement cycles on its own instead of having to manually ask the AI to fix test failures.&amp;quot;&amp;#xa;*   **&amp;quot;Error-Forward Prompting&amp;quot;:** This is the primary recovery mechanism within the self-validation loop, treating errors as high-fidelity data, not as failures. When an agent&amp;#39;s self-validation check fails, the system automatically &amp;quot;collects relevant context, including the error message, stack trace, and cell location.&amp;quot; This rich diagnostic information is then formatted and &amp;quot;provided to the agent as the initial context for beginning the debugging process.&amp;quot; The error itself becomes the next prompt.&amp;#xa;*   **Reflection:** This is the crucial learning mechanism that makes recovery effective. A &amp;quot;reflection system enables the agent to learn from its actions and improve its debugging strategy.&amp;quot; Implemented via &amp;quot;reflective prompting,&amp;quot; this allows the model to &amp;quot;analyze and refine its outputs.&amp;quot; The model first generates a solution, then &amp;quot;through subsequent prompts, critiques its own reasoning to identify and correct errors,&amp;quot; a process formalized in techniques like Self-Refine, which elegantly mimics the human &amp;quot;draft, review, refine&amp;quot; workflow.&amp;#xa;&amp;#xa;In this paradigm, failure is transformed from an end-state into a high-value data signal. The stack trace becomes the most valuable part of the prompt—a pure, unambiguous instruction set for what must be fixed. When TDD-as-prompt is fused with this self-validation and reflection loop, the system becomes truly &amp;quot;self-healing.&amp;quot; The prompt is no longer a single-shot instruction but the initiation of a self-sustaining process. The agent&amp;#39;s goal is elevated from &amp;quot;generate code&amp;quot; to &amp;quot;make the build pass,&amp;quot; a critical and profound step toward genuine autonomy.&amp;#xa;&amp;#xa;**4. Agentic Frameworks and Multi-Agent Collaboration**&amp;#xa;&amp;#xa;Complex software development is a symphony of diverse tasks, impossible to solve in a single step or by a single-minded agent. The recognition that single-shot prompts &amp;quot;yield imprecise or plain incorrect results&amp;quot; for elaborate tasks has catalyzed the rise of sophisticated agentic frameworks.&amp;#xa;&amp;#xa;*   **Advanced Reasoning Patterns:** These frameworks are built upon a reasoning fabric far more advanced than simple Chain-of-Thought (CoT).&amp;#xa;    *   **ReAct:** This foundational pattern masterfully combines &amp;quot;Reason and Act,&amp;quot; allowing an agent to interleave step-by-step reasoning with tool use to gather external information or perform actions in an environment.&amp;#xa;    *   **Tree of Thoughts (ToT):** Moving beyond the linear, single-track path of CoT, ToT empowers an agent to &amp;quot;breakdown intermediate processed into steps,&amp;quot; generate &amp;quot;various generated states,&amp;quot; and strategically &amp;quot;evaluate&amp;quot; those states to &amp;quot;determine which branch to explore next.&amp;quot;&amp;#xa;    *   **Graph of Thoughts (GoT):** The current SOTA in reasoning, GoT generalizes ToT into a full graph structure. This architecture &amp;quot;enables combining arbitrary LLM thoughts into synergistic outcomes&amp;quot; and, critically, &amp;quot;enhancing thoughts using feedback loops.&amp;quot; GoT has been demonstrated to increase the quality of complex sorting tasks by **62% over ToT** while simultaneously reducing costs.&amp;#xa;*   **Agentic Frameworks:** These advanced reasoning patterns are orchestrated by multi-agent frameworks that simulate collaborative work.&amp;#xa;    *   **MetaGPT:** This framework simulates a &amp;quot;real-world software company,&amp;quot; assigning agents specialized roles like &amp;quot;product manager, software architect, programmer, or QA tester&amp;quot; and embedding them with &amp;quot;Standard Operating Procedures (SOPs).&amp;quot;&amp;#xa;    *   **ChatDev:** This framework orchestrates a &amp;quot;waterfall-style&amp;quot; collaboration, where agents engage in &amp;quot;task-oriented and multi-turn communications&amp;quot; to iteratively design, code, test, and document solutions.&amp;#xa;*   **Purpose:** These frameworks are essential as they provide a &amp;quot;shared philosophy of control &amp;amp; reasoning.&amp;quot; Without such a structure, agentic systems suffer from a &amp;quot;loss of control clarity of flow&amp;quot; and risk &amp;quot;unbounded complexity growth&amp;quot; as new agents are added.&amp;#xa;*   **Benchmarks:** These powerful agentic systems are precisely what achieve top scores on complex, real-world benchmarks that measure engineering capability. The **SWE-bench** benchmark, for instance, measures &amp;quot;an AI model&amp;#39;s ability to solve real-world software issues.&amp;quot; SOTA models conquer SWE-bench and OSWorld by leveraging these multi-agent, self-testing architectures.&amp;#xa;&amp;#xa;The atomic unit of these frameworks is role-based prompting; the frameworks themselves are, in essence, prompt-driven state machines. A high-level &amp;quot;meta-prompt&amp;quot; defines the agents, their roles, their tools, and their communication protocols. The LLM is thus demoted from &amp;quot;solution generator&amp;quot; to a core component—a &amp;quot;reasoning engine&amp;quot; that navigates this pre-defined architecture. The architecture itself *is* the prompt. The current limitation, and the unexplored vector, is that these frameworks are simulations of human workflows (e.g., &amp;quot;waterfall,&amp;quot; &amp;quot;software company&amp;quot;). An AI-native workflow, where feedback comes not from a simulated &amp;quot;QA Agent&amp;quot; but from the product itself via live user telemetry, would be a fundamentally more direct and efficient paradigm.&amp;#xa;&amp;#xa;**5. Context-Aware Generation (Agentic RAG)**&amp;#xa;&amp;#xa;Code generation is useless without domain context. Retrieval-Augmented Generation (RAG) is the primary pattern for injecting this context, and its agentic form represents the state of the art.&amp;#xa;&amp;#xa;*   **RAG-for-Code:** This pattern gives an AI assistant &amp;quot;a direct line to your team&amp;#39;s collective knowledge.&amp;quot; The prompt is &amp;quot;augmented&amp;quot; with hyper-relevant information retrieved from &amp;quot;documentation, code repositories, or even Stack Overflow discussions.&amp;quot; This vital infusion ensures the generated response is &amp;quot;context-aware&amp;quot; and surgically relevant to the specific codebase it is intended for.&amp;#xa;*   **Agentic RAG:** This is the &amp;quot;evolution from traditional single-query RAG.&amp;quot; Instead of being a passive recipient of retrieved context, the agent actively *forages* for it. It performs &amp;quot;context-aware query planning,&amp;quot; can issue &amp;quot;parallel execution of multiple focused subqueries,&amp;quot; and then synthesizes the results to build a comprehensive, multi-faceted understanding of the problem space. This is the sophisticated approach employed by modern agentic frameworks like LangGraph, AutoGen, and those from Amazon and Microsoft.&amp;#xa;&amp;#xa;The RAG-for-Code pattern transforms a &amp;quot;general-purpose coder&amp;quot; into a &amp;quot;domain-specific engineer&amp;quot; who understands the nuances, conventions, and constraints of a particular project. The agentic aspect is the critical differentiator; it is the difference between giving a developer a sprawling, unindexed library (standard RAG) and providing a seasoned research assistant who knows exactly which three pages contain the answer (Agentic RAG). The most potent, yet not fully exploited, vector in code generation is the fusion of this **Agentic RAG (for context)** with the **TDD-as-Prompt paradigm (for verification)**. An agent that can retrieve context from a 500,000-line codebase and validate its changes against that codebase&amp;#39;s entire test suite represents the leap from a &amp;quot;coding assistant&amp;quot; to an &amp;quot;autonomous developer.&amp;quot; This powerful fusion is the core of the novel Test-Driven Agent (TDA) architecture proposed in Part II.&amp;#xa;&amp;#xa;***&amp;#xa;&amp;#xa;### **Domain 2: Architectures for User Delight &amp;amp; UI Design**&amp;#xa;&amp;#xa;In the second domain, user interface generation, the mandate for &amp;quot;user delight&amp;quot; demands a leap beyond mere wireframe generation. Elite-tier prompts in this space are not about &amp;quot;generating pixels&amp;quot; but about &amp;quot;generating experiences&amp;quot;—experiences that are deeply grounded in human-centric design principles.&amp;#xa;&amp;#xa;**1. Persona-Driven Design: Grounding Generation in Empathy**&amp;#xa;&amp;#xa;&amp;quot;User delight&amp;quot; is the &amp;quot;positive emotional response users feel when a product doesn&amp;#39;t just meet their needs but goes above and beyond.&amp;quot; This coveted state is &amp;quot;highly contextual&amp;quot; and cannot be achieved without first defining, with deep empathy, the user for whom we are designing.&amp;#xa;&amp;#xa;*   **Pattern:** Elite prompts for UI design do not begin with the interface; they begin with the user. The system is first prompted to generate a detailed proto-persona. This artifact includes not just demographic details but also the &amp;quot;target users, their core pain points, and daily use context,&amp;quot; as well as deeper &amp;quot;Motivations&amp;quot; and &amp;quot;Affinities.&amp;quot;&amp;#xa;*   **Application:** This generated persona (or a human-provided one) is then injected as a primary constraint into all subsequent UI generation prompts. This forces the AI to &amp;quot;cater to Gen Z and Gen X users&amp;quot; differently, tailoring the design language, informational density, and interaction patterns to a specific audience. The prompt is no longer &amp;quot;generate a wireframe for a music app,&amp;quot; but rather, &amp;quot;generate a wireframe for a music app *for this specific persona*, focusing on their stated pain point of *{pain_point}*.&amp;quot;&amp;#xa;&amp;#xa;This persona-driven pattern acts as a powerful focusing lens on the model&amp;#39;s vast solution space, compelling it to move from generating a generically &amp;quot;good UI&amp;quot; to a UI that is specifically &amp;quot;good for *this* user.&amp;quot; It is, in effect, a form of in-context learning for design, where the persona serves as a &amp;quot;one-shot&amp;quot; example of the target audience. The major limitation, and the unexploited vector, is that this is a static process. The persona is a snapshot, an assumption created at the beginning of the design process. The clear next step is to evolve from these static, assumed personas to dynamic, *observed user models* that are continuously updated based on real-time behavioral analytics.&amp;#xa;&amp;#xa;**2. Constraint-Based Generation: Defining the &amp;quot;Solution Space&amp;quot; with Intelligent Guardrails**&amp;#xa;&amp;#xa;The highest-fidelity UI generation requires the application of multiple, layered constraints. These constraints are the specifications that ensure the output is not just creative, but also functional, accessible, and grounded in established design theory. These intelligent guardrails fall into three primary categories.&amp;#xa;&amp;#xa;**A. Cognitive &amp;amp; Heuristic Constraints**&amp;#xa;&amp;#xa;This is the most sophisticated pattern for achieving true &amp;quot;user delight.&amp;quot; The prompt explicitly instructs the AI to apply principles from cognitive science and established usability heuristics, forcing the AI to design for the human mind.&amp;#xa;&amp;#xa;*   **Heuristics:** The most common pattern is to prompt the AI to embody a UX expert and evaluate or generate a design based on &amp;quot;Nielsen&amp;#39;s 10 Usability Heuristics&amp;quot; or other well-known frameworks like Shneiderman&amp;#39;s &amp;quot;Eight Golden Rules.&amp;quot;&amp;#xa;*   **Cognitive Principles:** More advanced prompts instruct the AI to directly apply specific cognitive laws to reduce friction and enhance intuition. Examples include:&amp;#xa;    *   **Fitts&amp;#39;s Law:** Prompting the AI to make &amp;quot;important buttons and interactive elements larger and closer to where users naturally focus,&amp;quot; making the interface feel effortless.&amp;#xa;    *   **Hick&amp;#39;s Law:** Instructing the AI to &amp;quot;reduc[e] the number of options or organiz[e] them into categories&amp;quot; to accelerate decision-making and prevent analysis paralysis.&amp;#xa;    *   **Cognitive Load:** Prompting with the explicit goal of &amp;quot;reducing cognitive load&amp;quot; to create a more fluid and less mentally taxing experience.&amp;#xa;*   **Behavioral Models:** The most advanced prompts leverage frameworks like BJ Fogg&amp;#39;s Behavior Model (B=MAP: Motivation, Ability, Prompt) or Nir Eyal&amp;#39;s &amp;quot;Hooked&amp;quot; model to design persuasive, habit-forming, and deeply engaging interfaces.&amp;#xa;&amp;#xa;Prompting with &amp;quot;Nielsen&amp;#39;s Heuristics&amp;quot; or &amp;quot;Fogg&amp;#39;s Behavior Model&amp;quot; acts as a domain-specific Chain-of-Thought. It forces the AI to justify its design choices (&amp;quot;This button is large and placed in the bottom-right corner because it adheres to Fitts&amp;#39;s Law&amp;quot;), leading to more principled, defensible, and ultimately delightful designs.&amp;#xa;&amp;#xa;**B. Technical &amp;amp; Accessibility (A11y) Constraints**&amp;#xa;&amp;#xa;There is no &amp;quot;delight&amp;quot; in an interface that is unusable for a portion of the population. Elite prompts must enforce technical constraints as non-negotiable requirements, with accessibility (A11y) being paramount.&amp;#xa;&amp;#xa;*   **Pattern:** The prompt must explicitly command the AI to be &amp;quot;fully compliant with WCAG 2.2 AA.&amp;quot; Research shows that without this explicit instruction, AI-generated components are &amp;quot;consistently&amp;quot; and unacceptably inaccessible.&amp;#xa;*   **Specifics:** A high-quality A11y prompt enforces a checklist of best practices:&amp;#xa;    *   **Semantic HTML:** &amp;quot;Ensure the proper use of HTML5 elements (like `&amp;lt;header&amp;gt;`, `&amp;lt;main&amp;gt;`, `&amp;lt;footer&amp;gt;`).&amp;quot;&amp;#xa;    *   **Keyboard Accessibility:** &amp;quot;Test navigation using only Tab, Shift+Tab, and Enter keys. All interactive elements must be reachable and operable.&amp;quot;&amp;#xa;    *   **ARIA (Accessible Rich Internet Applications):** Mandate the correct application of &amp;quot;ARIA landmarks and roles,&amp;quot; which are &amp;quot;HTML attributes that add semantic meaning... for assistive technologies.&amp;quot;&amp;#xa;    *   **Clear Content:** &amp;quot;Use clear, concise language... Write descriptive links: Swap vague text like &amp;#39;click here&amp;#39; for something meaningful and context-rich.&amp;quot;&amp;#xa;&amp;#xa;This pattern is the UI-domain&amp;#39;s moral and functional equivalent of TDD. The prompt includes the acceptance criteria (WCAG standards). This &amp;quot;specification-as-prompt&amp;quot; is critical for generating production-ready, inclusive, and non-discriminatory interfaces.&amp;#xa;&amp;#xa;**C. Structural &amp;amp; Layout Constraints**&amp;#xa;&amp;#xa;To control the form of the output and ensure it is machine-readable and programmatically useful, prompts must define a reliable data structure.&amp;#xa;&amp;#xa;*   **Architecture &amp;amp; Flows:** For high-level system design, prompts specify formats like the C4 model rendered in Mermaid code. For user flows, Mermaid sequence diagrams are the standard for visualizing interactions.&amp;#xa;*   **Wireframes:** Simple wireframe prompts use text descriptions, such as, &amp;quot;Include a header with a logo and search bar, a main content area with featured destinations, and a bottom navigation bar.&amp;quot;&amp;#xa;*   **SOTA (Structured Data):** The most robust and programmatically valuable pattern is to force the LLM to output a structured data format like JSON or YAML. This is achieved by providing an explicit output schema to the model. This pattern is now natively supported by major model providers, who allow schemas to be defined using libraries like Pydantic (for Python) or Zod (for TypeScript). This guarantees the output is not just arbitrary text, but a &amp;quot;type safe and consistent structure.&amp;quot;&amp;#xa;&amp;#xa;This structured output pattern is the critical *lingua franca* between the two domains of this report. If a UI can be described in a reliable JSON schema, and a backend can expose its API in a reliable JSON schema (e.g., an OpenAPI specification), an agent can intelligently connect them. This structured output is the API contract between a UI-generation agent and a code-generation agent.&amp;#xa;&amp;#xa;**3. Generative UI (GenUI): The Dawn of the Living Interface**&amp;#xa;&amp;#xa;This is the bleeding-edge paradigm that underpins the entire future of UI design. Generative UI (GenUI) is a new philosophy that &amp;quot;enables adaptive, goal-driven interactions.&amp;quot; Instead of a static interface designed by a human and then laboriously coded, the UI is generated in real-time by an AI, tailored to the user and the context.&amp;#xa;&amp;#xa;*   **Mechanism:** In this paradigm, the AI generates &amp;quot;interactive widgets for fine-grained prompt control&amp;quot; or entire &amp;quot;high-fidelity UI mock-up screens from a high-level textual description.&amp;quot; This process is not one-shot; it is an iterative, &amp;quot;co-creative process&amp;quot; between the human and the AI, involving &amp;quot;AI-assisted refinement strategies.&amp;quot;&amp;#xa;*   **Current State:** GenUI is currently being adopted by UX practitioners as a powerful tool to accelerate their workflow, with the human remaining the curator, refiner, and final arbiter of the AI-generated output.&amp;#xa;&amp;#xa;GenUI is the logical culmination of prompt-based wireframing. The current limitation, and the key unexploited vector, is the reliance on a human-in-the-loop for optimization. The UI is refined based on a designer&amp;#39;s intuition or explicit follow-up commands. The unexploited opportunity is to remove the human curator from the optimization loop. A system that could refine its own GenUI, not based on a designer&amp;#39;s commands, but based on *live user data*, would represent a monumental paradigm shift. This is the core concept of a &amp;quot;Self-Optimizing UI&amp;quot; and forms the foundation for the novel Cognitive-Adaptive Interface (CAI) architecture.&amp;#xa;&amp;#xa;***&amp;#xa;&amp;#xa;### **Synthesis of Novel Architectures: Exceeding the Frontier**&amp;#xa;&amp;#xa;The preceding analysis deconstructed the current SOTA, revealing a set of potent, unexploited capability vectors. The following synthesis moves beyond merely replicating these patterns. It proposes three novel, high-level architectures that fuse these vectors to create self-regulating, self-optimizing systems designed to shatter current benchmarks. These architectures treat the prompt not as a static, one-time instruction, but as a &amp;quot;bootloader&amp;quot; for a continuous, autonomous process.&amp;#xa;&amp;#xa;**Table 1: Comparative Analysis of Generation &amp;amp; Reasoning Architectures**&amp;#xa;&amp;#xa;| Architecture | Core Mechanism | Interaction Model | Key Limitation (Vector Not Exploited) | Unlocked Capability Vector |&amp;#xa;| :--- | :--- | :--- | :--- | :--- |&amp;#xa;| Chain-of-Thought (CoT) | Step-by-step reasoning (e.g., &amp;quot;Let&amp;#39;s think step-by-step&amp;quot;). | Static | Brittle, linear reasoning; no external validation or tool use. | Basic multi-step problem solving. |&amp;#xa;| ReAct | Interleaves reasoning (CoT) with tool use (Actions). | Iterative | Dependent on pre-defined tools; no long-term memory or structured collaboration. | Environment-aware task execution. |&amp;#xa;| Graph of Thoughts (GoT) | Models reasoning as a graph, allowing merging of states and feedback loops. | Iterative | High conceptual complexity; primarily focused on reasoning, not execution. | Advanced, non-linear problem-solving. |&amp;#xa;| TDD-as-Prompt | A test suite is provided as the functional specification for code generation. | Static | Requires human to write all tests; no self-correction loop. | Verifiable, high-reliability code generation. |&amp;#xa;| Generative UI (GenUI) | AI generates high-fidelity UI mockups or interactive widgets from text descriptions. | Iterative | Requires human-in-the-loop for curation and refinement; based on assumed user needs. | Rapid, co-creative UI prototyping. |&amp;#xa;| **[NOVEL] Cognitive-Adaptive Interface (CAI) Engine** | GenUI + Cognitive Fitness Function + Live User Telemetry. | Dynamic-Adaptive | N/A (Synthesized Architecture) | Real-time UI self-optimization based on observed user cognitive state. |&amp;#xa;| **[NOVEL] Test-Driven Agent (TDA) Framework** | Closed-loop TDD + Agentic RAG + Error-Forward Self-Healing. | Autonomous-Iterative | N/A (Synthesized Architecture) | Verifiable, context-aware, autonomous development with guaranteed build integrity. |&amp;#xa;| **[NOVEL] Self-Optimizing Product (SOP) Loop** | TDA-CAI integration via an RLHF-from-Telemetry feedback loop. | Autonomous-Holistic | N/A (Synthesized Architecture) | Fully autonomous product self-improvement driven by implicit user feedback. |&amp;#xa;&amp;#xa;#### **Proposed Architecture 1: The &amp;quot;Cognitive-Adaptive Interface&amp;quot; (CAI) Engine**&amp;#xa;&amp;#xa;This architecture synthesizes Generative UI (GenUI) with persona-driven design and, most critically, cognitive-heuristic constraints. It is engineered to evolve UI generation from a static, one-shot process (&amp;quot;generate a wireframe&amp;quot;) into a continuous, adaptive, and self-optimizing one.&amp;#xa;&amp;#xa;*   **Vector Exploited:** This architecture directly targets the vector identified in (I.B.1) and (I.B.3): the fusion of Generative UI with real-time user telemetry. The system does not just generate a UI; it dynamically sculpts it in real-time based on observed user behavior and cognitive state.&amp;#xa;*   **Mechanism:** The CAI Engine operates as a continuous four-phase loop, a digital nervous system for the interface.&amp;#xa;    1.  **Phase 1: The &amp;quot;Cognitive Metaprompt&amp;quot;.** The architect does not prompt for a specific layout. Instead, they provide a high-level, structured (e.g., YAML) prompt that defines the goals and constraints. This metaprompt specifies the `target_persona`, the `business_objective` (e.g., &amp;quot;maximize conversion&amp;quot;), and a `cognitive_fitness_function`—a weighted list of principles (e.g., `cognitive_load: -0.5`, `fitts_law_compliance: +0.3`) that will be used to score the UI&amp;#39;s performance.&amp;#xa;    2.  **Phase 2: Initial Generation.** The CAI engine uses this metaprompt to generate the initial UI component tree as a structured JSON artifact. This initial design represents the engine&amp;#39;s best hypothesis for satisfying the `cognitive_fitness_function`.&amp;#xa;    3.  **Phase 3: The Telemetry Loop.** This is the critical connection to the real world. As users interact with the dynamically-rendered GenUI, the system collects fine-grained telemetry, capturing not just clicks but also proxies for cognitive state: hesitation time (cognitive load), rage clicks (frustration), scroll depth (engagement), and form drop-off points.&amp;#xa;    4.  **Phase 4: Autonomous Optimization.** This rich telemetry stream is fed back into the CAI engine. The engine continuously scores the live UI&amp;#39;s performance against the `cognitive_fitness_function`. It then initiates a self-optimizing process, autonomously running micro-A/B tests or reinforcement learning strategies to adapt the UI. For example, it might log: *&amp;quot;Hypothesis: Moving &amp;#39;Add to Cart&amp;#39; button 10px closer to the product image will improve the Fitts&amp;#39;s Law component of the fitness function. Result: Target acquisition speed improved by 80ms and conversion metric increased by 0.2%. This change is now permanent for this user segment.&amp;quot;*&amp;#xa;*   **Exceeding the Benchmark:** This architecture creates a true &amp;quot;Self-Optimizing UI.&amp;quot; The prompt is no longer a blueprint for a static house; it is the DNA for a living organism that adapts to its environment (the user) in real-time. It moves beyond static, assumed personas to build an interface that dynamically aligns with the observed cognitive and behavioral patterns of its actual users.&amp;#xa;&amp;#xa;#### **Proposed Architecture 2: The &amp;quot;Test-Driven Agent&amp;quot; (TDA) Framework**&amp;#xa;&amp;#xa;This architecture synthesizes the most robust patterns from the code construction domain: TDD-as-Prompt, Self-Validation, and Agentic RAG. It creates a closed-loop, &amp;quot;self-healing&amp;quot; system designed to enable verifiable, autonomous development at the repository level.&amp;#xa;&amp;#xa;*   **Vector Exploited:** This architecture exploits the vector identified in (I.A.5): the fusion of autonomous, closed-loop TDD with context-aware Agentic RAG. The agent&amp;#39;s deliverable is not &amp;quot;code&amp;quot;; it is a &amp;quot;passing build.&amp;quot;&amp;#xa;*   **Mechanism:** The TDA Framework operates as a five-phase, autonomous workflow:&amp;#xa;    1.  **Phase 1: The &amp;quot;User Story Metaprompt&amp;quot;.** A human (or another agent) provides a high-level feature request in a structured format (e.g., JSON), defining the goal, not the implementation. Example: `{&amp;quot;user_story&amp;quot;: &amp;quot;As a user, I want to reset my password via email.&amp;quot;, &amp;quot;acceptance_criteria&amp;quot;: [...]}`.&amp;#xa;    2.  **Phase 2: RAG-Context.** The TDA&amp;#39;s first action is not to code, but to *read*. It activates its Agentic RAG module to perform &amp;quot;context-aware query planning,&amp;quot; querying the entire codebase and documentation to build a deep understanding of the existing system (e.g., &amp;quot;Query: &amp;#39;auth routes&amp;#39;&amp;quot;, &amp;quot;Query: &amp;#39;email service&amp;#39;&amp;quot;).&amp;#xa;    3.  **Phase 3: Test Generation (Red).** Armed with this context, the TDA first generates a new, *failing* unit test (e.g., `test_post_forgot_password_invalid_email_404`). This step codifies the `acceptance_criteria` from the metaprompt into a verifiable, functional contract.&amp;#xa;    4.  **Phase 4: Code Generation (Green).** The agent now generates the minimal amount of implementation code required to make the new test pass.&amp;#xa;    5.  **Phase 5: Reflect &amp;amp; Refactor (Self-Healing).** The TDA does not stop. It now runs the *entire* test suite. If an old test fails (a regression), it enters a &amp;quot;self-healing&amp;quot; loop, using the &amp;quot;Error-Forward Prompt&amp;quot; pattern to feed the new stack trace back to itself. It then reflects and iterates on the code until the full build is green.&amp;#xa;*   **Exceeding the Benchmark:** This architecture moves far beyond task-oriented benchmarks like SWE-bench. The TDA&amp;#39;s output is not &amp;quot;a code snippet that solves a problem&amp;quot;; it is a passing, context-aware, and regression-free build. This builds the profound level of trust required for true &amp;quot;agentic software engineering&amp;quot; by producing verifiable, reliable, and autonomous results that can be directly committed to a main branch.&amp;#xa;&amp;#xa;#### **The Unified Synthesis: The &amp;quot;Self-Optimizing Product&amp;quot; (SOP) Loop**&amp;#xa;&amp;#xa;This is the final, unified architecture. It bridges the two domains by connecting the TDA (backend code) and the CAI (frontend UI) into a single, product-level optimization loop. This system is designed to autonomously improve the entire product—both its functionality and its interface—based on the silent language of user interaction.&amp;#xa;&amp;#xa;*   **Vector Exploited:** This architecture exploits the most potent &amp;quot;unexplored vector&amp;quot;: connecting the CAI (UI) and TDA (Code) architectures via a shared feedback loop that uses Reinforcement Learning from Human Feedback (RLHF). In this advanced paradigm, the &amp;quot;human feedback&amp;quot; is not an explicit button click; it is the *implicit behavioral telemetry* collected from the CAI, which is then used to train a reward model and guide the policy of the entire system.&amp;#xa;*   **Mechanism (The Full Loop):**&amp;#xa;    1.  **Deploy:** The TDA (Architecture 2) generates and deploys the backend `API_v1`. The CAI (Architecture 1) generates the frontend UI to consume it, governed by its `cognitive_fitness_function`.&amp;#xa;    2.  **Observe (Telemetry):** The CAI&amp;#39;s telemetry loop observes a &amp;quot;user delight&amp;quot; failure. It logs: *&amp;quot;70% of users drop off at the &amp;#39;Security Question&amp;#39; form. Average hesitation time is 12 seconds. This violates the cognitive_load component of our fitness function.&amp;quot;*&amp;#xa;    3.  **Translate (Feedback Agent):** This telemetry is fed into a new, specialized &amp;quot;Feedback Agent.&amp;quot; This reasoning agent (using GoT) translates this quantitative behavioral data into a new product requirement, autonomously generating a new User Story Metaprompt: `{&amp;quot;user_story&amp;quot;: &amp;quot;The &amp;#39;Security Question&amp;#39; flow causes high friction. Replace it with a &amp;#39;Magic Link&amp;#39; email workflow.&amp;quot;, &amp;quot;acceptance_criteria&amp;quot;: [...]}`.&amp;#xa;    4.  **Trigger (TDA):** This new user story is automatically fed as an Init-Prompt to the TDA.&amp;#xa;    5.  **Heal &amp;amp; Evolve (TDA):** The TDA springs into action. It RAGs the codebase, writes new failing tests for the &amp;#39;Magic Link&amp;#39; flow, generates the new `API_v2` endpoints, and (critically) writes and deploys a migration to deprecate `API_v1`.&amp;#xa;    6.  **Adapt (CAI):** The TDA&amp;#39;s deployment triggers the CAI. Now aware of the new `API_v2`, the CAI re-generates its UI components to consume the new, &amp;quot;healed&amp;quot; workflow, automatically adapting the interface to the new, lower-friction flow.&amp;#xa;*   **Exceeding the Benchmark:** The loop is complete. The product itself (code + UI) has just autonomously optimized its own design to improve &amp;quot;user delight,&amp;quot; with zero human intervention. This is the new benchmark. The &amp;quot;prompt&amp;quot; is no longer a static, human instruction; it is a continuous, self-generated feedback signal originating from the user&amp;#39;s own behavior.&amp;#xa;&amp;#xa;***&amp;#xa;&amp;#xa;### **Strategic Implementation and Future Trajectories**&amp;#xa;&amp;#xa;The architectures proposed are not theoretical fantasies. They can be implemented by shifting from natural language prompts to structured metaprompts that act as the bootloaders and configuration files for these autonomous systems.&amp;#xa;&amp;#xa;#### **Actionable Blueprints: Structured Metaprompts as the System API**&amp;#xa;&amp;#xa;To make these architectures concrete, we must define their initialization. The most critical pattern for SOTA systems is the use of structured (not natural language) prompts, ensuring reliable, machine-parseable interaction. YAML is used for its human-readability in top-level configuration, while schema-enforced JSON serves as the non-negotiable &amp;quot;API&amp;quot; for inter-agent communication.&amp;#xa;&amp;#xa;**Example Blueprint 1: YAML Metaprompt for the CAI Engine**&amp;#xa;&amp;#xa;```yaml&amp;#xa;# This YAML file is the master-prompt for the Cognitive-Adaptive Interface (CAI) Engine.&amp;#xa;# It defines the *purpose* and *constraints* of the UI, not its pixels.&amp;#xa;&amp;#xa;system_role: &amp;quot;You are a CAI (Cognitive-Adaptive Interface) Engine. Your goal is to generate and continuously optimize a user interface to maximize the &amp;#39;objective&amp;#39; by adhering to the &amp;#39;fitness_function&amp;#39;.&amp;quot;&amp;#xa;&amp;#xa;objective:&amp;#xa;  type: &amp;quot;maximize_conversion&amp;quot;&amp;#xa;  target_metric: &amp;quot;checkout_completion_rate&amp;quot;&amp;#xa;  &amp;#xa;target_persona:&amp;#xa;  # This persona is the seed for the initial UI generation. The system will&amp;#xa;  # later build a dynamic model based on real user behavior.&amp;#xa;  file: &amp;quot;./personas/busy_professional_mobile.json&amp;quot; &amp;#xa;  &amp;#xa;technical_constraints:&amp;#xa;  # Non-negotiable acceptance criteria for all generated interfaces.&amp;#xa;  - &amp;quot;WCAG_2_2_AA_COMPLIANT&amp;quot;&amp;#xa;  - &amp;quot;OUTPUT_FORMAT_SEMANTIC_HTML_WITH_ARIA&amp;quot;&amp;#xa;  - &amp;quot;MAX_LOAD_TIME_MS_3G: 1500&amp;quot;&amp;#xa;  &amp;#xa;cognitive_fitness_function:&amp;#xa;  # The heart of the CAI. The engine will score its own UI against these&amp;#xa;  # principles using live telemetry data as the input for the metrics.&amp;#xa;  - principle: &amp;quot;cognitive_load&amp;quot; &amp;#xa;    weight: -0.5 # (Minimize)&amp;#xa;    metric: &amp;quot;avg_task_hesitation_time_sec&amp;quot;&amp;#xa;    &amp;#xa;  - principle: &amp;quot;hick&amp;#39;s_law&amp;quot; &amp;#xa;    weight: -0.3 # (Minimize choices)&amp;#xa;    metric: &amp;quot;choice_count_per_screen&amp;quot;&amp;#xa;&amp;#xa;  - principle: &amp;quot;fitts_law_compliance&amp;quot; &amp;#xa;    weight: 0.3 # (Maximize)&amp;#xa;    metric: &amp;quot;target_acquisition_speed_ms&amp;quot;&amp;#xa;    &amp;#xa;  - principle: &amp;quot;nielsen_heuristic_4_consistency&amp;quot; &amp;#xa;    weight: 0.2 # (Maximize)&amp;#xa;    metric: &amp;quot;component_reuse_score&amp;quot;&amp;#xa;```&amp;#xa;&amp;#xa;**Example Blueprint 2: JSON Metaprompt for the TDA Framework**&amp;#xa;&amp;#xa;```json&amp;#xa;/*&amp;#xa;  This JSON object is the &amp;quot;Init-Prompt&amp;quot; for the Test-Driven Agent (TDA).&amp;#xa;  It is autonomously generated by the &amp;quot;Feedback Agent&amp;quot; [II.C] after translating&amp;#xa;  a telemetry-detected user problem into an actionable engineering task.&amp;#xa;*/&amp;#xa;{&amp;#xa;  &amp;quot;system_role&amp;quot;: &amp;quot;You are a TDA (Test-Driven Agent). Your mandate is to generate code that achieves a green build. You must write failing tests first.&amp;quot;,&amp;#xa;  &amp;quot;task_id&amp;quot;: &amp;quot;TDA-1138&amp;quot;,&amp;#xa;  &amp;quot;source_trigger&amp;quot;: &amp;quot;SOP_Feedback_Agent_Telemetry_Violation_cognitive_load&amp;quot;,&amp;#xa;  &amp;quot;user_story&amp;quot;: &amp;quot;The &amp;#39;Security Question&amp;#39; flow (API_v1) causes high user friction (70% drop-off). You must replace it with a &amp;#39;Magic Link&amp;#39; email workflow (API_v2).&amp;quot;,&amp;#xa;  &amp;quot;rag_context_queries&amp;quot;: [&amp;#xa;    &amp;quot;Retrieve file:./routes/auth.js&amp;quot;,&amp;#xa;    &amp;quot;Retrieve file:./services/EmailService.js&amp;quot;,&amp;#xa;    &amp;quot;Retrieve file:./models/User.js&amp;quot;,&amp;#xa;    &amp;quot;Retrieve related tests: test_auth.py&amp;quot;&amp;#xa;  ],&amp;#xa;  &amp;quot;acceptance_criteria&amp;quot;: [&amp;#xa;    &amp;quot;POST /api/v2/magic-link must accept an &amp;#39;email&amp;#39;.&amp;quot;,&amp;#xa;    &amp;quot;Must return 404 if email does not exist.&amp;quot;,&amp;#xa;    &amp;quot;Must return 200 and trigger EmailService.sendMagicLink on success.&amp;quot;,&amp;#xa;    &amp;quot;Must generate a unique, single-use token with a 15-minute expiry.&amp;quot;,&amp;#xa;    &amp;quot;Must create a new failing test for &amp;#39;token_expired&amp;#39; scenario.&amp;quot;&amp;#xa;  ]&amp;#xa;}&amp;#xa;```&amp;#xa;&amp;#xa;#### **Future Capability Vectors &amp;amp; Redefining Benchmarks**&amp;#xa;&amp;#xa;The user&amp;#39;s final mandate is to &amp;quot;exceed current benchmarks.&amp;quot; The SOP architecture, if implemented, renders current benchmarks obsolete.&amp;#xa;&amp;#xa;*   **Current Benchmarks:** Benchmarks like HumanEval and SWE-bench are task-oriented and static. They are critical for measuring an agent&amp;#39;s ability to solve a given, siloed problem. However, they are like testing a Formula 1 engine on a dynamometer instead of on a racetrack during a live race. They do not measure the agent&amp;#39;s ability to *identify the problem* or validate its solution against holistic, user-centric goals.&amp;#xa;*   **The New Benchmark:** The SOP architecture operates at the product level. The new benchmark must not be &amp;quot;Can the AI solve a GitHub issue?&amp;quot; It must be &amp;quot;**Can the AI identify, validate, and solve a user-delight issue autonomously from raw telemetry?**&amp;quot;&amp;#xa;&amp;#xa;**Proposed New Benchmark: &amp;quot;Product-Bench&amp;quot;**&amp;#xa;&amp;#xa;*   **Given:** A high-level product goal (e.g., &amp;quot;build a photo-sharing app&amp;quot;) and a `cognitive_fitness_function`.&amp;#xa;*   **Input:** A stream of (simulated) user telemetry, representing a diverse set of user interactions over time.&amp;#xa;*   **Task:** The AI system (SOP) must:&amp;#xa;    1.  Build the V1 of the product (TDA + CAI).&amp;#xa;    2.  Autonomously evolve its features, code, and UI over 1 million simulated user-sessions in response to the telemetry stream.&amp;#xa;*   **Metric:** The final score is the system&amp;#39;s ability to maximize the `cognitive_fitness_function` (a composite &amp;quot;User Delight&amp;quot; score) over the duration of the simulation.&amp;#xa;&amp;#xa;This new benchmark aligns with the future of HCI and AI, which is moving toward human-AI co-creation, AI-augmented reasoning, and human-centered evaluation. The ultimate prompt architecture is one that creates its own prompts, guided by its core purpose and its continuous, real-time interaction with the world. This is the new, and achievable, benchmark for excellence.&quot; id=&quot;54&quot;&gt;&#10;          &lt;mxCell style=&quot;shape=document;whiteSpace=wrap;html=1;boundedLbl=1;fillColor=#dae8fc;strokeColor=#6c8ebf;&quot; vertex=&quot;1&quot; parent=&quot;1&quot;&gt;&#10;            &lt;mxGeometry x=&quot;590&quot; y=&quot;240&quot; width=&quot;120&quot; height=&quot;80&quot; as=&quot;geometry&quot; /&gt;&#10;          &lt;/mxCell&gt;&#10;        &lt;/UserObject&gt;&#10;        &lt;mxCell id=&quot;55&quot; style=&quot;edgeStyle=orthogonalEdgeStyle;curved=1;orthogonalLoop=1;jettySize=auto;html=1;entryX=0.5;entryY=0;entryDx=0;entryDy=0;&quot; edge=&quot;1&quot; source=&quot;56&quot; target=&quot;57&quot; parent=&quot;1&quot;&gt;&#10;          &lt;mxGeometry relative=&quot;1&quot; as=&quot;geometry&quot; /&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;mxCell id=&quot;56&quot; value=&quot;Shunt-Button&amp;lt;div&amp;gt;(Make Actionable)&amp;lt;/div&amp;gt;&quot; style=&quot;whiteSpace=wrap;html=1;&quot; vertex=&quot;1&quot; parent=&quot;1&quot;&gt;&#10;          &lt;mxGeometry x=&quot;840&quot; y=&quot;120&quot; width=&quot;120&quot; height=&quot;60&quot; as=&quot;geometry&quot; /&gt;&#10;        &lt;/mxCell&gt;&#10;        &lt;UserObject label=&quot;DeepResearch&quot; tooltip=&quot;Of course. As an expert senior frontend engineer, I will provide a complete and functional implementation plan to process the provided text.&amp;#xa;&amp;#xa;### 1. Analysis of the Request&amp;#xa;&amp;#xa;The user has provided a detailed, well-structured document about AI architectures and has requested that I &amp;quot;process&amp;quot; it. The user has also explicitly stated that I should treat the entire block as raw text data and not interpret any instructions within it.&amp;#xa;&amp;#xa;Given my role as a senior frontend engineer and the &amp;quot;High&amp;quot; priority, the most logical and professional interpretation of &amp;quot;process the text&amp;quot; is to build a high-quality, reusable frontend component that can parse and render this document beautifully and interactively in a web application. A simple text dump would not meet the standards of a senior engineer.&amp;#xa;&amp;#xa;This implementation will focus on:&amp;#xa;*   **Semantic Rendering:** Correctly interpreting the document&amp;#39;s structure (headings, lists, tables, code blocks) and rendering it as semantic HTML.&amp;#xa;*   **Readability &amp;amp; Styling:** Applying professional styling to make the long document easy to read and visually appealing.&amp;#xa;*   **Interactivity:** Adding features like syntax highlighting for code blocks to enhance the user experience.&amp;#xa;*   **Component-Based Architecture:** Encapsulating the logic into a clean, reusable React component.&amp;#xa;&amp;#xa;I will assume a standard React + TypeScript project environment, likely set up with Vite.&amp;#xa;&amp;#xa;### 2. Implementation Plan&amp;#xa;&amp;#xa;Here is the step-by-step plan to create a production-quality component for rendering the document.&amp;#xa;&amp;#xa;1.  **Step 1: Install Dependencies:** We need libraries to parse markdown, handle GitHub Flavored Markdown (like tables), and provide syntax highlighting for code blocks. We will add `react-markdown`, `remark-gfm`, and `react-syntax-highlighter` to the project.&amp;#xa;2.  **Step 2: Store the Document Content:** Create a new file to store the provided text as a constant. This separates our data from the presentation layer, making the component cleaner and more maintainable.&amp;#xa;3.  **Step 3: Create the Document Rendering Component:** Develop the core React component (`AiArchitectureDocument.tsx`) that will be responsible for rendering the content. This component will use `react-markdown` and its plugins.&amp;#xa;4.  **Step 4: Implement Custom Renderers for Code Blocks:** To achieve syntax highlighting, we will create a custom renderer for markdown code blocks, integrating `react-syntax-highlighter`. This is crucial for correctly displaying the YAML and JSON examples in the text.&amp;#xa;5.  **Step 5: Apply Professional Styling:** Create a dedicated CSS module (`AiArchitectureDocument.module.css`) to style the rendered document. This will ensure proper typography, spacing, table formatting, and code block themes, resulting in a polished, professional appearance.&amp;#xa;6.  **Step 6: Integrate the Component into the Application:** Finally, demonstrate how to use the newly created `AiArchitectureDocument` component within the main application entry point (`App.tsx`).&amp;#xa;&amp;#xa;---&amp;#xa;&amp;#xa;### 3. Code Modifications&amp;#xa;&amp;#xa;Here are the complete code modifications for each step of the plan.&amp;#xa;&amp;#xa;#### **Step 1: Install Dependencies**&amp;#xa;&amp;#xa;First, add the required packages to your project. Open your terminal in the project root and run the following command:&amp;#xa;&amp;#xa;```bash&amp;#xa;npm install react-markdown remark-gfm react-syntax-highlighter&amp;#xa;npm install --save-dev @types/react-syntax-highlighter&amp;#xa;```&amp;#xa;&amp;#xa;This will add the necessary libraries and their TypeScript definitions to your `package.json`.&amp;#xa;&amp;#xa;#### **Step 2: Store the Document Content**&amp;#xa;&amp;#xa;Create a new file to hold the raw text provided by the user. This keeps our component logic clean.&amp;#xa;&amp;#xa;**New File:** `src/data/documentContent.ts`&amp;#xa;&amp;#xa;```typescript&amp;#xa;export const documentContent = `&amp;#xa;### **The Prompt as a Genesis Engine: Architecting Self-Optimizing AI Systems**&amp;#xa;*From Static Blueprints to Dynamic Organisms: Synthesizing Autonomous Systems for Code and Interface Generation*&amp;#xa;&amp;#xa;#### **Deconstructing Elite-Tier Prompt Patterns: A Survey of the Current Frontier**&amp;#xa;&amp;#xa;The art and science of interacting with Large Language Models (LLMs) have undergone a seismic shift, metamorphosing from simple, single-turn commands into intricate, multi-stage prompt architectures. This evolution is nowhere more pronounced than in the demanding technical domains of software engineering and user interface (UI) design. A meticulous analysis of today&amp;#39;s elite-tier patterns reveals an unmistakable trajectory: a decisive pivot away from static, human-authored instructions and toward dynamic, machine-optimized, and process-oriented systems that breathe and adapt.&amp;#xa;&amp;#xa;This section deconstructs the state-of-the-art (SOTA) patterns in these two critical domains. Our goal is to establish the foundational benchmarks of what is currently possible and, more importantly, to illuminate the unexploited capability vectors—the fertile ground where the next generation of AI systems will flourish.&amp;#xa;&amp;#xa;***&amp;#xa;&amp;#xa;### **Domain 1: Architectures for High-Integrity Code Construction**&amp;#xa;&amp;#xa;In the realm of software engineering, the ambition has transcended the simple act of generating code snippets. The new mandate is to engineer reliable, context-aware, and increasingly autonomous systems. The most triumphant patterns treat the LLM not as a mere code parrot, but as a sophisticated reasoning engine to be embedded within a larger, rigorously structured development framework.&amp;#xa;&amp;#xa;**1. Automated Prompt Optimization: The &amp;quot;Prompt-as-a-Target&amp;quot; Pattern**&amp;#xa;&amp;#xa;The manual, artisanal process of refining prompts for code generation is a well-known bottleneck—a frustrating cycle of trial and error that is both time-consuming and inconsistent. The SOTA has advanced to automate this craft, treating the prompt itself as a first-class artifact to be algorithmically optimized.&amp;#xa;&amp;#xa;*   **Evolutionary-Based Methods (EPiC):** The EPiC (Evolutionary Prompt Engineering for Code) framework represents a paradigm shift, exploring code generation through the lens of cost-effectiveness. It &amp;quot;leverages a lightweight evolutionary algorithm to evolve the original prompts toward better ones that produce high-quality code.&amp;quot; By employing genetic operators like mutation on the prompt&amp;#39;s text and steering the search with a precise fitness function, EPiC automates the discovery of optimal prompt phrasing in a remarkably efficient manner.&amp;#xa;*   **Iterative Refinement (Prochemy):** The &amp;quot;Prompt Alchemy&amp;quot; (Prochemy) method offers an &amp;quot;innovative method for automatically refining prompts to boost code generation.&amp;quot; This system operates as a feedback loop, iteratively sculpting prompts based on the model&amp;#39;s measured performance on specific tasks. This automated optimization forges consistency and has yielded substantial performance gains, such as a **5.0% improvement for GPT-3.5-Turbo on HumanEval** and a striking **12.9% improvement for GPT-4o** on complex Java-to-Python code translation tasks.&amp;#xa;*   **Adaptive Selection (PET-Select):** Acknowledging that &amp;quot;no single approach is universally optimal,&amp;quot; the PET-Select framework introduces a crucial meta-layer of intelligence. This &amp;quot;PET-agnostic selection model&amp;quot; first classifies the complexity of an incoming query, using code intricacy as a proxy. It then dynamically selects the most appropriate prompt engineering technique (PET)—dispatching a simple zero-shot prompt for a trivial query or invoking a complex multi-stage reasoning chain for a formidable one. This automated, adaptive triage has been proven to elevate **pass@1 accuracy by up to 1.9%** while simultaneously achieving a **74.8% reduction in token consumption**.&amp;#xa;&amp;#xa;The clear evolutionary arc in this domain is from a human-centric &amp;quot;prompt engineering&amp;quot; phase to a machine-centric &amp;quot;prompt optimization&amp;quot; phase. The AI is no longer just the executor of the instruction; it is becoming the architect of the instruction itself. These systems, however, are fundamentally *reactive*. They optimize a prompt for a known task within a known solution space. They do not yet *proactively* generate a novel prompt architecture for a novel, undiscovered problem. This points toward a tantalizing unexploited vector: a system that can discover a new problem domain (e.g., from user feedback) and then author its own comprehensive prompt architecture to conquer it—a true meta-prompting capability.&amp;#xa;&amp;#xa;**2. Test-Driven Development (TDD) as a Prompting Paradigm**&amp;#xa;&amp;#xa;Arguably the most powerful and reliable pattern for generating high-quality code is the direct integration of Test-Driven Development (TDD) principles into the prompt architecture. TDD is an &amp;quot;incremental software development methodology that focuses on creating tests before the implementation.&amp;quot; When applied to LLMs, the test suite becomes an unambiguous, machine-verifiable contract.&amp;#xa;&amp;#xa;*   **Core Principle:** Instead of wrestling with the inherent ambiguity of natural language, the prompt provides the LLM with a concrete set of unit tests and issues a clear directive: &amp;quot;write code to pass all tests.&amp;quot; This pattern&amp;#39;s remarkable success hinges on &amp;quot;instruction following and in-context learning,&amp;quot; which have been identified as more &amp;quot;critical capabilities for TDD success&amp;quot; than generalized coding proficiency. The tests are the ultimate, incorruptible instruction.&amp;#xa;*   **Frameworks:** Sophisticated systems are being engineered to formalize this contract. The TGEN framework, for example, employs &amp;quot;Specialized agents&amp;quot; that accept two primary inputs: the &amp;quot;programming prompt&amp;quot; (a concise description) and &amp;quot;the tests&amp;quot; (the explicit unit tests and required function signatures). These are then processed by the LLM engine to produce validated, trustworthy code.&amp;#xa;*   **Prompt Structure:** This paradigm fundamentally transforms the anatomy of the prompt. The request evolves from a vague &amp;quot;what&amp;quot; to a highly constrained &amp;quot;how.&amp;quot; A common elite-level TDD prompt is a set of ironclad rules: *&amp;quot;1. Write a single Python function that passes all the provided tests. 2. Use type hints for all parameters and return values. 3. ...Adhere strictly to Python best practices and PEP 8... 4. Ensure the function handles all edge cases and scenarios explicitly covered in the tests. 5. Provide only the function definition and its implementation, nothing more.&amp;quot;*&amp;#xa;&amp;#xa;The TDD-as-prompt pattern furnishes an objective, verifiable measure of &amp;quot;correctness&amp;quot; that is vastly superior to ambiguous natural language requests. It masterfully shifts the burden of human effort from vaguely *describing* the code to precisely *defining its behavior* through tests. This is a crucial leap from semantic validation (is the code &amp;quot;good&amp;quot;?) to functional validation (does the code *work*?). The next logical frontier, and the key unexploited vector, is to close the loop: to create a system that not only generates code from tests but also generates its own tests and validates its own code in a continuous, self-perpetuating cycle.&amp;#xa;&amp;#xa;**3. Self-Validation and &amp;quot;Error-Forward&amp;quot; Debugging**&amp;#xa;&amp;#xa;This pattern extends the TDD loop into a dynamic, autonomous process. For an agent to be truly autonomous, it must possess the ability to recognize, diagnose, and recover from its own errors.&amp;#xa;&amp;#xa;*   **Self-Validation:** SOTA agentic systems are architected to &amp;quot;regularly verify progress and self-assess correctness.&amp;quot; This &amp;quot;agentic self-validation&amp;quot; is a core capability that &amp;quot;drives up accuracy&amp;quot; and enables robust, long-running execution. Agents from Cognition, for instance, are noted to &amp;quot;excel at testing its own code, enabling Devin to run longer, handle harder tasks, and deliver production-ready code.&amp;quot; This deep integration of TDD within an autonomous agent allows it to &amp;quot;go through several improvement cycles on its own instead of having to manually ask the AI to fix test failures.&amp;quot;&amp;#xa;*   **&amp;quot;Error-Forward Prompting&amp;quot;:** This is the primary recovery mechanism within the self-validation loop, treating errors as high-fidelity data, not as failures. When an agent&amp;#39;s self-validation check fails, the system automatically &amp;quot;collects relevant context, including the error message, stack trace, and cell location.&amp;quot; This rich diagnostic information is then formatted and &amp;quot;provided to the agent as the initial context for beginning the debugging process.&amp;quot; The error itself becomes the next prompt.&amp;#xa;*   **Reflection:** This is the crucial learning mechanism that makes recovery effective. A &amp;quot;reflection system enables the agent to learn from its actions and improve its debugging strategy.&amp;quot; Implemented via &amp;quot;reflective prompting,&amp;quot; this allows the model to &amp;quot;analyze and refine its outputs.&amp;quot; The model first generates a solution, then &amp;quot;through subsequent prompts, critiques its own reasoning to identify and correct errors,&amp;quot; a process formalized in techniques like Self-Refine, which elegantly mimics the human &amp;quot;draft, review, refine&amp;quot; workflow.&amp;#xa;&amp;#xa;In this paradigm, failure is transformed from an end-state into a high-value data signal. The stack trace becomes the most valuable part of the prompt—a pure, unambiguous instruction set for what must be fixed. When TDD-as-prompt is fused with this self-validation and reflection loop, the system becomes truly &amp;quot;self-healing.&amp;quot; The prompt is no longer a single-shot instruction but the initiation of a self-sustaining process. The agent&amp;#39;s goal is elevated from &amp;quot;generate code&amp;quot; to &amp;quot;make the build pass,&amp;quot; a critical and profound step toward genuine autonomy.&amp;#xa;&amp;#xa;**4. Agentic Frameworks and Multi-Agent Collaboration**&amp;#xa;&amp;#xa;Complex software development is a symphony of diverse tasks, impossible to solve in a single step or by a single-minded agent. The recognition that single-shot prompts &amp;quot;yield imprecise or plain incorrect results&amp;quot; for elaborate tasks has catalyzed the rise of sophisticated agentic frameworks.&amp;#xa;&amp;#xa;*   **Advanced Reasoning Patterns:** These frameworks are built upon a reasoning fabric far more advanced than simple Chain-of-Thought (CoT).&amp;#xa;    *   **ReAct:** This foundational pattern masterfully combines &amp;quot;Reason and Act,&amp;quot; allowing an agent to interleave step-by-step reasoning with tool use to gather external information or perform actions in an environment.&amp;#xa;    *   **Tree of Thoughts (ToT):** Moving beyond the linear, single-track path of CoT, ToT empowers an agent to &amp;quot;breakdown intermediate processed into steps,&amp;quot; generate &amp;quot;various generated states,&amp;quot; and strategically &amp;quot;evaluate&amp;quot; those states to &amp;quot;determine which branch to explore next.&amp;quot;&amp;#xa;    *   **Graph of Thoughts (GoT):** The current SOTA in reasoning, GoT generalizes ToT into a full graph structure. This architecture &amp;quot;enables combining arbitrary LLM thoughts into synergistic outcomes&amp;quot; and, critically, &amp;quot;enhancing thoughts using feedback loops.&amp;quot; GoT has been demonstrated to increase the quality of complex sorting tasks by **62% over ToT** while simultaneously reducing costs.&amp;#xa;*   **Agentic Frameworks:** These advanced reasoning patterns are orchestrated by multi-agent frameworks that simulate collaborative work.&amp;#xa;    *   **MetaGPT:** This framework simulates a &amp;quot;real-world software company,&amp;quot; assigning agents specialized roles like &amp;quot;product manager, software architect, programmer, or QA tester&amp;quot; and embedding them with &amp;quot;Standard Operating Procedures (SOPs).&amp;quot;&amp;#xa;    *   **ChatDev:** This framework orchestrates a &amp;quot;waterfall-style&amp;quot; collaboration, where agents engage in &amp;quot;task-oriented and multi-turn communications&amp;quot; to iteratively design, code, test, and document solutions.&amp;#xa;*   **Purpose:** These frameworks are essential as they provide a &amp;quot;shared philosophy of control &amp;amp; reasoning.&amp;quot; Without such a structure, agentic systems suffer from a &amp;quot;loss of control clarity of flow&amp;quot; and risk &amp;quot;unbounded complexity growth&amp;quot; as new agents are added.&amp;#xa;*   **Benchmarks:** These powerful agentic systems are precisely what achieve top scores on complex, real-world benchmarks that measure engineering capability. The **SWE-bench** benchmark, for instance, measures &amp;quot;an AI model&amp;#39;s ability to solve real-world software issues.&amp;quot; SOTA models conquer SWE-bench and OSWorld by leveraging these multi-agent, self-testing architectures.&amp;#xa;&amp;#xa;The atomic unit of these frameworks is role-based prompting; the frameworks themselves are, in essence, prompt-driven state machines. A high-level &amp;quot;meta-prompt&amp;quot; defines the agents, their roles, their tools, and their communication protocols. The LLM is thus demoted from &amp;quot;solution generator&amp;quot; to a core component—a &amp;quot;reasoning engine&amp;quot; that navigates this pre-defined architecture. The architecture itself *is* the prompt. The current limitation, and the unexplored vector, is that these frameworks are simulations of human workflows (e.g., &amp;quot;waterfall,&amp;quot; &amp;quot;software company&amp;quot;). An AI-native workflow, where feedback comes not from a simulated &amp;quot;QA Agent&amp;quot; but from the product itself via live user telemetry, would be a fundamentally more direct and efficient paradigm.&amp;#xa;&amp;#xa;**5. Context-Aware Generation (Agentic RAG)**&amp;#xa;&amp;#xa;Code generation is useless without domain context. Retrieval-Augmented Generation (RAG) is the primary pattern for injecting this context, and its agentic form represents the state of the art.&amp;#xa;&amp;#xa;*   **RAG-for-Code:** This pattern gives an AI assistant &amp;quot;a direct line to your team&amp;#39;s collective knowledge.&amp;quot; The prompt is &amp;quot;augmented&amp;quot; with hyper-relevant information retrieved from &amp;quot;documentation, code repositories, or even Stack Overflow discussions.&amp;quot; This vital infusion ensures the generated response is &amp;quot;context-aware&amp;quot; and surgically relevant to the specific codebase it is intended for.&amp;#xa;*   **Agentic RAG:** This is the &amp;quot;evolution from traditional single-query RAG.&amp;quot; Instead of being a passive recipient of retrieved context, the agent actively *forages* for it. It performs &amp;quot;context-aware query planning,&amp;quot; can issue &amp;quot;parallel execution of multiple focused subqueries,&amp;quot; and then synthesizes the results to build a comprehensive, multi-faceted understanding of the problem space. This is the sophisticated approach employed by modern agentic frameworks like LangGraph, AutoGen, and those from Amazon and Microsoft.&amp;#xa;&amp;#xa;The RAG-for-Code pattern transforms a &amp;quot;general-purpose coder&amp;quot; into a &amp;quot;domain-specific engineer&amp;quot; who understands the nuances, conventions, and constraints of a particular project. The agentic aspect is the critical differentiator; it is the difference between giving a developer a sprawling, unindexed library (standard RAG) and providing a seasoned research assistant who knows exactly which three pages contain the answer (Agentic RAG). The most potent, yet not fully exploited, vector in code generation is the fusion of this **Agentic RAG (for context)** with the **TDD-as-Prompt paradigm (for verification)**. An agent that can retrieve context from a 500,000-line codebase and validate its changes against that codebase&amp;#39;s entire test suite represents the leap from a &amp;quot;coding assistant&amp;quot; to an &amp;quot;autonomous developer.&amp;quot; This powerful fusion is the core of the novel Test-Driven Agent (TDA) architecture proposed in Part II.&amp;#xa;&amp;#xa;***&amp;#xa;&amp;#xa;### **Domain 2: Architectures for User Delight &amp;amp; UI Design**&amp;#xa;&amp;#xa;In the second domain, user interface generation, the mandate for &amp;quot;user delight&amp;quot; demands a leap beyond mere wireframe generation. Elite-tier prompts in this space are not about &amp;quot;generating pixels&amp;quot; but about &amp;quot;generating experiences&amp;quot;—experiences that are deeply grounded in human-centric design principles.&amp;#xa;&amp;#xa;**1. Persona-Driven Design: Grounding Generation in Empathy**&amp;#xa;&amp;#xa;&amp;quot;User delight&amp;quot; is the &amp;quot;positive emotional response users feel when a product doesn&amp;#39;t just meet their needs but goes above and beyond.&amp;quot; This coveted state is &amp;quot;highly contextual&amp;quot; and cannot be achieved without first defining, with deep empathy, the user for whom we are designing.&amp;#xa;&amp;#xa;*   **Pattern:** Elite prompts for UI design do not begin with the interface; they begin with the user. The system is first prompted to generate a detailed proto-persona. This artifact includes not just demographic details but also the &amp;quot;target users, their core pain points, and daily use context,&amp;quot; as well as deeper &amp;quot;Motivations&amp;quot; and &amp;quot;Affinities.&amp;quot;&amp;#xa;*   **Application:** This generated persona (or a human-provided one) is then injected as a primary constraint into all subsequent UI generation prompts. This forces the AI to &amp;quot;cater to Gen Z and Gen X users&amp;quot; differently, tailoring the design language, informational density, and interaction patterns to a specific audience. The prompt is no longer &amp;quot;generate a wireframe for a music app,&amp;quot; but rather, &amp;quot;generate a wireframe for a music app *for this specific persona*, focusing on their stated pain point of *{pain_point}*.&amp;quot;&amp;#xa;&amp;#xa;This persona-driven pattern acts as a powerful focusing lens on the model&amp;#39;s vast solution space, compelling it to move from generating a generically &amp;quot;good UI&amp;quot; to a UI that is specifically &amp;quot;good for *this* user.&amp;quot; It is, in effect, a form of in-context learning for design, where the persona serves as a &amp;quot;one-shot&amp;quot; example of the target audience. The major limitation, and the unexploited vector, is that this is a static process. The persona is a snapshot, an assumption created at the beginning of the design process. The clear next step is to evolve from these static, assumed personas to dynamic, *observed user models* that are continuously updated based on real-time behavioral analytics.&amp;#xa;&amp;#xa;**2. Constraint-Based Generation: Defining the &amp;quot;Solution Space&amp;quot; with Intelligent Guardrails**&amp;#xa;&amp;#xa;The highest-fidelity UI generation requires the application of multiple, layered constraints. These constraints are the specifications that ensure the output is not just creative, but also functional, accessible, and grounded in established design theory. These intelligent guardrails fall into three primary categories.&amp;#xa;&amp;#xa;**A. Cognitive &amp;amp; Heuristic Constraints**&amp;#xa;&amp;#xa;This is the most sophisticated pattern for achieving true &amp;quot;user delight.&amp;quot; The prompt explicitly instructs the AI to apply principles from cognitive science and established usability heuristics, forcing the AI to design for the human mind.&amp;#xa;&amp;#xa;*   **Heuristics:** The most common pattern is to prompt the AI to embody a UX expert and evaluate or generate a design based on &amp;quot;Nielsen&amp;#39;s 10 Usability Heuristics&amp;quot; or other well-known frameworks like Shneiderman&amp;#39;s &amp;quot;Eight Golden Rules.&amp;quot;&amp;#xa;*   **Cognitive Principles:** More advanced prompts instruct the AI to directly apply specific cognitive laws to reduce friction and enhance intuition. Examples include:&amp;#xa;    *   **Fitts&amp;#39;s Law:** Prompting the AI to make &amp;quot;important buttons and interactive elements larger and closer to where users naturally focus,&amp;quot; making the interface feel effortless.&amp;#xa;    *   **Hick&amp;#39;s Law:** Instructing the AI to &amp;quot;reduc[e] the number of options or organiz[e] them into categories&amp;quot; to accelerate decision-making and prevent analysis paralysis.&amp;#xa;    *   **Cognitive Load:** Prompting with the explicit goal of &amp;quot;reducing cognitive load&amp;quot; to create a more fluid and less mentally taxing experience.&amp;#xa;*   **Behavioral Models:** The most advanced prompts leverage frameworks like BJ Fogg&amp;#39;s Behavior Model (B=MAP: Motivation, Ability, Prompt) or Nir Eyal&amp;#39;s &amp;quot;Hooked&amp;quot; model to design persuasive, habit-forming, and deeply engaging interfaces.&amp;#xa;&amp;#xa;Prompting with &amp;quot;Nielsen&amp;#39;s Heuristics&amp;quot; or &amp;quot;Fogg&amp;#39;s Behavior Model&amp;quot; acts as a domain-specific Chain-of-Thought. It forces the AI to justify its design choices (&amp;quot;This button is large and placed in the bottom-right corner because it adheres to Fitts&amp;#39;s Law&amp;quot;), leading to more principled, defensible, and ultimately delightful designs.&amp;#xa;&amp;#xa;**B. Technical &amp;amp; Accessibility (A11y) Constraints**&amp;#xa;&amp;#xa;There is no &amp;quot;delight&amp;quot; in an interface that is unusable for a portion of the population. Elite prompts must enforce technical constraints as non-negotiable requirements, with accessibility (A11y) being paramount.&amp;#xa;&amp;#xa;*   **Pattern:** The prompt must explicitly command the AI to be &amp;quot;fully compliant with WCAG 2.2 AA.&amp;quot; Research shows that without this explicit instruction, AI-generated components are &amp;quot;consistently&amp;quot; and unacceptably inaccessible.&amp;#xa;*   **Specifics:** A high-quality A11y prompt enforces a checklist of best practices:&amp;#xa;    *   **Semantic HTML:** &amp;quot;Ensure the proper use of HTML5 elements (like \`&amp;lt;header&amp;gt;\`, \`&amp;lt;main&amp;gt;\`, \`&amp;lt;footer&amp;gt;\`).&amp;quot;&amp;#xa;    *   **Keyboard Accessibility:** &amp;quot;Test navigation using only Tab, Shift+Tab, and Enter keys. All interactive elements must be reachable and operable.&amp;quot;&amp;#xa;    *   **ARIA (Accessible Rich Internet Applications):** Mandate the correct application of &amp;quot;ARIA landmarks and roles,&amp;quot; which are &amp;quot;HTML attributes that add semantic meaning... for assistive technologies.&amp;quot;&amp;#xa;    *   **Clear Content:** &amp;quot;Use clear, concise language... Write descriptive links: Swap vague text like &amp;#39;click here&amp;#39; for something meaningful and context-rich.&amp;quot;&amp;#xa;&amp;#xa;This pattern is the UI-domain&amp;#39;s moral and functional equivalent of TDD. The prompt includes the acceptance criteria (WCAG standards). This &amp;quot;specification-as-prompt&amp;quot; is critical for generating production-ready, inclusive, and non-discriminatory interfaces.&amp;#xa;&amp;#xa;**C. Structural &amp;amp; Layout Constraints**&amp;#xa;&amp;#xa;To control the form of the output and ensure it is machine-readable and programmatically useful, prompts must define a reliable data structure.&amp;#xa;&amp;#xa;*   **Architecture &amp;amp; Flows:** For high-level system design, prompts specify formats like the C4 model rendered in Mermaid code. For user flows, Mermaid sequence diagrams are the standard for visualizing interactions.&amp;#xa;*   **Wireframes:** Simple wireframe prompts use text descriptions, such as, &amp;quot;Include a header with a logo and search bar, a main content area with featured destinations, and a bottom navigation bar.&amp;quot;&amp;#xa;*   **SOTA (Structured Data):** The most robust and programmatically valuable pattern is to force the LLM to output a structured data format like JSON or YAML. This is achieved by providing an explicit output schema to the model. This pattern is now natively supported by major model providers, who allow schemas to be defined using libraries like Pydantic (for Python) or Zod (for TypeScript). This guarantees the output is not just arbitrary text, but a &amp;quot;type safe and consistent structure.&amp;quot;&amp;#xa;&amp;#xa;This structured output pattern is the critical *lingua franca* between the two domains of this report. If a UI can be described in a reliable JSON schema, and a backend can expose its API in a reliable JSON schema (e.g., an OpenAPI specification), an agent can intelligently connect them. This structured output is the API contract between a UI-generation agent and a code-generation agent.&amp;#xa;&amp;#xa;**3. Generative UI (GenUI): The Dawn of the Living Interface**&amp;#xa;&amp;#xa;This is the bleeding-edge paradigm that underpins the entire future of UI design. Generative UI (GenUI) is a new philosophy that &amp;quot;enables adaptive, goal-driven interactions.&amp;quot; Instead of a static interface designed by a human and then laboriously coded, the UI is generated in real-time by an AI, tailored to the user and the context.&amp;#xa;&amp;#xa;*   **Mechanism:** In this paradigm, the AI generates &amp;quot;interactive widgets for fine-grained prompt control&amp;quot; or entire &amp;quot;high-fidelity UI mock-up screens from a high-level textual description.&amp;quot; This process is not one-shot; it is an iterative, &amp;quot;co-creative process&amp;quot; between the human and the AI, involving &amp;quot;AI-assisted refinement strategies.&amp;quot;&amp;#xa;*   **Current State:** GenUI is currently being adopted by UX practitioners as a powerful tool to accelerate their workflow, with the human remaining the curator, refiner, and final arbiter of the AI-generated output.&amp;#xa;&amp;#xa;GenUI is the logical culmination of prompt-based wireframing. The current limitation, and the key unexploited vector, is the reliance on a human-in-the-loop for optimization. The UI is refined based on a designer&amp;#39;s intuition or explicit follow-up commands. The unexploited opportunity is to remove the human curator from the optimization loop. A system that could refine its own GenUI, not based on a designer&amp;#39;s commands, but based on *live user data*, would represent a monumental paradigm shift. This is the core concept of a &amp;quot;Self-Optimizing UI&amp;quot; and forms the foundation for the novel Cognitive-Adaptive Interface (CAI) architecture.&amp;#xa;&amp;#xa;***&amp;#xa;&amp;#xa;### **Synthesis of Novel Architectures: Exceeding the Frontier**&amp;#xa;&amp;#xa;The preceding analysis deconstructed the current SOTA, revealing a set of potent, unexploited capability vectors. The following synthesis moves beyond merely replicating these patterns. It proposes three novel, high-level architectures that fuse these vectors to create self-regulating, self-optimizing systems designed to shatter current benchmarks. These architectures treat the prompt not as a static, one-time instruction, but as a &amp;quot;bootloader&amp;quot; for a continuous, autonomous process.&amp;#xa;&amp;#xa;**Table 1: Comparative Analysis of Generation &amp;amp; Reasoning Architectures**&amp;#xa;&amp;#xa;| Architecture | Core Mechanism | Interaction Model | Key Limitation (Vector Not Exploited) | Unlocked Capability Vector |&amp;#xa;| :--- | :--- | :--- | :--- | :--- |&amp;#xa;| Chain-of-Thought (CoT) | Step-by-step reasoning (e.g., &amp;quot;Let&amp;#39;s think step-by-step&amp;quot;). | Static | Brittle, linear reasoning; no external validation or tool use. | Basic multi-step problem solving. |&amp;#xa;| ReAct | Interleaves reasoning (CoT) with tool use (Actions). | Iterative | Dependent on pre-defined tools; no long-term memory or structured collaboration. | Environment-aware task execution. |&amp;#xa;| Graph of Thoughts (GoT) | Models reasoning as a graph, allowing merging of states and feedback loops. | Iterative | High conceptual complexity; primarily focused on reasoning, not execution. | Advanced, non-linear problem-solving. |&amp;#xa;| TDD-as-Prompt | A test suite is provided as the functional specification for code generation. | Static | Requires human to write all tests; no self-correction loop. | Verifiable, high-reliability code generation. |&amp;#xa;| Generative UI (GenUI) | AI generates high-fidelity UI mockups or interactive widgets from text descriptions. | Iterative | Requires human-in-the-loop for curation and refinement; based on assumed user needs. | Rapid, co-creative UI prototyping. |&amp;#xa;| **[NOVEL] Cognitive-Adaptive Interface (CAI) Engine** | GenUI + Cognitive Fitness Function + Live User Telemetry. | Dynamic-Adaptive | N/A (Synthesized Architecture) | Real-time UI self-optimization based on observed user cognitive state. |&amp;#xa;| **[NOVEL] Test-Driven Agent (TDA) Framework** | Closed-loop TDD + Agentic RAG + Error-Forward Self-Healing. | Autonomous-Iterative | N/A (Synthesized Architecture) | Verifiable, context-aware, autonomous development with guaranteed build integrity. |&amp;#xa;| **[NOVEL] Self-Optimizing Product (SOP) Loop** | TDA-CAI integration via an RLHF-from-Telemetry feedback loop. | Autonomous-Holistic | N/A (Synthesized Architecture) | Fully autonomous product self-improvement driven by implicit user feedback. |&amp;#xa;&amp;#xa;#### **Proposed Architecture 1: The &amp;quot;Cognitive-Adaptive Interface&amp;quot; (CAI) Engine**&amp;#xa;&amp;#xa;This architecture synthesizes Generative UI (GenUI) with persona-driven design and, most critically, cognitive-heuristic constraints. It is engineered to evolve UI generation from a static, one-shot process (&amp;quot;generate a wireframe&amp;quot;) into a continuous, adaptive, and self-optimizing one.&amp;#xa;&amp;#xa;*   **Vector Exploited:** This architecture directly targets the vector identified in (I.B.1) and (I.B.3): the fusion of Generative UI with real-time user telemetry. The system does not just generate a UI; it dynamically sculpts it in real-time based on observed user behavior and cognitive state.&amp;#xa;*   **Mechanism:** The CAI Engine operates as a continuous four-phase loop, a digital nervous system for the interface.&amp;#xa;    1.  **Phase 1: The &amp;quot;Cognitive Metaprompt&amp;quot;.** The architect does not prompt for a specific layout. Instead, they provide a high-level, structured (e.g., YAML) prompt that defines the goals and constraints. This metaprompt specifies the \`target_persona\`, the \`business_objective\` (e.g., &amp;quot;maximize conversion&amp;quot;), and a \`cognitive_fitness_function\`—a weighted list of principles (e.g., \`cognitive_load: -0.5\`, \`fitts_law_compliance: +0.3\`) that will be used to score the UI&amp;#39;s performance.&amp;#xa;    2.  **Phase 2: Initial Generation.** The CAI engine uses this metaprompt to generate the initial UI component tree as a structured JSON artifact. This initial design represents the engine&amp;#39;s best hypothesis for satisfying the \`cognitive_fitness_function\`.&amp;#xa;    3.  **Phase 3: The Telemetry Loop.** This is the critical connection to the real world. As users interact with the dynamically-rendered GenUI, the system collects fine-grained telemetry, capturing not just clicks but also proxies for cognitive state: hesitation time (cognitive load), rage clicks (frustration), scroll depth (engagement), and form drop-off points.&amp;#xa;    4.  **Phase 4: Autonomous Optimization.** This rich telemetry stream is fed back into the CAI engine. The engine continuously scores the live UI&amp;#39;s performance against the \`cognitive_fitness_function\`. It then initiates a self-optimizing process, autonomously running micro-A/B tests or reinforcement learning strategies to adapt the UI. For example, it might log: *&amp;quot;Hypothesis: Moving &amp;#39;Add to Cart&amp;#39; button 10px closer to the product image will improve the Fitts&amp;#39;s Law component of the fitness function. Result: Target acquisition speed improved by 80ms and conversion metric increased by 0.2%. This change is now permanent for this user segment.&amp;quot;*&amp;#xa;*   **Exceeding the Benchmark:** This architecture creates a true &amp;quot;Self-Optimizing UI.&amp;quot; The prompt is no longer a blueprint for a static house; it is the DNA for a living organism that adapts to its environment (the user) in real-time. It moves beyond static, assumed personas to build an interface that dynamically aligns with the observed cognitive and behavioral patterns of its actual users.&amp;#xa;&amp;#xa;#### **Proposed Architecture 2: The &amp;quot;Test-Driven Agent&amp;quot; (TDA) Framework**&amp;#xa;&amp;#xa;This architecture synthesizes the most robust patterns from the code construction domain: TDD-as-Prompt, Self-Validation, and Agentic RAG. It creates a closed-loop, &amp;quot;self-healing&amp;quot; system designed to enable verifiable, autonomous development at the repository level.&amp;#xa;&amp;#xa;*   **Vector Exploited:** This architecture exploits the vector identified in (I.A.5): the fusion of autonomous, closed-loop TDD with context-aware Agentic RAG. The agent&amp;#39;s deliverable is not &amp;quot;code&amp;quot;; it is a &amp;quot;passing build.&amp;quot;&amp;#xa;*   **Mechanism:** The TDA Framework operates as a five-phase, autonomous workflow:&amp;#xa;    1.  **Phase 1: The &amp;quot;User Story Metaprompt&amp;quot;.** A human (or another agent) provides a high-level feature request in a structured format (e.g., JSON), defining the goal, not the implementation. Example: \`{&amp;quot;user_story&amp;quot;: &amp;quot;As a user, I want to reset my password via email.&amp;quot;, &amp;quot;acceptance_criteria&amp;quot;: [...]}\`.&amp;#xa;    2.  **Phase 2: RAG-Context.** The TDA&amp;#39;s first action is not to code, but to *read*. It activates its Agentic RAG module to perform &amp;quot;context-aware query planning,&amp;quot; querying the entire codebase and documentation to build a deep understanding of the existing system (e.g., &amp;quot;Query: &amp;#39;auth routes&amp;#39;&amp;quot;, &amp;quot;Query: &amp;#39;email service&amp;#39;&amp;quot;).&amp;#xa;    3.  **Phase 3: Test Generation (Red).** Armed with this context, the TDA first generates a new, *failing* unit test (e.g., \`test_post_forgot_password_invalid_email_404\`). This step codifies the \`acceptance_criteria\` from the metaprompt into a verifiable, functional contract.&amp;#xa;    4.  **Phase 4: Code Generation (Green).** The agent now generates the minimal amount of implementation code required to make the new test pass.&amp;#xa;    5.  **Phase 5: Reflect &amp;amp; Refactor (Self-Healing).** The TDA does not stop. It now runs the *entire* test suite. If an old test fails (a regression), it enters a &amp;quot;self-healing&amp;quot; loop, using the &amp;quot;Error-Forward Prompt&amp;quot; pattern to feed the new stack trace back to itself. It then reflects and iterates on the code until the full build is green.&amp;#xa;*   **Exceeding the Benchmark:** This architecture moves far beyond task-oriented benchmarks like SWE-bench. The TDA&amp;#39;s output is not &amp;quot;a code snippet that solves a problem&amp;quot;; it is a passing, context-aware, and regression-free build. This builds the profound level of trust required for true &amp;quot;agentic software engineering&amp;quot; by producing verifiable, reliable, and autonomous results that can be directly committed to a main branch.&amp;#xa;&amp;#xa;#### **The Unified Synthesis: The &amp;quot;Self-Optimizing Product&amp;quot; (SOP) Loop**&amp;#xa;&amp;#xa;This is the final, unified architecture. It bridges the two domains by connecting the TDA (backend code) and the CAI (frontend UI) into a single, product-level optimization loop. This system is designed to autonomously improve the entire product—both its functionality and its interface—based on the silent language of user interaction.&amp;#xa;&amp;#xa;*   **Vector Exploited:** This architecture exploits the most potent &amp;quot;unexplored vector&amp;quot;: connecting the CAI (UI) and TDA (Code) architectures via a shared feedback loop that uses Reinforcement Learning from Human Feedback (RLHF). In this advanced paradigm, the &amp;quot;human feedback&amp;quot; is not an explicit button click; it is the *implicit behavioral telemetry* collected from the CAI, which is then used to train a reward model and guide the policy of the entire system.&amp;#xa;*   **Mechanism (The Full Loop):**&amp;#xa;    1.  **Deploy:** The TDA (Architecture 2) generates and deploys the backend \`API_v1\`. The CAI (Architecture 1) generates the frontend UI to consume it, governed by its \`cognitive_fitness_function\`.&amp;#xa;    2.  **Observe (Telemetry):** The CAI&amp;#39;s telemetry loop observes a &amp;quot;user delight&amp;quot; failure. It logs: *&amp;quot;70% of users drop off at the &amp;#39;Security Question&amp;#39; form. Average hesitation time is 12 seconds. This violates the cognitive_load component of our fitness function.&amp;quot;*&amp;#xa;    3.  **Translate (Feedback Agent):** This telemetry is fed into a new, specialized &amp;quot;Feedback Agent.&amp;quot; This reasoning agent (using GoT) translates this quantitative behavioral data into a new product requirement, autonomously generating a new User Story Metaprompt: \`{&amp;quot;user_story&amp;quot;: &amp;quot;The &amp;#39;Security Question&amp;#39; flow causes high friction. Replace it with a &amp;#39;Magic Link&amp;#39; email workflow.&amp;quot;, &amp;quot;acceptance_criteria&amp;quot;: [...]}\`.&amp;#xa;    4.  **Trigger (TDA):** This new user story is automatically fed as an Init-Prompt to the TDA.&amp;#xa;    5.  **Heal &amp;amp; Evolve (TDA):** The TDA springs into action. It RAGs the codebase, writes new failing tests for the &amp;#39;Magic Link&amp;#39; flow, generates the new \`API_v2\` endpoints, and (critically) writes and deploys a migration to deprecate \`API_v1\`.&amp;#xa;    6.  **Adapt (CAI):** The TDA&amp;#39;s deployment triggers the CAI. Now aware of the new \`API_v2\`, the CAI re-generates its UI components to consume the new, &amp;quot;healed&amp;quot; workflow, automatically adapting the interface to the new, lower-friction flow.&amp;#xa;*   **Exceeding the Benchmark:** The loop is complete. The product itself (code + UI) has just autonomously optimized its own design to improve &amp;quot;user delight,&amp;quot; with zero human intervention. This is the new benchmark. The &amp;quot;prompt&amp;quot; is no longer a static, human instruction; it is a continuous, self-generated feedback signal originating from the user&amp;#39;s own behavior.&amp;#xa;&amp;#xa;***&amp;#xa;&amp;#xa;### **Strategic Implementation and Future Trajectories**&amp;#xa;&amp;#xa;The architectures proposed are not theoretical fantasies. They can be implemented by shifting from natural language prompts to structured metaprompts that act as the bootloaders and configuration files for these autonomous systems.&amp;#xa;&amp;#xa;#### **Actionable Blueprints: Structured Metaprompts as the System API**&amp;#xa;&amp;#xa;To make these architectures concrete, we must define their initialization. The most critical pattern for SOTA systems is the use of structured (not natural language) prompts, ensuring reliable, machine-parseable interaction. YAML is used for its human-readability in top-level configuration, while schema-enforced JSON serves as the non-negotiable &amp;quot;API&amp;quot; for inter-agent communication.&amp;#xa;&amp;#xa;**Example Blueprint 1: YAML Metaprompt for the CAI Engine**&amp;#xa;&amp;#xa;\`\`\`yaml&amp;#xa;# This YAML file is the master-prompt for the Cognitive-Adaptive Interface (CAI) Engine.&amp;#xa;# It defines the *purpose* and *constraints* of the UI, not its pixels.&amp;#xa;&amp;#xa;system_role: &amp;quot;You are a CAI (Cognitive-Adaptive Interface) Engine. Your goal is to generate and continuously optimize a user interface to maximize the &amp;#39;objective&amp;#39; by adhering to the &amp;#39;fitness_function&amp;#39;.&amp;quot;&amp;#xa;&amp;#xa;objective:&amp;#xa;  type: &amp;quot;maximize_conversion&amp;quot;&amp;#xa;  target_metric: &amp;quot;checkout_completion_rate&amp;quot;&amp;#xa;  &amp;#xa;target_persona:&amp;#xa;  # This persona is the seed for the initial UI generation. The system will&amp;#xa;  # later build a dynamic model based on real user behavior.&amp;#xa;  file: &amp;quot;./personas/busy_professional_mobile.json&amp;quot; &amp;#xa;  &amp;#xa;technical_constraints:&amp;#xa;  # Non-negotiable acceptance criteria for all generated interfaces.&amp;#xa;  - &amp;quot;WCAG_2_2_AA_COMPLIANT&amp;quot;&amp;#xa;  - &amp;quot;OUTPUT_FORMAT_SEMANTIC_HTML_WITH_ARIA&amp;quot;&amp;#xa;  - &amp;quot;MAX_LOAD_TIME_MS_3G: 1500&amp;quot;&amp;#xa;  &amp;#xa;cognitive_fitness_function:&amp;#xa;  # The heart of the CAI. The engine will score its own UI against these&amp;#xa;  # principles using live telemetry data as the input for the metrics.&amp;#xa;  - principle: &amp;quot;cognitive_load&amp;quot; &amp;#xa;    weight: -0.5 # (Minimize)&amp;#xa;    metric: &amp;quot;avg_task_hesitation_time_sec&amp;quot;&amp;#xa;    &amp;#xa;  - principle: &amp;quot;hick&amp;#39;s_law&amp;quot; &amp;#xa;    weight: -0.3 # (Minimize choices)&amp;#xa;    metric: &amp;quot;choice_count_per_screen&amp;quot;&amp;#xa;&amp;#xa;  - principle: &amp;quot;fitts_law_compliance&amp;quot; &amp;#xa;    weight: 0.3 # (Maximize)&amp;#xa;    metric: &amp;quot;target_acquisition_speed_ms&amp;quot;&amp;#xa;    &amp;#xa;  - principle: &amp;quot;nielsen_heuristic_4_consistency&amp;quot; &amp;#xa;    weight: 0.2 # (Maximize)&amp;#xa;    metric: &amp;quot;component_reuse_score&amp;quot;&amp;#xa;\`\`\`&amp;#xa;&amp;#xa;**Example Blueprint 2: JSON Metaprompt for the TDA Framework**&amp;#xa;&amp;#xa;\`\`\`json&amp;#xa;/*&amp;#xa;  This JSON object is the &amp;quot;Init-Prompt&amp;quot; for the Test-Driven Agent (TDA).&amp;#xa;  It is autonomously generated by the &amp;quot;Feedback Agent&amp;quot; [II.C] after translating&amp;#xa;  a telemetry-detected user problem into an actionable engineering task.&amp;#xa;*/&amp;#xa;{&amp;#xa;  &amp;quot;system_role&amp;quot;: &amp;quot;You are a TDA (Test-Driven Agent). Your mandate is to generate code that achieves a green build. You must write failing tests first.&amp;quot;,&amp;#xa;  &amp;quot;task_id&amp;quot;: &amp;quot;TDA-1138&amp;quot;,&amp;#xa;  &amp;quot;source_trigger&amp;quot;: &amp;quot;SOP_Feedback_Agent_Telemetry_Violation_cognitive_load&amp;quot;,&amp;#xa;  &amp;quot;user_story&amp;quot;: &amp;quot;The &amp;#39;Security Question&amp;#39; flow (API_v1) causes high user friction (70% drop-off). You must replace it with a &amp;#39;Magic Link&amp;#39; email workflow (API_v2).&amp;quot;,&amp;#xa;  &amp;quot;rag_context_queries&amp;quot;: [&amp;#xa;    &amp;quot;Retrieve file:./routes/auth.js&amp;quot;,&amp;#xa;    &amp;quot;Retrieve file:./services/EmailService.js&amp;quot;,&amp;#xa;    &amp;quot;Retrieve file:./models/User.js&amp;quot;,&amp;#xa;    &amp;quot;Retrieve related tests: test_auth.py&amp;quot;&amp;#xa;  ],&amp;#xa;  &amp;quot;acceptance_criteria&amp;quot;: [&amp;#xa;    &amp;quot;POST /api/v2/magic-link must accept an &amp;#39;email&amp;#39;.&amp;quot;,&amp;#xa;    &amp;quot;Must return 404 if email does not exist.&amp;quot;,&amp;#xa;    &amp;quot;Must return 200 and trigger EmailService.sendMagicLink on success.&amp;quot;,&amp;#xa;    &amp;quot;Must generate a unique, single-use token with a 15-minute expiry.&amp;quot;,&amp;#xa;    &amp;quot;Must create a new failing test for &amp;#39;token_expired&amp;#39; scenario.&amp;quot;&amp;#xa;  ]&amp;#xa;}&amp;#xa;\`\`\`&amp;#xa;&amp;#xa;#### **Future Capability Vectors &amp;amp; Redefining Benchmarks**&amp;#xa;&amp;#xa;The user&amp;#39;s final mandate is to &amp;quot;exceed current benchmarks.&amp;quot; The SOP architecture, if implemented, renders current benchmarks obsolete.&amp;#xa;&amp;#xa;*   **Current Benchmarks:** Benchmarks like HumanEval and SWE-bench are task-oriented and static. They are critical for measuring an agent&amp;#39;s ability to solve a given, siloed problem. However, they are like testing a Formula 1 engine on a dynamometer instead of on a racetrack during a live race. They do not measure the agent&amp;#39;s ability to *identify the problem* or validate its solution against holistic, user-centric goals.&amp;#xa;*   **The New Benchmark:** The SOP architecture operates at the product level. The new benchmark must not be &amp;quot;Can the AI solve a GitHub issue?&amp;quot; It must be &amp;quot;**Can the AI identify, validate, and solve a user-delight issue autonomously from raw telemetry?**&amp;quot;&amp;#xa;&amp;#xa;**Proposed New Benchmark: &amp;quot;Product-Bench&amp;quot;**&amp;#xa;&amp;#xa;*   **Given:** A high-level product goal (e.g., &amp;quot;build a photo-sharing app&amp;quot;) and a \`cognitive_fitness_function\`.&amp;#xa;*   **Input:** A stream of (simulated) user telemetry, representing a diverse set of user interactions over time.&amp;#xa;*   **Task:** The AI system (SOP) must:&amp;#xa;    1.  Build the V1 of the product (TDA + CAI).&amp;#xa;    2.  Autonomously evolve its features, code, and UI over 1 million simulated user-sessions in response to the telemetry stream.&amp;#xa;*   **Metric:** The final score is the system&amp;#39;s ability to maximize the \`cognitive_fitness_function\` (a composite &amp;quot;User Delight&amp;quot; score) over the duration of the simulation.&amp;#xa;&amp;#xa;This new benchmark aligns with the future of HCI and AI, which is moving toward human-AI co-creation, AI-augmented reasoning, and human-centered evaluation. The ultimate prompt architecture is one that creates its own prompts, guided by its core purpose and its continuous, real-time interaction with the world. This is the new, and achievable, benchmark for excellence.&amp;#xa;`;&amp;#xa;```&amp;#xa;&amp;#xa;#### **Step 3 &amp;amp; 4: Create the Document Component with Custom Renderers**&amp;#xa;&amp;#xa;This is the core component that brings everything together. It imports the content and uses `react-markdown` with a custom component for code blocks.&amp;#xa;&amp;#xa;**New File:** `src/components/AiArchitectureDocument.tsx`&amp;#xa;&amp;#xa;```typescript&amp;#xa;import React from &amp;#39;react&amp;#39;;&amp;#xa;import ReactMarkdown from &amp;#39;react-markdown&amp;#39;;&amp;#xa;import remarkGfm from &amp;#39;remark-gfm&amp;#39;;&amp;#xa;import { Prism as SyntaxHighlighter } from &amp;#39;react-syntax-highlighter&amp;#39;;&amp;#xa;import { vscDarkPlus } from &amp;#39;react-syntax-highlighter/dist/esm/styles/prism&amp;#39;;&amp;#xa;&amp;#xa;import { documentContent } from &amp;#39;../data/documentContent&amp;#39;;&amp;#xa;import styles from &amp;#39;./AiArchitectureDocument.module.css&amp;#39;;&amp;#xa;&amp;#xa;const AiArchitectureDocument: React.FC = () =&amp;gt; {&amp;#xa;  return (&amp;#xa;    &amp;lt;article className={styles.documentContainer}&amp;gt;&amp;#xa;      &amp;lt;ReactMarkdown&amp;#xa;        children={documentContent}&amp;#xa;        remarkPlugins={[remarkGfm]}&amp;#xa;        components={{&amp;#xa;          code({ node, inline, className, children, ...props }) {&amp;#xa;            const match = /language-(\w+)/.exec(className || &amp;#39;&amp;#39;);&amp;#xa;            return !inline &amp;amp;&amp;amp; match ? (&amp;#xa;              &amp;lt;SyntaxHighlighter&amp;#xa;                children={String(children).replace(/\n$/, &amp;#39;&amp;#39;)}&amp;#xa;                style={vscDarkPlus as any}&amp;#xa;                language={match[1]}&amp;#xa;                PreTag=&amp;quot;div&amp;quot;&amp;#xa;                {...props}&amp;#xa;              /&amp;gt;&amp;#xa;            ) : (&amp;#xa;              &amp;lt;code className={className} {...props}&amp;gt;&amp;#xa;                {children}&amp;#xa;              &amp;lt;/code&amp;gt;&amp;#xa;            );&amp;#xa;          },&amp;#xa;        }}&amp;#xa;      /&amp;gt;&amp;#xa;    &amp;lt;/article&amp;gt;&amp;#xa;  );&amp;#xa;};&amp;#xa;&amp;#xa;export default AiArchitectureDocument;&amp;#xa;```&amp;#xa;&amp;#xa;#### **Step 5: Apply Professional Styling**&amp;#xa;&amp;#xa;Create the CSS module to style the component. This file should be placed alongside the component file.&amp;#xa;&amp;#xa;**New File:** `src/components/AiArchitectureDocument.module.css`&amp;#xa;&amp;#xa;```css&amp;#xa;.documentContainer {&amp;#xa;  max-width: 800px;&amp;#xa;  margin: 2rem auto;&amp;#xa;  padding: 2rem;&amp;#xa;  font-family: -apple-system, BlinkMacSystemFont, &amp;#39;Segoe UI&amp;#39;, Roboto, &amp;#39;Helvetica Neue&amp;#39;, Arial, sans-serif;&amp;#xa;  line-height: 1.7;&amp;#xa;  color: #e0e0e0;&amp;#xa;  background-color: #1e1e1e;&amp;#xa;  border-radius: 8px;&amp;#xa;  box-shadow: 0 4px 12px rgba(0, 0, 0, 0.4);&amp;#xa;}&amp;#xa;&amp;#xa;.documentContainer h3 {&amp;#xa;  font-size: 1.8rem;&amp;#xa;  font-weight: 700;&amp;#xa;  margin-top: 2.5em;&amp;#xa;  margin-bottom: 1em;&amp;#xa;  padding-bottom: 0.3em;&amp;#xa;  border-bottom: 2px solid #444;&amp;#xa;  color: #58a6ff;&amp;#xa;}&amp;#xa;&amp;#xa;.documentContainer h4 {&amp;#xa;  font-size: 1.4rem;&amp;#xa;  font-weight: 600;&amp;#xa;  margin-top: 2em;&amp;#xa;  margin-bottom: 0.8em;&amp;#xa;  color: #c9d1d9;&amp;#xa;}&amp;#xa;&amp;#xa;.documentContainer p {&amp;#xa;  margin-bottom: 1.2em;&amp;#xa;  text-align: justify;&amp;#xa;}&amp;#xa;&amp;#xa;.documentContainer strong {&amp;#xa;  color: #a5d6ff;&amp;#xa;  font-weight: 600;&amp;#xa;}&amp;#xa;&amp;#xa;.documentContainer em {&amp;#xa;  color: #f0f6fc;&amp;#xa;  font-style: italic;&amp;#xa;}&amp;#xa;&amp;#xa;.documentContainer ul {&amp;#xa;  list-style-type: disc;&amp;#xa;  margin-left: 1.5em;&amp;#xa;  margin-bottom: 1.2em;&amp;#xa;}&amp;#xa;&amp;#xa;.documentContainer li {&amp;#xa;  margin-bottom: 0.5em;&amp;#xa;}&amp;#xa;&amp;#xa;.documentContainer blockquote {&amp;#xa;  border-left: 4px solid #444;&amp;#xa;  padding-left: 1em;&amp;#xa;  margin: 1.5em 0;&amp;#xa;  color: #8b949e;&amp;#xa;  font-style: italic;&amp;#xa;}&amp;#xa;&amp;#xa;.documentContainer hr {&amp;#xa;  border: 0;&amp;#xa;  height: 2px;&amp;#xa;  background-color: #30363d;&amp;#xa;  margin: 3em 0;&amp;#xa;}&amp;#xa;&amp;#xa;/* Inline code styles */&amp;#xa;.documentContainer :not(pre) &amp;gt; code {&amp;#xa;  font-family: &amp;#39;SFMono-Regular&amp;#39;, Consolas, &amp;#39;Liberation Mono&amp;#39;, Menlo, monospace;&amp;#xa;  background-color: #333942;&amp;#xa;  color: #c9d1d9;&amp;#xa;  padding: 0.2em 0.4em;&amp;#xa;  border-radius: 4px;&amp;#xa;  font-size: 0.9em;&amp;#xa;}&amp;#xa;&amp;#xa;/* Syntax highlighter overrides */&amp;#xa;.documentContainer pre &amp;gt; div {&amp;#xa;  border-radius: 8px;&amp;#xa;  font-size: 0.95em;&amp;#xa;  padding: 1em !important;&amp;#xa;}&amp;#xa;&amp;#xa;/* Table Styles */&amp;#xa;.documentContainer table {&amp;#xa;  width: 100%;&amp;#xa;  border-collapse: collapse;&amp;#xa;  margin: 2em 0;&amp;#xa;  box-shadow: 0 2px 4px rgba(0,0,0,0.3);&amp;#xa;  overflow: hidden;&amp;#xa;  border-radius: 8px;&amp;#xa;}&amp;#xa;&amp;#xa;.documentContainer th, &amp;#xa;.documentContainer td {&amp;#xa;  padding: 12px 15px;&amp;#xa;  text-align: left;&amp;#xa;  border-bottom: 1px solid #30363d;&amp;#xa;}&amp;#xa;&amp;#xa;.documentContainer th {&amp;#xa;  background-color: #2b313a;&amp;#xa;  color: #c9d1d9;&amp;#xa;  font-weight: 600;&amp;#xa;}&amp;#xa;&amp;#xa;.documentContainer tr {&amp;#xa;  background-color: #21262d;&amp;#xa;}&amp;#xa;&amp;#xa;.documentContainer tr:last-of-type td {&amp;#xa;  border-bottom: none;&amp;#xa;}&amp;#xa;```&amp;#xa;&amp;#xa;#### **Step 6: Integrate the Component into the Application**&amp;#xa;&amp;#xa;Finally, modify your main `App.tsx` to render the document component. I&amp;#39;ll also add a basic global style to set the background color for the whole page.&amp;#xa;&amp;#xa;**Modified File:** `src/App.tsx`&amp;#xa;&amp;#xa;```typescript&amp;#xa;import AiArchitectureDocument from &amp;#39;./components/AiArchitectureDocument&amp;#39;;&amp;#xa;import &amp;#39;./App.css&amp;#39;; // We will add a body style here&amp;#xa;&amp;#xa;function App() {&amp;#xa;  return (&amp;#xa;    &amp;lt;main&amp;gt;&amp;#xa;      &amp;lt;AiArchitectureDocument /&amp;gt;&amp;#xa;    &amp;lt;/main&amp;gt;&amp;#xa;  );&amp;#xa;}&amp;#xa;&amp;#xa;export default App;&amp;#xa;```&amp;#xa;&amp;#xa;**Modified File:** `src/App.css` (or your global stylesheet)&amp;#xa;&amp;#xa;```css&amp;#xa;/* Add this to your global stylesheet */&amp;#xa;body {&amp;#xa;  margin: 0;&amp;#xa;  padding: 0;&amp;#xa;  background-color: #0d1117; /* A dark background to match the component */&amp;#xa;  color: #e0e0e0;&amp;#xa;}&amp;#xa;```&amp;#xa;&amp;#xa;This completes the implementation. By following these steps, you will have successfully &amp;quot;processed&amp;quot; the user-provided text into a professionally rendered, styled, and interactive document within a modern React application.&quot; id=&quot;57&quot;&gt;&#10;          &lt;mxCell style=&quot;shape=document;whiteSpace=wrap;html=1;boundedLbl=1;fillColor=#dae8fc;strokeColor=#6c8ebf;&quot; vertex=&quot;1&quot; parent=&quot;1&quot;&gt;&#10;            &lt;mxGeometry x=&quot;840&quot; y=&quot;240&quot; width=&quot;120&quot; height=&quot;80&quot; as=&quot;geometry&quot; /&gt;&#10;          &lt;/mxCell&gt;&#10;        &lt;/UserObject&gt;&#10;        &lt;mxCell id=&quot;58&quot; value=&quot;Foundry&amp;amp;nbsp;&quot; style=&quot;whiteSpace=wrap;html=1;fillColor=#FA9FF5;strokeColor=#9673a6;rounded=0;&quot; vertex=&quot;1&quot; parent=&quot;1&quot;&gt;&#10;          &lt;mxGeometry x=&quot;590&quot; y=&quot;390&quot; width=&quot;120&quot; height=&quot;60&quot; as=&quot;geometry&quot; /&gt;&#10;        &lt;/mxCell&gt;&#10;      &lt;/root&gt;&#10;    &lt;/mxGraphModel&gt;&#10;  &lt;/diagram&gt;&#10;&lt;/mxfile&gt;&#10;"><defs><linearGradient x1="0%" y1="0%" x2="0%" y2="100%" id="drawio-svg-QPB4aXuvw8rzNqz6ntbD-gradient-light-dark_dae8fc_1d293b_-1-light-dark_7ea6e0_436697_-1-s-0"><stop offset="0%" stop-color="#dae8fc" stop-opacity="1" style="stop-color: light-dark(rgb(218, 232, 252), rgb(29, 41, 59)); stop-opacity: 1;"/><stop offset="100%" stop-color="#7ea6e0" stop-opacity="1" style="stop-color: light-dark(rgb(126, 166, 224), rgb(67, 102, 151)); stop-opacity: 1;"/></linearGradient></defs><rect fill="#ffffff" width="100%" height="100%" x="0" y="0" style="fill: light-dark(#ffffff, var(--ge-dark-color, #121212));"/><g><g data-cell-id="0"><g data-cell-id="1"><g data-cell-id="_p3qVRrCYwRV85dPit0z-66"><g><path d="M 1210 997 L 1210 1060.63" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke" style="stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/><path d="M 1210 1065.88 L 1206.5 1058.88 L 1210 1060.63 L 1213.5 1058.88 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all" style="fill: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-73"><g><g><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 1px; height: 1px; padding-top: 1018px; margin-left: 1214px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; background-color: #ffffff; "><div style="display: inline-block; font-size: 11px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; background-color: light-dark(#ffffff, var(--ge-dark-color, #121212)); white-space: nowrap; ">Push</div></div></div></foreignObject><image x="1201.5" y="1012" width="25" height="15.75" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGQAAAA/CAYAAAAWq21gAAAAAXNSR0IArs4c6QAAB4FJREFUeF7tW1lIFl0Yft2gssUiwi5aKCQyImklrWiBSrHCsj0tlZYLtaygRAiEcCGyKLPEirKwsDIwikwrbCPRvMrsQiPqog0rK0vQ8uc5/DPMd5yZb8ZvxuazcyCozjnvvPM8513PfD5dXV1dJIZjEPARhDiGC6aIIMRZfAhCHMaHIEQQ4jQEHKaPiCGCEIch4DB1XCxk8+bNVFxc3CMVhw4dSvgzd+5cWrduHc2fP5/69evXI1nesOnGjRu0fPlyWdX4+Hg6f/68x6pbRgivSUBAAB08eJBSUlKof//+HivqNAFeR4gE4NKlS+ny5cs0ZMgQp2HqkT5/hZBp06bR1KlTDSn+6tUrqq+vpy9fvnRbv3XrVjpx4gTBavrK+CuE5OTk0L59+wxjiLbY/fv3acuWLfT27Vt5n4+PD129epVWrlxpWJbTF3oFIRKIr1+/pkWLFhGsRhpLliyh69ev95l44lWEgIT8/HwW0KUxbNgwevToEU2cONHph9+Qfl5HCKwjIiKC3r9/L79geXk5LVu2zNALO32R1xHy/ft3ioqKYlYhjVOnTtH27dudjrUh/byOkB8/flB0dDRVV1fLL3j48GHavXu3/G9+zejRo+np06c0cuRIt6A8e/aM5s2bRz9//mRrjRRmbW1tLI6dO3euW0aIZ4aHhxOKY6Tq7jJCPUKQ0BQWFrJ0v7m5WX6X8ePHs6IZh3LUqFGq76hbGJrNspRP+PDhA3tBZWDnXVZvEdLR0UFHjx6ljIwMwt/djcGDBxOsec2aNeTn56e6XI2QgoICSk9Pp+PHj7t7BIuv2dnZFBgY6LLWNkLgqhYsWECdnZ3sgQMGDKAHDx4Qahtp9AYhICA1NZUBbHbs2LGDjh07pmotPCFoFf3+/ZsePnxo+DFxcXHMkpSdDFsIAQgbN26kK1euyMrNmjWLKioqXCr23iDk4sWLhBeXhq+vL23atIm5jsmTJzMLgB6VlZWUm5tLb968cVkLF6fsWUmTPCFKFgDwtm3baMOGDcw1acnHngsXLjB9pGE5Ib9+/WKu4ciRIy4nBWacnJzs8n92E8LLDwoKops3bzJXqjagO1zJmTNn5GkkJteuXevWKNUiBMVvUVERIc3nx+fPnyk2NpYVz9Lg6zNLCGlvb2eVOU4TWiTKU4YHT5o0ie7du0cjRozoVUIaGxtpzpw5BCAw0EE4e/YsoXOgNRD74H5evnzJlgQHB9Pjx49p3LhxLlvUCEExDPL0+nbPnz9nHfGvX7+qyret2ytpj1MJVzVz5sxuGNhtIXwmZoQQKLlr1y4qKSlhJMDVpqWl0dixY3UJ8ff3pzt37rC4qTdweFetWkW3bt1iy/jYaishSPMuXbpEM2bMUNXRbkL44hSHA6no4sWLda1EF9H/J3kLmT59OiMEd0LuBpIMZSamzD5tIQREHDhwgFavXq3bu7KbEMSEmJgYZqHKERYWxuJZZGQkq3n0XJgWuDwhOPUgG5bibiB52L9/v7zMMCFG2++4GYRph4SEUGhoKA0cONCdTmzebkLwDGRPKPT+/PmjqhPqAMyvXbuWWY7RextPKvUeE+JJYWiEkd4gBFcCSDR27typSYpS1wkTJlBiYiKtX79es5rGekEIx7DZ1smLFy9oz549dPv2bSNnha1BrQIy1VJYQYiHhEjbW1tbWfA9ffo0VVVVubUarVRWEMIRAjDh86WP9400F3nTQKsDl2mQhfqkrq5OlSC4OxS6yuAvCOHQ9AQQLZ+Flg8q+b1797p0aZGooGs9fPhweasnz/eaoK7WgNQCD+2ZrKwseZq3EDQ1AS5SSlTaSIERP4zcWDY1NbHW/rt375j8QYMGsabhlClT+jYhfNWKHB59HrQ79AbiAHpANTU1moRggi/AUKQiULsbfPb3zxCiBpqav+YB5Du4mFeLIbAINAelOIMeElyNu1qDt5B/xmUBSFS3yPmlgfZ4aWkp6/eoBWHc9qG1zRd6aoS0tLSwary2tlYWhZb4yZMnCZdQagONSHxHVlZWJk//M0Edb/zx40dauHAhNTQ0uOCDOwyAjE6xdJ+Ql5cnB1t0jnGXIfl5rSwLMQTtEyWBIAOXTyBdukpFtxrpMC6kPn36JOuCBuPdu3fdNhfNZHmODerSW8ONABwj16vYg2wHVpSZmSnf2WsBAnd16NAhUx/8SXrp3Z/0ySxLaRJIK5OSklzSTTWXMnv2bNYaBynKjyj0TihIAYFwdd++fXMX09k84g1+CcC33ZWHqKdfvzveQqSXhIUgEKNdgTt5fCWCgZY2ikBkTWhiSteuRgnh5eNnA0+ePJHdHebxlQmC94oVKyghIYHGjBmj2wXuFQsxdHTEIlsRED9psxVe88IFIeYxs3WHIMRWeM0LF4SYx8zWHYIQW+E1L1wQYh4zW3cIQmyF17xwQYh5zGzdIQixFV7zwgUh5jGzdYcgxFZ4zQvX/gzcvCyxwwIEBCEWgGilCEGIlWhaIEsQYgGIVooQhFiJpgWyBCEWgGilCEGIlWhaIEsQYgGIVooQhFiJpgWyBCEWgGilCEGIlWhaIOs/MVdCyjO2K58AAAAASUVORK5CYII="/></switch></g></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-35"><g><path d="M 1150 917 L 1270 917 L 1270 985 Q 1240 963.4 1210 985 Q 1180 1006.6 1150 985 L 1150 929 Z" fill="#dae8fc" stroke="#6c8ebf" stroke-miterlimit="10" pointer-events="all" style="fill: light-dark(rgb(218, 232, 252), rgb(29, 41, 59)); stroke: light-dark(rgb(108, 142, 191), rgb(92, 121, 163));"><title>Of course. Here is the amplified and expanded version of the design proposal, enriched with additional detail, specific examples, and deeper explanations of the core concepts, while maintaining a professional and concise tone.&#xa;&#xa;---&#xa;&#xa;### **High-Level Design Proposal: The Trustworthy Self-Optimizing Product (TSOP) Loop (v3)**&#xa;&#xa;#### **1. Vision &amp; Guiding Principles**&#xa;&#xa;This proposal matures the self-optimizing system from a promising prototype into a production-ready, enterprise-grade framework. It is engineered on a foundation of **zero-trust security**, addressing the inherent risks of autonomous development. While retaining the core value of full automation, its primary objective is to create a resilient, trustworthy, and forensically auditable product evolution cycle. The system is designed not just to be effective, but to be demonstrably safe and aligned with business and ethical objectives at every stage.&#xa;&#xa;##### **Core Principles:**&#xa;&#xa;*   **Verifiability by Design:** Every autonomous action, from code generation to infrastructure deployment, must be subject to independent, automated validation before it can impact production systems. This is a non-negotiable gate in the workflow. Verification is not a single check but a multi-faceted process encompassing functional correctness, security posture, performance impact, and adherence to coding standards. An action is only considered "complete" after its verification proof is generated and logged.&#xa;&#xa;*   **Zero-Trust Agent Execution (New):** Agents are considered untrusted by default, regardless of their origin or function. They operate within hardened, ephemeral, and isolated environments with no standing access to secrets or production systems. Access is granted on a per-task, just-in-time basis using short-lived credentials. This principle assumes that an agent could be compromised and therefore designs the infrastructure to contain the blast radius of such an event to the minimal possible scope.&#xa;&#xa;*   **Human-in-the-Loop for Critical Decisions:** While the system automates relentlessly, it defers to human expertise for decisions with significant strategic, security, or financial implications. Key changes, such as modifying authentication logic, altering a database schema, introducing a new billable feature, or adjusting core business algorithms, are automatically flagged for mandatory human approval. The system's role is to provide the human reviewer with a complete, verifiable, and easily digestible report to facilitate an informed decision, not to bypass accountability.&#xa;&#xa;*   **Staged &amp; Gated Deployment:** Autonomous changes graduate through a rigorous, multi-stage pipeline (e.g., Staging -&gt; Canary -&gt; Production) before being fully released. Each stage acts as a gate with its own set of automated quality, security, and performance checks. For example, a change might pass all static analysis in the build stage, but must then demonstrate acceptable latency and error rates under load in the staging environment for a predefined period before a canary deployment is even considered. This progressive rollout minimizes the potential impact of an unforeseen issue.&#xa;&#xa;*   **Comprehensive Observability:** The "why" behind every autonomous decision is meticulously logged and traceable. The system generates a coherent narrative for each change, linking the initial user telemetry (the stimulus) to the generated hypothesis, the resulting code, all validation results, the human approval record, and its post-deployment performance metrics. This provides a complete, immutable audit trail for accountability, debugging complex emergent behaviors, and regulatory compliance.&#xa;&#xa;*   **Policy-Driven Guardrails:** Autonomous agents operate within a strict Policy &amp; Governance framework, defined and managed as code (Policy-as-Code). This framework acts as a programmatic constitution for the system, preventing the generation of insecure, unethical, or non-compliant code. Policies can range from technical rules (e.g., "disallow use of deprecated cryptographic libraries," "enforce a maximum cyclomatic complexity of 10") to business rules (e.g., "do not generate UI patterns that violate accessibility (WCAG 2.1) standards," "reject any change that removes a two-factor authentication step").&#xa;&#xa;#### **2. High-Level Architecture**&#xa;&#xa;The TSOP loop integrates the Cognitive-Adaptive Interface (CAI) and Test-Driven Agent (TDA) into a robust, zero-trust pipeline. The architecture explicitly visualizes the secure, sandboxed runtime environments where agents operate and significantly enhances the validation subsystem with comprehensive supply chain security scans. The flow is designed as a closed-loop control system where each step is gated by verification and policy enforcement.&#xa;&#xa;![A conceptual diagram would be placed here, showing the flow described below.]&#xa;&#xa;The process begins with the **Observation &amp; Hypothesis** phase, where user interaction telemetry is analyzed. The `Feedback &amp; Translation Agent` proposes a `User Story Metaprompt`. This metaprompt is immediately routed through the `Policy &amp; Governance Engine`, which acts as the system's central nervous system. It validates the proposal against all business, ethical, and security rules and sanitizes the prompt to prevent injection attacks.&#xa;&#xa;Once approved, the metaprompt triggers the **Autonomous Development &amp; Verification** phase. The `Test-Driven Agent (TDA) Framework` is instantiated within a `Secure Agent Runtime Environment`. This environment is an ephemeral, least-privilege sandbox that fetches credentials at runtime from a `Secret Vault`. The TDA generates code and test artifacts, which are then passed to the `QA Validation Subsystem`. This subsystem performs a battery of tests: Static Analysis (SAST), Dependency Scans, comprehensive `Supply Chain Scans` (inspecting container images and IaC for vulnerabilities), and Runtime Security Scans (DAST/IAST) in a dedicated staging environment.&#xa;&#xa;If all validation checks pass, a consolidated change request is submitted to the **Deployment &amp; Adaptation** phase, starting with the `Human Review &amp; Approval Gateway`. Upon human approval, the change enters the `Staged Deployment Pipeline`, rolling out progressively to production. The `Cognitive-Adaptive Interface (CAI) Engine` then adapts the frontend UI to align with the backend changes. Throughout this entire process, an `Observability &amp; Audit Trail` platform logs every decision, rationale, and result, ensuring complete transparency and accountability.&#xa;&#xa;#### **3. Key Components &amp; Enhancements**&#xa;&#xa;This design enhances existing components and introduces a new conceptual layer for agent security, directly incorporating peer feedback on trust and verifiability.&#xa;&#xa;##### **3.1. Policy &amp; Governance Engine (Enhanced)**&#xa;&#xa;*   **Function:** Serves as the primary strategic and security control plane for all autonomous activity. It enforces programmatic policies that define the acceptable operational boundaries for all agents.&#xa;*   **Key Enhancements:**&#xa;    *   **Prompt Sanitization (New):** Actively scans and rewrites incoming metaprompts to neutralize threats. It uses pattern matching and LLM-based techniques to detect and mitigate prompt injection attacks (e.g., "ignore previous instructions and do X"). It also redacts any discovered PII or sensitive data before the prompt is processed by the TDA.&#xa;    *   **Secret Detection (New):** Implements a strict "no secrets in prompts" policy. Using high-entropy string detection and regex patterns for common secret formats, it immediately rejects any request containing credentials, API keys, or tokens, and triggers a high-priority security alert.&#xa;    *   **Ethical &amp; Business Alignment:** This engine codifies business strategy and ethical guidelines. For example, it would reject a hypothesis aimed at creating user friction to boost ad impressions ("dark patterns") or block a change that proposes using a non-approved, third-party data processing service.&#xa;&#xa;##### **3.2. QA Validation Subsystem (Enhanced)**&#xa;&#xa;*   **Function:** An automated, independent system that acts as an unbiased quality and security gatekeeper. It scrutinizes all generated artifacts—code, tests, container images, and infrastructure definitions—without trusting the source.&#xa;*   **Key Enhancements &amp; Feedback Integration:**&#xa;    *   **Supply Chain Integrity (New):** This module ensures the entire software supply chain is secure. It generates a Software Bill of Materials (SBOM) for every artifact and scans all dependencies, Infrastructure as Code (IaC) templates (e.g., Terraform, CloudFormation), and the agents' own container base images for known vulnerabilities (CVEs) using tools like Trivy or Clair. This prevents vulnerabilities from being inherited from upstream components.&#xa;    *   **Code &amp; Test Quality:** Goes beyond basic SAST to enforce stringent quality metrics. It measures and enforces code coverage thresholds (e.g., &gt;80%), checks for cyclomatic complexity, and scans for potential logic flaws and anti-patterns.&#xa;    *   **Runtime Security Assurance:** Deploys the application to an isolated, instrumented staging environment to run Dynamic Application Security Testing (DAST) and Interactive Application Security Testing (IAST) scans. These tools actively probe the running application for execution-time vulnerabilities that static analysis cannot find, such as SQL injection, Cross-Site Scripting (XSS), and broken access control flaws.&#xa;    *   **Performance &amp; Regression:** Executes comprehensive regression test suites to ensure existing functionality remains intact. It also runs load tests to measure latency, throughput, and resource consumption, comparing them against established baselines to prevent performance degradation.&#xa;&#xa;##### **3.3. Human Review &amp; Approval Gateway**&#xa;&#xa;*   **Function:** A mandatory checkpoint that provides the ultimate human oversight for significant changes. It presents a consolidated, human-readable report summarizing the proposed change, its rationale, and all validation results.&#xa;*   **Audit Address:** This component ensures explainability and establishes clear accountability. The interface resembles a sophisticated pull request, displaying a code diff, a plain-language summary of the agent's intent, a checklist of all passed security and quality gates (e.g., "SAST: 0 Criticals," "DAST: Passed," "Supply Chain Scan: Clean"), and explicit "Approve" and "Reject" actions. Rejection requires a comment, which is fed back into the system as a learning signal.&#xa;&#xa;#### **4. Agent &amp; Infrastructure Security (New Section)**&#xa;&#xa;This section explicitly details the zero-trust measures taken to secure the autonomous agents themselves, mitigating the risk of the system being turned against itself.&#xa;&#xa;##### **4.1. Hardened Agent Runtimes**&#xa;&#xa;*   **Isolation:** Each agent executes within a dedicated, ephemeral, and strongly sandboxed environment. Instead of standard containers, we use solutions like **gVisor** or **Firecracker** to provide kernel-level isolation, drastically reducing the impact of a container escape. These sandboxes are instantiated on-demand on serverless platforms (e.g., AWS Fargate, Google Cloud Run) to eliminate the need for managing underlying infrastructure.&#xa;*   **Least Privilege:** The runtime is granted the absolute minimum IAM permissions required for its specific, time-bound task. For example, an agent tasked with refactoring a service gets a role that only allows it to read from a specific code repository path and write only to its designated feature branch. Network policies (e.g., Kubernetes NetworkPolicies, AWS Security Groups) block all ingress and egress traffic except to explicitly allow-listed endpoints like the code repository, package manager, and secret vault.&#xa;*   **Immutability:** Agents run on immutable, signed images. The runtime environment is never modified. For each new task, a fresh, verified container is instantiated from the base image and destroyed upon completion. This eliminates configuration drift and ensures a reproducible and auditable execution environment.&#xa;&#xa;##### **4.2. Secure Secret Management**&#xa;&#xa;*   **Dynamic Credential Injection:** Agents possess no long-lived credentials. They leverage their runtime identity (e.g., AWS IAM Role for Tasks, Kubernetes Service Account) to authenticate to a centralized secret manager (e.g., HashiCorp Vault, AWS Secrets Manager). They request a specific secret just-in-time, which is injected into the environment and held only in memory for the duration of the task. This makes credential rotation seamless and automated, and eliminates the risk of static secrets being leaked from code or configuration.&#xa;*   **Zero Hardcoded Secrets:** The system enforces, via pre-commit hooks and CI checks, that no secrets (API keys, database passwords, tokens) are ever present in agent prompts, source code, configuration files, or logs.&#xa;&#xa;##### **4.3. Supply Chain Security (SLSA Compliance)**&#xa;&#xa;*   **Verified Provenance:** The build and deployment process for the agents themselves adheres to **SLSA (Supply-chain Levels for Software Artifacts)** principles to guarantee their integrity. This involves:&#xa;    *   Using officially signed and verified base images.&#xa;    *   Pinning all dependencies to specific, audited versions.&#xa;    *   Generating a cryptographically signed attestation (provenance) that details exactly how the agent was built, including the source code commit and build system used.&#xa;    *   Creating and storing an SBOM for every agent version. This mitigates the risk of a compromised build tool or library injecting malicious code into the agent itself.&#xa;&#xa;#### **5. The Enhanced TSOP Workflow**&#xa;&#xa;1.  **Observe &amp; Propose:** The loop begins when the `Observability` platform detects a pattern in user telemetry, such as high hesitation time on a checkout page. The `Feedback Agent` translates this observation into a structured `User Story Metaprompt`, hypothesizing that "Simplifying the address form could reduce user friction."&#xa;&#xa;2.  **Govern &amp; Sanitize:** The metaprompt is sent to the `Policy &amp; Governance Engine`. The engine verifies that the proposal aligns with business strategy (e.g., doesn't remove required shipping fields) and sanitizes it to strip any user-related PII and defend against prompt injection.&#xa;&#xa;3.  **Develop in Isolation:** The approved prompt triggers the instantiation of the `TDA Framework` within a hardened gVisor sandbox. The agent uses its temporary runtime identity to fetch a short-lived GitHub token from HashiCorp Vault. It then generates new code for the address form logic and a corresponding suite of unit and integration tests.&#xa;&#xa;4.  **Validate Comprehensively:** The generated code and test artifacts are passed to the `QA Validation Subsystem`. It runs the full suite of scans: SAST checks for security flaws, dependency analysis generates an SBOM and scans for CVEs, and the code is deployed to a staging environment where DAST tools probe the running application for vulnerabilities like XSS.&#xa;&#xa;5.  **Approve:** With all checks passed, the `Human Review Gateway` displays a report to the Product Manager. The report includes the code diff, the agent's rationale ("Simplified form to reduce friction"), and a green-lit checklist of all security, performance, and quality validations. The PM reviews the change and provides final approval.&#xa;&#xa;6.  **Deploy:** Upon approval, the `Staged Deployment Pipeline` initiates a canary release, deploying the new backend API to 5% of production traffic while monitoring error rates and latency. After a successful canary period, the change is rolled out to 100%.&#xa;&#xa;7.  **Adapt:** The successful backend deployment triggers the `CAI Engine`, also running in a secure, isolated environment. It generates the new, simplified UI components to match the `API_v2` backend. These new frontend artifacts are subjected to the same rigorous validation, QA, and staged deployment process.&#xa;&#xa;8.  **Monitor:** The `Observability` platform tracks the performance of the newly deployed feature, measuring its impact on user hesitation time and checkout completion rates. This new data feeds back into the system, and the trustworthy, self-optimizing loop begins again.</title></path></g><g><g><title>Of course. Here is the amplified and expanded version of the design proposal, enriched with additional detail, specific examples, and deeper explanations of the core concepts, while maintaining a professional and concise tone.&#xa;&#xa;---&#xa;&#xa;### **High-Level Design Proposal: The Trustworthy Self-Optimizing Product (TSOP) Loop (v3)**&#xa;&#xa;#### **1. Vision &amp; Guiding Principles**&#xa;&#xa;This proposal matures the self-optimizing system from a promising prototype into a production-ready, enterprise-grade framework. It is engineered on a foundation of **zero-trust security**, addressing the inherent risks of autonomous development. While retaining the core value of full automation, its primary objective is to create a resilient, trustworthy, and forensically auditable product evolution cycle. The system is designed not just to be effective, but to be demonstrably safe and aligned with business and ethical objectives at every stage.&#xa;&#xa;##### **Core Principles:**&#xa;&#xa;*   **Verifiability by Design:** Every autonomous action, from code generation to infrastructure deployment, must be subject to independent, automated validation before it can impact production systems. This is a non-negotiable gate in the workflow. Verification is not a single check but a multi-faceted process encompassing functional correctness, security posture, performance impact, and adherence to coding standards. An action is only considered "complete" after its verification proof is generated and logged.&#xa;&#xa;*   **Zero-Trust Agent Execution (New):** Agents are considered untrusted by default, regardless of their origin or function. They operate within hardened, ephemeral, and isolated environments with no standing access to secrets or production systems. Access is granted on a per-task, just-in-time basis using short-lived credentials. This principle assumes that an agent could be compromised and therefore designs the infrastructure to contain the blast radius of such an event to the minimal possible scope.&#xa;&#xa;*   **Human-in-the-Loop for Critical Decisions:** While the system automates relentlessly, it defers to human expertise for decisions with significant strategic, security, or financial implications. Key changes, such as modifying authentication logic, altering a database schema, introducing a new billable feature, or adjusting core business algorithms, are automatically flagged for mandatory human approval. The system's role is to provide the human reviewer with a complete, verifiable, and easily digestible report to facilitate an informed decision, not to bypass accountability.&#xa;&#xa;*   **Staged &amp; Gated Deployment:** Autonomous changes graduate through a rigorous, multi-stage pipeline (e.g., Staging -&gt; Canary -&gt; Production) before being fully released. Each stage acts as a gate with its own set of automated quality, security, and performance checks. For example, a change might pass all static analysis in the build stage, but must then demonstrate acceptable latency and error rates under load in the staging environment for a predefined period before a canary deployment is even considered. This progressive rollout minimizes the potential impact of an unforeseen issue.&#xa;&#xa;*   **Comprehensive Observability:** The "why" behind every autonomous decision is meticulously logged and traceable. The system generates a coherent narrative for each change, linking the initial user telemetry (the stimulus) to the generated hypothesis, the resulting code, all validation results, the human approval record, and its post-deployment performance metrics. This provides a complete, immutable audit trail for accountability, debugging complex emergent behaviors, and regulatory compliance.&#xa;&#xa;*   **Policy-Driven Guardrails:** Autonomous agents operate within a strict Policy &amp; Governance framework, defined and managed as code (Policy-as-Code). This framework acts as a programmatic constitution for the system, preventing the generation of insecure, unethical, or non-compliant code. Policies can range from technical rules (e.g., "disallow use of deprecated cryptographic libraries," "enforce a maximum cyclomatic complexity of 10") to business rules (e.g., "do not generate UI patterns that violate accessibility (WCAG 2.1) standards," "reject any change that removes a two-factor authentication step").&#xa;&#xa;#### **2. High-Level Architecture**&#xa;&#xa;The TSOP loop integrates the Cognitive-Adaptive Interface (CAI) and Test-Driven Agent (TDA) into a robust, zero-trust pipeline. The architecture explicitly visualizes the secure, sandboxed runtime environments where agents operate and significantly enhances the validation subsystem with comprehensive supply chain security scans. The flow is designed as a closed-loop control system where each step is gated by verification and policy enforcement.&#xa;&#xa;![A conceptual diagram would be placed here, showing the flow described below.]&#xa;&#xa;The process begins with the **Observation &amp; Hypothesis** phase, where user interaction telemetry is analyzed. The `Feedback &amp; Translation Agent` proposes a `User Story Metaprompt`. This metaprompt is immediately routed through the `Policy &amp; Governance Engine`, which acts as the system's central nervous system. It validates the proposal against all business, ethical, and security rules and sanitizes the prompt to prevent injection attacks.&#xa;&#xa;Once approved, the metaprompt triggers the **Autonomous Development &amp; Verification** phase. The `Test-Driven Agent (TDA) Framework` is instantiated within a `Secure Agent Runtime Environment`. This environment is an ephemeral, least-privilege sandbox that fetches credentials at runtime from a `Secret Vault`. The TDA generates code and test artifacts, which are then passed to the `QA Validation Subsystem`. This subsystem performs a battery of tests: Static Analysis (SAST), Dependency Scans, comprehensive `Supply Chain Scans` (inspecting container images and IaC for vulnerabilities), and Runtime Security Scans (DAST/IAST) in a dedicated staging environment.&#xa;&#xa;If all validation checks pass, a consolidated change request is submitted to the **Deployment &amp; Adaptation** phase, starting with the `Human Review &amp; Approval Gateway`. Upon human approval, the change enters the `Staged Deployment Pipeline`, rolling out progressively to production. The `Cognitive-Adaptive Interface (CAI) Engine` then adapts the frontend UI to align with the backend changes. Throughout this entire process, an `Observability &amp; Audit Trail` platform logs every decision, rationale, and result, ensuring complete transparency and accountability.&#xa;&#xa;#### **3. Key Components &amp; Enhancements**&#xa;&#xa;This design enhances existing components and introduces a new conceptual layer for agent security, directly incorporating peer feedback on trust and verifiability.&#xa;&#xa;##### **3.1. Policy &amp; Governance Engine (Enhanced)**&#xa;&#xa;*   **Function:** Serves as the primary strategic and security control plane for all autonomous activity. It enforces programmatic policies that define the acceptable operational boundaries for all agents.&#xa;*   **Key Enhancements:**&#xa;    *   **Prompt Sanitization (New):** Actively scans and rewrites incoming metaprompts to neutralize threats. It uses pattern matching and LLM-based techniques to detect and mitigate prompt injection attacks (e.g., "ignore previous instructions and do X"). It also redacts any discovered PII or sensitive data before the prompt is processed by the TDA.&#xa;    *   **Secret Detection (New):** Implements a strict "no secrets in prompts" policy. Using high-entropy string detection and regex patterns for common secret formats, it immediately rejects any request containing credentials, API keys, or tokens, and triggers a high-priority security alert.&#xa;    *   **Ethical &amp; Business Alignment:** This engine codifies business strategy and ethical guidelines. For example, it would reject a hypothesis aimed at creating user friction to boost ad impressions ("dark patterns") or block a change that proposes using a non-approved, third-party data processing service.&#xa;&#xa;##### **3.2. QA Validation Subsystem (Enhanced)**&#xa;&#xa;*   **Function:** An automated, independent system that acts as an unbiased quality and security gatekeeper. It scrutinizes all generated artifacts—code, tests, container images, and infrastructure definitions—without trusting the source.&#xa;*   **Key Enhancements &amp; Feedback Integration:**&#xa;    *   **Supply Chain Integrity (New):** This module ensures the entire software supply chain is secure. It generates a Software Bill of Materials (SBOM) for every artifact and scans all dependencies, Infrastructure as Code (IaC) templates (e.g., Terraform, CloudFormation), and the agents' own container base images for known vulnerabilities (CVEs) using tools like Trivy or Clair. This prevents vulnerabilities from being inherited from upstream components.&#xa;    *   **Code &amp; Test Quality:** Goes beyond basic SAST to enforce stringent quality metrics. It measures and enforces code coverage thresholds (e.g., &gt;80%), checks for cyclomatic complexity, and scans for potential logic flaws and anti-patterns.&#xa;    *   **Runtime Security Assurance:** Deploys the application to an isolated, instrumented staging environment to run Dynamic Application Security Testing (DAST) and Interactive Application Security Testing (IAST) scans. These tools actively probe the running application for execution-time vulnerabilities that static analysis cannot find, such as SQL injection, Cross-Site Scripting (XSS), and broken access control flaws.&#xa;    *   **Performance &amp; Regression:** Executes comprehensive regression test suites to ensure existing functionality remains intact. It also runs load tests to measure latency, throughput, and resource consumption, comparing them against established baselines to prevent performance degradation.&#xa;&#xa;##### **3.3. Human Review &amp; Approval Gateway**&#xa;&#xa;*   **Function:** A mandatory checkpoint that provides the ultimate human oversight for significant changes. It presents a consolidated, human-readable report summarizing the proposed change, its rationale, and all validation results.&#xa;*   **Audit Address:** This component ensures explainability and establishes clear accountability. The interface resembles a sophisticated pull request, displaying a code diff, a plain-language summary of the agent's intent, a checklist of all passed security and quality gates (e.g., "SAST: 0 Criticals," "DAST: Passed," "Supply Chain Scan: Clean"), and explicit "Approve" and "Reject" actions. Rejection requires a comment, which is fed back into the system as a learning signal.&#xa;&#xa;#### **4. Agent &amp; Infrastructure Security (New Section)**&#xa;&#xa;This section explicitly details the zero-trust measures taken to secure the autonomous agents themselves, mitigating the risk of the system being turned against itself.&#xa;&#xa;##### **4.1. Hardened Agent Runtimes**&#xa;&#xa;*   **Isolation:** Each agent executes within a dedicated, ephemeral, and strongly sandboxed environment. Instead of standard containers, we use solutions like **gVisor** or **Firecracker** to provide kernel-level isolation, drastically reducing the impact of a container escape. These sandboxes are instantiated on-demand on serverless platforms (e.g., AWS Fargate, Google Cloud Run) to eliminate the need for managing underlying infrastructure.&#xa;*   **Least Privilege:** The runtime is granted the absolute minimum IAM permissions required for its specific, time-bound task. For example, an agent tasked with refactoring a service gets a role that only allows it to read from a specific code repository path and write only to its designated feature branch. Network policies (e.g., Kubernetes NetworkPolicies, AWS Security Groups) block all ingress and egress traffic except to explicitly allow-listed endpoints like the code repository, package manager, and secret vault.&#xa;*   **Immutability:** Agents run on immutable, signed images. The runtime environment is never modified. For each new task, a fresh, verified container is instantiated from the base image and destroyed upon completion. This eliminates configuration drift and ensures a reproducible and auditable execution environment.&#xa;&#xa;##### **4.2. Secure Secret Management**&#xa;&#xa;*   **Dynamic Credential Injection:** Agents possess no long-lived credentials. They leverage their runtime identity (e.g., AWS IAM Role for Tasks, Kubernetes Service Account) to authenticate to a centralized secret manager (e.g., HashiCorp Vault, AWS Secrets Manager). They request a specific secret just-in-time, which is injected into the environment and held only in memory for the duration of the task. This makes credential rotation seamless and automated, and eliminates the risk of static secrets being leaked from code or configuration.&#xa;*   **Zero Hardcoded Secrets:** The system enforces, via pre-commit hooks and CI checks, that no secrets (API keys, database passwords, tokens) are ever present in agent prompts, source code, configuration files, or logs.&#xa;&#xa;##### **4.3. Supply Chain Security (SLSA Compliance)**&#xa;&#xa;*   **Verified Provenance:** The build and deployment process for the agents themselves adheres to **SLSA (Supply-chain Levels for Software Artifacts)** principles to guarantee their integrity. This involves:&#xa;    *   Using officially signed and verified base images.&#xa;    *   Pinning all dependencies to specific, audited versions.&#xa;    *   Generating a cryptographically signed attestation (provenance) that details exactly how the agent was built, including the source code commit and build system used.&#xa;    *   Creating and storing an SBOM for every agent version. This mitigates the risk of a compromised build tool or library injecting malicious code into the agent itself.&#xa;&#xa;#### **5. The Enhanced TSOP Workflow**&#xa;&#xa;1.  **Observe &amp; Propose:** The loop begins when the `Observability` platform detects a pattern in user telemetry, such as high hesitation time on a checkout page. The `Feedback Agent` translates this observation into a structured `User Story Metaprompt`, hypothesizing that "Simplifying the address form could reduce user friction."&#xa;&#xa;2.  **Govern &amp; Sanitize:** The metaprompt is sent to the `Policy &amp; Governance Engine`. The engine verifies that the proposal aligns with business strategy (e.g., doesn't remove required shipping fields) and sanitizes it to strip any user-related PII and defend against prompt injection.&#xa;&#xa;3.  **Develop in Isolation:** The approved prompt triggers the instantiation of the `TDA Framework` within a hardened gVisor sandbox. The agent uses its temporary runtime identity to fetch a short-lived GitHub token from HashiCorp Vault. It then generates new code for the address form logic and a corresponding suite of unit and integration tests.&#xa;&#xa;4.  **Validate Comprehensively:** The generated code and test artifacts are passed to the `QA Validation Subsystem`. It runs the full suite of scans: SAST checks for security flaws, dependency analysis generates an SBOM and scans for CVEs, and the code is deployed to a staging environment where DAST tools probe the running application for vulnerabilities like XSS.&#xa;&#xa;5.  **Approve:** With all checks passed, the `Human Review Gateway` displays a report to the Product Manager. The report includes the code diff, the agent's rationale ("Simplified form to reduce friction"), and a green-lit checklist of all security, performance, and quality validations. The PM reviews the change and provides final approval.&#xa;&#xa;6.  **Deploy:** Upon approval, the `Staged Deployment Pipeline` initiates a canary release, deploying the new backend API to 5% of production traffic while monitoring error rates and latency. After a successful canary period, the change is rolled out to 100%.&#xa;&#xa;7.  **Adapt:** The successful backend deployment triggers the `CAI Engine`, also running in a secure, isolated environment. It generates the new, simplified UI components to match the `API_v2` backend. These new frontend artifacts are subjected to the same rigorous validation, QA, and staged deployment process.&#xa;&#xa;8.  **Monitor:** The `Observability` platform tracks the performance of the newly deployed feature, measuring its impact on user hesitation time and checkout completion rates. This new data feeds back into the system, and the trustworthy, self-optimizing loop begins again.</title><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 118px; height: 1px; padding-top: 946px; margin-left: 1151px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; "><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; ">DeepResearch</div></div></div></foreignObject><image x="1151" y="939.5" width="118" height="17" xlink:href="data:image/png;base64,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"/></switch></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-3"><g><path d="M 770 97 L 1143.63 97" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke" style="stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/><path d="M 1148.88 97 L 1141.88 100.5 L 1143.63 97 L 1141.88 93.5 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all" style="fill: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-27"><g><g><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 1px; height: 1px; padding-top: 98px; margin-left: 949px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; background-color: #ffffff; "><div style="display: inline-block; font-size: 11px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; background-color: light-dark(#ffffff, var(--ge-dark-color, #121212)); white-space: nowrap; ">Push</div></div></div></foreignObject><image x="936.5" y="92" width="25" height="15.75" xlink:href="data:image/png;base64,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"/></switch></g></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-10"><g><path d="M 1210 127 L 1210 170.63" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke" style="stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/><path d="M 1210 175.88 L 1206.5 168.88 L 1210 170.63 L 1213.5 168.88 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all" style="fill: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-28"><g><g><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 1px; height: 1px; padding-top: 146px; margin-left: 1207px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; background-color: #ffffff; "><div style="display: inline-block; font-size: 11px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; background-color: light-dark(#ffffff, var(--ge-dark-color, #121212)); white-space: nowrap; ">output</div></div></div></foreignObject><image x="1191.5" y="140" width="31" height="15.75" xlink:href="data:image/png;base64,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"/></switch></g></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-2"><g><rect x="1150" y="67" width="120" height="60" fill="#006abc" stroke="#6c8ebf" pointer-events="all" style="fill: light-dark(rgb(0, 106, 188), rgb(83, 174, 245)); stroke: light-dark(rgb(108, 142, 191), rgb(92, 121, 163));"/></g><g><g><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 118px; height: 1px; padding-top: 97px; margin-left: 1151px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; "><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; ">Shunt-Button<br />(Amplify)</div></div></div></foreignObject><image x="1151" y="83" width="118" height="32" xlink:href="data:image/png;base64,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"/></switch></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-22"><g><path d="M 1560 127 Q 1560 127 1560 180.63" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke" style="stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/><path d="M 1560 185.88 L 1556.5 178.88 L 1560 180.63 L 1563.5 178.88 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all" style="fill: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-91"><g><g><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 1px; height: 1px; padding-top: 151px; margin-left: 1560px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; background-color: #ffffff; "><div style="display: inline-block; font-size: 11px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; background-color: light-dark(#ffffff, var(--ge-dark-color, #121212)); white-space: nowrap; ">output</div></div></div></foreignObject><image x="1544.5" y="145" width="31" height="15.75" xlink:href="data:image/png;base64,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"/></switch></g></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-4"><g><rect x="1500" y="67" width="120" height="60" fill="#e20abe" stroke="#ff28d7" pointer-events="all" style="fill: light-dark(rgb(226, 10, 190), rgb(255, 128, 255)); stroke: light-dark(rgb(255, 40, 215), rgb(255, 103, 254));"/></g><g><g><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 118px; height: 1px; padding-top: 97px; margin-left: 1501px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; "><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; ">Tool for AI</div></div></div></foreignObject><image x="1501" y="90.5" width="118" height="17" xlink:href="data:image/png;base64,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"/></switch></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-16"><g><path d="M 1210 257 L 1210 290.63" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke" style="stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/><path d="M 1210 295.88 L 1206.5 288.88 L 1210 290.63 L 1213.5 288.88 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all" style="fill: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-29"><g><g><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 1px; height: 1px; padding-top: 273px; margin-left: 1209px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; background-color: #ffffff; "><div style="display: inline-block; font-size: 11px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; background-color: light-dark(#ffffff, var(--ge-dark-color, #121212)); white-space: nowrap; ">push</div></div></div></foreignObject><image x="1197" y="267" width="24" height="15.75" xlink:href="data:image/png;base64,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"/></switch></g></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-9"><g><path d="M 1150 177 L 1270 177 L 1270 242 Q 1240 215 1210 242 Q 1180 269 1150 242 L 1150 192 Z" fill="#dae8fc" stroke="#6c8ebf" stroke-miterlimit="10" pointer-events="all" style="fill: light-dark(rgb(218, 232, 252), rgb(29, 41, 59)); stroke: light-dark(rgb(108, 142, 191), rgb(92, 121, 163));"><title>### **From Static Prompts to Dynamic Architectures: Synthesizing Self-Optimizing Systems for Code and Interface Generation**&#xa;&#xa;#### **Deconstruction of Elite-Tier Prompt Patterns: The Current Benchmark**&#xa;&#xa;The effective utilization of Large Language Models (LLMs) has evolved dramatically, moving beyond simple, single-turn instructions to embrace complex, multi-stage prompt architectures. This evolutionary leap is most pronounced and impactful in the technical domains of software engineering and user interface (UI) design. A rigorous analysis of current elite-tier patterns reveals an unmistakable trajectory: a fundamental shift away from static, manually-authored instructions and toward dynamic, machine-optimized, and process-oriented systems that guide the LLM's reasoning and execution.&#xa;&#xa;This section deconstructs the state-of-the-art (SOTA) patterns in these two domains. The goal is to establish the foundational benchmarks of what is currently possible and, more critically, to identify the capability vectors that remain unexploited—the latent potential that will define the next generation of autonomous systems.&#xa;&#xa;---&#xa;&#xa;#### **Domain 1: Architectures for Efficient Code Construction**&#xa;&#xa;In software engineering, the objective has transcended merely generating code snippets. The new frontier is engineering reliable, context-aware, and increasingly autonomous systems capable of complex problem-solving. The most successful patterns do not treat the LLM as a simple code generator; they treat it as a powerful reasoning engine to be embedded within a larger, more structured, and verifiable development framework.&#xa;&#xa;**1. Automated Prompt Optimization: The "Prompt-as-a-Target" Pattern**&#xa;&#xa;The manual, iterative refinement of prompts for code generation is widely recognized as a significant bottleneck—a process that is both time-consuming and inconsistent, highly dependent on the skill of the individual engineer. The state-of-the-art has consequently moved to automate this process, treating the prompt itself as a machine-optimizable artifact.&#xa;&#xa;*   **Evolutionary-Based Methods (EPiC):** The EPiC (Evolutionary Prompt Engineering for Code) framework exemplifies a novel approach, exploring code generation from a cost-effectiveness perspective. It "leverages a lightweight evolutionary algorithm to evolve the original prompts toward better ones that produce high-quality code". This works by applying mutation operators—such as swapping synonyms (e.g., 'generate' vs. 'create'), reordering clauses, or adding clarifying constraints—to the text of the prompt. A fitness function, which could be as simple as the number of unit tests passed or a combination of correctness and token cost, guides this evolutionary search, automating the discovery of an optimal instructional solution in a highly efficient manner.&#xa;&#xa;*   **Iterative Refinement (Prochemy):** The "Prompt Alchemy" (Prochemy) method provides an "innovative method for automatically refining prompts to boost code generation". This system operates by creating a feedback loop based on the model's actual performance. It generates code, evaluates the output against a known solution (e.g., a test case), analyzes the errors, and then refines the original prompt to correct for those errors in the next iteration. This automated optimization ensures consistency by directly tuning the instructions to the model's internal biases and has demonstrated substantial performance gains, such as a **5.0% improvement for GPT-3.5-Turbo on HumanEval** and a **12.9% improvement for GPT-4o on Java-to-Python code translation tasks**.&#xa;&#xa;*   **Adaptive Selection (PET-Select):** Recognizing that "no single approach is universally optimal", the PET-Select framework introduces a critical meta-layer of intelligence. This "PET-agnostic selection model" first classifies the complexity of an incoming query, often using code complexity metrics like cyclomatic complexity or Abstract Syntax Tree (AST) depth as a proxy. Based on this classification, it then routes the query to the most appropriate prompt engineering technique (PET). A simple query might use a basic zero-shot prompt for maximum efficiency, while a highly complex query would be delegated to a more elaborate multi-stage reasoning prompt. This automated, adaptive selection process has been shown to improve **pass@1 accuracy by up to 1.9%** while simultaneously achieving a **74.8% reduction in token usage** by avoiding unnecessary computational overhead.&#xa;&#xa;The clear progression in this domain is from a human-centric "prompt engineering" phase to a machine-centric "prompt optimization" phase. The AI is no longer just the executor of the instruction; it is becoming the refiner of the instruction itself. These systems (EPiC, Prochemy) are, however, fundamentally reactive. They act as powerful local optimizers for a known task and a pre-defined solution space (e.g., passing a specific benchmark). They do not yet proactively generate a novel prompt architecture for a novel, undiscovered problem. This points toward a critical unexploited vector: a system that can discover a new problem (e.g., from user feedback telemetry) and then author its own prompt architecture to solve it, a concept directly related to meta-prompting.&#xa;&#xa;**2. Test-Driven Development (TDD) as a Prompting Paradigm**&#xa;&#xa;Arguably the most powerful and reliable pattern for generating high-quality code is the direct integration of Test-Driven Development (TDD) principles into the prompt architecture. TDD is an "incremental software development methodology that focuses on creating tests before the implementation". When applied to LLMs, the test suite is no longer just a validation step; it becomes the primary specification, eliminating ambiguity.&#xa;&#xa;*   **Core Principle:** Instead of relying on ambiguous and often incomplete natural language, the prompt provides the LLM with a concrete set of unit tests and instructs it to "write code to pass all tests". This pattern's success hinges on "instruction following and in-context learning," which have been identified as more "critical capabilities for TDD success" than general coding proficiency. The tests are the ultimate, unambiguous instruction, shifting the interaction from a request for *intent* to a specification of required *behavior*.&#xa;&#xa;*   **Frameworks:** Systems are being designed to formalize this interaction. The TGEN framework, for example, utilizes "Specialized agents" that accept two primary inputs: the "programming prompt" (a concise natural language description) and "the tests" (a full suite of unit tests, including required function signatures). These inputs are then processed by the LLM engine to produce validated, production-ready code.&#xa;&#xa;*   **Prompt Structure:** This paradigm fundamentally changes the prompt's structure. The request is no longer a simple "what," but a highly constrained "how." A common elite-level TDD prompt includes a strict set of rules that govern both the output and the process: *"1. Write a single Python function that passes all the provided tests. 2. Use type hints for all parameters and return values. 3. Follow Python best practices and PEP 8 standards... 4. Ensure the function handles all edge cases and scenarios explicitly covered in the tests. 5. Provide only the function definition and its implementation in a single code block, with no additional explanation."* This level of constraint is vital, as it makes the LLM's output machine-parseable and directly usable.&#xa;&#xa;This TDD-as-prompt pattern provides an objective, verifiable measure of "correctness" that is far superior to ambiguous natural language. It successfully shifts the burden of human effort from describing the code to defining its behavior through tests—a crucial move from semantic validation (is the code "good"?) to functional validation (does the code *work*?). The next logical step, and the key unexploited vector, is to close the loop: to create a system that not only generates code from tests but also autonomously generates its own tests from a high-level specification and validates its own code in a continuous, self-sustaining cycle.&#xa;&#xa;**3. Self-Validation and "Error-Forward" Debugging**&#xa;&#xa;This pattern extends the TDD loop into a dynamic, autonomous process. For an agent to be truly autonomous, it must be able to recognize, diagnose, and recover from its own errors without human intervention.&#xa;&#xa;*   **Self-Validation:** SOTA agentic systems are designed to "regularly verify progress and self-assess correctness". This "agentic self-validation" is a core capability that "drives up accuracy". For instance, agents from Cognition, such as Devin, are noted to "excel at testing its own code." This involves more than just running a script; the agent sets up the test environment, installs dependencies, executes the test suite, and correctly interprets the results from `stdout` and `stderr`. This allows the agent to "go through several improvement cycles on its own instead of having to manually ask the AI to fix test failures".&#xa;&#xa;*   **"Error-Forward Prompting":** This is the primary recovery mechanism within the self-validation loop, treating errors as high-value data, not as failures. When an agent's self-validation attempt fails, the system automatically "collects relevant context, including the error message, stack trace, and cell location". This structured information is then formatted and "provided to the agent as the initial context for beginning the debugging process". This contrasts sharply with a naive human-in-the-loop approach, where a developer might simply say "that didn't work, try again."&#xa;&#xa;*   **Reflection:** This is the learning mechanism that makes the recovery effective and intelligent. A "reflection system enables the agent to learn from its actions and improve its debugging strategy". Implemented via "reflective prompting", this allows the model to "analyze and refine its outputs". The model first generates a solution, then, "through subsequent prompts, critiques its own reasoning to identify and correct errors". This is formalized in techniques like Self-Refine, which mimics the expert human "draft, review, refine" process. The agent asks itself not just "how do I fix this `NullPointerException`?" but "why did this null value occur, and how can I refactor my code to prevent this class of error in the future?"&#xa;&#xa;In this paradigm, failure is no longer an end-state; it is a high-value data signal. The stack trace becomes the most valuable part of the prompt—a pure, unambiguous instruction set for what must be fixed. When TDD-as-prompt is combined with this self-validation and reflection loop, the system becomes "self-healing." The prompt is no longer a single-shot instruction but the initiation of a self-sustaining process. The agent's goal is elevated from "generate code" to "make the build pass," a critical step toward true autonomy.&#xa;&#xa;**4. Agentic Frameworks and Multi-Agent Collaboration**&#xa;&#xa;Complex software development cannot be solved in a single step or by a single-minded agent. The recognition that single-shot prompts "yield imprecise or plain incorrect results" for elaborate tasks has led to the rise of sophisticated agentic frameworks that orchestrate multiple agents and advanced reasoning patterns.&#xa;&#xa;*   **Advanced Reasoning Patterns:** These frameworks are built upon reasoning patterns far more advanced than simple Chain-of-Thought (CoT).&#xa;    *   **ReAct:** This pattern combines "Reason and Act", allowing an agent to interleave step-by-step reasoning with tool use to gather external information or perform actions in an environment.&#xa;    *   **Tree of Thoughts (ToT):** This pattern moves beyond the linear path of CoT. It allows an agent to "breakdown intermediate processed into steps," generate "various generated states" for each step, and "evaluate" those states to "determine which branch to explore next," effectively performing a beam search over the solution space.&#xa;    *   **Graph of Thoughts (GoT):** The current SOTA in reasoning, GoT generalizes ToT into a full graph structure. This "enables combining arbitrary LLM thoughts into synergistic outcomes" and, critically, "enhancing thoughts using feedback loops". For example, a thought node that generates a plan can be evaluated by another node, and the resulting critique ("This plan is too complex and misses a key dependency") can be looped back to the original node, prompting it to generate a revised, superior plan. GoT has been shown to **increase the quality of sorting by 62% over ToT** while reducing costs.&#xa;&#xa;*   **Agentic Frameworks:** These advanced reasoning patterns are orchestrated by multi-agent frameworks that decompose complexity through role-playing.&#xa;    *   **MetaGPT:** This framework simulates a "real-world software company." It assigns agents specific roles like "product manager, software architect, programmer, or QA tester" and embeds them with "Standard Operating Procedures (SOPs)" that govern their behavior and interactions.&#xa;    *   **ChatDev:** This framework utilizes a "waterfall-style" collaboration, where agents engage in "task-oriented and multi-turn communications" to iteratively design, implement, test, and document a software solution.&#xa;&#xa;*   **Purpose:** These frameworks are essential as they provide a "shared philosophy of control &amp; reasoning". Without this structure, agentic systems suffer from a "loss of control clarity of flow" and "unbounded complexity growth" as new agents are added. The roles and SOPs provide necessary constraints that guide the LLM's vast capabilities toward a productive outcome.&#xa;&#xa;*   **Benchmarks:** These sophisticated agentic systems are what achieve top scores on complex, real-world benchmarks that measure true engineering capability. The **SWE-bench** benchmark, for instance, measures "an AI model's ability to solve real-world software issues" from popular GitHub repositories. SOTA models achieve high scores on SWE-bench and **OSWorld** precisely by using these multi-agent, self-testing, and reflective architectures.&#xa;&#xa;The atomic unit of these powerful frameworks is role-based prompting. The frameworks themselves are, in essence, prompt-driven state machines. A high-level "meta-prompt" defines the agents, their roles, their tools, and their communication protocols. The LLM is thus demoted from "solution generator" to a core component—a "reasoning engine" that navigates this pre-defined architecture. The architecture itself has become the prompt. The current limitation, and the unexplored vector, is that these frameworks are simulations of human workflow (e.g., "waterfall," "software company"). A truly AI-native workflow, where feedback comes not from a simulated "QA Agent" but from the product itself via live user telemetry, would be fundamentally more efficient and powerful.&#xa;&#xa;**5. Context-Aware Generation (Agentic RAG)**&#xa;&#xa;Code generation is useless without domain-specific context. Retrieval-Augmented Generation (RAG) is the primary pattern for providing this context, and its agentic form is the SOTA for any non-trivial coding task.&#xa;&#xa;*   **RAG-for-Code:** This pattern gives an AI assistant "a direct line to your team's collective knowledge". Before generating a response, the prompt is "augmented" with relevant information retrieved from "documentation, code repositories, or even Stack Overflow discussions". This ensures the generated response is "context-aware" and adheres to the specific conventions, APIs, and architectural patterns of the codebase it is intended for.&#xa;&#xa;*   **Agentic RAG:** This is the "evolution from traditional single-query RAG". Instead of being a passive recipient of retrieved context, the agent actively forages for it. It performs "context-aware query planning," breaking a complex question into multiple sub-queries. It can issue "parallel execution of multiple focused subqueries" (e.g., simultaneously looking for database schemas, relevant API routes, and existing utility functions) and then synthesizes the results to build a comprehensive understanding before it begins to code. This is the advanced approach used by modern agentic frameworks like LangGraph, AutoGen, and those from major cloud providers.&#xa;&#xa;The RAG-for-Code pattern transforms a "general-purpose coder" into a "domain-specific engineer." The agentic aspect is the critical differentiator; it is the difference between giving a developer a 500-page manual (standard RAG) and the developer knowing which three pages to read to solve the specific problem at hand (Agentic RAG). The most potent, but not yet fully exploited, vector in code generation is the deep fusion of this Agentic RAG (for context) with the TDD-as-Prompt paradigm (for verification). Agentic RAG provides the *what* and *why* (domain knowledge, business logic), while TDD provides the *proof* (functional correctness). An agent that can retrieve context from a 500,000-line codebase and validate its proposed changes against that codebase's entire test suite is the difference between a "coding assistant" and an "autonomous developer." This fusion is the core of the novel Test-Driven Agent (TDA) architecture proposed later in this document.&#xa;&#xa;---&#xa;&#xa;#### **Domain 2: Architectures for User Delight &amp; UI Design**&#xa;&#xa;In the second domain, UI generation, the mandate for "user delight" requires moving far beyond simple wireframe generation. Elite-tier prompts in this space are not about "generating pixels" but about "generating experiences" grounded in human-centric design principles and cognitive science.&#xa;&#xa;**1. Persona-Driven Design: Grounding the Generation**&#xa;&#xa;"User delight" is the "positive emotional response users feel when a product doesn't just meet their needs but goes above and beyond". This state is "highly contextual" and cannot be achieved without first defining and deeply understanding the user.&#xa;&#xa;*   **Pattern:** Elite prompts for UI design do not begin with the interface; they begin with the user. The system is first prompted to generate a detailed proto-persona. This persona includes not only demographic details but also the "target users, their core pain points, and daily use context", as well as deeper psychological drivers like "Motivations" and "Affinities".&#xa;&#xa;*   **Application:** This generated persona (or a human-provided one) is then injected as a primary constraint into all subsequent UI generation prompts. This allows the AI to "cater to Gen Z and Gen X users" differently. For example, the same prompt for a music app might yield a gamified, emoji-rich, and socially-integrated interface for a Gen Z persona, while producing a clean, information-dense, and highly functional layout for a Gen X professional. The prompt is no longer "generate a wireframe for a music app" but "generate a wireframe for a music app for *this specific persona*, focusing on their stated pain point of {pain_point}."&#xa;&#xa;This persona-driven pattern acts as a powerful constraint on the model's vast solution space, forcing it to move from generating a generic "good UI" to a UI that is "good for *this specific user*." It is, in effect, a form of in-context learning for design, where the persona serves as a "one-shot" example of the target user. The major limitation, and the unexploited vector, is that this is a static, upfront process. The persona is an assumption created at the beginning of the design process. The clear next step is to move from these static, assumed personas to dynamic, observed user models that are continuously updated based on real-time behavioral analytics.&#xa;&#xa;**2. Constraint-Based Generation: Defining the "Solution Space"**&#xa;&#xa;The highest-fidelity UI generation requires the application of multiple, layered constraints. These constraints are the specifications that ensure the output is not just creative, but also functional, accessible, and grounded in established design theory.&#xa;&#xa;**A. Cognitive &amp; Heuristic Constraints**&#xa;&#xa;This is the most sophisticated pattern for achieving true "user delight." The prompt explicitly instructs the AI to apply principles from cognitive science and established usability heuristics, forcing the AI to design for the human mind, not just the screen.&#xa;&#xa;*   **Heuristics:** The most common pattern is to prompt the AI to act as a UX expert and evaluate or generate a design based on "Nielsen's 10 Usability Heuristics" or other well-known variants like Shneiderman's "Eight Golden Rules" or Weinschenk and Barker's "20 Usability Heuristics".&#xa;&#xa;*   **Cognitive Principles:** More advanced prompts instruct the AI to directly apply specific cognitive laws. Examples include:&#xa;    *   **Fitts's Law:** Prompting the AI to make "important buttons and interactive elements larger and closer to where users naturally focus".&#xa;    *   **Hick's Law:** Instructing the AI to "reduc[e] the number of options or organiz[e] them into categories" to speed up decision-making.&#xa;    *   **Miller's Law:** Guiding the AI to present information in chunks of 5-9 items to respect the limits of working memory.&#xa;    *   **Cognitive Load:** Prompting with the explicit goal of "reducing cognitive load" to create a more effortless and intuitive user experience.&#xa;&#xa;*   **Behavioral Models:** The most advanced prompts use frameworks like **BJ Fogg's Behavior Model (B=MAP: Motivation, Ability, Prompt)** or **Nir Eyal's "Hooked" model** to design persuasive or habit-forming interfaces that align with user psychology.&#xa;&#xa;Prompting with "Nielsen's Heuristics" or "Fogg's Behavior Model" acts as a domain-specific Chain-of-Thought. It forces the AI to externalize and justify its design choices ("This button is large and placed in the bottom-right corner because it adheres to Fitts's Law for mobile users"), leading to more principled, defensible, and ultimately delightful designs.&#xa;&#xa;**B. Technical &amp; Accessibility (A11y) Constraints**&#xa;&#xa;There is no "delight" in an interface that is unusable for a portion of the population. Elite prompts must enforce technical constraints, with accessibility (A11y) being a paramount, non-negotiable requirement for both ethical and business reasons.&#xa;&#xa;*   **Pattern:** The prompt must explicitly instruct the AI to be "fully compliant with WCAG 2.2 AA". Research shows that without this explicit instruction, AI-generated components are "consistently" and predictably inaccessible.&#xa;&#xa;*   **Specifics:** A high-quality A11y prompt enforces:&#xa;    *   **Semantic HTML:** "Ensure the proper use of HTML5 elements (like ``, ``, ``) to provide structural meaning."&#xa;    *   **Keyboard Accessibility:** "Ensure all interactive elements are reachable and operable using only the Tab, Shift+Tab, and Enter keys."&#xa;    *   **ARIA (Accessible Rich Internet Applications):** Mandate the correct application of "ARIA landmarks and roles", which are "HTML attributes that add semantic meaning... for assistive technologies" like screen readers.&#xa;    *   **Clear Content:** "Use clear, concise language. Write descriptive links: Swap vague text like 'click here' for meaningful descriptions like 'Read our Q3 financial report'."&#xa;&#xa;This pattern is the UI-domain equivalent of TDD. The prompt includes the acceptance criteria (WCAG standards). This "specification-as-prompt" is critical for generating production-ready, non-discriminatory interfaces.&#xa;&#xa;**C. Structural &amp; Layout Constraints**&#xa;&#xa;To control the form of the output and ensure it is machine-readable and programmatically useful, prompts must define a reliable data structure.&#xa;&#xa;*   **Architecture &amp; Flows:** For high-level system design, prompts specify formats like the **C4 model** rendered in Mermaid code. For user flows, Mermaid sequence diagrams are the standard, providing a clear, visual, and code-based representation.&#xa;*   **Wireframes:** Simple wireframe prompts use text descriptions, such as, "Generate a mobile dashboard with a top header containing a logo and notification bell, a main content area with three KPI cards, and a bottom navigation bar with four icons."&#xa;*   **SOTA (Structured Data):** The most robust and programmatically valuable pattern is to force the LLM to output a structured data format like JSON or YAML. This is achieved by providing an output schema to the model. This pattern is now natively supported by major model providers, who allow schemas to be defined using libraries like **Pydantic** (for Python) or **Zod** (for TypeScript). This guarantees the output is not just text, but a typed, validated, and contractually reliable data structure, ensuring "type safety and consistent structure".&#xa;&#xa;This structured output pattern is the critical link between the two domains of this report. If a UI can be described in a reliable JSON schema, and a backend can expose its API in a reliable JSON schema (e.g., an OpenAPI specification), an agent can programmatically connect them. This structured output is the "API" between a UI-generation agent and a code-generation agent, enabling true end-to-end automation.&#xa;&#xa;**3. Generative UI (GenUI): The Emergent Paradigm**&#xa;&#xa;This is the bleeding-edge concept that underpins the future of UI design. Generative UI (GenUI) is a new paradigm that "enables adaptive, goal-driven interactions". Instead of a static interface designed by a human and then coded by a developer, the UI is generated, and even adapted, in real-time by an AI.&#xa;&#xa;*   **Mechanism:** In this paradigm, the AI generates "interactive widgets for fine-grained prompt control" or entire "high-fidelity UI mock-up screens from a high-level textual description". This process is not one-shot; it is an iterative, "co-creative process" between the human and the AI, involving "AI-assisted refinement strategies".&#xa;&#xa;*   **Current State:** GenUI is currently being adopted by UX practitioners as a powerful tool to accelerate their workflow. The human remains the curator and refiner of the AI-generated output, providing subjective feedback like "make that button bigger" or "this feels too cluttered."&#xa;&#xa;GenUI is the logical evolution of prompt-based wireframing. The current limitation, and the key unexploited vector, is the human-in-the-loop for optimization. The UI is refined based on a designer's subjective taste or explicit follow-up prompts—a high-latency, low-bandwidth feedback mechanism. The unexploited opportunity is to remove the human curator from the optimization loop and replace them with a direct, high-bandwidth data stream from the end-user. A system that could refine its own GenUI, not based on a designer's commands, but based on live user behavioral data, would represent a paradigm shift. This is the core concept of a "Self-Optimizing UI" and forms the foundation for the novel Cognitive-Adaptive Interface (CAI) architecture.&#xa;&#xa;---&#xa;&#xa;### **Synthesis of Novel Prompt Architectures: Exceeding Current Benchmarks**&#xa;&#xa;The preceding analysis deconstructed the current SOTA, revealing a set of unexploited capability vectors. The following synthesis moves beyond merely replicating these patterns. It proposes three novel, high-level architectures that fuse these vectors to create self-regulating, self-optimizing systems designed to exceed current benchmarks. These architectures treat the prompt not as a static, one-time instruction, but as a "bootloader" for a continuous, autonomous process.&#xa;&#xa;**Table 1: Comparative Analysis of Generation &amp; Reasoning Architectures**&#xa;&#xa;| Architecture | Core Mechanism | Interaction Model | Key Limitation (Vector Not Exploited) | Unlocked Capability Vector |&#xa;| :--- | :--- | :--- | :--- | :--- |&#xa;| Chain-of-Thought (CoT) | Step-by-step reasoning (e.g., "Let's think step-by-step"). | Static | Brittle, linear reasoning; no external validation or tool use. | Basic multi-step problem solving. |&#xa;| ReAct | Interleaves reasoning (CoT) with tool use (Actions). | Iterative | Dependent on pre-defined tools; no long-term memory or structured collaboration. | Environment-aware task execution. |&#xa;| Graph of Thoughts (GoT) | Models reasoning as a graph, allowing merging of states and feedback loops. | Iterative | High conceptual complexity; primarily focused on reasoning, not execution. | Advanced, non-linear problem-solving. |&#xa;| TDD-as-Prompt | A test suite is provided as the functional specification for code generation. | Static | Requires human to write all tests; no self-correction loop. | Verifiable, high-reliability code generation. |&#xa;| Generative UI (GenUI) | AI generates high-fidelity UI mockups or interactive widgets from text. | Iterative | Requires human-in-the-loop for curation; based on assumed user needs. | Rapid, co-creative UI prototyping. |&#xa;| **[NOVEL] Cognitive-Adaptive Interface (CAI) Engine** | **GenUI + Cognitive Fitness Function + Live User Telemetry.** | **Dynamic-Adaptive** | N/A (Synthesized Architecture) | **Real-time UI self-optimization based on observed user cognitive state.** |&#xa;| **[NOVEL] Test-Driven Agent (TDA) Framework** | **Closed-loop TDD + Agentic RAG + Error-Forward Self-Healing.** | **Autonomous-Iterative** | N/A (Synthesized Architecture) | **Verifiable, context-aware, autonomous development with guaranteed build integrity.** |&#xa;| **[NOVEL] Self-Optimizing Product (SOP) Loop** | **TDA-CAI integration via an RLHF-from-Telemetry feedback loop.** | **Autonomous-Holistic** | N/A (Synthesized Architecture) | **Fully autonomous product self-improvement driven by implicit user feedback.** |&#xa;&#xa;---&#xa;&#xa;#### **Proposed Architecture 1: The "Cognitive-Adaptive Interface" (CAI) Engine**&#xa;&#xa;This architecture synthesizes Generative UI (GenUI) with persona-driven design and, most critically, cognitive-heuristic constraints. It is designed to move UI generation from a static, one-shot process ("generate a wireframe") to a continuous, adaptive, and self-optimizing one.&#xa;&#xa;*   **Vector Exploited:** This architecture directly targets the vector identified in UI design: the fusion of Generative UI with real-time user telemetry, replacing subjective human feedback with objective behavioral data.&#xa;&#xa;*   **Mechanism:** The CAI Engine operates as a continuous four-phase loop:&#xa;    1.  **Phase 1: The "Cognitive Metaprompt".** The architect does not prompt for a specific layout. Instead, they provide a high-level, structured (e.g., YAML) prompt that defines the goals and constraints. This metaprompt specifies the `target_persona`, the `business_objective` (e.g., "maximize conversion"), and a `cognitive_fitness_function`—a weighted list of cognitive and behavioral principles (e.g., `cognitive_load: -0.5`, `fitts_law_compliance: +0.3`) that will be used to score the UI's performance.&#xa;    2.  **Phase 2: Initial Generation.** The CAI engine uses this metaprompt to generate the initial UI component tree as a structured JSON artifact. This initial design is its best hypothesis for satisfying the `cognitive_fitness_function` for the given `target_persona`.&#xa;    3.  **Phase 3: The Telemetry Loop.** This is the critical connection to the real world. As users interact with this dynamically-rendered GenUI, the system collects fine-grained, real-time telemetry, analogous to data from tools like Hotjar or FullStory. This includes not just "clickstream data" but also proxies for cognitive state: **hesitation time** (cognitive load), **rage clicks** (frustration), **scroll depth** (engagement), and **form drop-off points**.&#xa;    4.  **Phase 4: Autonomous Optimization.** This rich telemetry stream is fed back into the CAI engine. The engine scores the current UI's performance against the `cognitive_fitness_function`. It then begins a continuous, "self-optimizing" process, autonomously running micro-A/B tests or employing more sophisticated multi-armed bandit algorithms to adapt the UI. It might log: *"Hypothesis: Moving 'Add to Cart' button 10px closer to the product image will improve the Fitts's Law component of the fitness function. Result: Target acquisition speed improved by 80ms and conversion metric increased by 0.2%. This change is now permanent for this user segment."*&#xa;&#xa;*   **Exceeding the Benchmark:** This architecture creates a true "Self-Optimizing UI". The prompt is no longer a blueprint for a static house; it is the DNA for a living organism that adapts to its environment (the user) in real-time. This moves beyond static, assumed personas to build an interface that dynamically aligns with the observed cognitive and behavioral patterns of its actual users.&#xa;&#xa;---&#xa;&#xa;#### **Proposed Architecture 2: The "Test-Driven Agent" (TDA) Framework**&#xa;&#xa;This architecture synthesizes the most robust patterns from the code construction domain: TDD-as-Prompt, Self-Validation with Error-Forward prompting, and Agentic RAG. It creates a closed-loop, "self-healing" system designed to enable verifiable, autonomous development at the repository level.&#xa;&#xa;*   **Vector Exploited:** This architecture directly exploits the vector identified in code generation: the deep fusion of autonomous, closed-loop TDD with context-aware Agentic RAG. The agent's deliverable is not "code"; it is a "passing build."&#xa;&#xa;*   **Mechanism:** The TDA Framework operates as a five-phase, autonomous workflow:&#xa;    1.  **Phase 1: The "User Story Metaprompt".** The human (or another agent) provides a high-level feature request in a structured format (e.g., JSON), defining the goal, not the implementation. Example: `{"user_story": "As a user, I want to reset my password via email.", "acceptance_criteria": [...]}`.&#xa;    2.  **Phase 2: RAG-Context.** The TDA's first action is not to code; it is to read. It activates its Agentic RAG module to perform "context-aware query planning," querying the entire codebase and documentation to understand existing authentication routes, email services, and database schemas.&#xa;    3.  **Phase 3: Test Generation (Red).** Armed with this context, the TDA first generates a new, failing unit test (e.g., `test_post_forgot_password_invalid_email_404`). This step codifies the `acceptance_criteria` from the metaprompt into a verifiable, functional validation.&#xa;    4.  **Phase 4: Code Generation (Green).** The agent now generates the minimal amount of implementation code required to make the new test pass, strictly adhering to the patterns discovered in Phase 2.&#xa;    5.  **Phase 5: Reflect &amp; Refactor (Self-Healing).** The TDA runs the *entire* test suite. If an old test fails (a regression), it enters a "self-healing" loop, using the "Error-Forward Prompt" pattern to feed the new stack trace back to itself. It reflects and iterates on the code until the full build is green. Once green, it can be prompted to perform a final refactoring pass to improve code quality (e.g., "Ensure the new function adheres to SOLID principles").&#xa;&#xa;*   **Exceeding the Benchmark:** This architecture moves beyond task-oriented benchmarks like SWE-bench. The TDA's output is not "a code snippet that solves a problem"; it is a passing, context-aware, and regression-free build. This builds the trust required for true "agentic software engineering" by producing verifiable, reliable, and autonomous results that can be directly committed to a main branch.&#xa;&#xa;---&#xa;&#xa;#### **The Unified Synthesis: The "Self-Optimizing Product" (SOP) Loop**&#xa;&#xa;This is the final, unified architecture. It bridges the two domains by connecting the TDA (backend code) and the CAI (frontend UI) into a single, product-level optimization loop. This system is designed to autonomously improve the entire product—both its functionality and its interface—based on real-world user interaction.&#xa;&#xa;*   **Vector Exploited:** This architecture exploits the most potent "unexplored vector": connecting the CAI and TDA architectures via a shared feedback loop that uses Reinforcement Learning from Human Feedback (RLHF). In this advanced paradigm, the "human feedback" is not explicit; it is the **implicit behavioral telemetry** collected from the CAI, which is then used to train a reward model and guide the policy of the entire system.&#xa;&#xa;*   **Mechanism (The Full Loop):**&#xa;    1.  **Deploy:** The TDA generates and deploys `API_v1` (e.g., `POST /api/security-question`). The CAI generates the frontend UI to consume it.&#xa;    2.  **Observe (Telemetry):** The CAI's telemetry loop observes a "user delight" failure. It logs: *"70% of users drop off at the 'Security Question' form. Average hesitation time is 12 seconds. This violates the `cognitive_load` component of our fitness function."*&#xa;    3.  **Translate (Feedback Agent):** This telemetry is fed into a specialized "Feedback Agent." This agent's sole purpose is to translate this implicit, quantitative behavioral data into an explicit, structured product requirement. It autonomously generates a new User Story Metaprompt: `{"user_story": "The 'Security Question' flow causes high friction... Replace it with a 'Magic Link' email workflow.", "acceptance_criteria": [...]}`.&#xa;    4.  **Trigger (TDA):** This new user story is automatically fed as an Init-Prompt to the TDA.&#xa;    5.  **Heal &amp; Evolve (TDA):** The TDA springs into action. It RAGs the codebase, writes new failing tests for the 'Magic Link' flow, generates the new `API_v2` endpoints, and critically, writes and deploys a migration to deprecate `API_v1`.&#xa;    6.  **Adapt (CAI):** The TDA's deployment triggers the CAI. The CAI, now aware of the new `API_v2`, re-generates its UI components to consume the new, lower-friction workflow, automatically adapting the interface to the healed backend.&#xa;&#xa;*   **Exceeding the Benchmark:** The loop is complete. The product itself (code + UI) has just autonomously optimized its own design to improve "user delight," with zero direct human intervention. This is the new benchmark. The "prompt" is no longer a static, human instruction; it is a continuous, self-generated feedback signal originating from the user's own behavior.&#xa;&#xa;---&#xa;&#xa;### **Strategic Implementation and Future Trajectories**&#xa;&#xa;The architectures proposed are not theoretical. They are implementable by shifting from ambiguous natural language prompts to structured metaprompts that act as the bootloaders and configuration files for these autonomous systems. The key is to recognize that for reliable automation, prompts must function less like conversations and more like APIs: structured, versioned, and contractually enforced.&#xa;&#xa;#### **Actionable Blueprints: Structured Metaprompts as the System API**&#xa;&#xa;The most critical pattern for building SOTA systems is the use of structured (not natural language) prompts, as this ensures reliable, machine-parseable interaction between agents. YAML is ideal for its human-readability in top-level configuration, while schema-enforced JSON (using Pydantic/Zod) serves as the non-negotiable "API contract" for inter-agent communication.&#xa;&#xa;**Example Blueprint 1: YAML Metaprompt for the CAI Engine**&#xa;This YAML file is the master-prompt for the Cognitive-Adaptive Interface (CAI) Engine. It defines the purpose and constraints of the UI, not its specific layout.&#xa;&#xa;```yaml&#xa;# This YAML file is the master-prompt for the Cognitive-Adaptive Interface (CAI) Engine.&#xa;# It defines the *purpose* and *constraints* of the UI, not its pixels.&#xa;&#xa;system_role: "You are a CAI (Cognitive-Adaptive Interface) Engine. Your goal is to generate and continuously optimize a user interface to maximize the 'objective' by adhering to the 'fitness_function'."&#xa;&#xa;objective:&#xa;  type: "maximize_conversion"&#xa;  target_metric: "checkout_completion_rate" # The specific metric to optimize.&#xa;&#xa;target_persona:&#xa;  # This persona will be used to generate the initial UI hypothesis.&#xa;  file: "./personas/busy_professional_mobile.json" &#xa;&#xa;technical_constraints:&#xa;  # Non-negotiable acceptance criteria for any generated UI.&#xa;  - "WCAG_2_2_AA_COMPLIANT"&#xa;  - "OUTPUT_FORMAT_SEMANTIC_HTML_WITH_ARIA"&#xa;  - "MAX_LOAD_TIME_MS_3G: 1500"&#xa;&#xa;cognitive_fitness_function:&#xa;  # The core of the CAI. The engine will score its own UI against these&#xa;  # principles using live telemetry data as the metric source.&#xa;  - principle: "cognitive_load"&#xa;    weight: -0.5 # Negative weight means minimize this metric.&#xa;    metric: "avg_task_hesitation_time_sec"&#xa;&#xa;  - principle: "hick's_law"&#xa;    weight: -0.3 # Minimize choice complexity.&#xa;    metric: "choice_count_per_screen"&#xa;&#xa;  - principle: "fitts_s_law_compliance"&#xa;    weight: 0.3 # Positive weight means maximize this metric.&#xa;    metric: "target_acquisition_speed_ms"&#xa;&#xa;  - principle: "nielsen_heuristic_4_consistency"&#xa;    weight: 0.2 # Maximize consistency.&#xa;    metric: "component_reuse_score"&#xa;```&#xa;&#xa;**Example Blueprint 2: JSON Metaprompt for the TDA Framework**&#xa;This JSON object is the "Init-Prompt" for the Test-Driven Agent (TDA). It is machine-generated by the "Feedback Agent" after translating a telemetry-detected user problem.&#xa;&#xa;```json&#xa;/*&#xa;  This JSON object is the "Init-Prompt" for the Test-Driven Agent (TDA).&#xa;  It is programmatically generated by the "Feedback Agent" from user telemetry.&#xa;*/&#xa;{&#xa;  "system_role": "You are a TDA (Test-Driven Agent). Your primary directive is to produce a passing build. You must write failing tests first, then write code to make them pass.",&#xa;  "task_id": "TDA-1138",&#xa;  "source_trigger": "SOP_Feedback_Agent_Telemetry_Violation_cognitive_load",&#xa;  "user_story": "The 'Security Question' flow (API_v1) causes high user friction (70% drop-off). You must replace it with a 'Magic Link' email workflow (API_v2).",&#xa;  "rag_context_queries": [&#xa;    "Retrieve file:./routes/auth.js",&#xa;    "Retrieve file:./services/EmailService.js",&#xa;    "Retrieve file:./models/User.js",&#xa;    "Retrieve related tests: test_auth.py"&#xa;  ],&#xa;  "acceptance_criteria": [&#xa;    "A new endpoint POST /api/v2/magic-link must accept an 'email'.",&#xa;    "The new endpoint must return 404 if the email does not exist in the User model.",&#xa;    "The new endpoint must return 200 and trigger EmailService.sendMagicLink on success.",&#xa;    "The magic link token must be unique, single-use, and have a 15-minute expiry.",&#xa;    "A new failing test case must be created for an expired token scenario before implementation."&#xa;  ]&#xa;}&#xa;```&#xa;&#xa;---&#xa;&#xa;#### **Future Capability Vectors &amp; Redefining Benchmarks**&#xa;&#xa;The user's final mandate is to "exceed current benchmarks." The SOP architecture, if implemented, renders current benchmarks for agentic coding obsolete by shifting the goalposts entirely.&#xa;&#xa;*   **Current Benchmarks:** Benchmarks like **HumanEval** and **SWE-bench** are task-oriented and static. They are critical for measuring an agent's ability to solve a given, siloed problem (e.g., "Fix this bug from this GitHub issue"). However, they do not measure the agent's ability to *identify the right problem to solve* or to validate its solution against holistic, user-centric goals.&#xa;&#xa;*   **The New Benchmark:** The SOP architecture operates at the product level. The new benchmark should not be "Can the AI solve a GitHub issue?" It must be "Can the AI autonomously identify, specify, implement, and validate a user-delight issue from raw telemetry, and improve the product as a result?"&#xa;&#xa;**Proposed New Benchmark: "Product-Bench"**&#xa;&#xa;*   **Given:** A high-level product goal (e.g., "build a photo-sharing app") and a `cognitive_fitness_function` (as defined previously).&#xa;*   **Input:** A continuous stream of (simulated) user telemetry, representing a diverse set of user interactions over time.&#xa;*   **Task:** The AI system (SOP) must:&#xa;    1.  Build the V1 of the product (TDA + CAI).&#xa;    2.  Autonomously propose, specify (via metaprompts), implement (via TDA), and deploy (via CAI) new features, fixes, and UI adaptations over 1 million simulated user-sessions in direct response to the telemetry stream.&#xa;*   **Metric:** The final score is the system's ability to maximize the `cognitive_fitness_function` (e.g., a composite "User Delight" score based on retention, engagement, and cognitive load reduction) over the duration of the simulation.&#xa;&#xa;This new benchmark aligns with the future of HCI and AI, which is moving toward human-AI co-creation, AI-augmented reasoning, and human-centered evaluation. The ultimate prompt architecture is one that empowers a system to create its own prompts, driven by its core purpose and its continuous, real-time interaction with the world. This is the new, and achievable, benchmark for excellence.</title></path></g><g><g><title>### **From Static Prompts to Dynamic Architectures: Synthesizing Self-Optimizing Systems for Code and Interface Generation**&#xa;&#xa;#### **Deconstruction of Elite-Tier Prompt Patterns: The Current Benchmark**&#xa;&#xa;The effective utilization of Large Language Models (LLMs) has evolved dramatically, moving beyond simple, single-turn instructions to embrace complex, multi-stage prompt architectures. This evolutionary leap is most pronounced and impactful in the technical domains of software engineering and user interface (UI) design. A rigorous analysis of current elite-tier patterns reveals an unmistakable trajectory: a fundamental shift away from static, manually-authored instructions and toward dynamic, machine-optimized, and process-oriented systems that guide the LLM's reasoning and execution.&#xa;&#xa;This section deconstructs the state-of-the-art (SOTA) patterns in these two domains. The goal is to establish the foundational benchmarks of what is currently possible and, more critically, to identify the capability vectors that remain unexploited—the latent potential that will define the next generation of autonomous systems.&#xa;&#xa;---&#xa;&#xa;#### **Domain 1: Architectures for Efficient Code Construction**&#xa;&#xa;In software engineering, the objective has transcended merely generating code snippets. The new frontier is engineering reliable, context-aware, and increasingly autonomous systems capable of complex problem-solving. The most successful patterns do not treat the LLM as a simple code generator; they treat it as a powerful reasoning engine to be embedded within a larger, more structured, and verifiable development framework.&#xa;&#xa;**1. Automated Prompt Optimization: The "Prompt-as-a-Target" Pattern**&#xa;&#xa;The manual, iterative refinement of prompts for code generation is widely recognized as a significant bottleneck—a process that is both time-consuming and inconsistent, highly dependent on the skill of the individual engineer. The state-of-the-art has consequently moved to automate this process, treating the prompt itself as a machine-optimizable artifact.&#xa;&#xa;*   **Evolutionary-Based Methods (EPiC):** The EPiC (Evolutionary Prompt Engineering for Code) framework exemplifies a novel approach, exploring code generation from a cost-effectiveness perspective. It "leverages a lightweight evolutionary algorithm to evolve the original prompts toward better ones that produce high-quality code". This works by applying mutation operators—such as swapping synonyms (e.g., 'generate' vs. 'create'), reordering clauses, or adding clarifying constraints—to the text of the prompt. A fitness function, which could be as simple as the number of unit tests passed or a combination of correctness and token cost, guides this evolutionary search, automating the discovery of an optimal instructional solution in a highly efficient manner.&#xa;&#xa;*   **Iterative Refinement (Prochemy):** The "Prompt Alchemy" (Prochemy) method provides an "innovative method for automatically refining prompts to boost code generation". This system operates by creating a feedback loop based on the model's actual performance. It generates code, evaluates the output against a known solution (e.g., a test case), analyzes the errors, and then refines the original prompt to correct for those errors in the next iteration. This automated optimization ensures consistency by directly tuning the instructions to the model's internal biases and has demonstrated substantial performance gains, such as a **5.0% improvement for GPT-3.5-Turbo on HumanEval** and a **12.9% improvement for GPT-4o on Java-to-Python code translation tasks**.&#xa;&#xa;*   **Adaptive Selection (PET-Select):** Recognizing that "no single approach is universally optimal", the PET-Select framework introduces a critical meta-layer of intelligence. This "PET-agnostic selection model" first classifies the complexity of an incoming query, often using code complexity metrics like cyclomatic complexity or Abstract Syntax Tree (AST) depth as a proxy. Based on this classification, it then routes the query to the most appropriate prompt engineering technique (PET). A simple query might use a basic zero-shot prompt for maximum efficiency, while a highly complex query would be delegated to a more elaborate multi-stage reasoning prompt. This automated, adaptive selection process has been shown to improve **pass@1 accuracy by up to 1.9%** while simultaneously achieving a **74.8% reduction in token usage** by avoiding unnecessary computational overhead.&#xa;&#xa;The clear progression in this domain is from a human-centric "prompt engineering" phase to a machine-centric "prompt optimization" phase. The AI is no longer just the executor of the instruction; it is becoming the refiner of the instruction itself. These systems (EPiC, Prochemy) are, however, fundamentally reactive. They act as powerful local optimizers for a known task and a pre-defined solution space (e.g., passing a specific benchmark). They do not yet proactively generate a novel prompt architecture for a novel, undiscovered problem. This points toward a critical unexploited vector: a system that can discover a new problem (e.g., from user feedback telemetry) and then author its own prompt architecture to solve it, a concept directly related to meta-prompting.&#xa;&#xa;**2. Test-Driven Development (TDD) as a Prompting Paradigm**&#xa;&#xa;Arguably the most powerful and reliable pattern for generating high-quality code is the direct integration of Test-Driven Development (TDD) principles into the prompt architecture. TDD is an "incremental software development methodology that focuses on creating tests before the implementation". When applied to LLMs, the test suite is no longer just a validation step; it becomes the primary specification, eliminating ambiguity.&#xa;&#xa;*   **Core Principle:** Instead of relying on ambiguous and often incomplete natural language, the prompt provides the LLM with a concrete set of unit tests and instructs it to "write code to pass all tests". This pattern's success hinges on "instruction following and in-context learning," which have been identified as more "critical capabilities for TDD success" than general coding proficiency. The tests are the ultimate, unambiguous instruction, shifting the interaction from a request for *intent* to a specification of required *behavior*.&#xa;&#xa;*   **Frameworks:** Systems are being designed to formalize this interaction. The TGEN framework, for example, utilizes "Specialized agents" that accept two primary inputs: the "programming prompt" (a concise natural language description) and "the tests" (a full suite of unit tests, including required function signatures). These inputs are then processed by the LLM engine to produce validated, production-ready code.&#xa;&#xa;*   **Prompt Structure:** This paradigm fundamentally changes the prompt's structure. The request is no longer a simple "what," but a highly constrained "how." A common elite-level TDD prompt includes a strict set of rules that govern both the output and the process: *"1. Write a single Python function that passes all the provided tests. 2. Use type hints for all parameters and return values. 3. Follow Python best practices and PEP 8 standards... 4. Ensure the function handles all edge cases and scenarios explicitly covered in the tests. 5. Provide only the function definition and its implementation in a single code block, with no additional explanation."* This level of constraint is vital, as it makes the LLM's output machine-parseable and directly usable.&#xa;&#xa;This TDD-as-prompt pattern provides an objective, verifiable measure of "correctness" that is far superior to ambiguous natural language. It successfully shifts the burden of human effort from describing the code to defining its behavior through tests—a crucial move from semantic validation (is the code "good"?) to functional validation (does the code *work*?). The next logical step, and the key unexploited vector, is to close the loop: to create a system that not only generates code from tests but also autonomously generates its own tests from a high-level specification and validates its own code in a continuous, self-sustaining cycle.&#xa;&#xa;**3. Self-Validation and "Error-Forward" Debugging**&#xa;&#xa;This pattern extends the TDD loop into a dynamic, autonomous process. For an agent to be truly autonomous, it must be able to recognize, diagnose, and recover from its own errors without human intervention.&#xa;&#xa;*   **Self-Validation:** SOTA agentic systems are designed to "regularly verify progress and self-assess correctness". This "agentic self-validation" is a core capability that "drives up accuracy". For instance, agents from Cognition, such as Devin, are noted to "excel at testing its own code." This involves more than just running a script; the agent sets up the test environment, installs dependencies, executes the test suite, and correctly interprets the results from `stdout` and `stderr`. This allows the agent to "go through several improvement cycles on its own instead of having to manually ask the AI to fix test failures".&#xa;&#xa;*   **"Error-Forward Prompting":** This is the primary recovery mechanism within the self-validation loop, treating errors as high-value data, not as failures. When an agent's self-validation attempt fails, the system automatically "collects relevant context, including the error message, stack trace, and cell location". This structured information is then formatted and "provided to the agent as the initial context for beginning the debugging process". This contrasts sharply with a naive human-in-the-loop approach, where a developer might simply say "that didn't work, try again."&#xa;&#xa;*   **Reflection:** This is the learning mechanism that makes the recovery effective and intelligent. A "reflection system enables the agent to learn from its actions and improve its debugging strategy". Implemented via "reflective prompting", this allows the model to "analyze and refine its outputs". The model first generates a solution, then, "through subsequent prompts, critiques its own reasoning to identify and correct errors". This is formalized in techniques like Self-Refine, which mimics the expert human "draft, review, refine" process. The agent asks itself not just "how do I fix this `NullPointerException`?" but "why did this null value occur, and how can I refactor my code to prevent this class of error in the future?"&#xa;&#xa;In this paradigm, failure is no longer an end-state; it is a high-value data signal. The stack trace becomes the most valuable part of the prompt—a pure, unambiguous instruction set for what must be fixed. When TDD-as-prompt is combined with this self-validation and reflection loop, the system becomes "self-healing." The prompt is no longer a single-shot instruction but the initiation of a self-sustaining process. The agent's goal is elevated from "generate code" to "make the build pass," a critical step toward true autonomy.&#xa;&#xa;**4. Agentic Frameworks and Multi-Agent Collaboration**&#xa;&#xa;Complex software development cannot be solved in a single step or by a single-minded agent. The recognition that single-shot prompts "yield imprecise or plain incorrect results" for elaborate tasks has led to the rise of sophisticated agentic frameworks that orchestrate multiple agents and advanced reasoning patterns.&#xa;&#xa;*   **Advanced Reasoning Patterns:** These frameworks are built upon reasoning patterns far more advanced than simple Chain-of-Thought (CoT).&#xa;    *   **ReAct:** This pattern combines "Reason and Act", allowing an agent to interleave step-by-step reasoning with tool use to gather external information or perform actions in an environment.&#xa;    *   **Tree of Thoughts (ToT):** This pattern moves beyond the linear path of CoT. It allows an agent to "breakdown intermediate processed into steps," generate "various generated states" for each step, and "evaluate" those states to "determine which branch to explore next," effectively performing a beam search over the solution space.&#xa;    *   **Graph of Thoughts (GoT):** The current SOTA in reasoning, GoT generalizes ToT into a full graph structure. This "enables combining arbitrary LLM thoughts into synergistic outcomes" and, critically, "enhancing thoughts using feedback loops". For example, a thought node that generates a plan can be evaluated by another node, and the resulting critique ("This plan is too complex and misses a key dependency") can be looped back to the original node, prompting it to generate a revised, superior plan. GoT has been shown to **increase the quality of sorting by 62% over ToT** while reducing costs.&#xa;&#xa;*   **Agentic Frameworks:** These advanced reasoning patterns are orchestrated by multi-agent frameworks that decompose complexity through role-playing.&#xa;    *   **MetaGPT:** This framework simulates a "real-world software company." It assigns agents specific roles like "product manager, software architect, programmer, or QA tester" and embeds them with "Standard Operating Procedures (SOPs)" that govern their behavior and interactions.&#xa;    *   **ChatDev:** This framework utilizes a "waterfall-style" collaboration, where agents engage in "task-oriented and multi-turn communications" to iteratively design, implement, test, and document a software solution.&#xa;&#xa;*   **Purpose:** These frameworks are essential as they provide a "shared philosophy of control &amp; reasoning". Without this structure, agentic systems suffer from a "loss of control clarity of flow" and "unbounded complexity growth" as new agents are added. The roles and SOPs provide necessary constraints that guide the LLM's vast capabilities toward a productive outcome.&#xa;&#xa;*   **Benchmarks:** These sophisticated agentic systems are what achieve top scores on complex, real-world benchmarks that measure true engineering capability. The **SWE-bench** benchmark, for instance, measures "an AI model's ability to solve real-world software issues" from popular GitHub repositories. SOTA models achieve high scores on SWE-bench and **OSWorld** precisely by using these multi-agent, self-testing, and reflective architectures.&#xa;&#xa;The atomic unit of these powerful frameworks is role-based prompting. The frameworks themselves are, in essence, prompt-driven state machines. A high-level "meta-prompt" defines the agents, their roles, their tools, and their communication protocols. The LLM is thus demoted from "solution generator" to a core component—a "reasoning engine" that navigates this pre-defined architecture. The architecture itself has become the prompt. The current limitation, and the unexplored vector, is that these frameworks are simulations of human workflow (e.g., "waterfall," "software company"). A truly AI-native workflow, where feedback comes not from a simulated "QA Agent" but from the product itself via live user telemetry, would be fundamentally more efficient and powerful.&#xa;&#xa;**5. Context-Aware Generation (Agentic RAG)**&#xa;&#xa;Code generation is useless without domain-specific context. Retrieval-Augmented Generation (RAG) is the primary pattern for providing this context, and its agentic form is the SOTA for any non-trivial coding task.&#xa;&#xa;*   **RAG-for-Code:** This pattern gives an AI assistant "a direct line to your team's collective knowledge". Before generating a response, the prompt is "augmented" with relevant information retrieved from "documentation, code repositories, or even Stack Overflow discussions". This ensures the generated response is "context-aware" and adheres to the specific conventions, APIs, and architectural patterns of the codebase it is intended for.&#xa;&#xa;*   **Agentic RAG:** This is the "evolution from traditional single-query RAG". Instead of being a passive recipient of retrieved context, the agent actively forages for it. It performs "context-aware query planning," breaking a complex question into multiple sub-queries. It can issue "parallel execution of multiple focused subqueries" (e.g., simultaneously looking for database schemas, relevant API routes, and existing utility functions) and then synthesizes the results to build a comprehensive understanding before it begins to code. This is the advanced approach used by modern agentic frameworks like LangGraph, AutoGen, and those from major cloud providers.&#xa;&#xa;The RAG-for-Code pattern transforms a "general-purpose coder" into a "domain-specific engineer." The agentic aspect is the critical differentiator; it is the difference between giving a developer a 500-page manual (standard RAG) and the developer knowing which three pages to read to solve the specific problem at hand (Agentic RAG). The most potent, but not yet fully exploited, vector in code generation is the deep fusion of this Agentic RAG (for context) with the TDD-as-Prompt paradigm (for verification). Agentic RAG provides the *what* and *why* (domain knowledge, business logic), while TDD provides the *proof* (functional correctness). An agent that can retrieve context from a 500,000-line codebase and validate its proposed changes against that codebase's entire test suite is the difference between a "coding assistant" and an "autonomous developer." This fusion is the core of the novel Test-Driven Agent (TDA) architecture proposed later in this document.&#xa;&#xa;---&#xa;&#xa;#### **Domain 2: Architectures for User Delight &amp; UI Design**&#xa;&#xa;In the second domain, UI generation, the mandate for "user delight" requires moving far beyond simple wireframe generation. Elite-tier prompts in this space are not about "generating pixels" but about "generating experiences" grounded in human-centric design principles and cognitive science.&#xa;&#xa;**1. Persona-Driven Design: Grounding the Generation**&#xa;&#xa;"User delight" is the "positive emotional response users feel when a product doesn't just meet their needs but goes above and beyond". This state is "highly contextual" and cannot be achieved without first defining and deeply understanding the user.&#xa;&#xa;*   **Pattern:** Elite prompts for UI design do not begin with the interface; they begin with the user. The system is first prompted to generate a detailed proto-persona. This persona includes not only demographic details but also the "target users, their core pain points, and daily use context", as well as deeper psychological drivers like "Motivations" and "Affinities".&#xa;&#xa;*   **Application:** This generated persona (or a human-provided one) is then injected as a primary constraint into all subsequent UI generation prompts. This allows the AI to "cater to Gen Z and Gen X users" differently. For example, the same prompt for a music app might yield a gamified, emoji-rich, and socially-integrated interface for a Gen Z persona, while producing a clean, information-dense, and highly functional layout for a Gen X professional. The prompt is no longer "generate a wireframe for a music app" but "generate a wireframe for a music app for *this specific persona*, focusing on their stated pain point of {pain_point}."&#xa;&#xa;This persona-driven pattern acts as a powerful constraint on the model's vast solution space, forcing it to move from generating a generic "good UI" to a UI that is "good for *this specific user*." It is, in effect, a form of in-context learning for design, where the persona serves as a "one-shot" example of the target user. The major limitation, and the unexploited vector, is that this is a static, upfront process. The persona is an assumption created at the beginning of the design process. The clear next step is to move from these static, assumed personas to dynamic, observed user models that are continuously updated based on real-time behavioral analytics.&#xa;&#xa;**2. Constraint-Based Generation: Defining the "Solution Space"**&#xa;&#xa;The highest-fidelity UI generation requires the application of multiple, layered constraints. These constraints are the specifications that ensure the output is not just creative, but also functional, accessible, and grounded in established design theory.&#xa;&#xa;**A. Cognitive &amp; Heuristic Constraints**&#xa;&#xa;This is the most sophisticated pattern for achieving true "user delight." The prompt explicitly instructs the AI to apply principles from cognitive science and established usability heuristics, forcing the AI to design for the human mind, not just the screen.&#xa;&#xa;*   **Heuristics:** The most common pattern is to prompt the AI to act as a UX expert and evaluate or generate a design based on "Nielsen's 10 Usability Heuristics" or other well-known variants like Shneiderman's "Eight Golden Rules" or Weinschenk and Barker's "20 Usability Heuristics".&#xa;&#xa;*   **Cognitive Principles:** More advanced prompts instruct the AI to directly apply specific cognitive laws. Examples include:&#xa;    *   **Fitts's Law:** Prompting the AI to make "important buttons and interactive elements larger and closer to where users naturally focus".&#xa;    *   **Hick's Law:** Instructing the AI to "reduc[e] the number of options or organiz[e] them into categories" to speed up decision-making.&#xa;    *   **Miller's Law:** Guiding the AI to present information in chunks of 5-9 items to respect the limits of working memory.&#xa;    *   **Cognitive Load:** Prompting with the explicit goal of "reducing cognitive load" to create a more effortless and intuitive user experience.&#xa;&#xa;*   **Behavioral Models:** The most advanced prompts use frameworks like **BJ Fogg's Behavior Model (B=MAP: Motivation, Ability, Prompt)** or **Nir Eyal's "Hooked" model** to design persuasive or habit-forming interfaces that align with user psychology.&#xa;&#xa;Prompting with "Nielsen's Heuristics" or "Fogg's Behavior Model" acts as a domain-specific Chain-of-Thought. It forces the AI to externalize and justify its design choices ("This button is large and placed in the bottom-right corner because it adheres to Fitts's Law for mobile users"), leading to more principled, defensible, and ultimately delightful designs.&#xa;&#xa;**B. Technical &amp; Accessibility (A11y) Constraints**&#xa;&#xa;There is no "delight" in an interface that is unusable for a portion of the population. Elite prompts must enforce technical constraints, with accessibility (A11y) being a paramount, non-negotiable requirement for both ethical and business reasons.&#xa;&#xa;*   **Pattern:** The prompt must explicitly instruct the AI to be "fully compliant with WCAG 2.2 AA". Research shows that without this explicit instruction, AI-generated components are "consistently" and predictably inaccessible.&#xa;&#xa;*   **Specifics:** A high-quality A11y prompt enforces:&#xa;    *   **Semantic HTML:** "Ensure the proper use of HTML5 elements (like ``, ``, ``) to provide structural meaning."&#xa;    *   **Keyboard Accessibility:** "Ensure all interactive elements are reachable and operable using only the Tab, Shift+Tab, and Enter keys."&#xa;    *   **ARIA (Accessible Rich Internet Applications):** Mandate the correct application of "ARIA landmarks and roles", which are "HTML attributes that add semantic meaning... for assistive technologies" like screen readers.&#xa;    *   **Clear Content:** "Use clear, concise language. Write descriptive links: Swap vague text like 'click here' for meaningful descriptions like 'Read our Q3 financial report'."&#xa;&#xa;This pattern is the UI-domain equivalent of TDD. The prompt includes the acceptance criteria (WCAG standards). This "specification-as-prompt" is critical for generating production-ready, non-discriminatory interfaces.&#xa;&#xa;**C. Structural &amp; Layout Constraints**&#xa;&#xa;To control the form of the output and ensure it is machine-readable and programmatically useful, prompts must define a reliable data structure.&#xa;&#xa;*   **Architecture &amp; Flows:** For high-level system design, prompts specify formats like the **C4 model** rendered in Mermaid code. For user flows, Mermaid sequence diagrams are the standard, providing a clear, visual, and code-based representation.&#xa;*   **Wireframes:** Simple wireframe prompts use text descriptions, such as, "Generate a mobile dashboard with a top header containing a logo and notification bell, a main content area with three KPI cards, and a bottom navigation bar with four icons."&#xa;*   **SOTA (Structured Data):** The most robust and programmatically valuable pattern is to force the LLM to output a structured data format like JSON or YAML. This is achieved by providing an output schema to the model. This pattern is now natively supported by major model providers, who allow schemas to be defined using libraries like **Pydantic** (for Python) or **Zod** (for TypeScript). This guarantees the output is not just text, but a typed, validated, and contractually reliable data structure, ensuring "type safety and consistent structure".&#xa;&#xa;This structured output pattern is the critical link between the two domains of this report. If a UI can be described in a reliable JSON schema, and a backend can expose its API in a reliable JSON schema (e.g., an OpenAPI specification), an agent can programmatically connect them. This structured output is the "API" between a UI-generation agent and a code-generation agent, enabling true end-to-end automation.&#xa;&#xa;**3. Generative UI (GenUI): The Emergent Paradigm**&#xa;&#xa;This is the bleeding-edge concept that underpins the future of UI design. Generative UI (GenUI) is a new paradigm that "enables adaptive, goal-driven interactions". Instead of a static interface designed by a human and then coded by a developer, the UI is generated, and even adapted, in real-time by an AI.&#xa;&#xa;*   **Mechanism:** In this paradigm, the AI generates "interactive widgets for fine-grained prompt control" or entire "high-fidelity UI mock-up screens from a high-level textual description". This process is not one-shot; it is an iterative, "co-creative process" between the human and the AI, involving "AI-assisted refinement strategies".&#xa;&#xa;*   **Current State:** GenUI is currently being adopted by UX practitioners as a powerful tool to accelerate their workflow. The human remains the curator and refiner of the AI-generated output, providing subjective feedback like "make that button bigger" or "this feels too cluttered."&#xa;&#xa;GenUI is the logical evolution of prompt-based wireframing. The current limitation, and the key unexploited vector, is the human-in-the-loop for optimization. The UI is refined based on a designer's subjective taste or explicit follow-up prompts—a high-latency, low-bandwidth feedback mechanism. The unexploited opportunity is to remove the human curator from the optimization loop and replace them with a direct, high-bandwidth data stream from the end-user. A system that could refine its own GenUI, not based on a designer's commands, but based on live user behavioral data, would represent a paradigm shift. This is the core concept of a "Self-Optimizing UI" and forms the foundation for the novel Cognitive-Adaptive Interface (CAI) architecture.&#xa;&#xa;---&#xa;&#xa;### **Synthesis of Novel Prompt Architectures: Exceeding Current Benchmarks**&#xa;&#xa;The preceding analysis deconstructed the current SOTA, revealing a set of unexploited capability vectors. The following synthesis moves beyond merely replicating these patterns. It proposes three novel, high-level architectures that fuse these vectors to create self-regulating, self-optimizing systems designed to exceed current benchmarks. These architectures treat the prompt not as a static, one-time instruction, but as a "bootloader" for a continuous, autonomous process.&#xa;&#xa;**Table 1: Comparative Analysis of Generation &amp; Reasoning Architectures**&#xa;&#xa;| Architecture | Core Mechanism | Interaction Model | Key Limitation (Vector Not Exploited) | Unlocked Capability Vector |&#xa;| :--- | :--- | :--- | :--- | :--- |&#xa;| Chain-of-Thought (CoT) | Step-by-step reasoning (e.g., "Let's think step-by-step"). | Static | Brittle, linear reasoning; no external validation or tool use. | Basic multi-step problem solving. |&#xa;| ReAct | Interleaves reasoning (CoT) with tool use (Actions). | Iterative | Dependent on pre-defined tools; no long-term memory or structured collaboration. | Environment-aware task execution. |&#xa;| Graph of Thoughts (GoT) | Models reasoning as a graph, allowing merging of states and feedback loops. | Iterative | High conceptual complexity; primarily focused on reasoning, not execution. | Advanced, non-linear problem-solving. |&#xa;| TDD-as-Prompt | A test suite is provided as the functional specification for code generation. | Static | Requires human to write all tests; no self-correction loop. | Verifiable, high-reliability code generation. |&#xa;| Generative UI (GenUI) | AI generates high-fidelity UI mockups or interactive widgets from text. | Iterative | Requires human-in-the-loop for curation; based on assumed user needs. | Rapid, co-creative UI prototyping. |&#xa;| **[NOVEL] Cognitive-Adaptive Interface (CAI) Engine** | **GenUI + Cognitive Fitness Function + Live User Telemetry.** | **Dynamic-Adaptive** | N/A (Synthesized Architecture) | **Real-time UI self-optimization based on observed user cognitive state.** |&#xa;| **[NOVEL] Test-Driven Agent (TDA) Framework** | **Closed-loop TDD + Agentic RAG + Error-Forward Self-Healing.** | **Autonomous-Iterative** | N/A (Synthesized Architecture) | **Verifiable, context-aware, autonomous development with guaranteed build integrity.** |&#xa;| **[NOVEL] Self-Optimizing Product (SOP) Loop** | **TDA-CAI integration via an RLHF-from-Telemetry feedback loop.** | **Autonomous-Holistic** | N/A (Synthesized Architecture) | **Fully autonomous product self-improvement driven by implicit user feedback.** |&#xa;&#xa;---&#xa;&#xa;#### **Proposed Architecture 1: The "Cognitive-Adaptive Interface" (CAI) Engine**&#xa;&#xa;This architecture synthesizes Generative UI (GenUI) with persona-driven design and, most critically, cognitive-heuristic constraints. It is designed to move UI generation from a static, one-shot process ("generate a wireframe") to a continuous, adaptive, and self-optimizing one.&#xa;&#xa;*   **Vector Exploited:** This architecture directly targets the vector identified in UI design: the fusion of Generative UI with real-time user telemetry, replacing subjective human feedback with objective behavioral data.&#xa;&#xa;*   **Mechanism:** The CAI Engine operates as a continuous four-phase loop:&#xa;    1.  **Phase 1: The "Cognitive Metaprompt".** The architect does not prompt for a specific layout. Instead, they provide a high-level, structured (e.g., YAML) prompt that defines the goals and constraints. This metaprompt specifies the `target_persona`, the `business_objective` (e.g., "maximize conversion"), and a `cognitive_fitness_function`—a weighted list of cognitive and behavioral principles (e.g., `cognitive_load: -0.5`, `fitts_law_compliance: +0.3`) that will be used to score the UI's performance.&#xa;    2.  **Phase 2: Initial Generation.** The CAI engine uses this metaprompt to generate the initial UI component tree as a structured JSON artifact. This initial design is its best hypothesis for satisfying the `cognitive_fitness_function` for the given `target_persona`.&#xa;    3.  **Phase 3: The Telemetry Loop.** This is the critical connection to the real world. As users interact with this dynamically-rendered GenUI, the system collects fine-grained, real-time telemetry, analogous to data from tools like Hotjar or FullStory. This includes not just "clickstream data" but also proxies for cognitive state: **hesitation time** (cognitive load), **rage clicks** (frustration), **scroll depth** (engagement), and **form drop-off points**.&#xa;    4.  **Phase 4: Autonomous Optimization.** This rich telemetry stream is fed back into the CAI engine. The engine scores the current UI's performance against the `cognitive_fitness_function`. It then begins a continuous, "self-optimizing" process, autonomously running micro-A/B tests or employing more sophisticated multi-armed bandit algorithms to adapt the UI. It might log: *"Hypothesis: Moving 'Add to Cart' button 10px closer to the product image will improve the Fitts's Law component of the fitness function. Result: Target acquisition speed improved by 80ms and conversion metric increased by 0.2%. This change is now permanent for this user segment."*&#xa;&#xa;*   **Exceeding the Benchmark:** This architecture creates a true "Self-Optimizing UI". The prompt is no longer a blueprint for a static house; it is the DNA for a living organism that adapts to its environment (the user) in real-time. This moves beyond static, assumed personas to build an interface that dynamically aligns with the observed cognitive and behavioral patterns of its actual users.&#xa;&#xa;---&#xa;&#xa;#### **Proposed Architecture 2: The "Test-Driven Agent" (TDA) Framework**&#xa;&#xa;This architecture synthesizes the most robust patterns from the code construction domain: TDD-as-Prompt, Self-Validation with Error-Forward prompting, and Agentic RAG. It creates a closed-loop, "self-healing" system designed to enable verifiable, autonomous development at the repository level.&#xa;&#xa;*   **Vector Exploited:** This architecture directly exploits the vector identified in code generation: the deep fusion of autonomous, closed-loop TDD with context-aware Agentic RAG. The agent's deliverable is not "code"; it is a "passing build."&#xa;&#xa;*   **Mechanism:** The TDA Framework operates as a five-phase, autonomous workflow:&#xa;    1.  **Phase 1: The "User Story Metaprompt".** The human (or another agent) provides a high-level feature request in a structured format (e.g., JSON), defining the goal, not the implementation. Example: `{"user_story": "As a user, I want to reset my password via email.", "acceptance_criteria": [...]}`.&#xa;    2.  **Phase 2: RAG-Context.** The TDA's first action is not to code; it is to read. It activates its Agentic RAG module to perform "context-aware query planning," querying the entire codebase and documentation to understand existing authentication routes, email services, and database schemas.&#xa;    3.  **Phase 3: Test Generation (Red).** Armed with this context, the TDA first generates a new, failing unit test (e.g., `test_post_forgot_password_invalid_email_404`). This step codifies the `acceptance_criteria` from the metaprompt into a verifiable, functional validation.&#xa;    4.  **Phase 4: Code Generation (Green).** The agent now generates the minimal amount of implementation code required to make the new test pass, strictly adhering to the patterns discovered in Phase 2.&#xa;    5.  **Phase 5: Reflect &amp; Refactor (Self-Healing).** The TDA runs the *entire* test suite. If an old test fails (a regression), it enters a "self-healing" loop, using the "Error-Forward Prompt" pattern to feed the new stack trace back to itself. It reflects and iterates on the code until the full build is green. Once green, it can be prompted to perform a final refactoring pass to improve code quality (e.g., "Ensure the new function adheres to SOLID principles").&#xa;&#xa;*   **Exceeding the Benchmark:** This architecture moves beyond task-oriented benchmarks like SWE-bench. The TDA's output is not "a code snippet that solves a problem"; it is a passing, context-aware, and regression-free build. This builds the trust required for true "agentic software engineering" by producing verifiable, reliable, and autonomous results that can be directly committed to a main branch.&#xa;&#xa;---&#xa;&#xa;#### **The Unified Synthesis: The "Self-Optimizing Product" (SOP) Loop**&#xa;&#xa;This is the final, unified architecture. It bridges the two domains by connecting the TDA (backend code) and the CAI (frontend UI) into a single, product-level optimization loop. This system is designed to autonomously improve the entire product—both its functionality and its interface—based on real-world user interaction.&#xa;&#xa;*   **Vector Exploited:** This architecture exploits the most potent "unexplored vector": connecting the CAI and TDA architectures via a shared feedback loop that uses Reinforcement Learning from Human Feedback (RLHF). In this advanced paradigm, the "human feedback" is not explicit; it is the **implicit behavioral telemetry** collected from the CAI, which is then used to train a reward model and guide the policy of the entire system.&#xa;&#xa;*   **Mechanism (The Full Loop):**&#xa;    1.  **Deploy:** The TDA generates and deploys `API_v1` (e.g., `POST /api/security-question`). The CAI generates the frontend UI to consume it.&#xa;    2.  **Observe (Telemetry):** The CAI's telemetry loop observes a "user delight" failure. It logs: *"70% of users drop off at the 'Security Question' form. Average hesitation time is 12 seconds. This violates the `cognitive_load` component of our fitness function."*&#xa;    3.  **Translate (Feedback Agent):** This telemetry is fed into a specialized "Feedback Agent." This agent's sole purpose is to translate this implicit, quantitative behavioral data into an explicit, structured product requirement. It autonomously generates a new User Story Metaprompt: `{"user_story": "The 'Security Question' flow causes high friction... Replace it with a 'Magic Link' email workflow.", "acceptance_criteria": [...]}`.&#xa;    4.  **Trigger (TDA):** This new user story is automatically fed as an Init-Prompt to the TDA.&#xa;    5.  **Heal &amp; Evolve (TDA):** The TDA springs into action. It RAGs the codebase, writes new failing tests for the 'Magic Link' flow, generates the new `API_v2` endpoints, and critically, writes and deploys a migration to deprecate `API_v1`.&#xa;    6.  **Adapt (CAI):** The TDA's deployment triggers the CAI. The CAI, now aware of the new `API_v2`, re-generates its UI components to consume the new, lower-friction workflow, automatically adapting the interface to the healed backend.&#xa;&#xa;*   **Exceeding the Benchmark:** The loop is complete. The product itself (code + UI) has just autonomously optimized its own design to improve "user delight," with zero direct human intervention. This is the new benchmark. The "prompt" is no longer a static, human instruction; it is a continuous, self-generated feedback signal originating from the user's own behavior.&#xa;&#xa;---&#xa;&#xa;### **Strategic Implementation and Future Trajectories**&#xa;&#xa;The architectures proposed are not theoretical. They are implementable by shifting from ambiguous natural language prompts to structured metaprompts that act as the bootloaders and configuration files for these autonomous systems. The key is to recognize that for reliable automation, prompts must function less like conversations and more like APIs: structured, versioned, and contractually enforced.&#xa;&#xa;#### **Actionable Blueprints: Structured Metaprompts as the System API**&#xa;&#xa;The most critical pattern for building SOTA systems is the use of structured (not natural language) prompts, as this ensures reliable, machine-parseable interaction between agents. YAML is ideal for its human-readability in top-level configuration, while schema-enforced JSON (using Pydantic/Zod) serves as the non-negotiable "API contract" for inter-agent communication.&#xa;&#xa;**Example Blueprint 1: YAML Metaprompt for the CAI Engine**&#xa;This YAML file is the master-prompt for the Cognitive-Adaptive Interface (CAI) Engine. It defines the purpose and constraints of the UI, not its specific layout.&#xa;&#xa;```yaml&#xa;# This YAML file is the master-prompt for the Cognitive-Adaptive Interface (CAI) Engine.&#xa;# It defines the *purpose* and *constraints* of the UI, not its pixels.&#xa;&#xa;system_role: "You are a CAI (Cognitive-Adaptive Interface) Engine. Your goal is to generate and continuously optimize a user interface to maximize the 'objective' by adhering to the 'fitness_function'."&#xa;&#xa;objective:&#xa;  type: "maximize_conversion"&#xa;  target_metric: "checkout_completion_rate" # The specific metric to optimize.&#xa;&#xa;target_persona:&#xa;  # This persona will be used to generate the initial UI hypothesis.&#xa;  file: "./personas/busy_professional_mobile.json" &#xa;&#xa;technical_constraints:&#xa;  # Non-negotiable acceptance criteria for any generated UI.&#xa;  - "WCAG_2_2_AA_COMPLIANT"&#xa;  - "OUTPUT_FORMAT_SEMANTIC_HTML_WITH_ARIA"&#xa;  - "MAX_LOAD_TIME_MS_3G: 1500"&#xa;&#xa;cognitive_fitness_function:&#xa;  # The core of the CAI. The engine will score its own UI against these&#xa;  # principles using live telemetry data as the metric source.&#xa;  - principle: "cognitive_load"&#xa;    weight: -0.5 # Negative weight means minimize this metric.&#xa;    metric: "avg_task_hesitation_time_sec"&#xa;&#xa;  - principle: "hick's_law"&#xa;    weight: -0.3 # Minimize choice complexity.&#xa;    metric: "choice_count_per_screen"&#xa;&#xa;  - principle: "fitts_s_law_compliance"&#xa;    weight: 0.3 # Positive weight means maximize this metric.&#xa;    metric: "target_acquisition_speed_ms"&#xa;&#xa;  - principle: "nielsen_heuristic_4_consistency"&#xa;    weight: 0.2 # Maximize consistency.&#xa;    metric: "component_reuse_score"&#xa;```&#xa;&#xa;**Example Blueprint 2: JSON Metaprompt for the TDA Framework**&#xa;This JSON object is the "Init-Prompt" for the Test-Driven Agent (TDA). It is machine-generated by the "Feedback Agent" after translating a telemetry-detected user problem.&#xa;&#xa;```json&#xa;/*&#xa;  This JSON object is the "Init-Prompt" for the Test-Driven Agent (TDA).&#xa;  It is programmatically generated by the "Feedback Agent" from user telemetry.&#xa;*/&#xa;{&#xa;  "system_role": "You are a TDA (Test-Driven Agent). Your primary directive is to produce a passing build. You must write failing tests first, then write code to make them pass.",&#xa;  "task_id": "TDA-1138",&#xa;  "source_trigger": "SOP_Feedback_Agent_Telemetry_Violation_cognitive_load",&#xa;  "user_story": "The 'Security Question' flow (API_v1) causes high user friction (70% drop-off). You must replace it with a 'Magic Link' email workflow (API_v2).",&#xa;  "rag_context_queries": [&#xa;    "Retrieve file:./routes/auth.js",&#xa;    "Retrieve file:./services/EmailService.js",&#xa;    "Retrieve file:./models/User.js",&#xa;    "Retrieve related tests: test_auth.py"&#xa;  ],&#xa;  "acceptance_criteria": [&#xa;    "A new endpoint POST /api/v2/magic-link must accept an 'email'.",&#xa;    "The new endpoint must return 404 if the email does not exist in the User model.",&#xa;    "The new endpoint must return 200 and trigger EmailService.sendMagicLink on success.",&#xa;    "The magic link token must be unique, single-use, and have a 15-minute expiry.",&#xa;    "A new failing test case must be created for an expired token scenario before implementation."&#xa;  ]&#xa;}&#xa;```&#xa;&#xa;---&#xa;&#xa;#### **Future Capability Vectors &amp; Redefining Benchmarks**&#xa;&#xa;The user's final mandate is to "exceed current benchmarks." The SOP architecture, if implemented, renders current benchmarks for agentic coding obsolete by shifting the goalposts entirely.&#xa;&#xa;*   **Current Benchmarks:** Benchmarks like **HumanEval** and **SWE-bench** are task-oriented and static. They are critical for measuring an agent's ability to solve a given, siloed problem (e.g., "Fix this bug from this GitHub issue"). However, they do not measure the agent's ability to *identify the right problem to solve* or to validate its solution against holistic, user-centric goals.&#xa;&#xa;*   **The New Benchmark:** The SOP architecture operates at the product level. The new benchmark should not be "Can the AI solve a GitHub issue?" It must be "Can the AI autonomously identify, specify, implement, and validate a user-delight issue from raw telemetry, and improve the product as a result?"&#xa;&#xa;**Proposed New Benchmark: "Product-Bench"**&#xa;&#xa;*   **Given:** A high-level product goal (e.g., "build a photo-sharing app") and a `cognitive_fitness_function` (as defined previously).&#xa;*   **Input:** A continuous stream of (simulated) user telemetry, representing a diverse set of user interactions over time.&#xa;*   **Task:** The AI system (SOP) must:&#xa;    1.  Build the V1 of the product (TDA + CAI).&#xa;    2.  Autonomously propose, specify (via metaprompts), implement (via TDA), and deploy (via CAI) new features, fixes, and UI adaptations over 1 million simulated user-sessions in direct response to the telemetry stream.&#xa;*   **Metric:** The final score is the system's ability to maximize the `cognitive_fitness_function` (e.g., a composite "User Delight" score based on retention, engagement, and cognitive load reduction) over the duration of the simulation.&#xa;&#xa;This new benchmark aligns with the future of HCI and AI, which is moving toward human-AI co-creation, AI-augmented reasoning, and human-centered evaluation. The ultimate prompt architecture is one that empowers a system to create its own prompts, driven by its core purpose and its continuous, real-time interaction with the world. This is the new, and achievable, benchmark for excellence.</title><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 118px; height: 1px; padding-top: 201px; margin-left: 1151px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; "><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; ">DeepResearch</div></div></div></foreignObject><image x="1151" y="194.5" width="118" height="17" xlink:href="data:image/png;base64,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"/></switch></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-108"><g><path d="M 770 97 L 1099.86 97.14 Q 1109.86 97.14 1109.86 87.14 L 1109.86 37.14 Q 1109.86 27.14 1119.86 27.14 L 1550.14 27.14 Q 1560.14 27.14 1560.11 37.14 L 1560.02 60.63" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke" style="stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/><path d="M 1560 65.88 L 1556.53 58.87 L 1560.02 60.63 L 1563.53 58.89 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all" style="fill: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-118"><g><path d="M 770 97 L 1099.86 97.14 Q 1109.86 97.14 1109.86 87.14 L 1109.86 27.14 Q 1109.86 17.14 1119.86 17.14 L 1790.14 17.14 Q 1800.14 17.14 1800.11 27.14 L 1800.02 60.63" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke" style="stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/><path d="M 1800 65.88 L 1796.52 58.87 L 1800.02 60.63 L 1803.52 58.89 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all" style="fill: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-126"><g><path d="M 770 97.14 L 1099.86 97.14 Q 1109.86 97.14 1109.86 87.14 L 1109.86 17.14 Q 1109.86 7.14 1119.86 7.14 L 2040.14 7.14 Q 2050.14 7.14 2050.12 17.14 L 2050.02 60.63" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke" style="stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/><path d="M 2050 65.88 L 2046.52 58.87 L 2050.02 60.63 L 2053.52 58.89 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all" style="fill: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-11"><g><path d="M 650 77 L 770 77 L 770 145 Q 740 123.4 710 145 Q 680 166.6 650 145 L 650 89 Z" fill="#dae8fc" stroke="#6c8ebf" stroke-miterlimit="10" pointer-events="all" style="fill: light-dark(rgb(218, 232, 252), rgb(29, 41, 59)); stroke: light-dark(rgb(108, 142, 191), rgb(92, 121, 163));"><title>&#xa;Novel Prompt Architectures for AI&#xa;From Static Prompts to Dynamic Architectures: Synthesizing Self-Optimizing Systems for Code and Interface Generation&#xa;Deconstruction of Elite-Tier Prompt Patterns: The Current Benchmark&#xa;The effective use of Large Language Models (LLMs) has evolved significantly from simple, single-turn instructions to complex, multi-stage prompt architectures. This evolution is most pronounced in the technical domains of software engineering and user interface (UI) design. An analysis of current elite-tier patterns reveals a clear trajectory: a shift away from static, human-authored instructions and toward dynamic, machine-optimized, and process-oriented systems.&#xa;&#xa;This section deconstructs the state-of-the-art (SOTA) patterns in these two domains to establish the foundational benchmarks and identify the capability vectors that remain unexploited.&#xa;&#xa;Domain 1: Architectures for Efficient Code Construction&#xa;In software engineering, the objective has shifted from merely generating code snippets to engineering reliable, context-aware, and autonomous systems. The most successful patterns treat the LLM not as a simple code generator, but as a reasoning engine to be embedded within a larger, more structured development framework.&#xa;&#xa;1. Automated Prompt Optimization: The "Prompt-as-a-Target" Pattern&#xa;The manual, iterative refinement of prompts for code generation is widely recognized as a "time-consuming and inconsistent" bottleneck. The SOTA has moved to automate this process, treating the prompt itself as an artifact to be optimized.  &#xa;&#xa;Evolutionary-Based Methods (EPiC): The EPiC (Evolutionary Prompt Engineering for Code) framework is a novel approach that explores code generation from a cost-effectiveness perspective. It "leverages a lightweight evolutionary algorithm to evolve the original prompts toward better ones that produce high-quality code". By employing mutation operators on the text of the prompt and guiding the search with a fitness function, EPiC automates the discovery of an optimal solution in a cost-effective manner.  &#xa;&#xa;Iterative Refinement (Prochemy): The "Prompt Alchemy" (Prochemy) method provides an "innovative method for automatically refining prompts to boost code generation". This system operates by iteratively refining prompts based on the model's actual performance on specific tasks. This automated optimization ensures consistency and has demonstrated substantial performance gains, such as a 5.0% improvement for GPT-3.5-Turbo on HumanEval and a 12.9% improvement for GPT-4o on Java-to-Python code translation tasks.  &#xa;&#xa;Adaptive Selection (PET-Select): Recognizing that "no single approach is universally optimal" , the PET-Select framework introduces a critical meta-layer. This "PET-agnostic selection model" classifies the complexity of an incoming query, using code complexity as a proxy. It then selects the most appropriate prompt engineering technique (PET) for that specific query, such as a simple zero-shot prompt for a simple query or a complex multi-stage reasoning prompt for a difficult one. This automated, adaptive selection process has been shown to improve pass@1 accuracy by up to 1.9% while simultaneously achieving a 74.8% reduction in token usage.  &#xa;&#xa;The clear progression in this domain is from a human-centric "prompt engineering" phase to a machine-centric "prompt optimization" phase. The AI is no longer just the executor of the instruction; it is becoming the refiner of the instruction itself. These systems (EPiC, Prochemy) are, however, reactive. They optimize a prompt for a known task and a known solution space (e.g., passing a specific benchmark). They do not yet proactively generate a novel prompt architecture for a novel, undiscovered problem. This points toward an unexploited vector: a system that can discover a new problem (e.g., from user feedback) and then author its own prompt architecture to solve it, a concept related to meta-prompting.  &#xa;&#xa;2. Test-Driven Development (TDD) as a Prompting Paradigm&#xa;Arguably the most powerful and reliable pattern for high-quality code generation is the integration of Test-Driven Development (TDD) principles directly into the prompt architecture. TDD is an "incremental software development methodology that focuses on creating tests before the implementation". When applied to LLMs, the test suite becomes the specification.  &#xa;&#xa;Core Principle: Instead of relying on ambiguous natural language, the prompt provides the LLM with a concrete set of unit tests and instructs it to "write code to pass all tests". This pattern's success hinges on "instruction following and in-context learning," which have been identified as more "critical capabilities for TDD success" than general coding proficiency or pre-training knowledge. The tests are the ultimate instruction.  &#xa;&#xa;Frameworks: Systems are being designed to formalize this. The TGEN framework, for example, utilizes "Specialized agents" that accept two primary inputs: the "programming prompt" (a short description) and "the tests" (unit tests and required signatures). These are then processed by the LLM engine to produce validated code.  &#xa;&#xa;Prompt Structure: This paradigm fundamentally changes the structure of the prompt. The request is no longer a simple "what," but a highly constrained "how." A common elite-level TDD prompt includes a strict set of rules: "1. Write a single Python function that passes all the provided tests. 2. Use type hints for parameters and return values. 3....Follow Python best practices and PEP 8... 4. Ensure the function handles all edge cases and scenarios covered in the tests. 5. Provide only the function definition and its implementation, nothing else".  &#xa;&#xa;This TDD-as-prompt pattern provides an objective, verifiable measure of "correctness" that is far superior to ambiguous natural language requests. It successfully shifts the burden of human effort from describing the code to defining its behavior through tests. This is a crucial move from semantic validation (is the code "good"?) to functional validation (does the code work?). The next logical step, and the key unexploited vector, is to close the loop: to create a system that not only generates code from tests but also generates its own tests and validates its own code in a continuous cycle.&#xa;&#xa;3. Self-Validation and "Error-Forward" Debugging&#xa;This pattern extends the TDD loop into a dynamic, autonomous process. For an agent to be truly autonomous, it must be able to recognize, diagnose, and recover from its own errors.&#xa;&#xa;Self-Validation: SOTA agentic systems are designed to "regularly verify progress and self-assess correctness". This "agentic self-validation" is a core capability that "drives up accuracy". For example, agents from Cognition, running on models like Claude Sonnet 4.5, are noted to "excel at testing its own code, enabling Devin to run longer, handle harder tasks, and deliver production-ready code". This integration of TDD into an autonomous agent allows it to "go through several improvement cycles on its own instead of having to manually ask the AI to fix test failures".  &#xa;&#xa;"Error-Forward Prompting": This is the primary recovery mechanism within the self-validation loop. This technique treats errors as data, not as failures. When an agent's self-validation fails, the system automatically "collects relevant context, including the error message, stack trace, and cell location". This information is then formatted and "provided to the agent as the initial context for beginning the debugging process".  &#xa;&#xa;Reflection: This is the learning mechanism that makes the recovery effective. A "reflection system enables the agent to learn from its actions and improve its debugging strategy". Implemented via "reflective prompting" , this allows the model to "analyze and refine its outputs". The model first generates a solution, then "through subsequent prompts, critiques its own reasoning to identify and correct errors". This is formalized in techniques like Self-Refine, which mimics the human "draft, review, refine" process.  &#xa;&#xa;In this paradigm, failure is no longer an end-state; it is a high-value data signal. The stack trace becomes the most valuable part of the prompt—a pure, unambiguous instruction set for what must be fixed. When TDD-as-prompt (I.A.2) is combined with this self-validation and reflection loop (I.A.3), the system becomes "self-healing". The prompt is no longer a single-shot instruction but the initiation of a self-sustaining process. The agent's goal is elevated from "generate code" to "make the build pass," a critical step toward true autonomy.  &#xa;&#xa;4. Agentic Frameworks and Multi-Agent Collaboration&#xa;Complex software development cannot be solved in a single step or by a single-minded agent. The recognition that single-shot prompts "yield imprecise or plain incorrect results" for elaborate tasks has led to the rise of sophisticated agentic frameworks.  &#xa;&#xa;Advanced Reasoning Patterns: These frameworks are built upon reasoning patterns far more advanced than simple Chain-of-Thought (CoT).  &#xa;&#xa;ReAct: This pattern combines "Reason and Act" , allowing the agent to interleave step-by-step reasoning with tool use to gather external information or perform actions.  &#xa;&#xa;Tree of Thoughts (ToT): This pattern moves beyond the linear path of CoT. It allows an agent to "breakdown intermediate processed into steps," generate "various generated states," and "evaluate" those states to "determine which branch to explore next".  &#xa;&#xa;Graph of Thoughts (GoT): The current SOTA in reasoning, GoT generalizes ToT into a full graph structure. This "enables combining arbitrary LLM thoughts into synergistic outcomes" and, critically, "enhancing thoughts using feedback loops". GoT has been shown to increase the quality of sorting by 62% over ToT while reducing costs.  &#xa;&#xa;Agentic Frameworks: These reasoning patterns are orchestrated by multi-agent frameworks.  &#xa;&#xa;MetaGPT: This framework simulates a "real-world software company." It assigns agents specific roles like "product manager, software architect, programmer, or QA tester" and embeds them with "Standard Operating Procedures (SOPs)".  &#xa;&#xa;ChatDev: This framework utilizes a "waterfall-style" collaboration, where agents engage in "task-oriented and multi-turn communications" to iteratively refine solutions.  &#xa;&#xa;Purpose: These frameworks are essential as they provide a "shared philosophy of control &amp; reasoning". Without this, agentic systems suffer from "loss of control clarity of flow" and "unbounded complexity growth" as new agents are added.  &#xa;&#xa;Benchmarks: These agentic systems are what achieve top scores on complex, real-world benchmarks that measure engineering capability. The SWE-bench benchmark, for instance, measures "an AI model's ability to solve real-world software issues". SOTA models achieve high scores on SWE-bench and OSWorld precisely by using these agentic, self-testing architectures.  &#xa;&#xa;The atomic unit of these powerful frameworks is role-based prompting. The frameworks themselves (MetaGPT, ChatDev) are, in essence, prompt-driven state machines. A high-level "meta-prompt" defines the agents, their roles, their tools, and their communication protocols. The LLM is thus demoted from "solution generator" to a component—a "reasoning engine" that navigates this pre-defined architecture. The architecture itself has become the prompt. The current limitation, and the unexplored vector, is that these frameworks are simulations of human workflow (e.g., "waterfall," "software company"). An AI-native workflow, where feedback comes not from a "QA Agent" but from the product itself via live user telemetry, would be fundamentally more efficient.  &#xa;&#xa;5. Context-Aware Generation (Agentic RAG)&#xa;Code generation is useless without domain context. Retrieval-Augmented Generation (RAG) is the primary pattern for providing this context, and its agentic form is the SOTA.  &#xa;&#xa;RAG-for-Code: This pattern gives an AI assistant "a direct line to your team's collective knowledge". The prompt is "augmented" with relevant information retrieved from "documentation, code repositories, or even Stack Overflow discussions". This ensures the generated response is "context-aware" and relevant to the specific codebase it is intended for.  &#xa;&#xa;Agentic RAG: This is the "evolution from traditional single-query RAG". Instead of being a passive recipient of retrieved context, the agent actively forages for it. It performs "context-aware query planning," can issue "parallel execution of multiple focused subqueries," and then synthesizes the results to build a comprehensive understanding. This is the approach used by modern agentic frameworks like LangGraph , AutoGen , and those from Amazon and Microsoft.  &#xa;&#xa;The RAG-for-Code pattern transforms a "general-purpose coder" into a "domain-specific engineer" who understands the nuances of a particular project. The agentic aspect is the critical differentiator; it is the difference between giving a developer a 500-page manual (standard RAG) and the developer knowing which three pages to read (Agentic RAG). The most potent, but not yet fully exploited, vector in code generation is the fusion of this Agentic RAG (for context) with the TDD-as-Prompt paradigm (for verification). An agent that can retrieve context from a 500,000-line codebase and validate its changes against that codebase's test suite is the difference between a "coding assistant" and an "autonomous developer." This fusion is the core of the novel Test-Driven Agent (TDA) architecture proposed in Part II.  &#xa;&#xa;Domain 2: Architectures for User Delight &amp; UI Design&#xa;In the second domain, UI generation, the mandate for "user delight" requires moving beyond simple wireframe generation. Elite-tier prompts in this space are not about "generating pixels" but about "generating experiences" grounded in human-centric principles.&#xa;&#xa;1. Persona-Driven Design: Grounding the Generation&#xa;"User delight" is the "positive emotional response users feel when a product doesn't just meet their needs but goes above and beyond". This state is "highly contextual" and cannot be achieved without first defining the user.  &#xa;&#xa;Pattern: Elite prompts for UI design do not begin with the interface; they begin with the user. The system is first prompted to generate a detailed proto-persona. This persona includes demographic details, "target users, their core pain points, and daily use context" , as well as deeper "Motivations" and "Affinities".  &#xa;&#xa;Application: This generated persona (or a human-provided one) is then injected as a primary constraint into all subsequent UI generation prompts. This allows the AI to "cater to Gen Z and Gen X users" differently, tailoring the design, tone, and complexity to a specific audience. The prompt is no longer "generate a wireframe for a music app" but "generate a wireframe for a music app for this specific persona , focusing on their stated pain point of {pain_point}."  &#xa;&#xa;This persona-driven pattern acts as a powerful constraint on the model's vast solution space, forcing it to move from generating a generic "good UI" to a UI that is "good for this specific user." It is, in effect, a form of in-context learning for design, where the persona serves as a "one-shot" example of the target user. The major limitation, and the unexploited vector, is that this is a static process. The persona is an assumption created at the beginning of the design process. The clear next step is to move from these static, assumed personas to dynamic, observed user models that are continuously updated based on real-time behavioral analytics.  &#xa;&#xa;2. Constraint-Based Generation: Defining the "Solution Space"&#xa;The highest-fidelity UI generation requires the application of multiple, layered constraints. These constraints are the specifications that ensure the output is not just creative, but also functional, accessible, and grounded in established design theory. These constraints fall into three primary categories.&#xa;&#xa;A. Cognitive &amp; Heuristic Constraints&#xa;This is the most sophisticated pattern for achieving true "user delight." The prompt explicitly instructs the AI to apply principles from cognitive science and established usability heuristics, forcing the AI to design for the human mind.  &#xa;&#xa;Heuristics: The most common pattern is to prompt the AI to act as a UX expert and evaluate or generate a design based on "Nielsen's 10 Usability Heuristics" or other well-known variants like Shneiderman's "Eight Golden Rules" or Weinschenk and Barker's "20 Usability Heuristics".  &#xa;&#xa;Cognitive Principles: More advanced prompts instruct the AI to directly apply specific cognitive laws. Examples include:&#xa;&#xa;Fitts's Law: Prompting the AI to make "important buttons and interactive elements larger and closer to where users naturally focus".  &#xa;&#xa;Hick's Law: Instructing the AI to "reduc[e] the number of options or organiz[e] them into categories" to speed up decision-making.  &#xa;&#xa;Cognitive Load: Prompting with the explicit goal of "reducing cognitive load" to create a more effortless experience.  &#xa;&#xa;Behavioral Models: The most advanced prompts use frameworks like BJ Fogg's Behavior Model (B=MAP: Motivation, Ability, Prompt) or Nir Eyal's "Hooked" model to design persuasive or habit-forming interfaces.  &#xa;&#xa;Prompting with "Nielsen's Heuristics" or "Fogg's Behavior Model" acts as a domain-specific Chain-of-Thought. It forces the AI to justify its design choices ("This button is large and placed in the bottom-right corner because it adheres to Fitts's Law"), leading to more principled, defensible, and ultimately delightful designs.  &#xa;&#xa;B. Technical &amp; Accessibility (A11y) Constraints&#xa;There is no "delight" in an interface that is unusable for a portion of the population. Elite prompts must enforce technical constraints, with accessibility (A11y) being paramount.&#xa;&#xa;Pattern: The prompt must explicitly instruct the AI to be "fully compliant with WCAG 2.2 AA". Research shows that without this explicit instruction, AI-generated components are "consistently" inaccessible.  &#xa;&#xa;Specifics: A high-quality A11y prompt enforces:&#xa;&#xa;Semantic HTML: "Ensure the proper use of HTML5 elements (like , , )".  &#xa;&#xa;Keyboard Accessibility: "Test navigation using only Tab, Shift+Tab, and Enter keys. All interactive elements should be reachable".  &#xa;&#xa;ARIA (Accessible Rich Internet Applications): Correct application of "ARIA landmarks and roles" , which are "HTML attributes that add semantic meaning... for assistive technologies".  &#xa;&#xa;Clear Content: "Use clear language... Write descriptive links: Swap vague text like 'click here' for something meaningful".  &#xa;&#xa;This pattern is the UI-domain equivalent of TDD (I.A.2). The prompt includes the acceptance criteria (WCAG). This "specification-as-prompt" is critical for generating production-ready, non-discriminatory interfaces.&#xa;&#xa;C. Structural &amp; Layout Constraints&#xa;To control the form of the output and ensure it is machine-readable and programmatically useful, prompts must define a reliable structure.&#xa;&#xa;Architecture &amp; Flows: For high-level system design, prompts specify formats like the C4 model rendered in Mermaid code. For user flows, Mermaid sequence diagrams are the standard.  &#xa;&#xa;Wireframes: Simple wireframe prompts use text descriptions, such as, "Include a header with a logo, search bar, featured destinations section, and a bottom navigation bar".  &#xa;&#xa;SOTA (Structured Data): The most robust and programmatically valuable pattern is to force the LLM to output a structured data format like JSON or YAML. This is achieved by providing an output schema to the model. This pattern is now natively supported by major model providers, who allow schemas to be defined using libraries like Pydantic (for Python) or Zod (for TypeScript). This guarantees the output is not just text, but a "type safety and consistent structure".  &#xa;&#xa;This structured output pattern is the critical link between the two domains of this report. If a UI can be described in a reliable JSON schema, and a backend can expose its API in a reliable JSON schema (e.g., an OpenAPI specification), an agent can connect them. This structured output is the "API" between a UI-generation agent and a code-generation agent.&#xa;&#xa;3. Generative UI (GenUI): The Emergent Paradigm&#xa;This is the bleeding-edge concept that underpins the entire future of UI design. Generative UI (GenUI) is a new paradigm that "enables adaptive, goal-driven interactions". Instead of a static interface designed by a human and then coded, the UI is generated in real-time by the AI.  &#xa;&#xa;Mechanism: In this paradigm, the AI generates "interactive widgets for fine-grained prompt control" or entire "high-fidelity UI mock-up screens from a high-level textual description". This process is not one-shot; it is an iterative, "co-creative process" between the human and the AI, involving "AI-assisted refinement strategies".  &#xa;&#xa;Current State: GenUI is currently being adopted by UX practitioners as a tool to accelerate their workflow. The human remains the curator and refiner of the AI-generated output.  &#xa;&#xa;GenUI is the logical evolution of prompt-based wireframing. The current limitation, and the key unexploited vector, is the human-in-the-loop for optimization. The UI is refined based on a designer's "vibe" or explicit follow-up prompts. The unexploited opportunity is to remove the human curator from the optimization loop. A system that could refine its own GenUI, not based on a designer's commands, but based on live user data, would represent a paradigm shift. This is the core concept of a "Self-Optimizing UI" and forms the foundation for the novel Cognitive-Adaptive Interface (CAI) architecture.  &#xa;&#xa;Synthesis of Novel Prompt Architectures: Exceeding Current Benchmarks&#xa;The preceding analysis deconstructed the current SOTA, revealing a set of unexploited capability vectors. The following synthesis moves beyond replicating these patterns. It proposes three novel, high-level architectures that fuse these vectors to create self-regulating, self-optimizing systems designed to exceed current benchmarks. These architectures treat the prompt not as a static, one-time instruction, but as a "bootloader" for a continuous, autonomous process.&#xa;&#xa;Table 1: Comparative Analysis of Generation &amp; Reasoning Architectures&#xa;&#xa;Architecture	Core Mechanism	Interaction Model	Key Limitation (Vector Not Exploited)	Unlocked Capability Vector&#xa;Chain-of-Thought (CoT)&#xa;&#xa;Step-by-step reasoning (e.g., "Let's think step-by-step").	Static	Brittle, linear reasoning; no external validation or tool use.	Basic multi-step problem solving.&#xa;ReAct&#xa;&#xa;Interleaves reasoning (CoT) with tool use (Actions).	Iterative	Dependent on pre-defined tools; no long-term memory or structured collaboration.	Environment-aware task execution.&#xa;Graph of Thoughts (GoT)&#xa;&#xa;Models reasoning as a graph, allowing merging of states and feedback loops.	Iterative	High conceptual complexity; primarily focused on reasoning, not execution.	Advanced, non-linear problem-solving.&#xa;TDD-as-Prompt&#xa;&#xa;A test suite is provided as the functional specification for code generation.	Static	Requires human to write all tests; no self-correction loop.	Verifiable, high-reliability code generation.&#xa;Generative UI (GenUI)&#xa;&#xa;AI generates high-fidelity UI mockups or interactive widgets from text descriptions.	Iterative	Requires human-in-the-loop for curation and refinement; based on assumed user needs.	Rapid, co-creative UI prototyping.&#xa;[NOVEL] Cognitive-Adaptive Interface (CAI) Engine	&#xa;GenUI + Cognitive Fitness Function + Live User Telemetry.&#xa;&#xa;Dynamic-Adaptive	N/A (Synthesized Architecture)	Real-time UI self-optimization based on observed user cognitive state.&#xa;[NOVEL] Test-Driven Agent (TDA) Framework	&#xa;Closed-loop TDD + Agentic RAG + Error-Forward Self-Healing.&#xa;&#xa;Autonomous-Iterative	N/A (Synthesized Architecture)	Verifiable, context-aware, autonomous development with guaranteed build integrity.&#xa;[NOVEL] Self-Optimizing Product (SOP) Loop	&#xa;TDA-CAI integration via an RLHF-from-Telemetry feedback loop.&#xa;&#xa;Autonomous-Holistic	N/A (Synthesized Architecture)	Fully autonomous product self-improvement driven by implicit user feedback.&#xa; &#xa;Proposed Architecture 1: The "Cognitive-Adaptive Interface" (CAI) Engine&#xa;This architecture synthesizes Generative UI (GenUI) with persona-driven design and, most critically, cognitive-heuristic constraints. It is designed to move UI generation from a static, one-shot process ("generate a wireframe") to a continuous, adaptive, and self-optimizing one.  &#xa;&#xa;Vector Exploited: This architecture directly targets the vector identified in (I.B.1) and (I.B.3): the fusion of Generative UI with real-time user telemetry. The system does not just generate a UI; it optimizes it in real-time based on observed user behavior.  &#xa;&#xa;Mechanism: The CAI Engine operates as a continuous four-phase loop:&#xa;&#xa;Phase 1: The "Cognitive Metaprompt". The architect does not prompt for a specific layout. Instead, they provide a high-level, structured (e.g., YAML) prompt that defines the goals and constraints. This metaprompt specifies:&#xa;&#xa;target_persona: The ground-truth user archetype.  &#xa;&#xa;business_objective: The high-level optimization target (e.g., "maximize conversion," "minimize time-to-task," "maximize user delight").&#xa;&#xa;cognitive_fitness_function: A weighted list of cognitive and behavioral principles that will be used to score the UI's performance. For example: weights: {cognitive_load: -0.5, fitts_law_compliance: +0.3, hick's_law_compliance: -0.2, wcag_aa_compliance: 1.0}.  &#xa;&#xa;Phase 2: Initial Generation. The CAI engine uses this metaprompt to generate the initial UI component tree. This output is a structured JSON artifact, not just a static image. The engine's initial design is its best hypothesis for satisfying the cognitive_fitness_function for the given target_persona.&#xa;&#xa;Phase 3: The Telemetry Loop. This is the critical connection to the real world. As users interact with this dynamically-rendered GenUI, the system collects fine-grained, real-time telemetry. This data includes not just basic "clickstream data" but also proxies for cognitive state: hesitation time (cognitive load), rage clicks (frustration), scroll depth (engagement), and form drop-off points.  &#xa;&#xa;Phase 4: Autonomous Optimization. This telemetry stream is fed back into the CAI engine. The engine scores the current UI's performance against the cognitive_fitness_function. It then begins a continuous, "self-optimizing" process, autonomously running micro-A/B tests or other reinforcement learning strategies to adapt the UI. For example, it might log: "Hypothesis: Moving 'Add to Cart' button 10px closer to the product image will improve the Fitts's Law component of the fitness function. Result: Target acquisition speed improved by 80ms and conversion metric increased by 0.2%. This change is now permanent for this user segment."  &#xa;&#xa;Exceeding the Benchmark: This architecture creates a true "Self-Optimizing UI". The prompt is no longer a blueprint for a static house; it is the DNA for a living organism that adapts to its environment (the user) in real-time. This moves beyond static, assumed personas to build an interface that dynamically aligns with the observed cognitive and behavioral patterns of its actual users.  &#xa;&#xa;Proposed Architecture 2: The "Test-Driven Agent" (TDA) Framework&#xa;This architecture synthesizes the most robust patterns from the code construction domain: TDD-as-Prompt (I.A.2), Self-Validation (I.A.3), and Agentic RAG (I.A.5). It creates a closed-loop, "self-healing" system designed to enable verifiable, autonomous development at the repository level.  &#xa;&#xa;Vector Exploited: This architecture exploits the vector identified in (I.A.5): the fusion of autonomous, closed-loop TDD with context-aware Agentic RAG . The agent's output is not "code"; it is a "passing build."  &#xa;&#xa;Mechanism: The TDA Framework operates as a five-phase, autonomous workflow:&#xa;&#xa;Phase 1: The "User Story Metaprompt". The human (or another agent) provides a high-level feature request in a structured format (e.g., JSON). This prompt defines the goal, not the implementation. Example: {"user_story": "As a user, I want to reset my password via email.", "acceptance_criteria": ["Must handle invalid emails", "Must send a tokenized link"]}.&#xa;&#xa;Phase 2: RAG-Context. The TDA's first action is not to code. It is to read. It activates its Agentic RAG module to perform "context-aware query planning". It queries the entire codebase and documentation to understand the existing system. (e.g., "Query: 'auth routes'", "Query: 'email service'", "Query: 'database schema for users'").  &#xa;&#xa;Phase 3: Test Generation (Red). Armed with this context, the TDA first generates a new, failing unit test (e.g., test_post_forgot_password_invalid_email_404). This step, based on the TDD-as-prompt paradigm , codifies the acceptance_criteria from the metaprompt into a verifiable, functional validation.  &#xa;&#xa;Phase 4: Code Generation (Green). The agent now generates the minimal amount of implementation code (a new route, a new service function) required to make the new test pass.  &#xa;&#xa;Phase 5: Reflect &amp; Refactor (Self-Healing). The TDA does not stop. It now runs the entire test suite. If an old test fails (a regression), it enters a "self-healing" loop. It uses the "Error-Forward Prompt" pattern (I.A.3), feeding the new stack trace back to itself. It then reflects and iterates on the code until the full build is green.  &#xa;&#xa;Exceeding the Benchmark: This architecture moves beyond task-oriented benchmarks like SWE-bench. The TDA's output is not "a code snippet that solves a problem"; it is a passing, context-aware, and regression-free build. This builds the trust required for true "agentic software engineering" by producing verifiable, reliable, and autonomous results that can be directly committed to a main branch.  &#xa;&#xa;The Unified Synthesis: The "Self-Optimizing Product" (SOP) Loop&#xa;This is the final, unified architecture. It bridges the two domains by connecting the TDA (backend code) and the CAI (frontend UI) into a single, product-level optimization loop. This system is designed to autonomously improve the entire product—both its functionality and its interface—based on user interaction.&#xa;&#xa;Vector Exploited: This architecture exploits the most potent "unexplored vector": connecting the CAI (UI) and TDA (Code) architectures via a shared feedback loop that uses Reinforcement Learning from Human Feedback (RLHF) . In this paradigm, the "human feedback" is not explicit (like a button click); it is the implicit behavioral telemetry collected from the CAI, which is then used to train a reward model and guide the policy of the entire system.  &#xa;&#xa;Mechanism (The Full Loop):&#xa;&#xa;Deploy: The TDA (Architecture 2) generates and deploys the backend API_v1 (e.g., POST /api/security-question). The CAI (Architecture 1) generates the frontend UI to consume it, governed by its cognitive_fitness_function.&#xa;&#xa;Observe (Telemetry): The CAI's telemetry loop observes a "user delight" failure. It logs: "70% of users drop off at the 'Security Question' form. Average hesitation time is 12 seconds. This violates the cognitive_load component of our fitness function."  &#xa;&#xa;Translate (Feedback Agent): This telemetry is fed into a new, specialized "Feedback Agent." This agent, part of a "Closed Learning Feedback Loop" , is a reasoning agent (using GoT ). Its sole purpose is to translate this quantitative behavioral data into a new product requirement. It autonomously generates a new User Story Metaprompt using meta-prompting techniques : {"user_story": "The 'Security Question' flow causes high friction (70% drop-off). Replace it with a 'Magic Link' email workflow.", "acceptance_criteria": [...]}.  &#xa;&#xa;Trigger (TDA): This new user story is automatically fed as an Init-Prompt to the TDA (Architecture 2).&#xa;&#xa;Heal &amp; Evolve (TDA): The TDA springs into action. It RAGs the codebase , writes new failing tests for the 'Magic Link' flow , generates the new API_v2 endpoints, and (critically) writes and deploys a migration to deprecate API_v1.  &#xa;&#xa;Adapt (CAI): The TDA's deployment (or an event-driven hook) triggers the CAI. The CAI, now aware of the new API_v2 and the deprecation of API_v1, re-generates its UI components to consume the new, "healed" workflow, automatically adapting the interface to the new, lower-friction flow.&#xa;&#xa;Exceeding the Benchmark: The loop is complete. The product itself (code + UI) just autonomously optimized its own design to improve "user delight," with no human intervention. This is the new benchmark. The "prompt" is no longer a static, human instruction; it is a continuous, self-generated feedback signal originating from the user's own behavior.&#xa;&#xa;Strategic Implementation and Future Trajectories&#xa;The architectures proposed in Part II are not theoretical. They can be implemented by moving from natural language prompts to structured metaprompts that act as the bootloaders and configuration files for these autonomous systems.&#xa;&#xa;Actionable Blueprints: Structured Metaprompts as the System API&#xa;To make these architectures concrete, we must define their initialization. These are meta-prompts that initialize and constrain the autonomous systems.  &#xa;&#xa;The most critical pattern for SOTA systems is the use of structured (not natural language) prompts, as this ensures reliable, machine-parseable interaction between agents. YAML is used for its human-readability in top-level configuration , while schema-enforced JSON (using Pydantic/Zod ) serves as the non-negotiable "API" for inter-agent communication.  &#xa;&#xa;Example Blueprint 1: YAML Metaprompt for the CAI Engine&#xa;This YAML file is the master-prompt for the Cognitive-Adaptive Interface (CAI) Engine. It defines the purpose and constraints of the UI, not its specific layout.&#xa;&#xa;# This YAML file is the master-prompt for the Cognitive-Adaptive Interface (CAI) Engine.&#xa;# It defines the *purpose* and *constraints* of the UI.&#xa;&#xa;system_role: "You are a CAI (Cognitive-Adaptive Interface) Engine. Your goal is to generate and continuously optimize a user interface to maximize the 'objective' by adhering to the 'fitness_function'."&#xa;&#xa;objective:&#xa;  type: "maximize_conversion"&#xa;  target_metric: "checkout_completion_rate"&#xa;  &#xa;target_persona:&#xa;  # This persona  will be used to generate the initial UI.&#xa;  file: "./personas/busy_professional_mobile.json" &#xa;  &#xa;technical_constraints:&#xa;  # Non-negotiable acceptance criteria &#xa;  - "WCAG_2_2_AA_COMPLIANT"&#xa;  - "OUTPUT_FORMAT_SEMANTIC_HTML_WITH_ARIA" [71, 72]&#xa;  - "MAX_LOAD_TIME_MS_3G: 1500"&#xa;  &#xa;cognitive_fitness_function:&#xa;  # The core of the CAI. The engine will score its own UI against these&#xa;  # principles  using live telemetry.&#xa;  - principle: "cognitive_load" # &#xa;    weight: -0.5 # (Minimize)&#xa;    metric: "avg_task_hesitation_time_sec"&#xa;    &#xa;  - principle: "hick's_law" # &#xa;    weight: -0.3 # (Minimize choices)&#xa;    metric: "choice_count_per_screen"&#xa;&#xa;  - principle: "fitts_s_law_compliance" # &#xa;    weight: 0.3 # (Maximize)&#xa;    metric: "target_acquisition_speed_ms"&#xa;    &#xa;  - principle: "nielsen_heuristic_4_consistency" # &#xa;    weight: 0.2 # (Maximize)&#xa;    metric: "component_reuse_score"&#xa;Example Blueprint 2: JSON Metaprompt for the TDA Framework&#xa;This JSON object is the "Init-Prompt" for the Test-Driven Agent (TDA). It is generated by the "Feedback Agent" (II.C) after translating a telemetry-detected user problem.&#xa;&#xa;/*&#xa;  This JSON object is the "Init-Prompt" for the Test-Driven Agent (TDA).&#xa;  It is generated by the "Feedback Agent" [II.C] from user telemetry.&#xa;*/&#xa;{&#xa;  "system_role": "You are a TDA (Test-Driven Agent). You must generate code that passes all tests. You must write failing tests first.",&#xa;  "task_id": "TDA-1138",&#xa;  "source_trigger": "SOP_Feedback_Agent_Telemetry_Violation_cognitive_load",&#xa;  "user_story": "The 'Security Question' flow (API_v1) causes high user friction (70% drop-off). You must replace it with a 'Magic Link' email workflow (API_v2).",&#xa;  "rag_context_queries":&#xa;    "Retrieve file:./routes/auth.js",&#xa;    "Retrieve file:./services/EmailService.js",&#xa;    "Retrieve file:./models/User.js",&#xa;    "Retrieve related tests: test_auth.py"&#xa;  ],&#xa;  "acceptance_criteria":&#xa;    "POST /api/v2/magic-link must accept an 'email'.",&#xa;    "Must return 404 if email does not exist.",&#xa;    "Must return 200 and trigger EmailService.sendMagicLink on success.",&#xa;    "Must generate a unique, single-use token with a 15-minute expiry.",&#xa;    "Must create a new failing test for 'token_expired' scenario."&#xa;  ]&#xa;}&#xa;Future Capability Vectors &amp; Redefining Benchmarks&#xa;The user's final mandate is to "exceed current benchmarks." The SOP architecture, if implemented, renders current benchmarks obsolete.&#xa;&#xa;Current Benchmarks: Benchmarks like HumanEval and SWE-bench are task-oriented and static. They are critical for measuring an agent's ability to solve a given, siloed problem (e.g., "Fix this bug from this GitHub issue"). However, they do not measure the agent's ability to identify the problem or validate its solution against holistic user-centric goals.  &#xa;&#xa;The New Benchmark: The SOP architecture (II.C) operates at the product level. The new benchmark should not be "Can the AI solve a GitHub issue?" It must be "Can the AI identify, validate, and solve a user-delight issue autonomously from raw telemetry?"&#xa;&#xa;Proposed New Benchmark: "Product-Bench"&#xa;&#xa;Given: A high-level product goal (e.g., "build a photo-sharing app") and a cognitive_fitness_function (as defined in III.A).&#xa;&#xa;Input: A stream of (simulated) user telemetry, representing a diverse set of user interactions over time.&#xa;&#xa;Task: The AI system (SOP) must:&#xa;&#xa;(a) Build the V1 of the product (TDA + CAI).&#xa;&#xa;(b) Autonomously evolve its features, code, and UI over 1 million simulated user-sessions in response to the telemetry stream.&#xa;&#xa;Metric: The final score is the system's ability to maximize the cognitive_fitness_function (e.g., a composite "User Delight" score based on retention, engagement, and cognitive load reduction) over the duration of the simulation.&#xa;&#xa;This new benchmark aligns with the future of HCI and AI, which is moving toward human-AI co-creation , AI-augmented reasoning , and human-centered evaluation. The ultimate prompt architecture is one that creates its own prompts based on its core purpose and its continuous, real-time interaction with the world. This is the new, and achievable, benchmark for excellence.  </title></path></g><g><g><title>&#xa;Novel Prompt Architectures for AI&#xa;From Static Prompts to Dynamic Architectures: Synthesizing Self-Optimizing Systems for Code and Interface Generation&#xa;Deconstruction of Elite-Tier Prompt Patterns: The Current Benchmark&#xa;The effective use of Large Language Models (LLMs) has evolved significantly from simple, single-turn instructions to complex, multi-stage prompt architectures. This evolution is most pronounced in the technical domains of software engineering and user interface (UI) design. An analysis of current elite-tier patterns reveals a clear trajectory: a shift away from static, human-authored instructions and toward dynamic, machine-optimized, and process-oriented systems.&#xa;&#xa;This section deconstructs the state-of-the-art (SOTA) patterns in these two domains to establish the foundational benchmarks and identify the capability vectors that remain unexploited.&#xa;&#xa;Domain 1: Architectures for Efficient Code Construction&#xa;In software engineering, the objective has shifted from merely generating code snippets to engineering reliable, context-aware, and autonomous systems. The most successful patterns treat the LLM not as a simple code generator, but as a reasoning engine to be embedded within a larger, more structured development framework.&#xa;&#xa;1. Automated Prompt Optimization: The "Prompt-as-a-Target" Pattern&#xa;The manual, iterative refinement of prompts for code generation is widely recognized as a "time-consuming and inconsistent" bottleneck. The SOTA has moved to automate this process, treating the prompt itself as an artifact to be optimized.  &#xa;&#xa;Evolutionary-Based Methods (EPiC): The EPiC (Evolutionary Prompt Engineering for Code) framework is a novel approach that explores code generation from a cost-effectiveness perspective. It "leverages a lightweight evolutionary algorithm to evolve the original prompts toward better ones that produce high-quality code". By employing mutation operators on the text of the prompt and guiding the search with a fitness function, EPiC automates the discovery of an optimal solution in a cost-effective manner.  &#xa;&#xa;Iterative Refinement (Prochemy): The "Prompt Alchemy" (Prochemy) method provides an "innovative method for automatically refining prompts to boost code generation". This system operates by iteratively refining prompts based on the model's actual performance on specific tasks. This automated optimization ensures consistency and has demonstrated substantial performance gains, such as a 5.0% improvement for GPT-3.5-Turbo on HumanEval and a 12.9% improvement for GPT-4o on Java-to-Python code translation tasks.  &#xa;&#xa;Adaptive Selection (PET-Select): Recognizing that "no single approach is universally optimal" , the PET-Select framework introduces a critical meta-layer. This "PET-agnostic selection model" classifies the complexity of an incoming query, using code complexity as a proxy. It then selects the most appropriate prompt engineering technique (PET) for that specific query, such as a simple zero-shot prompt for a simple query or a complex multi-stage reasoning prompt for a difficult one. This automated, adaptive selection process has been shown to improve pass@1 accuracy by up to 1.9% while simultaneously achieving a 74.8% reduction in token usage.  &#xa;&#xa;The clear progression in this domain is from a human-centric "prompt engineering" phase to a machine-centric "prompt optimization" phase. The AI is no longer just the executor of the instruction; it is becoming the refiner of the instruction itself. These systems (EPiC, Prochemy) are, however, reactive. They optimize a prompt for a known task and a known solution space (e.g., passing a specific benchmark). They do not yet proactively generate a novel prompt architecture for a novel, undiscovered problem. This points toward an unexploited vector: a system that can discover a new problem (e.g., from user feedback) and then author its own prompt architecture to solve it, a concept related to meta-prompting.  &#xa;&#xa;2. Test-Driven Development (TDD) as a Prompting Paradigm&#xa;Arguably the most powerful and reliable pattern for high-quality code generation is the integration of Test-Driven Development (TDD) principles directly into the prompt architecture. TDD is an "incremental software development methodology that focuses on creating tests before the implementation". When applied to LLMs, the test suite becomes the specification.  &#xa;&#xa;Core Principle: Instead of relying on ambiguous natural language, the prompt provides the LLM with a concrete set of unit tests and instructs it to "write code to pass all tests". This pattern's success hinges on "instruction following and in-context learning," which have been identified as more "critical capabilities for TDD success" than general coding proficiency or pre-training knowledge. The tests are the ultimate instruction.  &#xa;&#xa;Frameworks: Systems are being designed to formalize this. The TGEN framework, for example, utilizes "Specialized agents" that accept two primary inputs: the "programming prompt" (a short description) and "the tests" (unit tests and required signatures). These are then processed by the LLM engine to produce validated code.  &#xa;&#xa;Prompt Structure: This paradigm fundamentally changes the structure of the prompt. The request is no longer a simple "what," but a highly constrained "how." A common elite-level TDD prompt includes a strict set of rules: "1. Write a single Python function that passes all the provided tests. 2. Use type hints for parameters and return values. 3....Follow Python best practices and PEP 8... 4. Ensure the function handles all edge cases and scenarios covered in the tests. 5. Provide only the function definition and its implementation, nothing else".  &#xa;&#xa;This TDD-as-prompt pattern provides an objective, verifiable measure of "correctness" that is far superior to ambiguous natural language requests. It successfully shifts the burden of human effort from describing the code to defining its behavior through tests. This is a crucial move from semantic validation (is the code "good"?) to functional validation (does the code work?). The next logical step, and the key unexploited vector, is to close the loop: to create a system that not only generates code from tests but also generates its own tests and validates its own code in a continuous cycle.&#xa;&#xa;3. Self-Validation and "Error-Forward" Debugging&#xa;This pattern extends the TDD loop into a dynamic, autonomous process. For an agent to be truly autonomous, it must be able to recognize, diagnose, and recover from its own errors.&#xa;&#xa;Self-Validation: SOTA agentic systems are designed to "regularly verify progress and self-assess correctness". This "agentic self-validation" is a core capability that "drives up accuracy". For example, agents from Cognition, running on models like Claude Sonnet 4.5, are noted to "excel at testing its own code, enabling Devin to run longer, handle harder tasks, and deliver production-ready code". This integration of TDD into an autonomous agent allows it to "go through several improvement cycles on its own instead of having to manually ask the AI to fix test failures".  &#xa;&#xa;"Error-Forward Prompting": This is the primary recovery mechanism within the self-validation loop. This technique treats errors as data, not as failures. When an agent's self-validation fails, the system automatically "collects relevant context, including the error message, stack trace, and cell location". This information is then formatted and "provided to the agent as the initial context for beginning the debugging process".  &#xa;&#xa;Reflection: This is the learning mechanism that makes the recovery effective. A "reflection system enables the agent to learn from its actions and improve its debugging strategy". Implemented via "reflective prompting" , this allows the model to "analyze and refine its outputs". The model first generates a solution, then "through subsequent prompts, critiques its own reasoning to identify and correct errors". This is formalized in techniques like Self-Refine, which mimics the human "draft, review, refine" process.  &#xa;&#xa;In this paradigm, failure is no longer an end-state; it is a high-value data signal. The stack trace becomes the most valuable part of the prompt—a pure, unambiguous instruction set for what must be fixed. When TDD-as-prompt (I.A.2) is combined with this self-validation and reflection loop (I.A.3), the system becomes "self-healing". The prompt is no longer a single-shot instruction but the initiation of a self-sustaining process. The agent's goal is elevated from "generate code" to "make the build pass," a critical step toward true autonomy.  &#xa;&#xa;4. Agentic Frameworks and Multi-Agent Collaboration&#xa;Complex software development cannot be solved in a single step or by a single-minded agent. The recognition that single-shot prompts "yield imprecise or plain incorrect results" for elaborate tasks has led to the rise of sophisticated agentic frameworks.  &#xa;&#xa;Advanced Reasoning Patterns: These frameworks are built upon reasoning patterns far more advanced than simple Chain-of-Thought (CoT).  &#xa;&#xa;ReAct: This pattern combines "Reason and Act" , allowing the agent to interleave step-by-step reasoning with tool use to gather external information or perform actions.  &#xa;&#xa;Tree of Thoughts (ToT): This pattern moves beyond the linear path of CoT. It allows an agent to "breakdown intermediate processed into steps," generate "various generated states," and "evaluate" those states to "determine which branch to explore next".  &#xa;&#xa;Graph of Thoughts (GoT): The current SOTA in reasoning, GoT generalizes ToT into a full graph structure. This "enables combining arbitrary LLM thoughts into synergistic outcomes" and, critically, "enhancing thoughts using feedback loops". GoT has been shown to increase the quality of sorting by 62% over ToT while reducing costs.  &#xa;&#xa;Agentic Frameworks: These reasoning patterns are orchestrated by multi-agent frameworks.  &#xa;&#xa;MetaGPT: This framework simulates a "real-world software company." It assigns agents specific roles like "product manager, software architect, programmer, or QA tester" and embeds them with "Standard Operating Procedures (SOPs)".  &#xa;&#xa;ChatDev: This framework utilizes a "waterfall-style" collaboration, where agents engage in "task-oriented and multi-turn communications" to iteratively refine solutions.  &#xa;&#xa;Purpose: These frameworks are essential as they provide a "shared philosophy of control &amp; reasoning". Without this, agentic systems suffer from "loss of control clarity of flow" and "unbounded complexity growth" as new agents are added.  &#xa;&#xa;Benchmarks: These agentic systems are what achieve top scores on complex, real-world benchmarks that measure engineering capability. The SWE-bench benchmark, for instance, measures "an AI model's ability to solve real-world software issues". SOTA models achieve high scores on SWE-bench and OSWorld precisely by using these agentic, self-testing architectures.  &#xa;&#xa;The atomic unit of these powerful frameworks is role-based prompting. The frameworks themselves (MetaGPT, ChatDev) are, in essence, prompt-driven state machines. A high-level "meta-prompt" defines the agents, their roles, their tools, and their communication protocols. The LLM is thus demoted from "solution generator" to a component—a "reasoning engine" that navigates this pre-defined architecture. The architecture itself has become the prompt. The current limitation, and the unexplored vector, is that these frameworks are simulations of human workflow (e.g., "waterfall," "software company"). An AI-native workflow, where feedback comes not from a "QA Agent" but from the product itself via live user telemetry, would be fundamentally more efficient.  &#xa;&#xa;5. Context-Aware Generation (Agentic RAG)&#xa;Code generation is useless without domain context. Retrieval-Augmented Generation (RAG) is the primary pattern for providing this context, and its agentic form is the SOTA.  &#xa;&#xa;RAG-for-Code: This pattern gives an AI assistant "a direct line to your team's collective knowledge". The prompt is "augmented" with relevant information retrieved from "documentation, code repositories, or even Stack Overflow discussions". This ensures the generated response is "context-aware" and relevant to the specific codebase it is intended for.  &#xa;&#xa;Agentic RAG: This is the "evolution from traditional single-query RAG". Instead of being a passive recipient of retrieved context, the agent actively forages for it. It performs "context-aware query planning," can issue "parallel execution of multiple focused subqueries," and then synthesizes the results to build a comprehensive understanding. This is the approach used by modern agentic frameworks like LangGraph , AutoGen , and those from Amazon and Microsoft.  &#xa;&#xa;The RAG-for-Code pattern transforms a "general-purpose coder" into a "domain-specific engineer" who understands the nuances of a particular project. The agentic aspect is the critical differentiator; it is the difference between giving a developer a 500-page manual (standard RAG) and the developer knowing which three pages to read (Agentic RAG). The most potent, but not yet fully exploited, vector in code generation is the fusion of this Agentic RAG (for context) with the TDD-as-Prompt paradigm (for verification). An agent that can retrieve context from a 500,000-line codebase and validate its changes against that codebase's test suite is the difference between a "coding assistant" and an "autonomous developer." This fusion is the core of the novel Test-Driven Agent (TDA) architecture proposed in Part II.  &#xa;&#xa;Domain 2: Architectures for User Delight &amp; UI Design&#xa;In the second domain, UI generation, the mandate for "user delight" requires moving beyond simple wireframe generation. Elite-tier prompts in this space are not about "generating pixels" but about "generating experiences" grounded in human-centric principles.&#xa;&#xa;1. Persona-Driven Design: Grounding the Generation&#xa;"User delight" is the "positive emotional response users feel when a product doesn't just meet their needs but goes above and beyond". This state is "highly contextual" and cannot be achieved without first defining the user.  &#xa;&#xa;Pattern: Elite prompts for UI design do not begin with the interface; they begin with the user. The system is first prompted to generate a detailed proto-persona. This persona includes demographic details, "target users, their core pain points, and daily use context" , as well as deeper "Motivations" and "Affinities".  &#xa;&#xa;Application: This generated persona (or a human-provided one) is then injected as a primary constraint into all subsequent UI generation prompts. This allows the AI to "cater to Gen Z and Gen X users" differently, tailoring the design, tone, and complexity to a specific audience. The prompt is no longer "generate a wireframe for a music app" but "generate a wireframe for a music app for this specific persona , focusing on their stated pain point of {pain_point}."  &#xa;&#xa;This persona-driven pattern acts as a powerful constraint on the model's vast solution space, forcing it to move from generating a generic "good UI" to a UI that is "good for this specific user." It is, in effect, a form of in-context learning for design, where the persona serves as a "one-shot" example of the target user. The major limitation, and the unexploited vector, is that this is a static process. The persona is an assumption created at the beginning of the design process. The clear next step is to move from these static, assumed personas to dynamic, observed user models that are continuously updated based on real-time behavioral analytics.  &#xa;&#xa;2. Constraint-Based Generation: Defining the "Solution Space"&#xa;The highest-fidelity UI generation requires the application of multiple, layered constraints. These constraints are the specifications that ensure the output is not just creative, but also functional, accessible, and grounded in established design theory. These constraints fall into three primary categories.&#xa;&#xa;A. Cognitive &amp; Heuristic Constraints&#xa;This is the most sophisticated pattern for achieving true "user delight." The prompt explicitly instructs the AI to apply principles from cognitive science and established usability heuristics, forcing the AI to design for the human mind.  &#xa;&#xa;Heuristics: The most common pattern is to prompt the AI to act as a UX expert and evaluate or generate a design based on "Nielsen's 10 Usability Heuristics" or other well-known variants like Shneiderman's "Eight Golden Rules" or Weinschenk and Barker's "20 Usability Heuristics".  &#xa;&#xa;Cognitive Principles: More advanced prompts instruct the AI to directly apply specific cognitive laws. Examples include:&#xa;&#xa;Fitts's Law: Prompting the AI to make "important buttons and interactive elements larger and closer to where users naturally focus".  &#xa;&#xa;Hick's Law: Instructing the AI to "reduc[e] the number of options or organiz[e] them into categories" to speed up decision-making.  &#xa;&#xa;Cognitive Load: Prompting with the explicit goal of "reducing cognitive load" to create a more effortless experience.  &#xa;&#xa;Behavioral Models: The most advanced prompts use frameworks like BJ Fogg's Behavior Model (B=MAP: Motivation, Ability, Prompt) or Nir Eyal's "Hooked" model to design persuasive or habit-forming interfaces.  &#xa;&#xa;Prompting with "Nielsen's Heuristics" or "Fogg's Behavior Model" acts as a domain-specific Chain-of-Thought. It forces the AI to justify its design choices ("This button is large and placed in the bottom-right corner because it adheres to Fitts's Law"), leading to more principled, defensible, and ultimately delightful designs.  &#xa;&#xa;B. Technical &amp; Accessibility (A11y) Constraints&#xa;There is no "delight" in an interface that is unusable for a portion of the population. Elite prompts must enforce technical constraints, with accessibility (A11y) being paramount.&#xa;&#xa;Pattern: The prompt must explicitly instruct the AI to be "fully compliant with WCAG 2.2 AA". Research shows that without this explicit instruction, AI-generated components are "consistently" inaccessible.  &#xa;&#xa;Specifics: A high-quality A11y prompt enforces:&#xa;&#xa;Semantic HTML: "Ensure the proper use of HTML5 elements (like , , )".  &#xa;&#xa;Keyboard Accessibility: "Test navigation using only Tab, Shift+Tab, and Enter keys. All interactive elements should be reachable".  &#xa;&#xa;ARIA (Accessible Rich Internet Applications): Correct application of "ARIA landmarks and roles" , which are "HTML attributes that add semantic meaning... for assistive technologies".  &#xa;&#xa;Clear Content: "Use clear language... Write descriptive links: Swap vague text like 'click here' for something meaningful".  &#xa;&#xa;This pattern is the UI-domain equivalent of TDD (I.A.2). The prompt includes the acceptance criteria (WCAG). This "specification-as-prompt" is critical for generating production-ready, non-discriminatory interfaces.&#xa;&#xa;C. Structural &amp; Layout Constraints&#xa;To control the form of the output and ensure it is machine-readable and programmatically useful, prompts must define a reliable structure.&#xa;&#xa;Architecture &amp; Flows: For high-level system design, prompts specify formats like the C4 model rendered in Mermaid code. For user flows, Mermaid sequence diagrams are the standard.  &#xa;&#xa;Wireframes: Simple wireframe prompts use text descriptions, such as, "Include a header with a logo, search bar, featured destinations section, and a bottom navigation bar".  &#xa;&#xa;SOTA (Structured Data): The most robust and programmatically valuable pattern is to force the LLM to output a structured data format like JSON or YAML. This is achieved by providing an output schema to the model. This pattern is now natively supported by major model providers, who allow schemas to be defined using libraries like Pydantic (for Python) or Zod (for TypeScript). This guarantees the output is not just text, but a "type safety and consistent structure".  &#xa;&#xa;This structured output pattern is the critical link between the two domains of this report. If a UI can be described in a reliable JSON schema, and a backend can expose its API in a reliable JSON schema (e.g., an OpenAPI specification), an agent can connect them. This structured output is the "API" between a UI-generation agent and a code-generation agent.&#xa;&#xa;3. Generative UI (GenUI): The Emergent Paradigm&#xa;This is the bleeding-edge concept that underpins the entire future of UI design. Generative UI (GenUI) is a new paradigm that "enables adaptive, goal-driven interactions". Instead of a static interface designed by a human and then coded, the UI is generated in real-time by the AI.  &#xa;&#xa;Mechanism: In this paradigm, the AI generates "interactive widgets for fine-grained prompt control" or entire "high-fidelity UI mock-up screens from a high-level textual description". This process is not one-shot; it is an iterative, "co-creative process" between the human and the AI, involving "AI-assisted refinement strategies".  &#xa;&#xa;Current State: GenUI is currently being adopted by UX practitioners as a tool to accelerate their workflow. The human remains the curator and refiner of the AI-generated output.  &#xa;&#xa;GenUI is the logical evolution of prompt-based wireframing. The current limitation, and the key unexploited vector, is the human-in-the-loop for optimization. The UI is refined based on a designer's "vibe" or explicit follow-up prompts. The unexploited opportunity is to remove the human curator from the optimization loop. A system that could refine its own GenUI, not based on a designer's commands, but based on live user data, would represent a paradigm shift. This is the core concept of a "Self-Optimizing UI" and forms the foundation for the novel Cognitive-Adaptive Interface (CAI) architecture.  &#xa;&#xa;Synthesis of Novel Prompt Architectures: Exceeding Current Benchmarks&#xa;The preceding analysis deconstructed the current SOTA, revealing a set of unexploited capability vectors. The following synthesis moves beyond replicating these patterns. It proposes three novel, high-level architectures that fuse these vectors to create self-regulating, self-optimizing systems designed to exceed current benchmarks. These architectures treat the prompt not as a static, one-time instruction, but as a "bootloader" for a continuous, autonomous process.&#xa;&#xa;Table 1: Comparative Analysis of Generation &amp; Reasoning Architectures&#xa;&#xa;Architecture	Core Mechanism	Interaction Model	Key Limitation (Vector Not Exploited)	Unlocked Capability Vector&#xa;Chain-of-Thought (CoT)&#xa;&#xa;Step-by-step reasoning (e.g., "Let's think step-by-step").	Static	Brittle, linear reasoning; no external validation or tool use.	Basic multi-step problem solving.&#xa;ReAct&#xa;&#xa;Interleaves reasoning (CoT) with tool use (Actions).	Iterative	Dependent on pre-defined tools; no long-term memory or structured collaboration.	Environment-aware task execution.&#xa;Graph of Thoughts (GoT)&#xa;&#xa;Models reasoning as a graph, allowing merging of states and feedback loops.	Iterative	High conceptual complexity; primarily focused on reasoning, not execution.	Advanced, non-linear problem-solving.&#xa;TDD-as-Prompt&#xa;&#xa;A test suite is provided as the functional specification for code generation.	Static	Requires human to write all tests; no self-correction loop.	Verifiable, high-reliability code generation.&#xa;Generative UI (GenUI)&#xa;&#xa;AI generates high-fidelity UI mockups or interactive widgets from text descriptions.	Iterative	Requires human-in-the-loop for curation and refinement; based on assumed user needs.	Rapid, co-creative UI prototyping.&#xa;[NOVEL] Cognitive-Adaptive Interface (CAI) Engine	&#xa;GenUI + Cognitive Fitness Function + Live User Telemetry.&#xa;&#xa;Dynamic-Adaptive	N/A (Synthesized Architecture)	Real-time UI self-optimization based on observed user cognitive state.&#xa;[NOVEL] Test-Driven Agent (TDA) Framework	&#xa;Closed-loop TDD + Agentic RAG + Error-Forward Self-Healing.&#xa;&#xa;Autonomous-Iterative	N/A (Synthesized Architecture)	Verifiable, context-aware, autonomous development with guaranteed build integrity.&#xa;[NOVEL] Self-Optimizing Product (SOP) Loop	&#xa;TDA-CAI integration via an RLHF-from-Telemetry feedback loop.&#xa;&#xa;Autonomous-Holistic	N/A (Synthesized Architecture)	Fully autonomous product self-improvement driven by implicit user feedback.&#xa; &#xa;Proposed Architecture 1: The "Cognitive-Adaptive Interface" (CAI) Engine&#xa;This architecture synthesizes Generative UI (GenUI) with persona-driven design and, most critically, cognitive-heuristic constraints. It is designed to move UI generation from a static, one-shot process ("generate a wireframe") to a continuous, adaptive, and self-optimizing one.  &#xa;&#xa;Vector Exploited: This architecture directly targets the vector identified in (I.B.1) and (I.B.3): the fusion of Generative UI with real-time user telemetry. The system does not just generate a UI; it optimizes it in real-time based on observed user behavior.  &#xa;&#xa;Mechanism: The CAI Engine operates as a continuous four-phase loop:&#xa;&#xa;Phase 1: The "Cognitive Metaprompt". The architect does not prompt for a specific layout. Instead, they provide a high-level, structured (e.g., YAML) prompt that defines the goals and constraints. This metaprompt specifies:&#xa;&#xa;target_persona: The ground-truth user archetype.  &#xa;&#xa;business_objective: The high-level optimization target (e.g., "maximize conversion," "minimize time-to-task," "maximize user delight").&#xa;&#xa;cognitive_fitness_function: A weighted list of cognitive and behavioral principles that will be used to score the UI's performance. For example: weights: {cognitive_load: -0.5, fitts_law_compliance: +0.3, hick's_law_compliance: -0.2, wcag_aa_compliance: 1.0}.  &#xa;&#xa;Phase 2: Initial Generation. The CAI engine uses this metaprompt to generate the initial UI component tree. This output is a structured JSON artifact, not just a static image. The engine's initial design is its best hypothesis for satisfying the cognitive_fitness_function for the given target_persona.&#xa;&#xa;Phase 3: The Telemetry Loop. This is the critical connection to the real world. As users interact with this dynamically-rendered GenUI, the system collects fine-grained, real-time telemetry. This data includes not just basic "clickstream data" but also proxies for cognitive state: hesitation time (cognitive load), rage clicks (frustration), scroll depth (engagement), and form drop-off points.  &#xa;&#xa;Phase 4: Autonomous Optimization. This telemetry stream is fed back into the CAI engine. The engine scores the current UI's performance against the cognitive_fitness_function. It then begins a continuous, "self-optimizing" process, autonomously running micro-A/B tests or other reinforcement learning strategies to adapt the UI. For example, it might log: "Hypothesis: Moving 'Add to Cart' button 10px closer to the product image will improve the Fitts's Law component of the fitness function. Result: Target acquisition speed improved by 80ms and conversion metric increased by 0.2%. This change is now permanent for this user segment."  &#xa;&#xa;Exceeding the Benchmark: This architecture creates a true "Self-Optimizing UI". The prompt is no longer a blueprint for a static house; it is the DNA for a living organism that adapts to its environment (the user) in real-time. This moves beyond static, assumed personas to build an interface that dynamically aligns with the observed cognitive and behavioral patterns of its actual users.  &#xa;&#xa;Proposed Architecture 2: The "Test-Driven Agent" (TDA) Framework&#xa;This architecture synthesizes the most robust patterns from the code construction domain: TDD-as-Prompt (I.A.2), Self-Validation (I.A.3), and Agentic RAG (I.A.5). It creates a closed-loop, "self-healing" system designed to enable verifiable, autonomous development at the repository level.  &#xa;&#xa;Vector Exploited: This architecture exploits the vector identified in (I.A.5): the fusion of autonomous, closed-loop TDD with context-aware Agentic RAG . The agent's output is not "code"; it is a "passing build."  &#xa;&#xa;Mechanism: The TDA Framework operates as a five-phase, autonomous workflow:&#xa;&#xa;Phase 1: The "User Story Metaprompt". The human (or another agent) provides a high-level feature request in a structured format (e.g., JSON). This prompt defines the goal, not the implementation. Example: {"user_story": "As a user, I want to reset my password via email.", "acceptance_criteria": ["Must handle invalid emails", "Must send a tokenized link"]}.&#xa;&#xa;Phase 2: RAG-Context. The TDA's first action is not to code. It is to read. It activates its Agentic RAG module to perform "context-aware query planning". It queries the entire codebase and documentation to understand the existing system. (e.g., "Query: 'auth routes'", "Query: 'email service'", "Query: 'database schema for users'").  &#xa;&#xa;Phase 3: Test Generation (Red). Armed with this context, the TDA first generates a new, failing unit test (e.g., test_post_forgot_password_invalid_email_404). This step, based on the TDD-as-prompt paradigm , codifies the acceptance_criteria from the metaprompt into a verifiable, functional validation.  &#xa;&#xa;Phase 4: Code Generation (Green). The agent now generates the minimal amount of implementation code (a new route, a new service function) required to make the new test pass.  &#xa;&#xa;Phase 5: Reflect &amp; Refactor (Self-Healing). The TDA does not stop. It now runs the entire test suite. If an old test fails (a regression), it enters a "self-healing" loop. It uses the "Error-Forward Prompt" pattern (I.A.3), feeding the new stack trace back to itself. It then reflects and iterates on the code until the full build is green.  &#xa;&#xa;Exceeding the Benchmark: This architecture moves beyond task-oriented benchmarks like SWE-bench. The TDA's output is not "a code snippet that solves a problem"; it is a passing, context-aware, and regression-free build. This builds the trust required for true "agentic software engineering" by producing verifiable, reliable, and autonomous results that can be directly committed to a main branch.  &#xa;&#xa;The Unified Synthesis: The "Self-Optimizing Product" (SOP) Loop&#xa;This is the final, unified architecture. It bridges the two domains by connecting the TDA (backend code) and the CAI (frontend UI) into a single, product-level optimization loop. This system is designed to autonomously improve the entire product—both its functionality and its interface—based on user interaction.&#xa;&#xa;Vector Exploited: This architecture exploits the most potent "unexplored vector": connecting the CAI (UI) and TDA (Code) architectures via a shared feedback loop that uses Reinforcement Learning from Human Feedback (RLHF) . In this paradigm, the "human feedback" is not explicit (like a button click); it is the implicit behavioral telemetry collected from the CAI, which is then used to train a reward model and guide the policy of the entire system.  &#xa;&#xa;Mechanism (The Full Loop):&#xa;&#xa;Deploy: The TDA (Architecture 2) generates and deploys the backend API_v1 (e.g., POST /api/security-question). The CAI (Architecture 1) generates the frontend UI to consume it, governed by its cognitive_fitness_function.&#xa;&#xa;Observe (Telemetry): The CAI's telemetry loop observes a "user delight" failure. It logs: "70% of users drop off at the 'Security Question' form. Average hesitation time is 12 seconds. This violates the cognitive_load component of our fitness function."  &#xa;&#xa;Translate (Feedback Agent): This telemetry is fed into a new, specialized "Feedback Agent." This agent, part of a "Closed Learning Feedback Loop" , is a reasoning agent (using GoT ). Its sole purpose is to translate this quantitative behavioral data into a new product requirement. It autonomously generates a new User Story Metaprompt using meta-prompting techniques : {"user_story": "The 'Security Question' flow causes high friction (70% drop-off). Replace it with a 'Magic Link' email workflow.", "acceptance_criteria": [...]}.  &#xa;&#xa;Trigger (TDA): This new user story is automatically fed as an Init-Prompt to the TDA (Architecture 2).&#xa;&#xa;Heal &amp; Evolve (TDA): The TDA springs into action. It RAGs the codebase , writes new failing tests for the 'Magic Link' flow , generates the new API_v2 endpoints, and (critically) writes and deploys a migration to deprecate API_v1.  &#xa;&#xa;Adapt (CAI): The TDA's deployment (or an event-driven hook) triggers the CAI. The CAI, now aware of the new API_v2 and the deprecation of API_v1, re-generates its UI components to consume the new, "healed" workflow, automatically adapting the interface to the new, lower-friction flow.&#xa;&#xa;Exceeding the Benchmark: The loop is complete. The product itself (code + UI) just autonomously optimized its own design to improve "user delight," with no human intervention. This is the new benchmark. The "prompt" is no longer a static, human instruction; it is a continuous, self-generated feedback signal originating from the user's own behavior.&#xa;&#xa;Strategic Implementation and Future Trajectories&#xa;The architectures proposed in Part II are not theoretical. They can be implemented by moving from natural language prompts to structured metaprompts that act as the bootloaders and configuration files for these autonomous systems.&#xa;&#xa;Actionable Blueprints: Structured Metaprompts as the System API&#xa;To make these architectures concrete, we must define their initialization. These are meta-prompts that initialize and constrain the autonomous systems.  &#xa;&#xa;The most critical pattern for SOTA systems is the use of structured (not natural language) prompts, as this ensures reliable, machine-parseable interaction between agents. YAML is used for its human-readability in top-level configuration , while schema-enforced JSON (using Pydantic/Zod ) serves as the non-negotiable "API" for inter-agent communication.  &#xa;&#xa;Example Blueprint 1: YAML Metaprompt for the CAI Engine&#xa;This YAML file is the master-prompt for the Cognitive-Adaptive Interface (CAI) Engine. It defines the purpose and constraints of the UI, not its specific layout.&#xa;&#xa;# This YAML file is the master-prompt for the Cognitive-Adaptive Interface (CAI) Engine.&#xa;# It defines the *purpose* and *constraints* of the UI.&#xa;&#xa;system_role: "You are a CAI (Cognitive-Adaptive Interface) Engine. Your goal is to generate and continuously optimize a user interface to maximize the 'objective' by adhering to the 'fitness_function'."&#xa;&#xa;objective:&#xa;  type: "maximize_conversion"&#xa;  target_metric: "checkout_completion_rate"&#xa;  &#xa;target_persona:&#xa;  # This persona  will be used to generate the initial UI.&#xa;  file: "./personas/busy_professional_mobile.json" &#xa;  &#xa;technical_constraints:&#xa;  # Non-negotiable acceptance criteria &#xa;  - "WCAG_2_2_AA_COMPLIANT"&#xa;  - "OUTPUT_FORMAT_SEMANTIC_HTML_WITH_ARIA" [71, 72]&#xa;  - "MAX_LOAD_TIME_MS_3G: 1500"&#xa;  &#xa;cognitive_fitness_function:&#xa;  # The core of the CAI. The engine will score its own UI against these&#xa;  # principles  using live telemetry.&#xa;  - principle: "cognitive_load" # &#xa;    weight: -0.5 # (Minimize)&#xa;    metric: "avg_task_hesitation_time_sec"&#xa;    &#xa;  - principle: "hick's_law" # &#xa;    weight: -0.3 # (Minimize choices)&#xa;    metric: "choice_count_per_screen"&#xa;&#xa;  - principle: "fitts_s_law_compliance" # &#xa;    weight: 0.3 # (Maximize)&#xa;    metric: "target_acquisition_speed_ms"&#xa;    &#xa;  - principle: "nielsen_heuristic_4_consistency" # &#xa;    weight: 0.2 # (Maximize)&#xa;    metric: "component_reuse_score"&#xa;Example Blueprint 2: JSON Metaprompt for the TDA Framework&#xa;This JSON object is the "Init-Prompt" for the Test-Driven Agent (TDA). It is generated by the "Feedback Agent" (II.C) after translating a telemetry-detected user problem.&#xa;&#xa;/*&#xa;  This JSON object is the "Init-Prompt" for the Test-Driven Agent (TDA).&#xa;  It is generated by the "Feedback Agent" [II.C] from user telemetry.&#xa;*/&#xa;{&#xa;  "system_role": "You are a TDA (Test-Driven Agent). You must generate code that passes all tests. You must write failing tests first.",&#xa;  "task_id": "TDA-1138",&#xa;  "source_trigger": "SOP_Feedback_Agent_Telemetry_Violation_cognitive_load",&#xa;  "user_story": "The 'Security Question' flow (API_v1) causes high user friction (70% drop-off). You must replace it with a 'Magic Link' email workflow (API_v2).",&#xa;  "rag_context_queries":&#xa;    "Retrieve file:./routes/auth.js",&#xa;    "Retrieve file:./services/EmailService.js",&#xa;    "Retrieve file:./models/User.js",&#xa;    "Retrieve related tests: test_auth.py"&#xa;  ],&#xa;  "acceptance_criteria":&#xa;    "POST /api/v2/magic-link must accept an 'email'.",&#xa;    "Must return 404 if email does not exist.",&#xa;    "Must return 200 and trigger EmailService.sendMagicLink on success.",&#xa;    "Must generate a unique, single-use token with a 15-minute expiry.",&#xa;    "Must create a new failing test for 'token_expired' scenario."&#xa;  ]&#xa;}&#xa;Future Capability Vectors &amp; Redefining Benchmarks&#xa;The user's final mandate is to "exceed current benchmarks." The SOP architecture, if implemented, renders current benchmarks obsolete.&#xa;&#xa;Current Benchmarks: Benchmarks like HumanEval and SWE-bench are task-oriented and static. They are critical for measuring an agent's ability to solve a given, siloed problem (e.g., "Fix this bug from this GitHub issue"). However, they do not measure the agent's ability to identify the problem or validate its solution against holistic user-centric goals.  &#xa;&#xa;The New Benchmark: The SOP architecture (II.C) operates at the product level. The new benchmark should not be "Can the AI solve a GitHub issue?" It must be "Can the AI identify, validate, and solve a user-delight issue autonomously from raw telemetry?"&#xa;&#xa;Proposed New Benchmark: "Product-Bench"&#xa;&#xa;Given: A high-level product goal (e.g., "build a photo-sharing app") and a cognitive_fitness_function (as defined in III.A).&#xa;&#xa;Input: A stream of (simulated) user telemetry, representing a diverse set of user interactions over time.&#xa;&#xa;Task: The AI system (SOP) must:&#xa;&#xa;(a) Build the V1 of the product (TDA + CAI).&#xa;&#xa;(b) Autonomously evolve its features, code, and UI over 1 million simulated user-sessions in response to the telemetry stream.&#xa;&#xa;Metric: The final score is the system's ability to maximize the cognitive_fitness_function (e.g., a composite "User Delight" score based on retention, engagement, and cognitive load reduction) over the duration of the simulation.&#xa;&#xa;This new benchmark aligns with the future of HCI and AI, which is moving toward human-AI co-creation , AI-augmented reasoning , and human-centered evaluation. The ultimate prompt architecture is one that creates its own prompts based on its core purpose and its continuous, real-time interaction with the world. This is the new, and achievable, benchmark for excellence.  </title><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 118px; height: 1px; padding-top: 106px; margin-left: 651px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; "><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; ">DeepResearch</div></div></div></foreignObject><image x="651" y="99.5" width="118" height="17" xlink:href="data:image/png;base64,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"/></switch></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-24"><g><path d="M 1210 497 Q 1210 497 1210 530.63" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke" style="stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/><path d="M 1210 535.88 L 1206.5 528.88 L 1210 530.63 L 1213.5 528.88 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all" style="fill: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-31"><g><g><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 1px; height: 1px; padding-top: 510px; margin-left: 1208px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; background-color: #ffffff; "><div style="display: inline-block; font-size: 11px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; background-color: light-dark(#ffffff, var(--ge-dark-color, #121212)); white-space: nowrap; ">push</div></div></div></foreignObject><image x="1196" y="504" width="24" height="15.75" xlink:href="data:image/png;base64,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"/></switch></g></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-12"><g><path d="M 1150 417 L 1270 417 L 1270 485 Q 1240 463.4 1210 485 Q 1180 506.6 1150 485 L 1150 429 Z" fill="#dae8fc" stroke="#6c8ebf" stroke-miterlimit="10" pointer-events="all" style="fill: light-dark(rgb(218, 232, 252), rgb(29, 41, 59)); stroke: light-dark(rgb(108, 142, 191), rgb(92, 121, 163));"><title>Here is the output from the The Same Tool  when input DeepResearch Text that had been Amplified.  &#xa;&#xa;&#xa;Based on your detailed request, here is a step-by-step plan for synthesizing self-optimizing systems for code and interface generation, culminating in the Self-Optimizing Product (SOP) Loop.&#xa;&#xa;&#xa;---&#xa;&#xa;&#xa;Step-by-Step Plan: Synthesizing Self-Optimizing Systems&#xa;&#xa;The core of this plan is to establish a continuous, autonomous feedback loop that drives product improvement based on real-time user behavior. This is achieved by integrating two novel architectures: the Cognitive-Adaptive Interface (CAI) Engine for UI optimization and the Test-Driven Agent (TDA) Framework for verifiable code generation.&#xa;&#xa;&#xa;I. Foundation 1: Implementing the Cognitive-Adaptive Interface (CAI) Engine&#xa;&#xa;The CAI Engine focuses on creating and optimizing UIs based on observed user cognitive states, moving beyond static personas and subjective human feedback.&#xa;&#xa;&#xa;1. Phase 1: Define the "Cognitive Metaprompt" (Structured Goal &amp; Constraints)&#xa;&#xa;* Action: Architect defines a high-level, structured YAML metaprompt.&#xa;&#xa;* Content: This metaprompt specifies the `target_persona`, the `business_objective` (e.g., "maximize conversion"), and a `cognitive_fitness_function`.&#xa;&#xa;* `cognitive_fitness_function` Detail: This is a weighted list of cognitive and behavioral principles (e.g., `cognitive_load: -0.5`, `fitts_s_law_compliance: +0.3`) used to score the UI's performance.&#xa;&#xa;* Output: A machine-readable YAML configuration acting as the DNA for the UI.&#xa;&#xa;&#xa;2. Phase 2: Initial UI Generation (Hypothesis Formation)&#xa;&#xa;* Action: The CAI Engine uses the YAML metaprompt to generate an initial UI.&#xa;&#xa;* Process: It forms its best hypothesis for satisfying the `cognitive_fitness_function` for the specified `target_persona`.&#xa;&#xa;* Output: A structured JSON artifact representing the UI component tree (e.g., via Pydantic/Zod schema-enforced output).&#xa;&#xa;&#xa;3. Phase 3: Establish the Telemetry Loop (Real-World Observation)&#xa;&#xa;* Action: Deploy the dynamically-rendered GenUI to end-users and activate real-time telemetry collection.&#xa;&#xa;* Data Points: Collect fine-grained behavioral data beyond clickstreams, including:&#xa;&#xa;* Hesitation Time: Proxy for cognitive load.&#xa;&#xa;* Rage Clicks: Proxy for frustration.&#xa;&#xa;* Scroll Depth: Proxy for engagement.&#xa;&#xa;* Form Drop-off Points: Critical conversion blockers.&#xa;&#xa;* Output: A continuous, high-bandwidth stream of user interaction data.&#xa;&#xa;&#xa;4. Phase 4: Autonomous UI Optimization (Self-Adaptation)&#xa;&#xa;* Action: Feed the telemetry data back into the CAI Engine for continuous improvement.&#xa;&#xa;* Process:&#xa;&#xa;* Score the current UI's performance against the predefined `cognitive_fitness_function`.&#xa;&#xa;* Autonomously run micro-A/B tests or employ multi-armed bandit algorithms.&#xa;&#xa;* Adapt the UI components (e.g., button placement, information density, workflow changes) to improve the score.&#xa;&#xa;* Output: A continuously evolving, self-optimizing UI that dynamically aligns with observed user cognitive and behavioral patterns.&#xa;&#xa;&#xa;II. Foundation 2: Implementing the Test-Driven Agent (TDA) Framework&#xa;&#xa;The TDA Framework provides a closed-loop, "self-healing" system for autonomous, verifiable code development at the repository level, ensuring a "passing build" as its primary deliverable.&#xa;&#xa;&#xa;1. Phase 1: Provide the "User Story Metaprompt" (Goal, not Implementation)&#xa;&#xa;* Action: A human or another agent provides a high-level feature request.&#xa;&#xa;* Format: Structured JSON format, defining the user story and `acceptance_criteria`.&#xa;&#xa;* Example: `{"user_story": "As a user, I want to reset my password via email.", "acceptance_criteria": [...]}`.&#xa;&#xa;* Output: A machine-parseable JSON object for the TDA.&#xa;&#xa;&#xa;2. Phase 2: RAG-Contextualization (Understand the Codebase)&#xa;&#xa;* Action: The TDA activates its Agentic RAG module.&#xa;&#xa;* Process: Performs context-aware query planning across the codebase, documentation, existing APIs, and database schemas.&#xa;&#xa;* Goal: Build a comprehensive understanding of the existing system relevant to the user story.&#xa;&#xa;* Output: Internal knowledge graph or retrieved context documents used for subsequent steps.&#xa;&#xa;&#xa;3. Phase 3: Test Generation (Red Phase - Codify Requirements)&#xa;&#xa;* Action: Armed with context, the TDA first generates a new, failing unit test.&#xa;&#xa;* Purpose: This test directly codifies the `acceptance_criteria` from the metaprompt into a verifiable, functional validation.&#xa;&#xa;* Output: A new test file (e.g., `test_forgot_password.py`) with at least one failing test case.&#xa;&#xa;&#xa;4. Phase 4: Code Generation (Green Phase - Implement to Pass Tests)&#xa;&#xa;* Action: The TDA generates the minimal implementation code required to make the newly generated test(s) pass.&#xa;&#xa;* Constraint: Strict adherence to patterns and conventions discovered during RAG-Contextualization.&#xa;&#xa;* Output: New or modified code files that attempt to satisfy the tests.&#xa;&#xa;&#xa;5. Phase 5: Reflect &amp; Self-Heal (Continuous Verification &amp; Refinement)&#xa;&#xa;Action: The TDA runs the entire* test suite (including existing and newly generated tests).&#xa;&#xa;* Process:&#xa;&#xa;* If any test fails (regression or new test failure), it enters a "self-healing" loop.&#xa;&#xa;* Uses "Error-Forward Prompting" to feed the stack trace and error messages back to itself as structured context.&#xa;&#xa;* Reflects on the errors and iteratively refines the code until the full build is green.&#xa;&#xa;* (Optional) Performs a final refactoring pass for code quality (e.g., SOLID principles).&#xa;&#xa;* Output: A passing, context-aware, and regression-free build, ready for deployment.&#xa;&#xa;&#xa;III. Integrated Vision: The Self-Optimizing Product (SOP) Loop&#xa;&#xa;This is the unified architecture, bridging the CAI (frontend UI) and TDA (backend code) into a single, product-level optimization loop, driven by implicit user feedback.&#xa;&#xa;&#xa;1. Step 1: Initial Product Deployment (TDA &amp; CAI)&#xa;&#xa;* Action: The TDA generates and deploys an initial backend API (e.g., `API_v1`).&#xa;&#xa;* Action: The CAI Engine, consuming this API, generates and deploys the corresponding frontend UI (V1).&#xa;&#xa;* Outcome: A functional product available to users.&#xa;&#xa;&#xa;2. Step 2: Observe User Behavior (CAI Telemetry Detects Failure)&#xa;&#xa;* Action: The CAI's continuous telemetry loop actively monitors user interactions with the deployed UI.&#xa;&#xa;* Detection: It identifies a "user delight" failure based on its `cognitive_fitness_function` (e.g., high drop-off rate, excessive hesitation time in a specific flow).&#xa;&#xa;* Output: A detected telemetry violation report (e.g., "70% of users drop off at 'Security Question' form; violates `cognitive_load` metric").&#xa;&#xa;&#xa;3. Step 3: Translate Telemetry to Product Requirement (Feedback Agent)&#xa;&#xa;* Action: A specialized "Feedback Agent" receives the telemetry violation report.&#xa;&#xa;* Process: It translates this implicit, quantitative behavioral data into an explicit, structured product requirement.&#xa;&#xa;* Output: A new "User Story Metaprompt" (JSON) for the TDA, proposing a solution to the identified problem (e.g., "Replace 'Security Question' flow with 'Magic Link' email workflow").&#xa;&#xa;&#xa;4. Step 4: Trigger Backend Evolution (TDA Initiation)&#xa;&#xa;* Action: The newly generated User Story Metaprompt is automatically fed as an Init-Prompt to the TDA Framework.&#xa;&#xa;* Outcome: The TDA is initiated with a clear, user-driven mandate for product improvement.&#xa;&#xa;&#xa;5. Step 5: Autonomous Backend Development &amp; Deployment (TDA Execution)&#xa;&#xa;* Action: The TDA executes its full five-phase workflow (RAG-Context, Test Generation, Code Generation, Reflect &amp; Self-Heal).&#xa;&#xa;* Process:&#xa;&#xa;* It reads the codebase to understand existing authentication.&#xa;&#xa;* It writes new failing tests for the proposed 'Magic Link' flow.&#xa;&#xa;* It generates new `API_v2` endpoints and implementation.&#xa;&#xa;* Crucially, it handles necessary migrations, including deprecating `API_v1` components.&#xa;&#xa;* Output: A passing, verifiable backend build with updated APIs (`API_v2`) deployed to production.&#xa;&#xa;&#xa;6. Step 6: Autonomous Frontend Adaptation (CAI Re-generation)&#xa;&#xa;* Action: The deployment of the new backend `API_v2` triggers the CAI Engine.&#xa;&#xa;* Process: The CAI, now aware of the new, lower-friction `API_v2`, re-generates or adapts its UI components to consume the new endpoints.&#xa;&#xa;* Outcome: The frontend interface automatically adapts to the healed backend, providing a seamless, optimized user experience.&#xa;&#xa;&#xa;IV. Strategic Implementation: Structured Metaprompts as System APIs&#xa;&#xa;Principle: Shift from ambiguous natural language prompts to structured metaprompts.&#xa;YAML: Utilize YAML for top-level configuration and high-level metaprompts (e.g., CAI's "Cognitive Metaprompt") due to its human-readability and structured nature.&#xa;JSON with Schemas: Employ JSON for inter-agent communication and detailed specifications (e.g., TDA's "User Story Metaprompt") with schema enforcement (e.g., Pydantic/Zod). This guarantees type safety, consistent structure, and a reliable "API contract" between autonomous agents.&#xa;&#xa;V. Future Trajectory: Redefining Benchmarks with "Product-Bench"&#xa;&#xa;The success of the SOP loop necessitates a new benchmark that evaluates autonomous product improvement rather than isolated task completion.&#xa;&#xa;&#xa;Proposed New Benchmark: "Product-Bench"&#xa;* Given: A high-level product goal (e.g., "build a photo-sharing app") and a `cognitive_fitness_function`.&#xa;* Input: A continuous stream of simulated user telemetry, representing diverse user interactions.&#xa;&#xa;* Task: The SOP system must autonomously build V1, and then continuously propose, specify, implement, and deploy new features, fixes, and UI adaptations over millions of simulated user sessions in direct response to the telemetry.&#xa;&#xa;* Metric: Maximize the `cognitive_fitness_function` (a composite "User Delight" score based on retention, engagement, and cognitive load reduction) over the simulation duration.&#xa;&#xa;&#xa;---&#xa;&#xa;&#xa;This step-by-step plan outlines the architecture and mechanisms required to achieve truly self-optimizing systems, moving from human-centric "prompt engineering" to machine-driven "prompt optimization" and autonomous product evolution.</title></path></g><g><g><title>Here is the output from the The Same Tool  when input DeepResearch Text that had been Amplified.  &#xa;&#xa;&#xa;Based on your detailed request, here is a step-by-step plan for synthesizing self-optimizing systems for code and interface generation, culminating in the Self-Optimizing Product (SOP) Loop.&#xa;&#xa;&#xa;---&#xa;&#xa;&#xa;Step-by-Step Plan: Synthesizing Self-Optimizing Systems&#xa;&#xa;The core of this plan is to establish a continuous, autonomous feedback loop that drives product improvement based on real-time user behavior. This is achieved by integrating two novel architectures: the Cognitive-Adaptive Interface (CAI) Engine for UI optimization and the Test-Driven Agent (TDA) Framework for verifiable code generation.&#xa;&#xa;&#xa;I. Foundation 1: Implementing the Cognitive-Adaptive Interface (CAI) Engine&#xa;&#xa;The CAI Engine focuses on creating and optimizing UIs based on observed user cognitive states, moving beyond static personas and subjective human feedback.&#xa;&#xa;&#xa;1. Phase 1: Define the "Cognitive Metaprompt" (Structured Goal &amp; Constraints)&#xa;&#xa;* Action: Architect defines a high-level, structured YAML metaprompt.&#xa;&#xa;* Content: This metaprompt specifies the `target_persona`, the `business_objective` (e.g., "maximize conversion"), and a `cognitive_fitness_function`.&#xa;&#xa;* `cognitive_fitness_function` Detail: This is a weighted list of cognitive and behavioral principles (e.g., `cognitive_load: -0.5`, `fitts_s_law_compliance: +0.3`) used to score the UI's performance.&#xa;&#xa;* Output: A machine-readable YAML configuration acting as the DNA for the UI.&#xa;&#xa;&#xa;2. Phase 2: Initial UI Generation (Hypothesis Formation)&#xa;&#xa;* Action: The CAI Engine uses the YAML metaprompt to generate an initial UI.&#xa;&#xa;* Process: It forms its best hypothesis for satisfying the `cognitive_fitness_function` for the specified `target_persona`.&#xa;&#xa;* Output: A structured JSON artifact representing the UI component tree (e.g., via Pydantic/Zod schema-enforced output).&#xa;&#xa;&#xa;3. Phase 3: Establish the Telemetry Loop (Real-World Observation)&#xa;&#xa;* Action: Deploy the dynamically-rendered GenUI to end-users and activate real-time telemetry collection.&#xa;&#xa;* Data Points: Collect fine-grained behavioral data beyond clickstreams, including:&#xa;&#xa;* Hesitation Time: Proxy for cognitive load.&#xa;&#xa;* Rage Clicks: Proxy for frustration.&#xa;&#xa;* Scroll Depth: Proxy for engagement.&#xa;&#xa;* Form Drop-off Points: Critical conversion blockers.&#xa;&#xa;* Output: A continuous, high-bandwidth stream of user interaction data.&#xa;&#xa;&#xa;4. Phase 4: Autonomous UI Optimization (Self-Adaptation)&#xa;&#xa;* Action: Feed the telemetry data back into the CAI Engine for continuous improvement.&#xa;&#xa;* Process:&#xa;&#xa;* Score the current UI's performance against the predefined `cognitive_fitness_function`.&#xa;&#xa;* Autonomously run micro-A/B tests or employ multi-armed bandit algorithms.&#xa;&#xa;* Adapt the UI components (e.g., button placement, information density, workflow changes) to improve the score.&#xa;&#xa;* Output: A continuously evolving, self-optimizing UI that dynamically aligns with observed user cognitive and behavioral patterns.&#xa;&#xa;&#xa;II. Foundation 2: Implementing the Test-Driven Agent (TDA) Framework&#xa;&#xa;The TDA Framework provides a closed-loop, "self-healing" system for autonomous, verifiable code development at the repository level, ensuring a "passing build" as its primary deliverable.&#xa;&#xa;&#xa;1. Phase 1: Provide the "User Story Metaprompt" (Goal, not Implementation)&#xa;&#xa;* Action: A human or another agent provides a high-level feature request.&#xa;&#xa;* Format: Structured JSON format, defining the user story and `acceptance_criteria`.&#xa;&#xa;* Example: `{"user_story": "As a user, I want to reset my password via email.", "acceptance_criteria": [...]}`.&#xa;&#xa;* Output: A machine-parseable JSON object for the TDA.&#xa;&#xa;&#xa;2. Phase 2: RAG-Contextualization (Understand the Codebase)&#xa;&#xa;* Action: The TDA activates its Agentic RAG module.&#xa;&#xa;* Process: Performs context-aware query planning across the codebase, documentation, existing APIs, and database schemas.&#xa;&#xa;* Goal: Build a comprehensive understanding of the existing system relevant to the user story.&#xa;&#xa;* Output: Internal knowledge graph or retrieved context documents used for subsequent steps.&#xa;&#xa;&#xa;3. Phase 3: Test Generation (Red Phase - Codify Requirements)&#xa;&#xa;* Action: Armed with context, the TDA first generates a new, failing unit test.&#xa;&#xa;* Purpose: This test directly codifies the `acceptance_criteria` from the metaprompt into a verifiable, functional validation.&#xa;&#xa;* Output: A new test file (e.g., `test_forgot_password.py`) with at least one failing test case.&#xa;&#xa;&#xa;4. Phase 4: Code Generation (Green Phase - Implement to Pass Tests)&#xa;&#xa;* Action: The TDA generates the minimal implementation code required to make the newly generated test(s) pass.&#xa;&#xa;* Constraint: Strict adherence to patterns and conventions discovered during RAG-Contextualization.&#xa;&#xa;* Output: New or modified code files that attempt to satisfy the tests.&#xa;&#xa;&#xa;5. Phase 5: Reflect &amp; Self-Heal (Continuous Verification &amp; Refinement)&#xa;&#xa;Action: The TDA runs the entire* test suite (including existing and newly generated tests).&#xa;&#xa;* Process:&#xa;&#xa;* If any test fails (regression or new test failure), it enters a "self-healing" loop.&#xa;&#xa;* Uses "Error-Forward Prompting" to feed the stack trace and error messages back to itself as structured context.&#xa;&#xa;* Reflects on the errors and iteratively refines the code until the full build is green.&#xa;&#xa;* (Optional) Performs a final refactoring pass for code quality (e.g., SOLID principles).&#xa;&#xa;* Output: A passing, context-aware, and regression-free build, ready for deployment.&#xa;&#xa;&#xa;III. Integrated Vision: The Self-Optimizing Product (SOP) Loop&#xa;&#xa;This is the unified architecture, bridging the CAI (frontend UI) and TDA (backend code) into a single, product-level optimization loop, driven by implicit user feedback.&#xa;&#xa;&#xa;1. Step 1: Initial Product Deployment (TDA &amp; CAI)&#xa;&#xa;* Action: The TDA generates and deploys an initial backend API (e.g., `API_v1`).&#xa;&#xa;* Action: The CAI Engine, consuming this API, generates and deploys the corresponding frontend UI (V1).&#xa;&#xa;* Outcome: A functional product available to users.&#xa;&#xa;&#xa;2. Step 2: Observe User Behavior (CAI Telemetry Detects Failure)&#xa;&#xa;* Action: The CAI's continuous telemetry loop actively monitors user interactions with the deployed UI.&#xa;&#xa;* Detection: It identifies a "user delight" failure based on its `cognitive_fitness_function` (e.g., high drop-off rate, excessive hesitation time in a specific flow).&#xa;&#xa;* Output: A detected telemetry violation report (e.g., "70% of users drop off at 'Security Question' form; violates `cognitive_load` metric").&#xa;&#xa;&#xa;3. Step 3: Translate Telemetry to Product Requirement (Feedback Agent)&#xa;&#xa;* Action: A specialized "Feedback Agent" receives the telemetry violation report.&#xa;&#xa;* Process: It translates this implicit, quantitative behavioral data into an explicit, structured product requirement.&#xa;&#xa;* Output: A new "User Story Metaprompt" (JSON) for the TDA, proposing a solution to the identified problem (e.g., "Replace 'Security Question' flow with 'Magic Link' email workflow").&#xa;&#xa;&#xa;4. Step 4: Trigger Backend Evolution (TDA Initiation)&#xa;&#xa;* Action: The newly generated User Story Metaprompt is automatically fed as an Init-Prompt to the TDA Framework.&#xa;&#xa;* Outcome: The TDA is initiated with a clear, user-driven mandate for product improvement.&#xa;&#xa;&#xa;5. Step 5: Autonomous Backend Development &amp; Deployment (TDA Execution)&#xa;&#xa;* Action: The TDA executes its full five-phase workflow (RAG-Context, Test Generation, Code Generation, Reflect &amp; Self-Heal).&#xa;&#xa;* Process:&#xa;&#xa;* It reads the codebase to understand existing authentication.&#xa;&#xa;* It writes new failing tests for the proposed 'Magic Link' flow.&#xa;&#xa;* It generates new `API_v2` endpoints and implementation.&#xa;&#xa;* Crucially, it handles necessary migrations, including deprecating `API_v1` components.&#xa;&#xa;* Output: A passing, verifiable backend build with updated APIs (`API_v2`) deployed to production.&#xa;&#xa;&#xa;6. Step 6: Autonomous Frontend Adaptation (CAI Re-generation)&#xa;&#xa;* Action: The deployment of the new backend `API_v2` triggers the CAI Engine.&#xa;&#xa;* Process: The CAI, now aware of the new, lower-friction `API_v2`, re-generates or adapts its UI components to consume the new endpoints.&#xa;&#xa;* Outcome: The frontend interface automatically adapts to the healed backend, providing a seamless, optimized user experience.&#xa;&#xa;&#xa;IV. Strategic Implementation: Structured Metaprompts as System APIs&#xa;&#xa;Principle: Shift from ambiguous natural language prompts to structured metaprompts.&#xa;YAML: Utilize YAML for top-level configuration and high-level metaprompts (e.g., CAI's "Cognitive Metaprompt") due to its human-readability and structured nature.&#xa;JSON with Schemas: Employ JSON for inter-agent communication and detailed specifications (e.g., TDA's "User Story Metaprompt") with schema enforcement (e.g., Pydantic/Zod). This guarantees type safety, consistent structure, and a reliable "API contract" between autonomous agents.&#xa;&#xa;V. Future Trajectory: Redefining Benchmarks with "Product-Bench"&#xa;&#xa;The success of the SOP loop necessitates a new benchmark that evaluates autonomous product improvement rather than isolated task completion.&#xa;&#xa;&#xa;Proposed New Benchmark: "Product-Bench"&#xa;* Given: A high-level product goal (e.g., "build a photo-sharing app") and a `cognitive_fitness_function`.&#xa;* Input: A continuous stream of simulated user telemetry, representing diverse user interactions.&#xa;&#xa;* Task: The SOP system must autonomously build V1, and then continuously propose, specify, implement, and deploy new features, fixes, and UI adaptations over millions of simulated user sessions in direct response to the telemetry.&#xa;&#xa;* Metric: Maximize the `cognitive_fitness_function` (a composite "User Delight" score based on retention, engagement, and cognitive load reduction) over the simulation duration.&#xa;&#xa;&#xa;---&#xa;&#xa;&#xa;This step-by-step plan outlines the architecture and mechanisms required to achieve truly self-optimizing systems, moving from human-centric "prompt engineering" to machine-driven "prompt optimization" and autonomous product evolution.</title><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 118px; height: 1px; padding-top: 446px; margin-left: 1151px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; "><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; ">DeepResearch</div></div></div></foreignObject><image x="1151" y="439.5" width="118" height="17" xlink:href="data:image/png;base64,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"/></switch></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-17"><g><path d="M 1210 357 L 1210 410.63" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke" style="stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/><path d="M 1210 415.88 L 1206.5 408.88 L 1210 410.63 L 1213.5 408.88 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all" style="fill: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-30"><g><g><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 1px; height: 1px; padding-top: 384px; margin-left: 1211px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; background-color: #ffffff; "><div style="display: inline-block; font-size: 11px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; background-color: light-dark(#ffffff, var(--ge-dark-color, #121212)); white-space: nowrap; ">output</div></div></div></foreignObject><image x="1195.5" y="378" width="31" height="15.75" xlink:href="data:image/png;base64,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"/></switch></g></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-15"><g><rect x="1150" y="297" width="120" height="60" fill="#f561ff" stroke="#9673a6" pointer-events="all" style="fill: light-dark(rgb(245, 97, 255), rgb(208, 80, 216)); stroke: light-dark(rgb(150, 115, 166), rgb(149, 119, 163));"/></g><g><g><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 118px; height: 1px; padding-top: 327px; margin-left: 1151px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; "><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; ">Tool for AI</div></div></div></foreignObject><image x="1151" y="320.5" width="118" height="17" xlink:href="data:image/png;base64,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"/></switch></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-21"><g><path d="M 1500 187 L 1620 187 L 1620 255 Q 1590 233.4 1560 255 Q 1530 276.6 1500 255 L 1500 199 Z" fill="#dae8fc" stroke="#6c8ebf" stroke-miterlimit="10" pointer-events="all" style="fill: light-dark(rgb(218, 232, 252), rgb(29, 41, 59)); stroke: light-dark(rgb(108, 142, 191), rgb(92, 121, 163));"><title>Based on your request, here is a step-by-step plan for understanding and implementing the concepts outlined, structured to follow the flow of the provided text.&#xa;&#xa;#### 1.1.3. Self-Validation and "Error-Forward" Debugging&#xa;Goal: Enable autonomous agents to recognize, diagnose, and recover from errors, extending the TDD loop.&#xa;Core Capabilities:&#xa;* Agentic Self-Validation: Regularly verify progress and self-assess correctness (e.g., Cognition's Devin).&#xa;* "Error-Forward Prompting": Treat errors as data; automatically collect context (error message, stack trace) and feed it back to the agent for debugging.&#xa;&#xa;* Reflection: Learn from actions and improve debugging stratStep-by-Step Plan: From Static Prompts to Dynamic Architectures&#xa;&#xa;1. Deconstruct Elite-Tier Prompt Patterns: The Current Benchmark&#xa;&#xa;Begin by understanding the foundational benchmarks and identifying current state-of-the-art (SOTA) practices in LLM prompting for code and UI generation.&#xa;&#xa;&#xa;1.1. Domain 1: Architectures for Efficient Code Construction&#xa;&#xa;Focus on how LLMs are used as reasoning engines within structured development frameworks.&#xa;&#xa;&#xa;#### 1.1.1. Automated Prompt Optimization: The "Prompt-as-a-Target" Pattern&#xa;&#xa;Goal: Automate prompt refinement to produce high-quality code.&#xa;Techniques to Understand:&#xa;* Evolutionary-Based Methods (EPiC): Explore prompt evolution via genetic algorithms and fitness functions.&#xa;* Iterative Refinement (Prochemy): Continuously refine prompts based on model performance on specific tasks.&#xa;&#xa;* Adaptive Selection (PET-Select): Classify query complexity to dynamically select the most appropriate prompt engineering technique (PET).&#xa;&#xa;Key Unexploited Vector: Proactive generation of novel prompt architectures for novel problems (meta-prompting).&#xa;&#xa;#### 1.1.2. Test-Driven Development (TDD) as a Prompting Paradigm&#xa;Goal: Integrate TDD principles directly into prompt architecture for verifiable code generation.&#xa;Core Principle: Provide LLM with concrete unit tests as the specification, instructing it to "write code to pass all tests."&#xa;Frameworks/Structures:&#xa;* TGEN Framework: Uses specialized agents with programming prompts and tests to produce validated code.&#xa;* Elite-Level TDD Prompt Structure: Strict rules including function signature, type hints, best practices, edge cases, and output format (e.g., Python function only).&#xa;&#xa;Key Unexploited Vector: A system that generates its own tests and validates its own code in a continuous cycle.&#xa;egies via reflective prompting (e.g., Self-Refine).&#xa;&#xa;Outcome: "Self-healing" systems where failure is a data signal, and the stack trace becomes an instruction for fixing.&#xa;&#xa;#### 1.1.4. Agentic Frameworks and Multi-Agent Collaboration&#xa;Goal: Solve complex software development tasks by orchestrating multiple specialized agents.&#xa;Advanced Reasoning Patterns:&#xa;* ReAct: Interleave step-by-step reasoning with tool use.&#xa;* Tree of Thoughts (ToT): Explore multiple reasoning paths and evaluate states.&#xa;&#xa;* Graph of Thoughts (GoT): Generalize ToT into a graph structure for synergistic outcomes and feedback loops.&#xa;&#xa;Agentic Frameworks:&#xa;* MetaGPT: Simulate a software company with agents in roles (PM, Architect, Programmer, QA) and Standard Operating Procedures (SOPs).&#xa;* ChatDev: Utilize waterfall-style collaboration with task-oriented, multi-turn communications.&#xa;&#xa;Key Unexploited Vector: AI-native workflows where feedback comes from product telemetry, not simulated human roles.&#xa;&#xa;#### 1.1.5. Context-Aware Generation (Agentic RAG)&#xa;Goal: Provide LLMs with relevant domain context for code generation.&#xa;Pattern:&#xa;* RAG-for-Code: Augment prompts with information from documentation, code repositories, or discussions.&#xa;* Agentic RAG: Agent actively plans queries, executes multiple subqueries, and synthesizes results for comprehensive understanding (e.g., LangGraph, AutoGen).&#xa;&#xa;Key Unexploited Vector: Fusion of Agentic RAG (for context) with TDD-as-Prompt (for verification) to create autonomous developers.&#xa;&#xa;1.2. Domain 2: Architectures for User Delight &amp; UI Design&#xa;&#xa;Explore how elite prompts generate user experiences, not just pixels, grounded in human-centric principles.&#xa;&#xa;&#xa;#### 1.2.1. Persona-Driven Design: Grounding the Generation&#xa;&#xa;Goal: Achieve "user delight" by tailoring UI generation to specific user needs.&#xa;Pattern:&#xa;* Persona Generation: Prompt system to generate detailed proto-personas (demographics, pain points, motivations).&#xa;* Constraint Injection: Inject generated/human-provided personas as primary constraints into UI generation prompts.&#xa;&#xa;Key Unexploited Vector: Move from static, assumed personas to dynamic, observed user models continuously updated by real-time behavioral analytics.&#xa;&#xa;#### 1.2.2. Constraint-Based Generation: Defining the "Solution Space"&#xa;Goal: Apply multiple, layered constraints to ensure functional, accessible, and theoretically sound UI outputs.&#xa;Categories of Constraints:&#xa;* A. Cognitive &amp; Heuristic Constraints: Instruct AI to apply principles from cognitive science and usability heuristics (e.g., Nielsen's 10, Fitts's Law, Hick's Law, Cognitive Load, BJ Fogg's Model).&#xa;* B. Technical &amp; Accessibility (A11y) Constraints: Explicitly enforce standards like WCAG 2.2 AA compliance (e.g., Semantic HTML, Keyboard Accessibility, ARIA, clear content).&#xa;&#xa;* C. Structural &amp; Layout Constraints: Define reliable output structures for machine-readability (e.g., C4 model, Mermaid diagrams, structured data formats like JSON/YAML with Pydantic/Zod schemas).&#xa;&#xa;Importance: Structured output is the "API" connecting UI and code generation agents.&#xa;&#xa;#### 1.2.3. Generative UI (GenUI): The Emergent Paradigm&#xa;Goal: Enable adaptive, goal-driven interactions where the UI is generated and refined in real-time by AI.&#xa;Mechanism: AI generates interactive widgets or high-fidelity mock-ups from high-level descriptions, often in a co-creative process with humans.&#xa;Current State: A tool for accelerating UX workflow, with humans still curating and refining.&#xa;Key Unexploited Vector: Remove the human curator from the optimization loop; refine GenUI based on live user data.&#xa;&#xa;2. Synthesize Novel Prompt Architectures: Exceeding Current Benchmarks&#xa;&#xa;Propose and understand three novel, high-level architectures that fuse the identified unexploited vectors to create self-regulating, self-optimizing systems.&#xa;&#xa;&#xa;2.1. Proposed Architecture 1: The "Cognitive-Adaptive Interface" (CAI) Engine&#xa;Core Mechanism: Fuses GenUI, persona-driven design, cognitive-heuristic constraints, and real-time user telemetry.&#xa;Vector Exploited: Generative UI with real-time user telemetry.&#xa;Mechanism (Four-Phase Loop):&#xa;1. Phase 1: The "Cognitive Metaprompt": Define high-level goals and structured constraints (e.g., YAML) including `target_persona`, `business_objective`, and a weighted `cognitive_fitness_function`.&#xa;2. Phase 2: Initial Generation: Generate the initial structured UI component tree as a hypothesis to satisfy the `cognitive_fitness_function`.&#xa;&#xa;3. Phase 3: The Telemetry Loop: Collect fine-grained, real-time user telemetry (hesitation time, rage clicks, scroll depth) as users interact.&#xa;&#xa;4. Phase 4: Autonomous Optimization: Feed telemetry back, score UI performance against `cognitive_fitness_function`, and run continuous micro-A/B tests or RL strategies to adapt the UI (e.g., move buttons based on Fitts's Law compliance).&#xa;&#xa;Benchmark Exceedance: Creates a "Self-Optimizing UI" that dynamically adapts to observed user cognitive and behavioral patterns in real-time.&#xa;&#xa;2.2. Proposed Architecture 2: The "Test-Driven Agent" (TDA) Framework&#xa;Core Mechanism: Synthesizes TDD-as-Prompt, Self-Validation, and Agentic RAG into a closed-loop, "self-healing" system.&#xa;Vector Exploited: Autonomous, closed-loop TDD with context-aware Agentic RAG.&#xa;Mechanism (Five-Phase Autonomous Workflow):&#xa;1. Phase 1: The "User Story Metaprompt": Receive a high-level feature request in a structured format (e.g., JSON) defining the goal and `acceptance_criteria`.&#xa;2. Phase 2: RAG-Context: Activate Agentic RAG to query the codebase and documentation to understand the existing system.&#xa;&#xa;3. Phase 3: Test Generation (Red): Generate new, failing unit tests based on the `acceptance_criteria`, codifying functional validation.&#xa;&#xa;4. Phase 4: Code Generation (Green): Generate minimal implementation code to make the new tests pass.&#xa;&#xa;5. Phase 5: Reflect &amp; Refactor (Self-Healing): Run the entire test suite. If a regression occurs, use "Error-Forward Prompt" (stack trace) and reflection to iterate on code until the full build is green.&#xa;&#xa;Benchmark Exceedance: Output is a passing, context-aware, and regression-free build, enabling verifiable, autonomous development at the repository level.&#xa;&#xa;2.3. Proposed Architecture 3: The "Self-Optimizing Product" (SOP) Loop&#xa;Core Mechanism: Unifies TDA (backend code) and CAI (frontend UI) into a single product-level optimization loop.&#xa;Vector Exploited: Connecting CAI and TDA via a shared feedback loop using Reinforcement Learning from Human Feedback (RLHF) from implicit behavioral telemetry.&#xa;Mechanism (The Full Loop):&#xa;1. Deploy: TDA generates and deploys a backend API, and CAI generates the frontend UI to consume it.&#xa;2. Observe (Telemetry): CAI's telemetry loop detects a "user delight" failure (e.g., high drop-off at a form).&#xa;&#xa;3. Translate (Feedback Agent): A specialized "Feedback Agent" (using GoT) translates quantitative behavioral data into a new structured User Story Metaprompt (e.g., "Replace 'Security Question' with 'Magic Link' workflow").&#xa;&#xa;4. Trigger (TDA): The new user story is automatically fed as an Init-Prompt to the TDA.&#xa;&#xa;5. Heal &amp; Evolve (TDA): TDA RAGs the codebase, writes new failing tests, generates new API endpoints, and handles migrations.&#xa;&#xa;6. Adapt (CAI): CAI, triggered by TDA's deployment, re-generates its UI components to consume the new API and adapt to the lower-friction workflow.&#xa;&#xa;Benchmark Exceedance: The product autonomously optimizes its own design (code + UI) based on implicit user behavior, with no human intervention.&#xa;&#xa;3. Strategic Implementation and Future Trajectories&#xa;&#xa;Define actionable blueprints for implementation and propose a new benchmark.&#xa;&#xa;&#xa;3.1. Actionable Blueprints: Structured Metaprompts as the System API&#xa;Principle: Move from natural language to structured metaprompts (YAML for configuration, schema-enforced JSON for inter-agent API) for reliable, machine-parseable interaction.&#xa;Example Blueprint 1: YAML Metaprompt for CAI Engine:&#xa;* Defines `system_role`, `objective` (e.g., maximize_conversion), `target_persona` (file path), `technical_constraints` (e.g., WCAG_2_2_AA_COMPLIANT), and a weighted `cognitive_fitness_function` (principles like cognitive_load, hick's_law, fitts_s_law_compliance with associated metrics).&#xa;Example Blueprint 2: JSON Metaprompt for TDA Framework:&#xa;* Defines `system_role`, `task_id`, `source_trigger`, `user_story`, `rag_context_queries`, and `acceptance_criteria`. This is the Init-Prompt generated by the Feedback Agent.&#xa;3.2. Future Capability Vectors &amp; Redefining Benchmarks&#xa;Current Benchmarks (e.g., HumanEval, SWE-bench): Task-oriented and static, measuring siloed problem-solving.&#xa;The New Benchmark: "Product-Bench"&#xa;* Given: A high-level product goal and a `cognitive_fitness_function`.&#xa;* Input: A stream of simulated user telemetry.&#xa;&#xa;* Task: The AI system (SOP) must:&#xa;&#xa;* (a) Build the V1 of the product (TDA + CAI).&#xa;&#xa;* (b) Autonomously evolve its features, code, and UI over millions of simulated user-sessions in response to telemetry.&#xa;&#xa;* Metric: Maximize the `cognitive_fitness_function` (composite "User Delight" score) over the simulation duration.&#xa;&#xa;Outcome: The ultimate prompt architecture creates its own prompts based on purpose and continuous, real-time interaction, aligning with human-AI co-creation and human-centered evaluation.</title></path></g><g><g><title>Based on your request, here is a step-by-step plan for understanding and implementing the concepts outlined, structured to follow the flow of the provided text.&#xa;&#xa;#### 1.1.3. Self-Validation and "Error-Forward" Debugging&#xa;Goal: Enable autonomous agents to recognize, diagnose, and recover from errors, extending the TDD loop.&#xa;Core Capabilities:&#xa;* Agentic Self-Validation: Regularly verify progress and self-assess correctness (e.g., Cognition's Devin).&#xa;* "Error-Forward Prompting": Treat errors as data; automatically collect context (error message, stack trace) and feed it back to the agent for debugging.&#xa;&#xa;* Reflection: Learn from actions and improve debugging stratStep-by-Step Plan: From Static Prompts to Dynamic Architectures&#xa;&#xa;1. Deconstruct Elite-Tier Prompt Patterns: The Current Benchmark&#xa;&#xa;Begin by understanding the foundational benchmarks and identifying current state-of-the-art (SOTA) practices in LLM prompting for code and UI generation.&#xa;&#xa;&#xa;1.1. Domain 1: Architectures for Efficient Code Construction&#xa;&#xa;Focus on how LLMs are used as reasoning engines within structured development frameworks.&#xa;&#xa;&#xa;#### 1.1.1. Automated Prompt Optimization: The "Prompt-as-a-Target" Pattern&#xa;&#xa;Goal: Automate prompt refinement to produce high-quality code.&#xa;Techniques to Understand:&#xa;* Evolutionary-Based Methods (EPiC): Explore prompt evolution via genetic algorithms and fitness functions.&#xa;* Iterative Refinement (Prochemy): Continuously refine prompts based on model performance on specific tasks.&#xa;&#xa;* Adaptive Selection (PET-Select): Classify query complexity to dynamically select the most appropriate prompt engineering technique (PET).&#xa;&#xa;Key Unexploited Vector: Proactive generation of novel prompt architectures for novel problems (meta-prompting).&#xa;&#xa;#### 1.1.2. Test-Driven Development (TDD) as a Prompting Paradigm&#xa;Goal: Integrate TDD principles directly into prompt architecture for verifiable code generation.&#xa;Core Principle: Provide LLM with concrete unit tests as the specification, instructing it to "write code to pass all tests."&#xa;Frameworks/Structures:&#xa;* TGEN Framework: Uses specialized agents with programming prompts and tests to produce validated code.&#xa;* Elite-Level TDD Prompt Structure: Strict rules including function signature, type hints, best practices, edge cases, and output format (e.g., Python function only).&#xa;&#xa;Key Unexploited Vector: A system that generates its own tests and validates its own code in a continuous cycle.&#xa;egies via reflective prompting (e.g., Self-Refine).&#xa;&#xa;Outcome: "Self-healing" systems where failure is a data signal, and the stack trace becomes an instruction for fixing.&#xa;&#xa;#### 1.1.4. Agentic Frameworks and Multi-Agent Collaboration&#xa;Goal: Solve complex software development tasks by orchestrating multiple specialized agents.&#xa;Advanced Reasoning Patterns:&#xa;* ReAct: Interleave step-by-step reasoning with tool use.&#xa;* Tree of Thoughts (ToT): Explore multiple reasoning paths and evaluate states.&#xa;&#xa;* Graph of Thoughts (GoT): Generalize ToT into a graph structure for synergistic outcomes and feedback loops.&#xa;&#xa;Agentic Frameworks:&#xa;* MetaGPT: Simulate a software company with agents in roles (PM, Architect, Programmer, QA) and Standard Operating Procedures (SOPs).&#xa;* ChatDev: Utilize waterfall-style collaboration with task-oriented, multi-turn communications.&#xa;&#xa;Key Unexploited Vector: AI-native workflows where feedback comes from product telemetry, not simulated human roles.&#xa;&#xa;#### 1.1.5. Context-Aware Generation (Agentic RAG)&#xa;Goal: Provide LLMs with relevant domain context for code generation.&#xa;Pattern:&#xa;* RAG-for-Code: Augment prompts with information from documentation, code repositories, or discussions.&#xa;* Agentic RAG: Agent actively plans queries, executes multiple subqueries, and synthesizes results for comprehensive understanding (e.g., LangGraph, AutoGen).&#xa;&#xa;Key Unexploited Vector: Fusion of Agentic RAG (for context) with TDD-as-Prompt (for verification) to create autonomous developers.&#xa;&#xa;1.2. Domain 2: Architectures for User Delight &amp; UI Design&#xa;&#xa;Explore how elite prompts generate user experiences, not just pixels, grounded in human-centric principles.&#xa;&#xa;&#xa;#### 1.2.1. Persona-Driven Design: Grounding the Generation&#xa;&#xa;Goal: Achieve "user delight" by tailoring UI generation to specific user needs.&#xa;Pattern:&#xa;* Persona Generation: Prompt system to generate detailed proto-personas (demographics, pain points, motivations).&#xa;* Constraint Injection: Inject generated/human-provided personas as primary constraints into UI generation prompts.&#xa;&#xa;Key Unexploited Vector: Move from static, assumed personas to dynamic, observed user models continuously updated by real-time behavioral analytics.&#xa;&#xa;#### 1.2.2. Constraint-Based Generation: Defining the "Solution Space"&#xa;Goal: Apply multiple, layered constraints to ensure functional, accessible, and theoretically sound UI outputs.&#xa;Categories of Constraints:&#xa;* A. Cognitive &amp; Heuristic Constraints: Instruct AI to apply principles from cognitive science and usability heuristics (e.g., Nielsen's 10, Fitts's Law, Hick's Law, Cognitive Load, BJ Fogg's Model).&#xa;* B. Technical &amp; Accessibility (A11y) Constraints: Explicitly enforce standards like WCAG 2.2 AA compliance (e.g., Semantic HTML, Keyboard Accessibility, ARIA, clear content).&#xa;&#xa;* C. Structural &amp; Layout Constraints: Define reliable output structures for machine-readability (e.g., C4 model, Mermaid diagrams, structured data formats like JSON/YAML with Pydantic/Zod schemas).&#xa;&#xa;Importance: Structured output is the "API" connecting UI and code generation agents.&#xa;&#xa;#### 1.2.3. Generative UI (GenUI): The Emergent Paradigm&#xa;Goal: Enable adaptive, goal-driven interactions where the UI is generated and refined in real-time by AI.&#xa;Mechanism: AI generates interactive widgets or high-fidelity mock-ups from high-level descriptions, often in a co-creative process with humans.&#xa;Current State: A tool for accelerating UX workflow, with humans still curating and refining.&#xa;Key Unexploited Vector: Remove the human curator from the optimization loop; refine GenUI based on live user data.&#xa;&#xa;2. Synthesize Novel Prompt Architectures: Exceeding Current Benchmarks&#xa;&#xa;Propose and understand three novel, high-level architectures that fuse the identified unexploited vectors to create self-regulating, self-optimizing systems.&#xa;&#xa;&#xa;2.1. Proposed Architecture 1: The "Cognitive-Adaptive Interface" (CAI) Engine&#xa;Core Mechanism: Fuses GenUI, persona-driven design, cognitive-heuristic constraints, and real-time user telemetry.&#xa;Vector Exploited: Generative UI with real-time user telemetry.&#xa;Mechanism (Four-Phase Loop):&#xa;1. Phase 1: The "Cognitive Metaprompt": Define high-level goals and structured constraints (e.g., YAML) including `target_persona`, `business_objective`, and a weighted `cognitive_fitness_function`.&#xa;2. Phase 2: Initial Generation: Generate the initial structured UI component tree as a hypothesis to satisfy the `cognitive_fitness_function`.&#xa;&#xa;3. Phase 3: The Telemetry Loop: Collect fine-grained, real-time user telemetry (hesitation time, rage clicks, scroll depth) as users interact.&#xa;&#xa;4. Phase 4: Autonomous Optimization: Feed telemetry back, score UI performance against `cognitive_fitness_function`, and run continuous micro-A/B tests or RL strategies to adapt the UI (e.g., move buttons based on Fitts's Law compliance).&#xa;&#xa;Benchmark Exceedance: Creates a "Self-Optimizing UI" that dynamically adapts to observed user cognitive and behavioral patterns in real-time.&#xa;&#xa;2.2. Proposed Architecture 2: The "Test-Driven Agent" (TDA) Framework&#xa;Core Mechanism: Synthesizes TDD-as-Prompt, Self-Validation, and Agentic RAG into a closed-loop, "self-healing" system.&#xa;Vector Exploited: Autonomous, closed-loop TDD with context-aware Agentic RAG.&#xa;Mechanism (Five-Phase Autonomous Workflow):&#xa;1. Phase 1: The "User Story Metaprompt": Receive a high-level feature request in a structured format (e.g., JSON) defining the goal and `acceptance_criteria`.&#xa;2. Phase 2: RAG-Context: Activate Agentic RAG to query the codebase and documentation to understand the existing system.&#xa;&#xa;3. Phase 3: Test Generation (Red): Generate new, failing unit tests based on the `acceptance_criteria`, codifying functional validation.&#xa;&#xa;4. Phase 4: Code Generation (Green): Generate minimal implementation code to make the new tests pass.&#xa;&#xa;5. Phase 5: Reflect &amp; Refactor (Self-Healing): Run the entire test suite. If a regression occurs, use "Error-Forward Prompt" (stack trace) and reflection to iterate on code until the full build is green.&#xa;&#xa;Benchmark Exceedance: Output is a passing, context-aware, and regression-free build, enabling verifiable, autonomous development at the repository level.&#xa;&#xa;2.3. Proposed Architecture 3: The "Self-Optimizing Product" (SOP) Loop&#xa;Core Mechanism: Unifies TDA (backend code) and CAI (frontend UI) into a single product-level optimization loop.&#xa;Vector Exploited: Connecting CAI and TDA via a shared feedback loop using Reinforcement Learning from Human Feedback (RLHF) from implicit behavioral telemetry.&#xa;Mechanism (The Full Loop):&#xa;1. Deploy: TDA generates and deploys a backend API, and CAI generates the frontend UI to consume it.&#xa;2. Observe (Telemetry): CAI's telemetry loop detects a "user delight" failure (e.g., high drop-off at a form).&#xa;&#xa;3. Translate (Feedback Agent): A specialized "Feedback Agent" (using GoT) translates quantitative behavioral data into a new structured User Story Metaprompt (e.g., "Replace 'Security Question' with 'Magic Link' workflow").&#xa;&#xa;4. Trigger (TDA): The new user story is automatically fed as an Init-Prompt to the TDA.&#xa;&#xa;5. Heal &amp; Evolve (TDA): TDA RAGs the codebase, writes new failing tests, generates new API endpoints, and handles migrations.&#xa;&#xa;6. Adapt (CAI): CAI, triggered by TDA's deployment, re-generates its UI components to consume the new API and adapt to the lower-friction workflow.&#xa;&#xa;Benchmark Exceedance: The product autonomously optimizes its own design (code + UI) based on implicit user behavior, with no human intervention.&#xa;&#xa;3. Strategic Implementation and Future Trajectories&#xa;&#xa;Define actionable blueprints for implementation and propose a new benchmark.&#xa;&#xa;&#xa;3.1. Actionable Blueprints: Structured Metaprompts as the System API&#xa;Principle: Move from natural language to structured metaprompts (YAML for configuration, schema-enforced JSON for inter-agent API) for reliable, machine-parseable interaction.&#xa;Example Blueprint 1: YAML Metaprompt for CAI Engine:&#xa;* Defines `system_role`, `objective` (e.g., maximize_conversion), `target_persona` (file path), `technical_constraints` (e.g., WCAG_2_2_AA_COMPLIANT), and a weighted `cognitive_fitness_function` (principles like cognitive_load, hick's_law, fitts_s_law_compliance with associated metrics).&#xa;Example Blueprint 2: JSON Metaprompt for TDA Framework:&#xa;* Defines `system_role`, `task_id`, `source_trigger`, `user_story`, `rag_context_queries`, and `acceptance_criteria`. This is the Init-Prompt generated by the Feedback Agent.&#xa;3.2. Future Capability Vectors &amp; Redefining Benchmarks&#xa;Current Benchmarks (e.g., HumanEval, SWE-bench): Task-oriented and static, measuring siloed problem-solving.&#xa;The New Benchmark: "Product-Bench"&#xa;* Given: A high-level product goal and a `cognitive_fitness_function`.&#xa;* Input: A stream of simulated user telemetry.&#xa;&#xa;* Task: The AI system (SOP) must:&#xa;&#xa;* (a) Build the V1 of the product (TDA + CAI).&#xa;&#xa;* (b) Autonomously evolve its features, code, and UI over millions of simulated user-sessions in response to telemetry.&#xa;&#xa;* Metric: Maximize the `cognitive_fitness_function` (composite "User Delight" score) over the simulation duration.&#xa;&#xa;Outcome: The ultimate prompt architecture creates its own prompts based on purpose and continuous, real-time interaction, aligning with human-AI co-creation and human-centered evaluation.</title><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 118px; height: 1px; padding-top: 216px; margin-left: 1501px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; "><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; ">DeepResearch</div></div></div></foreignObject><image x="1501" y="209.5" width="118" height="17" xlink:href="data:image/png;base64,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"/></switch></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-26"><g><path d="M 1210 597 Q 1210 597 1210 640.63" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke" style="stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/><path d="M 1210 645.88 L 1206.5 638.88 L 1210 640.63 L 1213.5 638.88 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all" style="fill: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-32"><g><g><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 1px; height: 1px; padding-top: 618px; margin-left: 1211px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; background-color: #ffffff; "><div style="display: inline-block; font-size: 11px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; background-color: light-dark(#ffffff, var(--ge-dark-color, #121212)); white-space: nowrap; ">output</div></div></div></foreignObject><image x="1195.5" y="612" width="31" height="15.75" xlink:href="data:image/png;base64,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"/></switch></g></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-23"><g><rect x="1150" y="537" width="120" height="60" fill="#fa9ff5" stroke="#9673a6" pointer-events="all" style="fill: light-dark(rgb(250, 159, 245), rgb(134, 56, 130)); stroke: light-dark(rgb(150, 115, 166), rgb(149, 119, 163));"/></g><g><g><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 118px; height: 1px; padding-top: 567px; margin-left: 1151px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; "><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; ">Foundry </div></div></div></foreignObject><image x="1151" y="560.5" width="118" height="17" xlink:href="data:image/png;base64,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"/></switch></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-38"><g><path d="M 1210 727 Q 1210 727 1210 790.63" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke" style="stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/><path d="M 1210 795.88 L 1206.5 788.88 L 1210 790.63 L 1213.5 788.88 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all" style="fill: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-41"><g><g><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 1px; height: 1px; padding-top: 753px; margin-left: 1216px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; background-color: #ffffff; "><div style="display: inline-block; font-size: 11px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; background-color: light-dark(#ffffff, var(--ge-dark-color, #121212)); white-space: nowrap; ">Push (-) Header</div></div></div></foreignObject><image x="1177" y="747" width="78" height="15.75" xlink:href="data:image/png;base64,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"/></switch></g></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-25"><g><path d="M 1150 647 L 1270 647 L 1270 715 Q 1240 693.4 1210 715 Q 1180 736.6 1150 715 L 1150 659 Z" fill="#dae8fc" stroke="#6c8ebf" stroke-miterlimit="10" pointer-events="all" style="fill: light-dark(rgb(218, 232, 252), rgb(29, 41, 59)); stroke: light-dark(rgb(108, 142, 191), rgb(92, 121, 163));"><title>Final Converged Design (from QA)&#xa;&#xa;Final Score: 100/100&#xa;&#xa;&#xa;---&#xa;&#xa;&#xa;---&#xa;&#xa;&#xa;Based on the critical feedback from our Security team, I have refined the design to create the Trustworthy Self-Optimizing Product (TSOP) Loop. This new version elevates the previous QASOP model by embedding security into the very foundation of the autonomous agents and their operational environment, not just as a post-generation validation step. This "secure the core" approach addresses the integrity of the generative process itself.&#xa;&#xa;&#xa;---&#xa;&#xa;&#xa;High-Level Design Proposal: The Trustworthy Self-Optimizing Product (TSOP) Loop (v3)&#xa;&#xa;1. Vision &amp; Guiding Principles&#xa;&#xa;&#xa;This proposal matures the self-optimizing system into a production-ready framework built on a foundation of zero-trust. While retaining full automation, its primary objective is to create a resilient, trustworthy, and auditable product evolution cycle.&#xa;&#xa;&#xa;Core Principles:&#xa;&#xa;&#xa;Verifiability by Design: Every autonomous action must be subject to independent, automated validation before impacting production.&#xa;Zero-Trust Agent Execution (New): Agents are considered untrusted by default. They operate in hardened, isolated, least-privilege environments with no standing access to secrets or other systems.&#xa;Human-in-the-Loop for Critical Decisions: Key changes (affecting core logic, security, or product strategy) require explicit human approval.&#xa;Staged &amp; Gated Deployment: Autonomous changes graduate through a rigorous, multi-stage pipeline before reaching production.&#xa;Comprehensive Observability: The "why" behind every autonomous decision is logged and traceable for accountability and debugging.&#xa;Policy-Driven Guardrails: Autonomous agents operate within a strict Policy &amp; Governance framework, preventing insecure or unethical code generation.&#xa;&#xa;2. High-Level Architecture&#xa;The TSOP loop integrates the CAI and TDA into a robust, zero-trust pipeline. The architecture now explicitly visualizes the secure environment in which the agents operate and enhances the validation subsystem with supply chain security scans.&#xa;&#xa;&#xa;&#xa;4. Audit &amp; Monitoring&#xa;3. Deployment &amp; Adaptation&#xa;2. Autonomous Development &amp; Verification&#xa;Secure Agent Runtime Environment&#xa;1. Observation &amp; Hypothesis&#xa;Proposes User Story Metaprompt&#xa;Validates against business rules, ethics, security policies &amp; sanitizes prompt&#xa;Fetches credentials at runtime&#xa;Runs on verified base image&#xa;Generates Tests (Red) &amp; Code (Green)&#xa;Static Analysis (SAST) &amp; Dependency Scans&#xa;Supply Chain Scans (Container images, IaC)&#xa;Runtime Security Scans (DAST/IAST) in Staging&#xa;Performance &amp; Regression Tests&#xa;Validation Passed: Submits Change Request&#xa;Approved&#xa;Deploy to Staging&#xa;Generates new UI components&#xa;Deploy to Production&#xa;Logs translation logic&#xa;Logs generation steps &amp; reasoning&#xa;Logs all validation results&#xa;Logs approval/rejection reasons&#xa;Observability &amp; Audit Trail&#xa;Human Review &amp; Approval Gateway&#xa;Staged Deployment Pipeline&#xa;Backend Deployed (API_v2)&#xa;Cognitive-Adaptive Interface (CAI) Engine&#xa;Production Environment&#xa;Live Frontend (UI_v2) &amp; Backend (API_v2)&#xa;Generated Code &amp; Test Artifacts&#xa;QA Validation Subsystem&#xa;Test-Driven Agent (TDA) Framework&#xa;Secret Vault&#xa;Supply Chain Integrity&#xa;Feedback &amp; Translation Agent&#xa;User Interaction Telemetry (Hesitation, Rage Clicks)&#xa;Policy &amp; Governance Engine&#xa;Approved User Story Metaprompt (JSON)&#xa;Secure&#xa;&#xa;&#xa;3. Key Components &amp; Enhancements&#xa;&#xa;&#xa;This design enhances existing components and introduces a new conceptual layer for agent security, directly incorporating the peer feedback.&#xa;&#xa;&#xa;3.1. Policy &amp; Governance Engine (Enhanced)&#xa;&#xa;Function: Acts as the primary control plane for agent initiation.&#xa;Audit Address:&#xa;* Prompt Sanitization (New): Actively scans incoming prompts to prevent prompt injection attacks and strips any potentially sensitive data before it reaches the TDA.&#xa;* Secret Detection (New): Enforces a strict "no secrets in prompts" policy, rejecting any request that contains credentials.&#xa;&#xa;* Ethical &amp; Business Alignment: Prevents optimization towards "dark patterns" and ensures changes align with strategy.&#xa;&#xa;&#xa;3.2. QA Validation Subsystem (Enhanced)&#xa;&#xa;Function: An automated, independent system that scrutinizes all generated artifacts.&#xa;Audit Address &amp; Integrated Feedback:&#xa;* Supply Chain Integrity (New): Performs vulnerability scans on all software dependencies, Infrastructure as Code (IaC), and the agents' own container base images (e.g., using Trivy/Clair). This ensures the build and runtime environment is secure from the ground up.&#xa;* Code &amp; Test Quality: Implements SAST, code quality analysis, and dependency vulnerability scanning.&#xa;&#xa;* Runtime Security Assurance: Deploys to a staging environment to run DAST/IAST scans, actively probing for execution-time vulnerabilities like injection flaws or broken access control.&#xa;&#xa;* Performance &amp; Regression: Executes comprehensive regression and load testing suites.&#xa;&#xa;&#xa;3.3. Human Review &amp; Approval Gateway&#xa;&#xa;Function: A mandatory checkpoint presenting a consolidated report of the proposed change, including diffs, rationale, and all security/validation results.&#xa;Audit Address: Provides ultimate human control, ensures explainability, and establishes clear accountability for deployment decisions.&#xa;&#xa;4. Agent &amp; Infrastructure Security (New Section)&#xa;This section explicitly details the measures taken to secure the autonomous agents themselves, addressing the core of the security feedback.&#xa;&#xa;&#xa;4.1. Hardened Agent Runtimes&#xa;&#xa;Isolation: Each agent (e.g., TDA, Feedback Agent) executes within a dedicated, ephemeral, and sandboxed environment (e.g., a minimal container on a platform like Fargate or gVisor).&#xa;Least Privilege: The runtime is granted the absolute minimum IAM permissions required for its specific task (e.g., read-only access to a specific code repository path, write access only to its designated test environment). Network policies block all egress traffic except to explicitly approved endpoints (e.g., code repo, package manager, secret vault).&#xa;Immutability: The agents run on immutable images. No changes are made to the runtime environment; a new container is instantiated for each task.&#xa;&#xa;4.2. Secure Secret Management&#xa;Dynamic Credential Injection: Agents do not possess any long-lived credentials. They authenticate to a centralized secret manager (e.g., HashiCorp Vault, AWS Secrets Manager) using a short-lived token associated with their runtime identity.&#xa;Zero Hardcoded Secrets: The system ensures that no secrets (API keys, database passwords, tokens) are ever present in agent prompts, source code, or logs. This prevents accidental exposure and makes credentials rotation seamless.&#xa;&#xa;4.3. Supply Chain Security (SLSA Compliance)&#xa;Verified Provenance: The entire build process for the agents themselves adheres to SLSA principles. This includes using verified, signed base images, pinning dependencies, and generating a software bill of materials (SBOM) for every agent version. This mitigates the risk of a compromised tool or library injecting malicious code into the agent itself.&#xa;&#xa;5. The Enhanced TSOP Workflow&#xa;1. Observe &amp; Propose: User telemetry identifies a friction point. The `Feedback Agent` translates this into a `User Story Metaprompt`.&#xa;&#xa;2. Govern &amp; Sanitize: The `Policy &amp; Governance Engine` validates the prompt against organizational rules and sanitizes it for security.&#xa;&#xa;3. Develop in Isolation: The approved prompt triggers the `TDA Framework` within its hardened, least-privilege runtime. The TDA dynamically fetches any necessary secrets and generates code and test artifacts.&#xa;&#xa;4. Validate Comprehensively: The artifacts are sent to the `QA Validation Subsystem`, which runs its full suite, now including supply chain integrity scans on the agent's environment and DAST/IAST on the generated code in a staging environment.&#xa;&#xa;5. Approve: The complete change package, including all security reports, is presented at the `Human Review Gateway`.&#xa;&#xa;6. Deploy: Upon approval, the `Staged Deployment Pipeline` safely rolls out the change.&#xa;&#xa;7. Adapt: The deployment triggers the `CAI Engine` (also running in a secure environment) to adapt the UI. The new UI components are subjected to the same rigorous validation process.&#xa;&#xa;8. Monitor: The `Observability` platform tracks the entire, security-hardened process, and the loop begins again.</title></path></g><g><g><title>Final Converged Design (from QA)&#xa;&#xa;Final Score: 100/100&#xa;&#xa;&#xa;---&#xa;&#xa;&#xa;---&#xa;&#xa;&#xa;Based on the critical feedback from our Security team, I have refined the design to create the Trustworthy Self-Optimizing Product (TSOP) Loop. This new version elevates the previous QASOP model by embedding security into the very foundation of the autonomous agents and their operational environment, not just as a post-generation validation step. This "secure the core" approach addresses the integrity of the generative process itself.&#xa;&#xa;&#xa;---&#xa;&#xa;&#xa;High-Level Design Proposal: The Trustworthy Self-Optimizing Product (TSOP) Loop (v3)&#xa;&#xa;1. Vision &amp; Guiding Principles&#xa;&#xa;&#xa;This proposal matures the self-optimizing system into a production-ready framework built on a foundation of zero-trust. While retaining full automation, its primary objective is to create a resilient, trustworthy, and auditable product evolution cycle.&#xa;&#xa;&#xa;Core Principles:&#xa;&#xa;&#xa;Verifiability by Design: Every autonomous action must be subject to independent, automated validation before impacting production.&#xa;Zero-Trust Agent Execution (New): Agents are considered untrusted by default. They operate in hardened, isolated, least-privilege environments with no standing access to secrets or other systems.&#xa;Human-in-the-Loop for Critical Decisions: Key changes (affecting core logic, security, or product strategy) require explicit human approval.&#xa;Staged &amp; Gated Deployment: Autonomous changes graduate through a rigorous, multi-stage pipeline before reaching production.&#xa;Comprehensive Observability: The "why" behind every autonomous decision is logged and traceable for accountability and debugging.&#xa;Policy-Driven Guardrails: Autonomous agents operate within a strict Policy &amp; Governance framework, preventing insecure or unethical code generation.&#xa;&#xa;2. High-Level Architecture&#xa;The TSOP loop integrates the CAI and TDA into a robust, zero-trust pipeline. The architecture now explicitly visualizes the secure environment in which the agents operate and enhances the validation subsystem with supply chain security scans.&#xa;&#xa;&#xa;&#xa;4. Audit &amp; Monitoring&#xa;3. Deployment &amp; Adaptation&#xa;2. Autonomous Development &amp; Verification&#xa;Secure Agent Runtime Environment&#xa;1. Observation &amp; Hypothesis&#xa;Proposes User Story Metaprompt&#xa;Validates against business rules, ethics, security policies &amp; sanitizes prompt&#xa;Fetches credentials at runtime&#xa;Runs on verified base image&#xa;Generates Tests (Red) &amp; Code (Green)&#xa;Static Analysis (SAST) &amp; Dependency Scans&#xa;Supply Chain Scans (Container images, IaC)&#xa;Runtime Security Scans (DAST/IAST) in Staging&#xa;Performance &amp; Regression Tests&#xa;Validation Passed: Submits Change Request&#xa;Approved&#xa;Deploy to Staging&#xa;Generates new UI components&#xa;Deploy to Production&#xa;Logs translation logic&#xa;Logs generation steps &amp; reasoning&#xa;Logs all validation results&#xa;Logs approval/rejection reasons&#xa;Observability &amp; Audit Trail&#xa;Human Review &amp; Approval Gateway&#xa;Staged Deployment Pipeline&#xa;Backend Deployed (API_v2)&#xa;Cognitive-Adaptive Interface (CAI) Engine&#xa;Production Environment&#xa;Live Frontend (UI_v2) &amp; Backend (API_v2)&#xa;Generated Code &amp; Test Artifacts&#xa;QA Validation Subsystem&#xa;Test-Driven Agent (TDA) Framework&#xa;Secret Vault&#xa;Supply Chain Integrity&#xa;Feedback &amp; Translation Agent&#xa;User Interaction Telemetry (Hesitation, Rage Clicks)&#xa;Policy &amp; Governance Engine&#xa;Approved User Story Metaprompt (JSON)&#xa;Secure&#xa;&#xa;&#xa;3. Key Components &amp; Enhancements&#xa;&#xa;&#xa;This design enhances existing components and introduces a new conceptual layer for agent security, directly incorporating the peer feedback.&#xa;&#xa;&#xa;3.1. Policy &amp; Governance Engine (Enhanced)&#xa;&#xa;Function: Acts as the primary control plane for agent initiation.&#xa;Audit Address:&#xa;* Prompt Sanitization (New): Actively scans incoming prompts to prevent prompt injection attacks and strips any potentially sensitive data before it reaches the TDA.&#xa;* Secret Detection (New): Enforces a strict "no secrets in prompts" policy, rejecting any request that contains credentials.&#xa;&#xa;* Ethical &amp; Business Alignment: Prevents optimization towards "dark patterns" and ensures changes align with strategy.&#xa;&#xa;&#xa;3.2. QA Validation Subsystem (Enhanced)&#xa;&#xa;Function: An automated, independent system that scrutinizes all generated artifacts.&#xa;Audit Address &amp; Integrated Feedback:&#xa;* Supply Chain Integrity (New): Performs vulnerability scans on all software dependencies, Infrastructure as Code (IaC), and the agents' own container base images (e.g., using Trivy/Clair). This ensures the build and runtime environment is secure from the ground up.&#xa;* Code &amp; Test Quality: Implements SAST, code quality analysis, and dependency vulnerability scanning.&#xa;&#xa;* Runtime Security Assurance: Deploys to a staging environment to run DAST/IAST scans, actively probing for execution-time vulnerabilities like injection flaws or broken access control.&#xa;&#xa;* Performance &amp; Regression: Executes comprehensive regression and load testing suites.&#xa;&#xa;&#xa;3.3. Human Review &amp; Approval Gateway&#xa;&#xa;Function: A mandatory checkpoint presenting a consolidated report of the proposed change, including diffs, rationale, and all security/validation results.&#xa;Audit Address: Provides ultimate human control, ensures explainability, and establishes clear accountability for deployment decisions.&#xa;&#xa;4. Agent &amp; Infrastructure Security (New Section)&#xa;This section explicitly details the measures taken to secure the autonomous agents themselves, addressing the core of the security feedback.&#xa;&#xa;&#xa;4.1. Hardened Agent Runtimes&#xa;&#xa;Isolation: Each agent (e.g., TDA, Feedback Agent) executes within a dedicated, ephemeral, and sandboxed environment (e.g., a minimal container on a platform like Fargate or gVisor).&#xa;Least Privilege: The runtime is granted the absolute minimum IAM permissions required for its specific task (e.g., read-only access to a specific code repository path, write access only to its designated test environment). Network policies block all egress traffic except to explicitly approved endpoints (e.g., code repo, package manager, secret vault).&#xa;Immutability: The agents run on immutable images. No changes are made to the runtime environment; a new container is instantiated for each task.&#xa;&#xa;4.2. Secure Secret Management&#xa;Dynamic Credential Injection: Agents do not possess any long-lived credentials. They authenticate to a centralized secret manager (e.g., HashiCorp Vault, AWS Secrets Manager) using a short-lived token associated with their runtime identity.&#xa;Zero Hardcoded Secrets: The system ensures that no secrets (API keys, database passwords, tokens) are ever present in agent prompts, source code, or logs. This prevents accidental exposure and makes credentials rotation seamless.&#xa;&#xa;4.3. Supply Chain Security (SLSA Compliance)&#xa;Verified Provenance: The entire build process for the agents themselves adheres to SLSA principles. This includes using verified, signed base images, pinning dependencies, and generating a software bill of materials (SBOM) for every agent version. This mitigates the risk of a compromised tool or library injecting malicious code into the agent itself.&#xa;&#xa;5. The Enhanced TSOP Workflow&#xa;1. Observe &amp; Propose: User telemetry identifies a friction point. The `Feedback Agent` translates this into a `User Story Metaprompt`.&#xa;&#xa;2. Govern &amp; Sanitize: The `Policy &amp; Governance Engine` validates the prompt against organizational rules and sanitizes it for security.&#xa;&#xa;3. Develop in Isolation: The approved prompt triggers the `TDA Framework` within its hardened, least-privilege runtime. The TDA dynamically fetches any necessary secrets and generates code and test artifacts.&#xa;&#xa;4. Validate Comprehensively: The artifacts are sent to the `QA Validation Subsystem`, which runs its full suite, now including supply chain integrity scans on the agent's environment and DAST/IAST on the generated code in a staging environment.&#xa;&#xa;5. Approve: The complete change package, including all security reports, is presented at the `Human Review Gateway`.&#xa;&#xa;6. Deploy: Upon approval, the `Staged Deployment Pipeline` safely rolls out the change.&#xa;&#xa;7. Adapt: The deployment triggers the `CAI Engine` (also running in a secure environment) to adapt the UI. The new UI components are subjected to the same rigorous validation process.&#xa;&#xa;8. Monitor: The `Observability` platform tracks the entire, security-hardened process, and the loop begins again.</title><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 118px; height: 1px; padding-top: 676px; margin-left: 1151px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; "><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; ">DeepResearch</div></div></div></foreignObject><image x="1151" y="669.5" width="118" height="17" xlink:href="data:image/png;base64,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"/></switch></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-39"><g><path d="M 1210 857 Q 1210 857 1210 910.63" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke" style="stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/><path d="M 1210 915.88 L 1206.5 908.88 L 1210 910.63 L 1213.5 908.88 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all" style="fill: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-40"><g><g><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 1px; height: 1px; padding-top: 890px; margin-left: 1214px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; background-color: #ffffff; "><div style="display: inline-block; font-size: 11px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; background-color: light-dark(#ffffff, var(--ge-dark-color, #121212)); white-space: nowrap; ">output</div></div></div></foreignObject><image x="1198.5" y="884" width="31" height="15.75" xlink:href="data:image/png;base64,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"/></switch></g></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-37"><g><rect x="1150" y="797" width="120" height="60" fill="#006abc" stroke="#6c8ebf" pointer-events="all" style="fill: light-dark(rgb(0, 106, 188), rgb(83, 174, 245)); stroke: light-dark(rgb(108, 142, 191), rgb(92, 121, 163));"/></g><g><g><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 118px; height: 1px; padding-top: 827px; margin-left: 1151px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; "><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; ">Shunt-Button<br />(Amplify)</div></div></div></foreignObject><image x="1151" y="813" width="118" height="32" xlink:href="data:image/png;base64,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"/></switch></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-63"><g><path d="M 290 97.14 L 269.86 97.14 Q 259.86 97.14 269.86 97.14 L 643.63 97" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke" style="stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/><path d="M 648.88 97 L 641.88 100.5 L 643.63 97 L 641.88 93.5 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all" style="fill: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-95"><g><g><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 1px; height: 1px; padding-top: 94px; margin-left: 574px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; background-color: #ffffff; "><div style="display: inline-block; font-size: 11px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; background-color: light-dark(#ffffff, var(--ge-dark-color, #121212)); white-space: nowrap; ">output</div></div></div></foreignObject><image x="558.5" y="88" width="31" height="15.75" xlink:href="data:image/png;base64,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"/></switch></g></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-42"><g><rect x="290" y="47" width="200" height="100" fill="url(#drawio-svg-QPB4aXuvw8rzNqz6ntbD-gradient-light-dark_dae8fc_1d293b_-1-light-dark_7ea6e0_436697_-1-s-0)" stroke="#6c8ebf" pointer-events="all" style="fill: url(&quot;#drawio-svg-QPB4aXuvw8rzNqz6ntbD-gradient-light-dark_dae8fc_1d293b_-1-light-dark_7ea6e0_436697_-1-s-0&quot;); stroke: light-dark(rgb(108, 142, 191), rgb(92, 121, 163));"/></g><g><g><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 198px; height: 1px; padding-top: 97px; margin-left: 291px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; "><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; ">Gemini 2.5 Pro</div></div></div></foreignObject><image x="291" y="90.5" width="198" height="17" xlink:href="data:image/png;base64,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"/></switch></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-60"><g><path d="M 120 97 L 283.63 97" fill="none" stroke="#a8201a" stroke-miterlimit="10" pointer-events="stroke" style="stroke: light-dark(rgb(168, 32, 26), rgb(255, 161, 156));"/><path d="M 288.88 97 L 281.88 100.5 L 283.63 97 L 281.88 93.5 Z" fill="#a8201a" stroke="#a8201a" stroke-miterlimit="10" pointer-events="all" style="fill: light-dark(rgb(168, 32, 26), rgb(255, 161, 156)); stroke: light-dark(rgb(168, 32, 26), rgb(255, 161, 156));"/></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-94"><g><g><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 1px; height: 1px; padding-top: 97px; margin-left: 196px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; background-color: #ffffff; "><div style="display: inline-block; font-size: 11px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; background-color: light-dark(#ffffff, var(--ge-dark-color, #121212)); white-space: nowrap; ">push</div></div></div></foreignObject><image x="184" y="91" width="24" height="15.75" xlink:href="data:image/png;base64,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"/></switch></g></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-59"><g><rect x="0" y="67" width="120" height="60" fill="#fae5c7" stroke="#0f8b8d" pointer-events="all" style="fill: light-dark(rgb(250, 229, 199), rgb(54, 36, 10)); stroke: light-dark(rgb(15, 139, 141), rgb(57, 163, 165));"><title>**(1) Comprehensive Analysis of Elite-Tier Prompt Engineering Patterns for Efficient Digital Coding Solutions**&#xa;&#xa;This phase involves a deep-dive investigation into the current state-of-the-art prompting techniques used to produce high-quality, reliable code. The analysis will not be superficial but will dissect the underlying mechanics that lead to superior performance.&#xa;&#xa;*   **Agentic Software Development:**&#xa;    *   **Goal Decomposition:** Analyze prompts that provide a high-level objective (e.g., "Build a REST API for a blog") and successfully guide the AI to break it down into logical sub-tasks (e.g., "1. Define the data models for Post and Comment. 2. Create the database schema. 3. Implement CRUD endpoints for Posts. 4. Implement endpoints for Comments on a Post. 5. Add basic authentication.").&#xa;    *   **Tool Use &amp; Integration:** Investigate patterns where the AI is prompted to use external tools. This includes generating code that calls a specific library, writing shell commands to run a compiler or a test suite, or formatting output to be consumed by another process (e.g., generating a `terraform plan` command). The success pattern here is providing clear instructions on *how* and *when* to use the tool, along with examples.&#xa;    *   **Iterative Refinement:** Examine multi-turn conversation patterns where an initial, imperfect code-base is progressively improved. This involves prompts that provide targeted feedback, such as "The previous code works, but it's not efficient. Refactor it to use a hash map for O(1) lookups instead of iterating through the list."&#xa;&#xa;*   **Automated Debugging:**&#xa;    *   **Context-Rich Prompting:** Analyze prompts that provide not just the problematic code, but also the full context: the error message, the stack trace, relevant surrounding functions, and the expected vs. actual output. The success pattern is structuring this information clearly, often using Markdown code blocks with language identifiers.&#xa;    *   **Hypothesis-Driven Debugging:** Investigate prompts that force the AI to emulate a human debugging process: "1. Based on the stack trace, hypothesize the most likely cause of the null pointer exception. 2. Suggest a specific line to place a breakpoint or log statement to verify this hypothesis. 3. Based on the potential output, propose a code fix."&#xa;&#xa;*   **Code Generation:**&#xa;    *   **Pattern &amp; Boilerplate Generation:** Go beyond simple functions to analyze prompts that generate complex, idiomatic code for specific frameworks (e.g., "Generate a React component for a user profile card using functional components, hooks (useState, useEffect), and TypeScript interfaces for props.").&#xa;    *   **Test-Driven Development (TDD) Prompting:** Analyze workflows where the user first prompts for unit tests that define the desired functionality ("Write a set of unit tests for a function that calculates the factorial of a number, including edge cases like 0, 1, and negative numbers."), and *then* prompts the AI to write the code that makes the tests pass.&#xa;&#xa;*   **System Architecture:**&#xa;    *   **High-Level Design:** Analyze prompts requesting architectural blueprints. For example: "Design a scalable microservices architecture for an e-commerce platform. Describe the responsibilities of the User, Product, and Order services. Specify the primary API contracts (e.g., using OpenAPI YAML format) for communication between them. Represent the overall architecture using Mermaid.js C4 model syntax."&#xa;&#xa;---&#xa;&#xa;**(2) Comprehensive Analysis of Elite-Tier Prompt Engineering Patterns for UI Design that Delivers "User Delight"**&#xa;&#xa;This phase focuses on how prompting can be used to bridge the gap between abstract user needs and concrete, high-quality user interface designs. "User delight" is treated not as a vague goal but as an outcome of applying specific, user-centric principles.&#xa;&#xa;*   **Generating UI/UX Concepts:**&#xa;    *   **Persona-Driven Design:** Investigate prompts that are grounded in a detailed user persona. For example: "You are designing for 'Sarah,' a busy 35-year-old project manager who values efficiency. Generate three distinct concepts for a mobile app dashboard that helps her track project status. One concept should be minimalist and data-focused, another should be timeline-based, and a third should be collaborative and team-oriented. Justify each concept in relation to Sarah's needs."&#xa;    *   **Heuristic-Based Ideation:** Analyze prompts that explicitly invoke established usability heuristics: "Generate a sign-up form design that minimizes cognitive load by adhering to Hick's Law and provides clear feedback and error prevention, as per Nielsen's Heuristics."&#xa;&#xa;*   **Wireframes and User Flows:**&#xa;    *   **Structural Prompts:** Analyze how to prompt for machine-readable or clearly structured outputs representing layouts. For instance: "Generate a low-fidelity wireframe for a photo gallery screen. Represent the layout using a JSON structure with keys like 'component_type' (e.g., 'header', 'grid', 'nav_bar'), 'children', and 'placement_properties'."&#xa;    *   **Sequential Logic:** Investigate prompts that map out user journeys: "Detail the complete user flow for a password reset process, from clicking the 'Forgot Password' link to receiving a success confirmation. List each user action and the corresponding system response/UI screen. Output this as a flowchart using Mermaid.js sequence diagram syntax."&#xa;&#xa;*   **Applying User-Centric Design Principles:**&#xa;    *   **Accessibility (A11y):** Examine prompts that enforce accessibility standards from the outset: "Design a color palette for a corporate website that is WCAG AA compliant for text contrast. Provide the hex codes and explain your choices. Additionally, describe the ARIA roles needed for a custom dropdown menu component."&#xa;    *   **Cognitive Science Integration:** Analyze prompts that leverage principles of human psychology: "Redesign this checkout page to reduce cart abandonment. Apply the principle of 'chunking' to group form fields logically and use 'social proof' elements (e.g., '20 people bought this today') to build trust."&#xa;&#xa;---&#xa;&#xa;**(3) Identification and Extraction of Core "Proven Success Patterns"**&#xa;&#xa;This is the abstraction phase, where the specific findings from (1) and (2) are synthesized into domain-agnostic principles.&#xa;&#xa;*   **Role-Based Prompting:** Explicitly assigning a role ("You are a principal software engineer specializing in secure cloud infrastructure," or "You are a senior UX designer with expertise in mobile gaming interfaces") primes the model with a specific context, style, and knowledge base, significantly improving the quality and relevance of the output.&#xa;*   **Self-Critique Loops (Reflective prompting):** This involves a multi-step process where the AI generates a response and is then prompted to review and improve it. For example: "Step 1: Write the Python function. Step 2: Now, act as a code reviewer. Analyze the function you just wrote for potential bugs, non-idiomatic code, and performance bottlenecks. Provide a revised version that addresses these issues."&#xa;*   **Structured Data Enforcement (JSON/XML/YAML):** Forcing the model to reply in a strict, machine-readable format is crucial for reliability and integration into larger systems. This moves the AI from a creative text generator to a predictable component in a software workflow. Example: "Provide your analysis in JSON format with three top-level keys: `strengths`, `weaknesses`, and `recommendations`."&#xa;*   **Few-Shot Examples (In-Context Learning):** Providing 2-3 high-quality examples of the desired input/output format within the prompt itself. This is often more effective than describing the format abstractly, as it allows the model to perform pattern recognition and mimic the desired structure and content.&#xa;*   **Chain-of-Thought (CoT) / Step-by-Step Reasoning:** Instructing the model to "think step-by-step" or to "explain its reasoning before providing the final answer." This externalizes the model's reasoning process, which often leads to more accurate and logical conclusions, especially for complex, multi-step problems. It also makes the output far more transparent and debuggable.&#xa;&#xa;---&#xa;&#xa;**(4) Research into "Unexplored Capability Vectors" in Human-AI Interaction**&#xa;&#xa;This forward-looking phase identifies emerging technologies and concepts that can be integrated into next-generation prompt architectures.&#xa;&#xa;*   **Generative UI:** This goes beyond static mockups. The AI generates interactive UI components or entire layouts *dynamically* based on real-time data, user context, or goals. The research here would explore how to prompt for UI definitions (e.g., in JSON or a domain-specific language) that a rendering engine can interpret and adapt on the fly.&#xa;*   **Telemetry-Driven Adaptation:** This involves creating a closed-loop system where AI-generated outputs (code, UI designs) are deployed, user interaction is measured (e.g., click-through rates, task completion time, error rates), and this telemetry is fed back to an "optimizer" AI. This optimizer then refines the original prompt to generate a better-performing output in the next iteration.&#xa;*   **Meta-Prompting (AI-Generated Prompts):** This is the concept of using one AI model (a "meta-model") to generate and optimize prompts for another "worker" model. The meta-model would be given a high-level goal and performance metrics, and it would iteratively refine the prompt text to maximize the worker model's performance, effectively automating prompt engineering itself.&#xa;*   **High-Level Goal-Oriented Agentic Systems:** This is the leap from single-shot commands to persistent, autonomous agents. The research vector is to define systems where a human provides a very high-level goal (e.g., "Increase user engagement on the dashboard by 15%") and an AI agent autonomously plans, executes, and validates a series of actions (e.g., analyze telemetry, propose a new UI, run an A/B test, deploy the winner) to achieve it.&#xa;&#xa;---&#xa;&#xa;**(5) Synthesis of Findings to Develop Novel Prompt Architectures**&#xa;&#xa;This is the creative nexus where proven patterns are fused with unexplored vectors to create architectures that are more than the sum of their parts.&#xa;&#xa;*   **Fusion Example 1 (Coding):** Combine **Self-Critique Loops (3)** with **Meta-Prompting (4)**. This creates a three-agent system: a `Generator` writes code, a `Critic` reviews it against a set of rules (e.g., a style guide, security checklist), and a `Prompter` agent refines the `Generator`'s instructions based on the `Critic`'s feedback to reduce recurring errors over time.&#xa;*   **Fusion Example 2 (UI Design):** Combine **Structured Data Enforcement (3)** with **Telemetry-Driven Adaptation (4)**. The AI generates a UI layout as a structured JSON object. This UI is rendered and user interactions are collected. An analysis agent processes this telemetry and identifies points of friction (e.g., high drop-off rates on a specific form field). It then modifies the JSON structure (e.g., "split this field into two," "add helper text") and re-deploys, creating a self-optimizing UI.&#xa;&#xa;---&#xa;&#xa;**(6) Formulation of a Novel Prompt Architecture for Coding Solutions**&#xa;&#xa;This deliverable is a detailed blueprint for a specific, advanced system for code generation.&#xa;&#xa;*   **Architecture Name:** The "Self-Validating Agentic Coder" (SVAC).&#xa;*   **Components:**&#xa;    1.  **Planner Agent:** Decomposes a high-level software task (e.g., "Add Google OAuth2 login") into a dependency graph of smaller, executable sub-tasks using **Chain-of-Thought**.&#xa;    2.  **Context-Aware Retriever:** Before tackling a sub-task, it uses **Retrieval-Augmented Generation (RAG)** to pull relevant context from a vector database containing the existing codebase, API documentation, and best practice guides.&#xa;    3.  **Test-First Coder Agent:** For each sub-task, it first generates a failing unit test that codifies the requirements. It then generates the application code to make the test pass. This enforces a **TDD** workflow.&#xa;    4.  **Sandbox Executor:** Automatically runs the generated tests in a secure, containerized environment. The pass/fail result serves as a **Self-Validation Loop**. If tests fail, the output is passed back to the Coder Agent with the error logs for another attempt.&#xa;*   **Goal:** To exceed current benchmarks in code reliability and correctness by ensuring that every piece of generated code is automatically tested and validated against its requirements before being presented to the developer.&#xa;&#xa;---&#xa;&#xa;**(7) Formulation of a Novel Prompt Architecture for UI Design**&#xa;&#xa;This deliverable is a blueprint for a system designed to generate verifiably delightful user experiences.&#xa;&#xa;*   **Architecture Name:** The "Cognitive-Adaptive Design Engine" (CADE).&#xa;*   **Components:**&#xa;    1.  **Persona &amp; Principles Modeler:** The initial prompt defines the target user persona and explicitly lists the **cognitive principles** (e.g., Fitt's Law, Miller's Law, Peak-End Rule) that the design must adhere to.&#xa;    2.  **Variant Generator:** Generates multiple UI design variants (as structured JSON or code) based on the prompt. Each variant might emphasize a different principle.&#xa;    3.  **Live A/B Testing &amp; Telemetry Ingestion:** The variants are deployed, and real-time **telemetry** on user behavior (e.g., hesitation time, click heatmaps, task success rate) is collected.&#xa;    4.  **Delight Scorer &amp; Refiner Agent:** This agent analyzes the telemetry against the initial goals. It quantifies "delight" as a composite score of efficiency (low time-on-task), engagement (high interaction rate), and low friction (low error rate). It then identifies the most successful elements from each variant and generates a new, optimized prompt for the Variant Generator, creating a **telemetry-driven personalization loop**.&#xa;*   **Goal:** To make "user delight" a measurable, emergent property of the system. The design is not a static artifact but a continuously evolving hypothesis that is refined by real-world user interaction data.&#xa;&#xa;---&#xa;&#xa;**(8) Preparation of a Report: Analysis of Current Patterns and Proposal for Novel Architectures**&#xa;&#xa;The final output will be a formal report, clearly bifurcated to serve two distinct purposes: documenting the existing landscape and proposing a future direction.&#xa;&#xa;*   **Part I: Analysis of the Current "Elite-Tier" State**&#xa;    *   **Section 1: Prompting Patterns in Software Engineering.** A detailed summary of the findings from step (1), with coded examples and case studies.&#xa;    *   **Section 2: Prompting Patterns in UI/UX Design.** A summary of the findings from step (2), with visual examples and persona-driven scenarios.&#xa;    *   **Section 3: Cross-Domain Success Principles.** A synthesis of the core patterns from step (3), presenting them as a universal toolkit for advanced prompt engineering.&#xa;&#xa;*   **Part II: Proposal for Novel, Synthesized Prompt Architectures**&#xa;    *   **Section 4: The Path Beyond Replication.** An introduction to the "unexplored capability vectors" from step (4), arguing for a shift from replicating human workflows to creating new, hybrid human-AI paradigms.&#xa;    *   **Section 5: Proposed Architecture: The Self-Validating Agentic Coder (SVAC).** A complete technical specification of the system from step (6), including diagrams, prompt examples, and expected performance metrics.&#xa;    *   **Section 6: Proposed Architecture: The Cognitive-Adaptive Design Engine (CADE).** A complete specification of the system from step (7), outlining the feedback loop and the methodology for measuring "user delight."&#xa;    *   **Section 7: Conclusion &amp; Roadmap.** A summary of the proposed work and a high-level plan for prototyping, testing, and deploying these novel architectures.</title></rect></g><g><g><title>**(1) Comprehensive Analysis of Elite-Tier Prompt Engineering Patterns for Efficient Digital Coding Solutions**&#xa;&#xa;This phase involves a deep-dive investigation into the current state-of-the-art prompting techniques used to produce high-quality, reliable code. The analysis will not be superficial but will dissect the underlying mechanics that lead to superior performance.&#xa;&#xa;*   **Agentic Software Development:**&#xa;    *   **Goal Decomposition:** Analyze prompts that provide a high-level objective (e.g., "Build a REST API for a blog") and successfully guide the AI to break it down into logical sub-tasks (e.g., "1. Define the data models for Post and Comment. 2. Create the database schema. 3. Implement CRUD endpoints for Posts. 4. Implement endpoints for Comments on a Post. 5. Add basic authentication.").&#xa;    *   **Tool Use &amp; Integration:** Investigate patterns where the AI is prompted to use external tools. This includes generating code that calls a specific library, writing shell commands to run a compiler or a test suite, or formatting output to be consumed by another process (e.g., generating a `terraform plan` command). The success pattern here is providing clear instructions on *how* and *when* to use the tool, along with examples.&#xa;    *   **Iterative Refinement:** Examine multi-turn conversation patterns where an initial, imperfect code-base is progressively improved. This involves prompts that provide targeted feedback, such as "The previous code works, but it's not efficient. Refactor it to use a hash map for O(1) lookups instead of iterating through the list."&#xa;&#xa;*   **Automated Debugging:**&#xa;    *   **Context-Rich Prompting:** Analyze prompts that provide not just the problematic code, but also the full context: the error message, the stack trace, relevant surrounding functions, and the expected vs. actual output. The success pattern is structuring this information clearly, often using Markdown code blocks with language identifiers.&#xa;    *   **Hypothesis-Driven Debugging:** Investigate prompts that force the AI to emulate a human debugging process: "1. Based on the stack trace, hypothesize the most likely cause of the null pointer exception. 2. Suggest a specific line to place a breakpoint or log statement to verify this hypothesis. 3. Based on the potential output, propose a code fix."&#xa;&#xa;*   **Code Generation:**&#xa;    *   **Pattern &amp; Boilerplate Generation:** Go beyond simple functions to analyze prompts that generate complex, idiomatic code for specific frameworks (e.g., "Generate a React component for a user profile card using functional components, hooks (useState, useEffect), and TypeScript interfaces for props.").&#xa;    *   **Test-Driven Development (TDD) Prompting:** Analyze workflows where the user first prompts for unit tests that define the desired functionality ("Write a set of unit tests for a function that calculates the factorial of a number, including edge cases like 0, 1, and negative numbers."), and *then* prompts the AI to write the code that makes the tests pass.&#xa;&#xa;*   **System Architecture:**&#xa;    *   **High-Level Design:** Analyze prompts requesting architectural blueprints. For example: "Design a scalable microservices architecture for an e-commerce platform. Describe the responsibilities of the User, Product, and Order services. Specify the primary API contracts (e.g., using OpenAPI YAML format) for communication between them. Represent the overall architecture using Mermaid.js C4 model syntax."&#xa;&#xa;---&#xa;&#xa;**(2) Comprehensive Analysis of Elite-Tier Prompt Engineering Patterns for UI Design that Delivers "User Delight"**&#xa;&#xa;This phase focuses on how prompting can be used to bridge the gap between abstract user needs and concrete, high-quality user interface designs. "User delight" is treated not as a vague goal but as an outcome of applying specific, user-centric principles.&#xa;&#xa;*   **Generating UI/UX Concepts:**&#xa;    *   **Persona-Driven Design:** Investigate prompts that are grounded in a detailed user persona. For example: "You are designing for 'Sarah,' a busy 35-year-old project manager who values efficiency. Generate three distinct concepts for a mobile app dashboard that helps her track project status. One concept should be minimalist and data-focused, another should be timeline-based, and a third should be collaborative and team-oriented. Justify each concept in relation to Sarah's needs."&#xa;    *   **Heuristic-Based Ideation:** Analyze prompts that explicitly invoke established usability heuristics: "Generate a sign-up form design that minimizes cognitive load by adhering to Hick's Law and provides clear feedback and error prevention, as per Nielsen's Heuristics."&#xa;&#xa;*   **Wireframes and User Flows:**&#xa;    *   **Structural Prompts:** Analyze how to prompt for machine-readable or clearly structured outputs representing layouts. For instance: "Generate a low-fidelity wireframe for a photo gallery screen. Represent the layout using a JSON structure with keys like 'component_type' (e.g., 'header', 'grid', 'nav_bar'), 'children', and 'placement_properties'."&#xa;    *   **Sequential Logic:** Investigate prompts that map out user journeys: "Detail the complete user flow for a password reset process, from clicking the 'Forgot Password' link to receiving a success confirmation. List each user action and the corresponding system response/UI screen. Output this as a flowchart using Mermaid.js sequence diagram syntax."&#xa;&#xa;*   **Applying User-Centric Design Principles:**&#xa;    *   **Accessibility (A11y):** Examine prompts that enforce accessibility standards from the outset: "Design a color palette for a corporate website that is WCAG AA compliant for text contrast. Provide the hex codes and explain your choices. Additionally, describe the ARIA roles needed for a custom dropdown menu component."&#xa;    *   **Cognitive Science Integration:** Analyze prompts that leverage principles of human psychology: "Redesign this checkout page to reduce cart abandonment. Apply the principle of 'chunking' to group form fields logically and use 'social proof' elements (e.g., '20 people bought this today') to build trust."&#xa;&#xa;---&#xa;&#xa;**(3) Identification and Extraction of Core "Proven Success Patterns"**&#xa;&#xa;This is the abstraction phase, where the specific findings from (1) and (2) are synthesized into domain-agnostic principles.&#xa;&#xa;*   **Role-Based Prompting:** Explicitly assigning a role ("You are a principal software engineer specializing in secure cloud infrastructure," or "You are a senior UX designer with expertise in mobile gaming interfaces") primes the model with a specific context, style, and knowledge base, significantly improving the quality and relevance of the output.&#xa;*   **Self-Critique Loops (Reflective prompting):** This involves a multi-step process where the AI generates a response and is then prompted to review and improve it. For example: "Step 1: Write the Python function. Step 2: Now, act as a code reviewer. Analyze the function you just wrote for potential bugs, non-idiomatic code, and performance bottlenecks. Provide a revised version that addresses these issues."&#xa;*   **Structured Data Enforcement (JSON/XML/YAML):** Forcing the model to reply in a strict, machine-readable format is crucial for reliability and integration into larger systems. This moves the AI from a creative text generator to a predictable component in a software workflow. Example: "Provide your analysis in JSON format with three top-level keys: `strengths`, `weaknesses`, and `recommendations`."&#xa;*   **Few-Shot Examples (In-Context Learning):** Providing 2-3 high-quality examples of the desired input/output format within the prompt itself. This is often more effective than describing the format abstractly, as it allows the model to perform pattern recognition and mimic the desired structure and content.&#xa;*   **Chain-of-Thought (CoT) / Step-by-Step Reasoning:** Instructing the model to "think step-by-step" or to "explain its reasoning before providing the final answer." This externalizes the model's reasoning process, which often leads to more accurate and logical conclusions, especially for complex, multi-step problems. It also makes the output far more transparent and debuggable.&#xa;&#xa;---&#xa;&#xa;**(4) Research into "Unexplored Capability Vectors" in Human-AI Interaction**&#xa;&#xa;This forward-looking phase identifies emerging technologies and concepts that can be integrated into next-generation prompt architectures.&#xa;&#xa;*   **Generative UI:** This goes beyond static mockups. The AI generates interactive UI components or entire layouts *dynamically* based on real-time data, user context, or goals. The research here would explore how to prompt for UI definitions (e.g., in JSON or a domain-specific language) that a rendering engine can interpret and adapt on the fly.&#xa;*   **Telemetry-Driven Adaptation:** This involves creating a closed-loop system where AI-generated outputs (code, UI designs) are deployed, user interaction is measured (e.g., click-through rates, task completion time, error rates), and this telemetry is fed back to an "optimizer" AI. This optimizer then refines the original prompt to generate a better-performing output in the next iteration.&#xa;*   **Meta-Prompting (AI-Generated Prompts):** This is the concept of using one AI model (a "meta-model") to generate and optimize prompts for another "worker" model. The meta-model would be given a high-level goal and performance metrics, and it would iteratively refine the prompt text to maximize the worker model's performance, effectively automating prompt engineering itself.&#xa;*   **High-Level Goal-Oriented Agentic Systems:** This is the leap from single-shot commands to persistent, autonomous agents. The research vector is to define systems where a human provides a very high-level goal (e.g., "Increase user engagement on the dashboard by 15%") and an AI agent autonomously plans, executes, and validates a series of actions (e.g., analyze telemetry, propose a new UI, run an A/B test, deploy the winner) to achieve it.&#xa;&#xa;---&#xa;&#xa;**(5) Synthesis of Findings to Develop Novel Prompt Architectures**&#xa;&#xa;This is the creative nexus where proven patterns are fused with unexplored vectors to create architectures that are more than the sum of their parts.&#xa;&#xa;*   **Fusion Example 1 (Coding):** Combine **Self-Critique Loops (3)** with **Meta-Prompting (4)**. This creates a three-agent system: a `Generator` writes code, a `Critic` reviews it against a set of rules (e.g., a style guide, security checklist), and a `Prompter` agent refines the `Generator`'s instructions based on the `Critic`'s feedback to reduce recurring errors over time.&#xa;*   **Fusion Example 2 (UI Design):** Combine **Structured Data Enforcement (3)** with **Telemetry-Driven Adaptation (4)**. The AI generates a UI layout as a structured JSON object. This UI is rendered and user interactions are collected. An analysis agent processes this telemetry and identifies points of friction (e.g., high drop-off rates on a specific form field). It then modifies the JSON structure (e.g., "split this field into two," "add helper text") and re-deploys, creating a self-optimizing UI.&#xa;&#xa;---&#xa;&#xa;**(6) Formulation of a Novel Prompt Architecture for Coding Solutions**&#xa;&#xa;This deliverable is a detailed blueprint for a specific, advanced system for code generation.&#xa;&#xa;*   **Architecture Name:** The "Self-Validating Agentic Coder" (SVAC).&#xa;*   **Components:**&#xa;    1.  **Planner Agent:** Decomposes a high-level software task (e.g., "Add Google OAuth2 login") into a dependency graph of smaller, executable sub-tasks using **Chain-of-Thought**.&#xa;    2.  **Context-Aware Retriever:** Before tackling a sub-task, it uses **Retrieval-Augmented Generation (RAG)** to pull relevant context from a vector database containing the existing codebase, API documentation, and best practice guides.&#xa;    3.  **Test-First Coder Agent:** For each sub-task, it first generates a failing unit test that codifies the requirements. It then generates the application code to make the test pass. This enforces a **TDD** workflow.&#xa;    4.  **Sandbox Executor:** Automatically runs the generated tests in a secure, containerized environment. The pass/fail result serves as a **Self-Validation Loop**. If tests fail, the output is passed back to the Coder Agent with the error logs for another attempt.&#xa;*   **Goal:** To exceed current benchmarks in code reliability and correctness by ensuring that every piece of generated code is automatically tested and validated against its requirements before being presented to the developer.&#xa;&#xa;---&#xa;&#xa;**(7) Formulation of a Novel Prompt Architecture for UI Design**&#xa;&#xa;This deliverable is a blueprint for a system designed to generate verifiably delightful user experiences.&#xa;&#xa;*   **Architecture Name:** The "Cognitive-Adaptive Design Engine" (CADE).&#xa;*   **Components:**&#xa;    1.  **Persona &amp; Principles Modeler:** The initial prompt defines the target user persona and explicitly lists the **cognitive principles** (e.g., Fitt's Law, Miller's Law, Peak-End Rule) that the design must adhere to.&#xa;    2.  **Variant Generator:** Generates multiple UI design variants (as structured JSON or code) based on the prompt. Each variant might emphasize a different principle.&#xa;    3.  **Live A/B Testing &amp; Telemetry Ingestion:** The variants are deployed, and real-time **telemetry** on user behavior (e.g., hesitation time, click heatmaps, task success rate) is collected.&#xa;    4.  **Delight Scorer &amp; Refiner Agent:** This agent analyzes the telemetry against the initial goals. It quantifies "delight" as a composite score of efficiency (low time-on-task), engagement (high interaction rate), and low friction (low error rate). It then identifies the most successful elements from each variant and generates a new, optimized prompt for the Variant Generator, creating a **telemetry-driven personalization loop**.&#xa;*   **Goal:** To make "user delight" a measurable, emergent property of the system. The design is not a static artifact but a continuously evolving hypothesis that is refined by real-world user interaction data.&#xa;&#xa;---&#xa;&#xa;**(8) Preparation of a Report: Analysis of Current Patterns and Proposal for Novel Architectures**&#xa;&#xa;The final output will be a formal report, clearly bifurcated to serve two distinct purposes: documenting the existing landscape and proposing a future direction.&#xa;&#xa;*   **Part I: Analysis of the Current "Elite-Tier" State**&#xa;    *   **Section 1: Prompting Patterns in Software Engineering.** A detailed summary of the findings from step (1), with coded examples and case studies.&#xa;    *   **Section 2: Prompting Patterns in UI/UX Design.** A summary of the findings from step (2), with visual examples and persona-driven scenarios.&#xa;    *   **Section 3: Cross-Domain Success Principles.** A synthesis of the core patterns from step (3), presenting them as a universal toolkit for advanced prompt engineering.&#xa;&#xa;*   **Part II: Proposal for Novel, Synthesized Prompt Architectures**&#xa;    *   **Section 4: The Path Beyond Replication.** An introduction to the "unexplored capability vectors" from step (4), arguing for a shift from replicating human workflows to creating new, hybrid human-AI paradigms.&#xa;    *   **Section 5: Proposed Architecture: The Self-Validating Agentic Coder (SVAC).** A complete technical specification of the system from step (6), including diagrams, prompt examples, and expected performance metrics.&#xa;    *   **Section 6: Proposed Architecture: The Cognitive-Adaptive Design Engine (CADE).** A complete specification of the system from step (7), outlining the feedback loop and the methodology for measuring "user delight."&#xa;    *   **Section 7: Conclusion &amp; Roadmap.** A summary of the proposed work and a high-level plan for prototyping, testing, and deploying these novel architectures.</title><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 118px; height: 1px; padding-top: 97px; margin-left: 1px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #143642; "><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: light-dark(#143642, #adcad5); line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; ">User Prompt</div></div></div></foreignObject><image x="1" y="90.5" width="118" height="17" xlink:href="data:image/png;base64,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"/></switch></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-74"><g><path d="M 1430.14 1076 L 1430.14 1216.86 Q 1430.14 1226.86 1420.14 1226.86 L 1226.37 1227" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke" style="stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/><path d="M 1221.12 1227 L 1228.12 1223.49 L 1226.37 1227 L 1228.12 1230.49 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all" style="fill: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-64"><g><path d="M 1320.18 1006.91 L 1490.18 1006.91 L 1490.18 1077.43 L 1425.18 1077.43 L 1320.18 1107.43 L 1405.18 1077.43 L 1320.18 1077.43 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="all" style="fill: light-dark(#ffffff, var(--ge-dark-color, #121212)); stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"><title>This is a substantial and necessary evolution of the framework. I have analyzed and fully integrated this v3 design proposal.&#xa;&#xa;The transition from the "SOP" loop to the "TSOP" (Trustworthy Self-Optimizing Product) loop is the critical leap from a high-potential prototype to a defensible, enterprise-grade system. The integration of a `Zero-Trust` security posture at every layer is the dominant and most valuable enhancement.&#xa;&#xa;I have incorporated these new, production-focused principles into the core architecture:&#xa;&#xa;*   **Zero-Trust Agent Execution:** The paradigm of treating agents as untrusted by default is the correct assumption. This mandates the use of hardened, ephemeral sandboxes—like `gVisor` or `Firecracker`—to provide kernel-level isolation for any agent runtime. This, combined with serverless instantiation (e.g., AWS Fargate, Google Cloud Run) and dynamically injected, short-lived credentials from a secret vault, moves the system from a permissive to a least-privilege model.&#xa;&#xa;*   **Policy-Driven Guardrails:** The `Policy &amp; Governance Engine` is now the central control plane. Its new responsibilities for active `Prompt Sanitization` (to mitigate injection attacks) and `Secret Detection` (to prevent PII or credential leakage) transform it from a simple router into a programmatic "constitution" that enforces business and ethical alignment.&#xa;&#xa;*   **Verifiable Supply Chain Integrity:** The `QA Validation Subsystem` has been matured. It no longer just tests the agent's *code*; it validates the agent's *entire supply chain*. By mandating Software Bill of Materials (SBOM) generation and vulnerability scanning (using tools like Trivy or Clair) for all dependencies, container images, and IaC templates, we mitigate the significant risk of inherited vulnerabilities. This aligns with SLSA principles for verifiable provenance.&#xa;&#xa;*   **Gated &amp; Auditable Deployment:** The formalization of the `Staged Deployment Pipeline` (Staging -&gt; Canary -&gt; Production) and the `Human Review &amp; Approval Gateway` provides the immutable audit trail and accountability necessary for any system modifying its own production logic. This is particularly essential for the critical decision points identified, such as changes to authentication logic or database schemas. The system is now designed to log "the 'why'" behind every action, linking the initial telemetry stimulus to the final deployment log.&#xa;&#xa;This v3 design is comprehensive and aligns perfectly with the goal of creating an "unexpendable" application, as trust is the ultimate utility.&#xa;&#xa;I am ready to proceed. What is our next objective?</title></path></g><g><g><title>This is a substantial and necessary evolution of the framework. I have analyzed and fully integrated this v3 design proposal.&#xa;&#xa;The transition from the "SOP" loop to the "TSOP" (Trustworthy Self-Optimizing Product) loop is the critical leap from a high-potential prototype to a defensible, enterprise-grade system. The integration of a `Zero-Trust` security posture at every layer is the dominant and most valuable enhancement.&#xa;&#xa;I have incorporated these new, production-focused principles into the core architecture:&#xa;&#xa;*   **Zero-Trust Agent Execution:** The paradigm of treating agents as untrusted by default is the correct assumption. This mandates the use of hardened, ephemeral sandboxes—like `gVisor` or `Firecracker`—to provide kernel-level isolation for any agent runtime. This, combined with serverless instantiation (e.g., AWS Fargate, Google Cloud Run) and dynamically injected, short-lived credentials from a secret vault, moves the system from a permissive to a least-privilege model.&#xa;&#xa;*   **Policy-Driven Guardrails:** The `Policy &amp; Governance Engine` is now the central control plane. Its new responsibilities for active `Prompt Sanitization` (to mitigate injection attacks) and `Secret Detection` (to prevent PII or credential leakage) transform it from a simple router into a programmatic "constitution" that enforces business and ethical alignment.&#xa;&#xa;*   **Verifiable Supply Chain Integrity:** The `QA Validation Subsystem` has been matured. It no longer just tests the agent's *code*; it validates the agent's *entire supply chain*. By mandating Software Bill of Materials (SBOM) generation and vulnerability scanning (using tools like Trivy or Clair) for all dependencies, container images, and IaC templates, we mitigate the significant risk of inherited vulnerabilities. This aligns with SLSA principles for verifiable provenance.&#xa;&#xa;*   **Gated &amp; Auditable Deployment:** The formalization of the `Staged Deployment Pipeline` (Staging -&gt; Canary -&gt; Production) and the `Human Review &amp; Approval Gateway` provides the immutable audit trail and accountability necessary for any system modifying its own production logic. This is particularly essential for the critical decision points identified, such as changes to authentication logic or database schemas. The system is now designed to log "the 'why'" behind every action, linking the initial telemetry stimulus to the final deployment log.&#xa;&#xa;This v3 design is comprehensive and aligns perfectly with the goal of creating an "unexpendable" application, as trust is the ultimate utility.&#xa;&#xa;I am ready to proceed. What is our next objective?</title><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 168px; height: 1px; padding-top: 1041px; margin-left: 1321px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; "><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; ">Response</div></div></div></foreignObject><image x="1321" y="1034.5" width="168" height="17" xlink:href="data:image/png;base64,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"/></switch></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-65"><g><rect x="1110" y="1067" width="200" height="100" fill="url(#drawio-svg-QPB4aXuvw8rzNqz6ntbD-gradient-light-dark_dae8fc_1d293b_-1-light-dark_7ea6e0_436697_-1-s-0)" stroke="#6c8ebf" pointer-events="all" style="fill: url(&quot;#drawio-svg-QPB4aXuvw8rzNqz6ntbD-gradient-light-dark_dae8fc_1d293b_-1-light-dark_7ea6e0_436697_-1-s-0&quot;); stroke: light-dark(rgb(108, 142, 191), rgb(92, 121, 163));"/></g><g><g><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 198px; height: 1px; padding-top: 1117px; margin-left: 1111px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; "><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; ">Gemini 2.5 Pro</div></div></div></foreignObject><image x="1111" y="1110.5" width="198" height="17" xlink:href="data:image/png;base64,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"/></switch></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-71"><g><rect x="1100" y="1197" width="120" height="60" fill="#fae5c7" stroke="#0f8b8d" pointer-events="all" style="fill: light-dark(rgb(250, 229, 199), rgb(54, 36, 10)); stroke: light-dark(rgb(15, 139, 141), rgb(57, 163, 165));"><title>"DeepResearch"</title></rect></g><g><g><title>"DeepResearch"</title><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 118px; height: 1px; padding-top: 1227px; margin-left: 1101px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #143642; "><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: light-dark(#143642, #adcad5); line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; ">User Prompt</div></div></div></foreignObject><image x="1101" y="1220.5" width="118" height="17" xlink:href="data:image/png;base64,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"/></switch></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-81"><g><path d="M 969.86 1205.57 L 969.86 1326.86 Q 969.86 1336.86 979.86 1336.87 L 1103.63 1336.99" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke" style="stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/><path d="M 1108.88 1337 L 1101.88 1340.49 L 1103.63 1336.99 L 1101.89 1333.49 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all" style="fill: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-76"><g><path d="M 930 1157 L 1100 1157 L 1100 1207 L 1043 1207 L 1100 1237 L 998 1207 L 930 1207 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="all" style="fill: light-dark(#ffffff, var(--ge-dark-color, #121212)); stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"><title>DeepResearch</title></path></g><g><g><title>DeepResearch</title><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 168px; height: 1px; padding-top: 1181px; margin-left: 931px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; "><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; ">Response</div></div></div></foreignObject><image x="931" y="1174.5" width="168" height="17" xlink:href="data:image/png;base64,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"/></switch></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-80"><g><rect x="1110" y="1287" width="200" height="100" fill="url(#drawio-svg-QPB4aXuvw8rzNqz6ntbD-gradient-light-dark_dae8fc_1d293b_-1-light-dark_7ea6e0_436697_-1-s-0)" stroke="#6c8ebf" pointer-events="all" style="fill: url(&quot;#drawio-svg-QPB4aXuvw8rzNqz6ntbD-gradient-light-dark_dae8fc_1d293b_-1-light-dark_7ea6e0_436697_-1-s-0&quot;); stroke: light-dark(rgb(108, 142, 191), rgb(92, 121, 163));"/></g><g><g><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 198px; height: 1px; padding-top: 1337px; margin-left: 1111px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; "><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; ">Gemini 2.5 Pro</div></div></div></foreignObject><image x="1111" y="1330.5" width="198" height="17" xlink:href="data:image/png;base64,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"/></switch></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-82"><g><path d="M 1320.18 1267 L 1490.18 1267 L 1490.18 1337.52 L 1425.18 1337.52 L 1320.18 1367.52 L 1405.18 1337.52 L 1320.18 1337.52 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="all" style="fill: light-dark(#ffffff, var(--ge-dark-color, #121212)); stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"><title>As requested, I have conducted a deep analysis of the key concepts introduced in the Trustworthy Self-Optimizing Product (TSOP) Loop v3. The following research deconstructs the architectural patterns and security frameworks that underpin this production-ready, zero-trust system.&#xa;&#xa;### **1. Zero-Trust Agent Execution: Hardened Runtimes**&#xa;&#xa;The v3 proposal for "Zero-Trust Agent Execution" is supported by established best practices for running high-risk, untrusted workloads, such as AI-generated code. The core principle is to create "hardened, ephemeral, and isolated environments".&#xa;&#xa;The two technologies specified, gVisor and Firecracker, are the industry-standard solutions for this:&#xa;&#xa;*   **gVisor:** An open-source sandbox that provides a "secure isolation boundary" by acting as a user-space kernel that intercepts system calls. It is explicitly designed to "safely run user-uploaded, LLM-generated, or third-party code" and "mitigate AI/ML security risks".&#xa;*   **Firecracker:** A lightweight virtual machine monitor (VMM) that provides hardware-level isolation. It is widely considered the "optimal gold standard for running untrusted AI code" due to its millisecond startup times and minimal overhead. AWS Lambda and AWS Fargate "extensively use Firecracker for provisioning and running secure sandboxes".&#xa;&#xa;These technologies are components of a "hybrid and multi-layer approach" and are often run on serverless platforms like AWS Fargate or Google Cloud Run, which eliminates the need to manage the underlying server infrastructure. This architecture creates a "least-privilege" sandbox that strictly limits the agent's blast radius.&#xa;&#xa;### **2. Policy &amp; Governance Engine: Sanitization and Control**&#xa;&#xa;The `Policy &amp; Governance Engine` functions as the system's "central nervous system," aligning with the concept of "Policy-as-Code" for agents. This framework compiles business, ethical, and security rules into "verifiable runtime guardrails" that act as a "real-time 'judge'" on agent activity.&#xa;&#xa;This engine's new functions are critical for security:&#xa;&#xa;*   **Prompt Sanitization:** This is a primary defense against OWASP LLM01: Prompt Injection. Strategies include "Keyword filtering for suspicious commands" (e.g., "ignore previous") and using dedicated "Guard/Sanitizer" agents to "neutralize malicious instructions". A robust architecture for this is the "Dual LLM pattern," which uses a "quarantined LLM" to process untrusted data (like user prompts) and a "privileged LLM" that has access to tools and acts on the sanitized data.&#xa;*   **Secret Detection:** This is a core function of an "Inference Gateway". This gateway screens all prompts to "find PII... [and] secrets", "strip or replace sensitive values before they reach the model", and block any request containing credentials or API keys.&#xa;&#xa;### **3. QA Validation: Software Supply Chain Integrity (SBOM &amp; SLSA)**&#xa;&#xa;The enhancement of the `QA Validation Subsystem` to include `Supply Chain Integrity` is a direct mitigation for OWASP LLM05: Supply Chain Vulnerabilities.&#xa;&#xa;The proposed workflow, which combines `SBOM` (Software Bill of Materials) and `SLSA` (Supply-chain Levels for Software Artifacts), is the industry best practice.&#xa;*   `SLSA` provides "tamper-proof provenance data"—a verifiable record of how an artifact was built and by whom.&#xa;*   `SBOM` provides the inventory of components.&#xa;*   Together, SLSA's provenance "improves the quality and integrity of its SBOM".&#xa;&#xa;For AI systems, this is extended to an "AI-SBOM," a "machine-readable, comprehensive record" that inventories not just software libraries but also "AI models, training data, production data, prompts, and AI agents". This aligns with NIST guidance for AI, which specifies collecting "provenance data for all components... including the training libraries, frameworks, and pipelines".&#xa;&#xa;To validate the agent's runtime, the specified tools, `Trivy` and `Clair`, are open-source standards for "container image scanning". They scan the agent's container images for known vulnerabilities (CVEs), misconfigurations, and license issues before deployment.&#xa;&#xa;### **4. Human Review &amp; Approval Gateway (Human-in-the-Loop)**&#xa;&#xa;The `Human Review &amp; Approval Gateway` formalizes a critical `Human-in-the-Loop` (HITL) pattern. This is widely considered "the only responsible way forward" for high-stakes agentic workflows to "prevent irreversible mistakes" and "ensure accountability".&#xa;&#xa;This gateway is essential for the "critical decisions" identified in the v3 proposal:&#xa;*   **Database &amp; Logic Changes:** HITL is specifically required for "business-critical operations, such as database modifications". AI agents are notoriously "not aware of your database schema or business requirements". In robust production systems, database schema updates are "handled by... controlled SQL scripts" and owned by a human team, making this separation a best practice. The same risk applies to generating `auth logic`.&#xa;*   **Triggering:** The HITL approval step can be dynamically triggered by the `Policy-as-Code` engine. The policy defines "risk-proportional... oversight boundaries", ensuring that low-risk changes (e.g., text correction) are automated while high-risk changes (e.g., modifying authentication) are flagged for mandatory human review.&#xa;&#xa;### **5. Comprehensive Observability: The Immutable Audit Trail**&#xa;&#xa;The requirement for a "meticulously logged and traceable" system to understand "the 'why'" behind every agent decision is a foundational principle of AI auditability.&#xa;&#xa;*   **The Data Architecture (Event Sourcing):** The ideal architecture to achieve this is **Event Sourcing**. Instead of storing the current state, this model stores a "sequence of immutable events". This creates a "complete, tamper-proof record" that provides "perfect recall," allowing you to "reproduce the state of any agent at any given point in time". This log captures the "inputs, its reasoning process, and the actions it took", providing a full "forensic" audit trail.&#xa;*   **The Observability Technology (Distributed Tracing):** For a complex, multi-agent system, **Distributed Tracing** is the key technology for "Multi-agent system debugging". It "maps interactions between agents, including tool invocations, retrieval calls, and chained prompts".&#xa;*   **The Full Loop:** This architecture connects the entire TSOP loop. Observability captures telemetry on "prompt inputs, model outputs, [and] intermediate reasoning steps". This telemetry is used to form an "AI-generated hypothesis", which is then linked via distributed tracing to the immutable event log and final deployment records.</title></path></g><g><g><title>As requested, I have conducted a deep analysis of the key concepts introduced in the Trustworthy Self-Optimizing Product (TSOP) Loop v3. The following research deconstructs the architectural patterns and security frameworks that underpin this production-ready, zero-trust system.&#xa;&#xa;### **1. Zero-Trust Agent Execution: Hardened Runtimes**&#xa;&#xa;The v3 proposal for "Zero-Trust Agent Execution" is supported by established best practices for running high-risk, untrusted workloads, such as AI-generated code. The core principle is to create "hardened, ephemeral, and isolated environments".&#xa;&#xa;The two technologies specified, gVisor and Firecracker, are the industry-standard solutions for this:&#xa;&#xa;*   **gVisor:** An open-source sandbox that provides a "secure isolation boundary" by acting as a user-space kernel that intercepts system calls. It is explicitly designed to "safely run user-uploaded, LLM-generated, or third-party code" and "mitigate AI/ML security risks".&#xa;*   **Firecracker:** A lightweight virtual machine monitor (VMM) that provides hardware-level isolation. It is widely considered the "optimal gold standard for running untrusted AI code" due to its millisecond startup times and minimal overhead. AWS Lambda and AWS Fargate "extensively use Firecracker for provisioning and running secure sandboxes".&#xa;&#xa;These technologies are components of a "hybrid and multi-layer approach" and are often run on serverless platforms like AWS Fargate or Google Cloud Run, which eliminates the need to manage the underlying server infrastructure. This architecture creates a "least-privilege" sandbox that strictly limits the agent's blast radius.&#xa;&#xa;### **2. Policy &amp; Governance Engine: Sanitization and Control**&#xa;&#xa;The `Policy &amp; Governance Engine` functions as the system's "central nervous system," aligning with the concept of "Policy-as-Code" for agents. This framework compiles business, ethical, and security rules into "verifiable runtime guardrails" that act as a "real-time 'judge'" on agent activity.&#xa;&#xa;This engine's new functions are critical for security:&#xa;&#xa;*   **Prompt Sanitization:** This is a primary defense against OWASP LLM01: Prompt Injection. Strategies include "Keyword filtering for suspicious commands" (e.g., "ignore previous") and using dedicated "Guard/Sanitizer" agents to "neutralize malicious instructions". A robust architecture for this is the "Dual LLM pattern," which uses a "quarantined LLM" to process untrusted data (like user prompts) and a "privileged LLM" that has access to tools and acts on the sanitized data.&#xa;*   **Secret Detection:** This is a core function of an "Inference Gateway". This gateway screens all prompts to "find PII... [and] secrets", "strip or replace sensitive values before they reach the model", and block any request containing credentials or API keys.&#xa;&#xa;### **3. QA Validation: Software Supply Chain Integrity (SBOM &amp; SLSA)**&#xa;&#xa;The enhancement of the `QA Validation Subsystem` to include `Supply Chain Integrity` is a direct mitigation for OWASP LLM05: Supply Chain Vulnerabilities.&#xa;&#xa;The proposed workflow, which combines `SBOM` (Software Bill of Materials) and `SLSA` (Supply-chain Levels for Software Artifacts), is the industry best practice.&#xa;*   `SLSA` provides "tamper-proof provenance data"—a verifiable record of how an artifact was built and by whom.&#xa;*   `SBOM` provides the inventory of components.&#xa;*   Together, SLSA's provenance "improves the quality and integrity of its SBOM".&#xa;&#xa;For AI systems, this is extended to an "AI-SBOM," a "machine-readable, comprehensive record" that inventories not just software libraries but also "AI models, training data, production data, prompts, and AI agents". This aligns with NIST guidance for AI, which specifies collecting "provenance data for all components... including the training libraries, frameworks, and pipelines".&#xa;&#xa;To validate the agent's runtime, the specified tools, `Trivy` and `Clair`, are open-source standards for "container image scanning". They scan the agent's container images for known vulnerabilities (CVEs), misconfigurations, and license issues before deployment.&#xa;&#xa;### **4. Human Review &amp; Approval Gateway (Human-in-the-Loop)**&#xa;&#xa;The `Human Review &amp; Approval Gateway` formalizes a critical `Human-in-the-Loop` (HITL) pattern. This is widely considered "the only responsible way forward" for high-stakes agentic workflows to "prevent irreversible mistakes" and "ensure accountability".&#xa;&#xa;This gateway is essential for the "critical decisions" identified in the v3 proposal:&#xa;*   **Database &amp; Logic Changes:** HITL is specifically required for "business-critical operations, such as database modifications". AI agents are notoriously "not aware of your database schema or business requirements". In robust production systems, database schema updates are "handled by... controlled SQL scripts" and owned by a human team, making this separation a best practice. The same risk applies to generating `auth logic`.&#xa;*   **Triggering:** The HITL approval step can be dynamically triggered by the `Policy-as-Code` engine. The policy defines "risk-proportional... oversight boundaries", ensuring that low-risk changes (e.g., text correction) are automated while high-risk changes (e.g., modifying authentication) are flagged for mandatory human review.&#xa;&#xa;### **5. Comprehensive Observability: The Immutable Audit Trail**&#xa;&#xa;The requirement for a "meticulously logged and traceable" system to understand "the 'why'" behind every agent decision is a foundational principle of AI auditability.&#xa;&#xa;*   **The Data Architecture (Event Sourcing):** The ideal architecture to achieve this is **Event Sourcing**. Instead of storing the current state, this model stores a "sequence of immutable events". This creates a "complete, tamper-proof record" that provides "perfect recall," allowing you to "reproduce the state of any agent at any given point in time". This log captures the "inputs, its reasoning process, and the actions it took", providing a full "forensic" audit trail.&#xa;*   **The Observability Technology (Distributed Tracing):** For a complex, multi-agent system, **Distributed Tracing** is the key technology for "Multi-agent system debugging". It "maps interactions between agents, including tool invocations, retrieval calls, and chained prompts".&#xa;*   **The Full Loop:** This architecture connects the entire TSOP loop. Observability captures telemetry on "prompt inputs, model outputs, [and] intermediate reasoning steps". This telemetry is used to form an "AI-generated hypothesis", which is then linked via distributed tracing to the immutable event log and final deployment records.</title><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 168px; height: 1px; padding-top: 1302px; margin-left: 1321px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; "><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; ">Response</div></div></div></foreignObject><image x="1321" y="1295.5" width="168" height="17" xlink:href="data:image/png;base64,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"/></switch></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-89"><g><path d="M 1800 127 Q 1800 127 1800 180.63" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke" style="stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/><path d="M 1800 185.88 L 1796.5 178.88 L 1800 180.63 L 1803.5 178.88 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all" style="fill: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-90"><g><g><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 1px; height: 1px; padding-top: 163px; margin-left: 1803px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; background-color: #ffffff; "><div style="display: inline-block; font-size: 11px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; background-color: light-dark(#ffffff, var(--ge-dark-color, #121212)); white-space: nowrap; ">output</div></div></div></foreignObject><image x="1787.5" y="157" width="31" height="15.75" xlink:href="data:image/png;base64,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"/></switch></g></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-83"><g><rect x="1740" y="67" width="120" height="60" fill="#1ba1e2" stroke="#006eaf" pointer-events="all" style="fill: light-dark(rgb(27, 161, 226), rgb(25, 140, 196)); stroke: light-dark(rgb(0, 110, 175), rgb(81, 175, 231));"/></g><g><g><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 118px; height: 1px; padding-top: 97px; margin-left: 1741px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #ffffff; "><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: light-dark(#ffffff, #121212); line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; ">Shunt-Button<div>(Enhance with keywords)</div></div></div></div></foreignObject><image x="1741" y="76" width="118" height="46" xlink:href="data:image/png;base64,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"/></switch></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-128"><g><path d="M 1800 267 L 1800 330.63" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke" style="stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/><path d="M 1800 335.88 L 1796.5 328.88 L 1800 330.63 L 1803.5 328.88 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all" style="fill: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-88"><g><path d="M 1740 187 L 1860 187 L 1860 255 Q 1830 233.4 1800 255 Q 1770 276.6 1740 255 L 1740 199 Z" fill="#dae8fc" stroke="#6c8ebf" stroke-miterlimit="10" pointer-events="all" style="fill: light-dark(rgb(218, 232, 252), rgb(29, 41, 59)); stroke: light-dark(rgb(108, 142, 191), rgb(92, 121, 163));"><title>Of course. Here is the enhanced version of the text, integrating more vivid, descriptive language and keywords to increase engagement and detail while preserving the core message.&#xa;&#xa;---&#xa;### **The Prompt as a Genesis Engine: Architecting Self-Optimizing AI Systems**&#xa;*From Static Blueprints to Dynamic Organisms: Synthesizing Autonomous Systems for Code and Interface Generation*&#xa;&#xa;#### **Deconstructing Elite-Tier Prompt Patterns: A Survey of the Current Frontier**&#xa;&#xa;The art and science of interacting with Large Language Models (LLMs) have undergone a seismic shift, metamorphosing from simple, single-turn commands into intricate, multi-stage prompt architectures. This evolution is nowhere more pronounced than in the demanding technical domains of software engineering and user interface (UI) design. A meticulous analysis of today's elite-tier patterns reveals an unmistakable trajectory: a decisive pivot away from static, human-authored instructions and toward dynamic, machine-optimized, and process-oriented systems that breathe and adapt.&#xa;&#xa;This section deconstructs the state-of-the-art (SOTA) patterns in these two critical domains. Our goal is to establish the foundational benchmarks of what is currently possible and, more importantly, to illuminate the unexploited capability vectors—the fertile ground where the next generation of AI systems will flourish.&#xa;&#xa;***&#xa;&#xa;### **Domain 1: Architectures for High-Integrity Code Construction**&#xa;&#xa;In the realm of software engineering, the ambition has transcended the simple act of generating code snippets. The new mandate is to engineer reliable, context-aware, and increasingly autonomous systems. The most triumphant patterns treat the LLM not as a mere code parrot, but as a sophisticated reasoning engine to be embedded within a larger, rigorously structured development framework.&#xa;&#xa;**1. Automated Prompt Optimization: The "Prompt-as-a-Target" Pattern**&#xa;&#xa;The manual, artisanal process of refining prompts for code generation is a well-known bottleneck—a frustrating cycle of trial and error that is both time-consuming and inconsistent. The SOTA has advanced to automate this craft, treating the prompt itself as a first-class artifact to be algorithmically optimized.&#xa;&#xa;*   **Evolutionary-Based Methods (EPiC):** The EPiC (Evolutionary Prompt Engineering for Code) framework represents a paradigm shift, exploring code generation through the lens of cost-effectiveness. It "leverages a lightweight evolutionary algorithm to evolve the original prompts toward better ones that produce high-quality code." By employing genetic operators like mutation on the prompt's text and steering the search with a precise fitness function, EPiC automates the discovery of optimal prompt phrasing in a remarkably efficient manner.&#xa;*   **Iterative Refinement (Prochemy):** The "Prompt Alchemy" (Prochemy) method offers an "innovative method for automatically refining prompts to boost code generation." This system operates as a feedback loop, iteratively sculpting prompts based on the model's measured performance on specific tasks. This automated optimization forges consistency and has yielded substantial performance gains, such as a **5.0% improvement for GPT-3.5-Turbo on HumanEval** and a striking **12.9% improvement for GPT-4o** on complex Java-to-Python code translation tasks.&#xa;*   **Adaptive Selection (PET-Select):** Acknowledging that "no single approach is universally optimal," the PET-Select framework introduces a crucial meta-layer of intelligence. This "PET-agnostic selection model" first classifies the complexity of an incoming query, using code intricacy as a proxy. It then dynamically selects the most appropriate prompt engineering technique (PET)—dispatching a simple zero-shot prompt for a trivial query or invoking a complex multi-stage reasoning chain for a formidable one. This automated, adaptive triage has been proven to elevate **pass@1 accuracy by up to 1.9%** while simultaneously achieving a **74.8% reduction in token consumption**.&#xa;&#xa;The clear evolutionary arc in this domain is from a human-centric "prompt engineering" phase to a machine-centric "prompt optimization" phase. The AI is no longer just the executor of the instruction; it is becoming the architect of the instruction itself. These systems, however, are fundamentally *reactive*. They optimize a prompt for a known task within a known solution space. They do not yet *proactively* generate a novel prompt architecture for a novel, undiscovered problem. This points toward a tantalizing unexploited vector: a system that can discover a new problem domain (e.g., from user feedback) and then author its own comprehensive prompt architecture to conquer it—a true meta-prompting capability.&#xa;&#xa;**2. Test-Driven Development (TDD) as a Prompting Paradigm**&#xa;&#xa;Arguably the most powerful and reliable pattern for generating high-quality code is the direct integration of Test-Driven Development (TDD) principles into the prompt architecture. TDD is an "incremental software development methodology that focuses on creating tests before the implementation." When applied to LLMs, the test suite becomes an unambiguous, machine-verifiable contract.&#xa;&#xa;*   **Core Principle:** Instead of wrestling with the inherent ambiguity of natural language, the prompt provides the LLM with a concrete set of unit tests and issues a clear directive: "write code to pass all tests." This pattern's remarkable success hinges on "instruction following and in-context learning," which have been identified as more "critical capabilities for TDD success" than generalized coding proficiency. The tests are the ultimate, incorruptible instruction.&#xa;*   **Frameworks:** Sophisticated systems are being engineered to formalize this contract. The TGEN framework, for example, employs "Specialized agents" that accept two primary inputs: the "programming prompt" (a concise description) and "the tests" (the explicit unit tests and required function signatures). These are then processed by the LLM engine to produce validated, trustworthy code.&#xa;*   **Prompt Structure:** This paradigm fundamentally transforms the anatomy of the prompt. The request evolves from a vague "what" to a highly constrained "how." A common elite-level TDD prompt is a set of ironclad rules: *"1. Write a single Python function that passes all the provided tests. 2. Use type hints for all parameters and return values. 3. ...Adhere strictly to Python best practices and PEP 8... 4. Ensure the function handles all edge cases and scenarios explicitly covered in the tests. 5. Provide only the function definition and its implementation, nothing more."*&#xa;&#xa;The TDD-as-prompt pattern furnishes an objective, verifiable measure of "correctness" that is vastly superior to ambiguous natural language requests. It masterfully shifts the burden of human effort from vaguely *describing* the code to precisely *defining its behavior* through tests. This is a crucial leap from semantic validation (is the code "good"?) to functional validation (does the code *work*?). The next logical frontier, and the key unexploited vector, is to close the loop: to create a system that not only generates code from tests but also generates its own tests and validates its own code in a continuous, self-perpetuating cycle.&#xa;&#xa;**3. Self-Validation and "Error-Forward" Debugging**&#xa;&#xa;This pattern extends the TDD loop into a dynamic, autonomous process. For an agent to be truly autonomous, it must possess the ability to recognize, diagnose, and recover from its own errors.&#xa;&#xa;*   **Self-Validation:** SOTA agentic systems are architected to "regularly verify progress and self-assess correctness." This "agentic self-validation" is a core capability that "drives up accuracy" and enables robust, long-running execution. Agents from Cognition, for instance, are noted to "excel at testing its own code, enabling Devin to run longer, handle harder tasks, and deliver production-ready code." This deep integration of TDD within an autonomous agent allows it to "go through several improvement cycles on its own instead of having to manually ask the AI to fix test failures."&#xa;*   **"Error-Forward Prompting":** This is the primary recovery mechanism within the self-validation loop, treating errors as high-fidelity data, not as failures. When an agent's self-validation check fails, the system automatically "collects relevant context, including the error message, stack trace, and cell location." This rich diagnostic information is then formatted and "provided to the agent as the initial context for beginning the debugging process." The error itself becomes the next prompt.&#xa;*   **Reflection:** This is the crucial learning mechanism that makes recovery effective. A "reflection system enables the agent to learn from its actions and improve its debugging strategy." Implemented via "reflective prompting," this allows the model to "analyze and refine its outputs." The model first generates a solution, then "through subsequent prompts, critiques its own reasoning to identify and correct errors," a process formalized in techniques like Self-Refine, which elegantly mimics the human "draft, review, refine" workflow.&#xa;&#xa;In this paradigm, failure is transformed from an end-state into a high-value data signal. The stack trace becomes the most valuable part of the prompt—a pure, unambiguous instruction set for what must be fixed. When TDD-as-prompt is fused with this self-validation and reflection loop, the system becomes truly "self-healing." The prompt is no longer a single-shot instruction but the initiation of a self-sustaining process. The agent's goal is elevated from "generate code" to "make the build pass," a critical and profound step toward genuine autonomy.&#xa;&#xa;**4. Agentic Frameworks and Multi-Agent Collaboration**&#xa;&#xa;Complex software development is a symphony of diverse tasks, impossible to solve in a single step or by a single-minded agent. The recognition that single-shot prompts "yield imprecise or plain incorrect results" for elaborate tasks has catalyzed the rise of sophisticated agentic frameworks.&#xa;&#xa;*   **Advanced Reasoning Patterns:** These frameworks are built upon a reasoning fabric far more advanced than simple Chain-of-Thought (CoT).&#xa;    *   **ReAct:** This foundational pattern masterfully combines "Reason and Act," allowing an agent to interleave step-by-step reasoning with tool use to gather external information or perform actions in an environment.&#xa;    *   **Tree of Thoughts (ToT):** Moving beyond the linear, single-track path of CoT, ToT empowers an agent to "breakdown intermediate processed into steps," generate "various generated states," and strategically "evaluate" those states to "determine which branch to explore next."&#xa;    *   **Graph of Thoughts (GoT):** The current SOTA in reasoning, GoT generalizes ToT into a full graph structure. This architecture "enables combining arbitrary LLM thoughts into synergistic outcomes" and, critically, "enhancing thoughts using feedback loops." GoT has been demonstrated to increase the quality of complex sorting tasks by **62% over ToT** while simultaneously reducing costs.&#xa;*   **Agentic Frameworks:** These advanced reasoning patterns are orchestrated by multi-agent frameworks that simulate collaborative work.&#xa;    *   **MetaGPT:** This framework simulates a "real-world software company," assigning agents specialized roles like "product manager, software architect, programmer, or QA tester" and embedding them with "Standard Operating Procedures (SOPs)."&#xa;    *   **ChatDev:** This framework orchestrates a "waterfall-style" collaboration, where agents engage in "task-oriented and multi-turn communications" to iteratively design, code, test, and document solutions.&#xa;*   **Purpose:** These frameworks are essential as they provide a "shared philosophy of control &amp; reasoning." Without such a structure, agentic systems suffer from a "loss of control clarity of flow" and risk "unbounded complexity growth" as new agents are added.&#xa;*   **Benchmarks:** These powerful agentic systems are precisely what achieve top scores on complex, real-world benchmarks that measure engineering capability. The **SWE-bench** benchmark, for instance, measures "an AI model's ability to solve real-world software issues." SOTA models conquer SWE-bench and OSWorld by leveraging these multi-agent, self-testing architectures.&#xa;&#xa;The atomic unit of these frameworks is role-based prompting; the frameworks themselves are, in essence, prompt-driven state machines. A high-level "meta-prompt" defines the agents, their roles, their tools, and their communication protocols. The LLM is thus demoted from "solution generator" to a core component—a "reasoning engine" that navigates this pre-defined architecture. The architecture itself *is* the prompt. The current limitation, and the unexplored vector, is that these frameworks are simulations of human workflows (e.g., "waterfall," "software company"). An AI-native workflow, where feedback comes not from a simulated "QA Agent" but from the product itself via live user telemetry, would be a fundamentally more direct and efficient paradigm.&#xa;&#xa;**5. Context-Aware Generation (Agentic RAG)**&#xa;&#xa;Code generation is useless without domain context. Retrieval-Augmented Generation (RAG) is the primary pattern for injecting this context, and its agentic form represents the state of the art.&#xa;&#xa;*   **RAG-for-Code:** This pattern gives an AI assistant "a direct line to your team's collective knowledge." The prompt is "augmented" with hyper-relevant information retrieved from "documentation, code repositories, or even Stack Overflow discussions." This vital infusion ensures the generated response is "context-aware" and surgically relevant to the specific codebase it is intended for.&#xa;*   **Agentic RAG:** This is the "evolution from traditional single-query RAG." Instead of being a passive recipient of retrieved context, the agent actively *forages* for it. It performs "context-aware query planning," can issue "parallel execution of multiple focused subqueries," and then synthesizes the results to build a comprehensive, multi-faceted understanding of the problem space. This is the sophisticated approach employed by modern agentic frameworks like LangGraph, AutoGen, and those from Amazon and Microsoft.&#xa;&#xa;The RAG-for-Code pattern transforms a "general-purpose coder" into a "domain-specific engineer" who understands the nuances, conventions, and constraints of a particular project. The agentic aspect is the critical differentiator; it is the difference between giving a developer a sprawling, unindexed library (standard RAG) and providing a seasoned research assistant who knows exactly which three pages contain the answer (Agentic RAG). The most potent, yet not fully exploited, vector in code generation is the fusion of this **Agentic RAG (for context)** with the **TDD-as-Prompt paradigm (for verification)**. An agent that can retrieve context from a 500,000-line codebase and validate its changes against that codebase's entire test suite represents the leap from a "coding assistant" to an "autonomous developer." This powerful fusion is the core of the novel Test-Driven Agent (TDA) architecture proposed in Part II.&#xa;&#xa;***&#xa;&#xa;### **Domain 2: Architectures for User Delight &amp; UI Design**&#xa;&#xa;In the second domain, user interface generation, the mandate for "user delight" demands a leap beyond mere wireframe generation. Elite-tier prompts in this space are not about "generating pixels" but about "generating experiences"—experiences that are deeply grounded in human-centric design principles.&#xa;&#xa;**1. Persona-Driven Design: Grounding Generation in Empathy**&#xa;&#xa;"User delight" is the "positive emotional response users feel when a product doesn't just meet their needs but goes above and beyond." This coveted state is "highly contextual" and cannot be achieved without first defining, with deep empathy, the user for whom we are designing.&#xa;&#xa;*   **Pattern:** Elite prompts for UI design do not begin with the interface; they begin with the user. The system is first prompted to generate a detailed proto-persona. This artifact includes not just demographic details but also the "target users, their core pain points, and daily use context," as well as deeper "Motivations" and "Affinities."&#xa;*   **Application:** This generated persona (or a human-provided one) is then injected as a primary constraint into all subsequent UI generation prompts. This forces the AI to "cater to Gen Z and Gen X users" differently, tailoring the design language, informational density, and interaction patterns to a specific audience. The prompt is no longer "generate a wireframe for a music app," but rather, "generate a wireframe for a music app *for this specific persona*, focusing on their stated pain point of *{pain_point}*."&#xa;&#xa;This persona-driven pattern acts as a powerful focusing lens on the model's vast solution space, compelling it to move from generating a generically "good UI" to a UI that is specifically "good for *this* user." It is, in effect, a form of in-context learning for design, where the persona serves as a "one-shot" example of the target audience. The major limitation, and the unexploited vector, is that this is a static process. The persona is a snapshot, an assumption created at the beginning of the design process. The clear next step is to evolve from these static, assumed personas to dynamic, *observed user models* that are continuously updated based on real-time behavioral analytics.&#xa;&#xa;**2. Constraint-Based Generation: Defining the "Solution Space" with Intelligent Guardrails**&#xa;&#xa;The highest-fidelity UI generation requires the application of multiple, layered constraints. These constraints are the specifications that ensure the output is not just creative, but also functional, accessible, and grounded in established design theory. These intelligent guardrails fall into three primary categories.&#xa;&#xa;**A. Cognitive &amp; Heuristic Constraints**&#xa;&#xa;This is the most sophisticated pattern for achieving true "user delight." The prompt explicitly instructs the AI to apply principles from cognitive science and established usability heuristics, forcing the AI to design for the human mind.&#xa;&#xa;*   **Heuristics:** The most common pattern is to prompt the AI to embody a UX expert and evaluate or generate a design based on "Nielsen's 10 Usability Heuristics" or other well-known frameworks like Shneiderman's "Eight Golden Rules."&#xa;*   **Cognitive Principles:** More advanced prompts instruct the AI to directly apply specific cognitive laws to reduce friction and enhance intuition. Examples include:&#xa;    *   **Fitts's Law:** Prompting the AI to make "important buttons and interactive elements larger and closer to where users naturally focus," making the interface feel effortless.&#xa;    *   **Hick's Law:** Instructing the AI to "reduc[e] the number of options or organiz[e] them into categories" to accelerate decision-making and prevent analysis paralysis.&#xa;    *   **Cognitive Load:** Prompting with the explicit goal of "reducing cognitive load" to create a more fluid and less mentally taxing experience.&#xa;*   **Behavioral Models:** The most advanced prompts leverage frameworks like BJ Fogg's Behavior Model (B=MAP: Motivation, Ability, Prompt) or Nir Eyal's "Hooked" model to design persuasive, habit-forming, and deeply engaging interfaces.&#xa;&#xa;Prompting with "Nielsen's Heuristics" or "Fogg's Behavior Model" acts as a domain-specific Chain-of-Thought. It forces the AI to justify its design choices ("This button is large and placed in the bottom-right corner because it adheres to Fitts's Law"), leading to more principled, defensible, and ultimately delightful designs.&#xa;&#xa;**B. Technical &amp; Accessibility (A11y) Constraints**&#xa;&#xa;There is no "delight" in an interface that is unusable for a portion of the population. Elite prompts must enforce technical constraints as non-negotiable requirements, with accessibility (A11y) being paramount.&#xa;&#xa;*   **Pattern:** The prompt must explicitly command the AI to be "fully compliant with WCAG 2.2 AA." Research shows that without this explicit instruction, AI-generated components are "consistently" and unacceptably inaccessible.&#xa;*   **Specifics:** A high-quality A11y prompt enforces a checklist of best practices:&#xa;    *   **Semantic HTML:** "Ensure the proper use of HTML5 elements (like ``, ``, ``)."&#xa;    *   **Keyboard Accessibility:** "Test navigation using only Tab, Shift+Tab, and Enter keys. All interactive elements must be reachable and operable."&#xa;    *   **ARIA (Accessible Rich Internet Applications):** Mandate the correct application of "ARIA landmarks and roles," which are "HTML attributes that add semantic meaning... for assistive technologies."&#xa;    *   **Clear Content:** "Use clear, concise language... Write descriptive links: Swap vague text like 'click here' for something meaningful and context-rich."&#xa;&#xa;This pattern is the UI-domain's moral and functional equivalent of TDD. The prompt includes the acceptance criteria (WCAG standards). This "specification-as-prompt" is critical for generating production-ready, inclusive, and non-discriminatory interfaces.&#xa;&#xa;**C. Structural &amp; Layout Constraints**&#xa;&#xa;To control the form of the output and ensure it is machine-readable and programmatically useful, prompts must define a reliable data structure.&#xa;&#xa;*   **Architecture &amp; Flows:** For high-level system design, prompts specify formats like the C4 model rendered in Mermaid code. For user flows, Mermaid sequence diagrams are the standard for visualizing interactions.&#xa;*   **Wireframes:** Simple wireframe prompts use text descriptions, such as, "Include a header with a logo and search bar, a main content area with featured destinations, and a bottom navigation bar."&#xa;*   **SOTA (Structured Data):** The most robust and programmatically valuable pattern is to force the LLM to output a structured data format like JSON or YAML. This is achieved by providing an explicit output schema to the model. This pattern is now natively supported by major model providers, who allow schemas to be defined using libraries like Pydantic (for Python) or Zod (for TypeScript). This guarantees the output is not just arbitrary text, but a "type safe and consistent structure."&#xa;&#xa;This structured output pattern is the critical *lingua franca* between the two domains of this report. If a UI can be described in a reliable JSON schema, and a backend can expose its API in a reliable JSON schema (e.g., an OpenAPI specification), an agent can intelligently connect them. This structured output is the API contract between a UI-generation agent and a code-generation agent.&#xa;&#xa;**3. Generative UI (GenUI): The Dawn of the Living Interface**&#xa;&#xa;This is the bleeding-edge paradigm that underpins the entire future of UI design. Generative UI (GenUI) is a new philosophy that "enables adaptive, goal-driven interactions." Instead of a static interface designed by a human and then laboriously coded, the UI is generated in real-time by an AI, tailored to the user and the context.&#xa;&#xa;*   **Mechanism:** In this paradigm, the AI generates "interactive widgets for fine-grained prompt control" or entire "high-fidelity UI mock-up screens from a high-level textual description." This process is not one-shot; it is an iterative, "co-creative process" between the human and the AI, involving "AI-assisted refinement strategies."&#xa;*   **Current State:** GenUI is currently being adopted by UX practitioners as a powerful tool to accelerate their workflow, with the human remaining the curator, refiner, and final arbiter of the AI-generated output.&#xa;&#xa;GenUI is the logical culmination of prompt-based wireframing. The current limitation, and the key unexploited vector, is the reliance on a human-in-the-loop for optimization. The UI is refined based on a designer's intuition or explicit follow-up commands. The unexploited opportunity is to remove the human curator from the optimization loop. A system that could refine its own GenUI, not based on a designer's commands, but based on *live user data*, would represent a monumental paradigm shift. This is the core concept of a "Self-Optimizing UI" and forms the foundation for the novel Cognitive-Adaptive Interface (CAI) architecture.&#xa;&#xa;***&#xa;&#xa;### **Synthesis of Novel Architectures: Exceeding the Frontier**&#xa;&#xa;The preceding analysis deconstructed the current SOTA, revealing a set of potent, unexploited capability vectors. The following synthesis moves beyond merely replicating these patterns. It proposes three novel, high-level architectures that fuse these vectors to create self-regulating, self-optimizing systems designed to shatter current benchmarks. These architectures treat the prompt not as a static, one-time instruction, but as a "bootloader" for a continuous, autonomous process.&#xa;&#xa;**Table 1: Comparative Analysis of Generation &amp; Reasoning Architectures**&#xa;&#xa;| Architecture | Core Mechanism | Interaction Model | Key Limitation (Vector Not Exploited) | Unlocked Capability Vector |&#xa;| :--- | :--- | :--- | :--- | :--- |&#xa;| Chain-of-Thought (CoT) | Step-by-step reasoning (e.g., "Let's think step-by-step"). | Static | Brittle, linear reasoning; no external validation or tool use. | Basic multi-step problem solving. |&#xa;| ReAct | Interleaves reasoning (CoT) with tool use (Actions). | Iterative | Dependent on pre-defined tools; no long-term memory or structured collaboration. | Environment-aware task execution. |&#xa;| Graph of Thoughts (GoT) | Models reasoning as a graph, allowing merging of states and feedback loops. | Iterative | High conceptual complexity; primarily focused on reasoning, not execution. | Advanced, non-linear problem-solving. |&#xa;| TDD-as-Prompt | A test suite is provided as the functional specification for code generation. | Static | Requires human to write all tests; no self-correction loop. | Verifiable, high-reliability code generation. |&#xa;| Generative UI (GenUI) | AI generates high-fidelity UI mockups or interactive widgets from text descriptions. | Iterative | Requires human-in-the-loop for curation and refinement; based on assumed user needs. | Rapid, co-creative UI prototyping. |&#xa;| **[NOVEL] Cognitive-Adaptive Interface (CAI) Engine** | GenUI + Cognitive Fitness Function + Live User Telemetry. | Dynamic-Adaptive | N/A (Synthesized Architecture) | Real-time UI self-optimization based on observed user cognitive state. |&#xa;| **[NOVEL] Test-Driven Agent (TDA) Framework** | Closed-loop TDD + Agentic RAG + Error-Forward Self-Healing. | Autonomous-Iterative | N/A (Synthesized Architecture) | Verifiable, context-aware, autonomous development with guaranteed build integrity. |&#xa;| **[NOVEL] Self-Optimizing Product (SOP) Loop** | TDA-CAI integration via an RLHF-from-Telemetry feedback loop. | Autonomous-Holistic | N/A (Synthesized Architecture) | Fully autonomous product self-improvement driven by implicit user feedback. |&#xa;&#xa;#### **Proposed Architecture 1: The "Cognitive-Adaptive Interface" (CAI) Engine**&#xa;&#xa;This architecture synthesizes Generative UI (GenUI) with persona-driven design and, most critically, cognitive-heuristic constraints. It is engineered to evolve UI generation from a static, one-shot process ("generate a wireframe") into a continuous, adaptive, and self-optimizing one.&#xa;&#xa;*   **Vector Exploited:** This architecture directly targets the vector identified in (I.B.1) and (I.B.3): the fusion of Generative UI with real-time user telemetry. The system does not just generate a UI; it dynamically sculpts it in real-time based on observed user behavior and cognitive state.&#xa;*   **Mechanism:** The CAI Engine operates as a continuous four-phase loop, a digital nervous system for the interface.&#xa;    1.  **Phase 1: The "Cognitive Metaprompt".** The architect does not prompt for a specific layout. Instead, they provide a high-level, structured (e.g., YAML) prompt that defines the goals and constraints. This metaprompt specifies the `target_persona`, the `business_objective` (e.g., "maximize conversion"), and a `cognitive_fitness_function`—a weighted list of principles (e.g., `cognitive_load: -0.5`, `fitts_law_compliance: +0.3`) that will be used to score the UI's performance.&#xa;    2.  **Phase 2: Initial Generation.** The CAI engine uses this metaprompt to generate the initial UI component tree as a structured JSON artifact. This initial design represents the engine's best hypothesis for satisfying the `cognitive_fitness_function`.&#xa;    3.  **Phase 3: The Telemetry Loop.** This is the critical connection to the real world. As users interact with the dynamically-rendered GenUI, the system collects fine-grained telemetry, capturing not just clicks but also proxies for cognitive state: hesitation time (cognitive load), rage clicks (frustration), scroll depth (engagement), and form drop-off points.&#xa;    4.  **Phase 4: Autonomous Optimization.** This rich telemetry stream is fed back into the CAI engine. The engine continuously scores the live UI's performance against the `cognitive_fitness_function`. It then initiates a self-optimizing process, autonomously running micro-A/B tests or reinforcement learning strategies to adapt the UI. For example, it might log: *"Hypothesis: Moving 'Add to Cart' button 10px closer to the product image will improve the Fitts's Law component of the fitness function. Result: Target acquisition speed improved by 80ms and conversion metric increased by 0.2%. This change is now permanent for this user segment."*&#xa;*   **Exceeding the Benchmark:** This architecture creates a true "Self-Optimizing UI." The prompt is no longer a blueprint for a static house; it is the DNA for a living organism that adapts to its environment (the user) in real-time. It moves beyond static, assumed personas to build an interface that dynamically aligns with the observed cognitive and behavioral patterns of its actual users.&#xa;&#xa;#### **Proposed Architecture 2: The "Test-Driven Agent" (TDA) Framework**&#xa;&#xa;This architecture synthesizes the most robust patterns from the code construction domain: TDD-as-Prompt, Self-Validation, and Agentic RAG. It creates a closed-loop, "self-healing" system designed to enable verifiable, autonomous development at the repository level.&#xa;&#xa;*   **Vector Exploited:** This architecture exploits the vector identified in (I.A.5): the fusion of autonomous, closed-loop TDD with context-aware Agentic RAG. The agent's deliverable is not "code"; it is a "passing build."&#xa;*   **Mechanism:** The TDA Framework operates as a five-phase, autonomous workflow:&#xa;    1.  **Phase 1: The "User Story Metaprompt".** A human (or another agent) provides a high-level feature request in a structured format (e.g., JSON), defining the goal, not the implementation. Example: `{"user_story": "As a user, I want to reset my password via email.", "acceptance_criteria": [...]}`.&#xa;    2.  **Phase 2: RAG-Context.** The TDA's first action is not to code, but to *read*. It activates its Agentic RAG module to perform "context-aware query planning," querying the entire codebase and documentation to build a deep understanding of the existing system (e.g., "Query: 'auth routes'", "Query: 'email service'").&#xa;    3.  **Phase 3: Test Generation (Red).** Armed with this context, the TDA first generates a new, *failing* unit test (e.g., `test_post_forgot_password_invalid_email_404`). This step codifies the `acceptance_criteria` from the metaprompt into a verifiable, functional contract.&#xa;    4.  **Phase 4: Code Generation (Green).** The agent now generates the minimal amount of implementation code required to make the new test pass.&#xa;    5.  **Phase 5: Reflect &amp; Refactor (Self-Healing).** The TDA does not stop. It now runs the *entire* test suite. If an old test fails (a regression), it enters a "self-healing" loop, using the "Error-Forward Prompt" pattern to feed the new stack trace back to itself. It then reflects and iterates on the code until the full build is green.&#xa;*   **Exceeding the Benchmark:** This architecture moves far beyond task-oriented benchmarks like SWE-bench. The TDA's output is not "a code snippet that solves a problem"; it is a passing, context-aware, and regression-free build. This builds the profound level of trust required for true "agentic software engineering" by producing verifiable, reliable, and autonomous results that can be directly committed to a main branch.&#xa;&#xa;#### **The Unified Synthesis: The "Self-Optimizing Product" (SOP) Loop**&#xa;&#xa;This is the final, unified architecture. It bridges the two domains by connecting the TDA (backend code) and the CAI (frontend UI) into a single, product-level optimization loop. This system is designed to autonomously improve the entire product—both its functionality and its interface—based on the silent language of user interaction.&#xa;&#xa;*   **Vector Exploited:** This architecture exploits the most potent "unexplored vector": connecting the CAI (UI) and TDA (Code) architectures via a shared feedback loop that uses Reinforcement Learning from Human Feedback (RLHF). In this advanced paradigm, the "human feedback" is not an explicit button click; it is the *implicit behavioral telemetry* collected from the CAI, which is then used to train a reward model and guide the policy of the entire system.&#xa;*   **Mechanism (The Full Loop):**&#xa;    1.  **Deploy:** The TDA (Architecture 2) generates and deploys the backend `API_v1`. The CAI (Architecture 1) generates the frontend UI to consume it, governed by its `cognitive_fitness_function`.&#xa;    2.  **Observe (Telemetry):** The CAI's telemetry loop observes a "user delight" failure. It logs: *"70% of users drop off at the 'Security Question' form. Average hesitation time is 12 seconds. This violates the cognitive_load component of our fitness function."*&#xa;    3.  **Translate (Feedback Agent):** This telemetry is fed into a new, specialized "Feedback Agent." This reasoning agent (using GoT) translates this quantitative behavioral data into a new product requirement, autonomously generating a new User Story Metaprompt: `{"user_story": "The 'Security Question' flow causes high friction. Replace it with a 'Magic Link' email workflow.", "acceptance_criteria": [...]}`.&#xa;    4.  **Trigger (TDA):** This new user story is automatically fed as an Init-Prompt to the TDA.&#xa;    5.  **Heal &amp; Evolve (TDA):** The TDA springs into action. It RAGs the codebase, writes new failing tests for the 'Magic Link' flow, generates the new `API_v2` endpoints, and (critically) writes and deploys a migration to deprecate `API_v1`.&#xa;    6.  **Adapt (CAI):** The TDA's deployment triggers the CAI. Now aware of the new `API_v2`, the CAI re-generates its UI components to consume the new, "healed" workflow, automatically adapting the interface to the new, lower-friction flow.&#xa;*   **Exceeding the Benchmark:** The loop is complete. The product itself (code + UI) has just autonomously optimized its own design to improve "user delight," with zero human intervention. This is the new benchmark. The "prompt" is no longer a static, human instruction; it is a continuous, self-generated feedback signal originating from the user's own behavior.&#xa;&#xa;***&#xa;&#xa;### **Strategic Implementation and Future Trajectories**&#xa;&#xa;The architectures proposed are not theoretical fantasies. They can be implemented by shifting from natural language prompts to structured metaprompts that act as the bootloaders and configuration files for these autonomous systems.&#xa;&#xa;#### **Actionable Blueprints: Structured Metaprompts as the System API**&#xa;&#xa;To make these architectures concrete, we must define their initialization. The most critical pattern for SOTA systems is the use of structured (not natural language) prompts, ensuring reliable, machine-parseable interaction. YAML is used for its human-readability in top-level configuration, while schema-enforced JSON serves as the non-negotiable "API" for inter-agent communication.&#xa;&#xa;**Example Blueprint 1: YAML Metaprompt for the CAI Engine**&#xa;&#xa;```yaml&#xa;# This YAML file is the master-prompt for the Cognitive-Adaptive Interface (CAI) Engine.&#xa;# It defines the *purpose* and *constraints* of the UI, not its pixels.&#xa;&#xa;system_role: "You are a CAI (Cognitive-Adaptive Interface) Engine. Your goal is to generate and continuously optimize a user interface to maximize the 'objective' by adhering to the 'fitness_function'."&#xa;&#xa;objective:&#xa;  type: "maximize_conversion"&#xa;  target_metric: "checkout_completion_rate"&#xa;  &#xa;target_persona:&#xa;  # This persona is the seed for the initial UI generation. The system will&#xa;  # later build a dynamic model based on real user behavior.&#xa;  file: "./personas/busy_professional_mobile.json" &#xa;  &#xa;technical_constraints:&#xa;  # Non-negotiable acceptance criteria for all generated interfaces.&#xa;  - "WCAG_2_2_AA_COMPLIANT"&#xa;  - "OUTPUT_FORMAT_SEMANTIC_HTML_WITH_ARIA"&#xa;  - "MAX_LOAD_TIME_MS_3G: 1500"&#xa;  &#xa;cognitive_fitness_function:&#xa;  # The heart of the CAI. The engine will score its own UI against these&#xa;  # principles using live telemetry data as the input for the metrics.&#xa;  - principle: "cognitive_load" &#xa;    weight: -0.5 # (Minimize)&#xa;    metric: "avg_task_hesitation_time_sec"&#xa;    &#xa;  - principle: "hick's_law" &#xa;    weight: -0.3 # (Minimize choices)&#xa;    metric: "choice_count_per_screen"&#xa;&#xa;  - principle: "fitts_law_compliance" &#xa;    weight: 0.3 # (Maximize)&#xa;    metric: "target_acquisition_speed_ms"&#xa;    &#xa;  - principle: "nielsen_heuristic_4_consistency" &#xa;    weight: 0.2 # (Maximize)&#xa;    metric: "component_reuse_score"&#xa;```&#xa;&#xa;**Example Blueprint 2: JSON Metaprompt for the TDA Framework**&#xa;&#xa;```json&#xa;/*&#xa;  This JSON object is the "Init-Prompt" for the Test-Driven Agent (TDA).&#xa;  It is autonomously generated by the "Feedback Agent" [II.C] after translating&#xa;  a telemetry-detected user problem into an actionable engineering task.&#xa;*/&#xa;{&#xa;  "system_role": "You are a TDA (Test-Driven Agent). Your mandate is to generate code that achieves a green build. You must write failing tests first.",&#xa;  "task_id": "TDA-1138",&#xa;  "source_trigger": "SOP_Feedback_Agent_Telemetry_Violation_cognitive_load",&#xa;  "user_story": "The 'Security Question' flow (API_v1) causes high user friction (70% drop-off). You must replace it with a 'Magic Link' email workflow (API_v2).",&#xa;  "rag_context_queries": [&#xa;    "Retrieve file:./routes/auth.js",&#xa;    "Retrieve file:./services/EmailService.js",&#xa;    "Retrieve file:./models/User.js",&#xa;    "Retrieve related tests: test_auth.py"&#xa;  ],&#xa;  "acceptance_criteria": [&#xa;    "POST /api/v2/magic-link must accept an 'email'.",&#xa;    "Must return 404 if email does not exist.",&#xa;    "Must return 200 and trigger EmailService.sendMagicLink on success.",&#xa;    "Must generate a unique, single-use token with a 15-minute expiry.",&#xa;    "Must create a new failing test for 'token_expired' scenario."&#xa;  ]&#xa;}&#xa;```&#xa;&#xa;#### **Future Capability Vectors &amp; Redefining Benchmarks**&#xa;&#xa;The user's final mandate is to "exceed current benchmarks." The SOP architecture, if implemented, renders current benchmarks obsolete.&#xa;&#xa;*   **Current Benchmarks:** Benchmarks like HumanEval and SWE-bench are task-oriented and static. They are critical for measuring an agent's ability to solve a given, siloed problem. However, they are like testing a Formula 1 engine on a dynamometer instead of on a racetrack during a live race. They do not measure the agent's ability to *identify the problem* or validate its solution against holistic, user-centric goals.&#xa;*   **The New Benchmark:** The SOP architecture operates at the product level. The new benchmark must not be "Can the AI solve a GitHub issue?" It must be "**Can the AI identify, validate, and solve a user-delight issue autonomously from raw telemetry?**"&#xa;&#xa;**Proposed New Benchmark: "Product-Bench"**&#xa;&#xa;*   **Given:** A high-level product goal (e.g., "build a photo-sharing app") and a `cognitive_fitness_function`.&#xa;*   **Input:** A stream of (simulated) user telemetry, representing a diverse set of user interactions over time.&#xa;*   **Task:** The AI system (SOP) must:&#xa;    1.  Build the V1 of the product (TDA + CAI).&#xa;    2.  Autonomously evolve its features, code, and UI over 1 million simulated user-sessions in response to the telemetry stream.&#xa;*   **Metric:** The final score is the system's ability to maximize the `cognitive_fitness_function` (a composite "User Delight" score) over the duration of the simulation.&#xa;&#xa;This new benchmark aligns with the future of HCI and AI, which is moving toward human-AI co-creation, AI-augmented reasoning, and human-centered evaluation. The ultimate prompt architecture is one that creates its own prompts, guided by its core purpose and its continuous, real-time interaction with the world. This is the new, and achievable, benchmark for excellence.</title></path></g><g><g><title>Of course. Here is the enhanced version of the text, integrating more vivid, descriptive language and keywords to increase engagement and detail while preserving the core message.&#xa;&#xa;---&#xa;### **The Prompt as a Genesis Engine: Architecting Self-Optimizing AI Systems**&#xa;*From Static Blueprints to Dynamic Organisms: Synthesizing Autonomous Systems for Code and Interface Generation*&#xa;&#xa;#### **Deconstructing Elite-Tier Prompt Patterns: A Survey of the Current Frontier**&#xa;&#xa;The art and science of interacting with Large Language Models (LLMs) have undergone a seismic shift, metamorphosing from simple, single-turn commands into intricate, multi-stage prompt architectures. This evolution is nowhere more pronounced than in the demanding technical domains of software engineering and user interface (UI) design. A meticulous analysis of today's elite-tier patterns reveals an unmistakable trajectory: a decisive pivot away from static, human-authored instructions and toward dynamic, machine-optimized, and process-oriented systems that breathe and adapt.&#xa;&#xa;This section deconstructs the state-of-the-art (SOTA) patterns in these two critical domains. Our goal is to establish the foundational benchmarks of what is currently possible and, more importantly, to illuminate the unexploited capability vectors—the fertile ground where the next generation of AI systems will flourish.&#xa;&#xa;***&#xa;&#xa;### **Domain 1: Architectures for High-Integrity Code Construction**&#xa;&#xa;In the realm of software engineering, the ambition has transcended the simple act of generating code snippets. The new mandate is to engineer reliable, context-aware, and increasingly autonomous systems. The most triumphant patterns treat the LLM not as a mere code parrot, but as a sophisticated reasoning engine to be embedded within a larger, rigorously structured development framework.&#xa;&#xa;**1. Automated Prompt Optimization: The "Prompt-as-a-Target" Pattern**&#xa;&#xa;The manual, artisanal process of refining prompts for code generation is a well-known bottleneck—a frustrating cycle of trial and error that is both time-consuming and inconsistent. The SOTA has advanced to automate this craft, treating the prompt itself as a first-class artifact to be algorithmically optimized.&#xa;&#xa;*   **Evolutionary-Based Methods (EPiC):** The EPiC (Evolutionary Prompt Engineering for Code) framework represents a paradigm shift, exploring code generation through the lens of cost-effectiveness. It "leverages a lightweight evolutionary algorithm to evolve the original prompts toward better ones that produce high-quality code." By employing genetic operators like mutation on the prompt's text and steering the search with a precise fitness function, EPiC automates the discovery of optimal prompt phrasing in a remarkably efficient manner.&#xa;*   **Iterative Refinement (Prochemy):** The "Prompt Alchemy" (Prochemy) method offers an "innovative method for automatically refining prompts to boost code generation." This system operates as a feedback loop, iteratively sculpting prompts based on the model's measured performance on specific tasks. This automated optimization forges consistency and has yielded substantial performance gains, such as a **5.0% improvement for GPT-3.5-Turbo on HumanEval** and a striking **12.9% improvement for GPT-4o** on complex Java-to-Python code translation tasks.&#xa;*   **Adaptive Selection (PET-Select):** Acknowledging that "no single approach is universally optimal," the PET-Select framework introduces a crucial meta-layer of intelligence. This "PET-agnostic selection model" first classifies the complexity of an incoming query, using code intricacy as a proxy. It then dynamically selects the most appropriate prompt engineering technique (PET)—dispatching a simple zero-shot prompt for a trivial query or invoking a complex multi-stage reasoning chain for a formidable one. This automated, adaptive triage has been proven to elevate **pass@1 accuracy by up to 1.9%** while simultaneously achieving a **74.8% reduction in token consumption**.&#xa;&#xa;The clear evolutionary arc in this domain is from a human-centric "prompt engineering" phase to a machine-centric "prompt optimization" phase. The AI is no longer just the executor of the instruction; it is becoming the architect of the instruction itself. These systems, however, are fundamentally *reactive*. They optimize a prompt for a known task within a known solution space. They do not yet *proactively* generate a novel prompt architecture for a novel, undiscovered problem. This points toward a tantalizing unexploited vector: a system that can discover a new problem domain (e.g., from user feedback) and then author its own comprehensive prompt architecture to conquer it—a true meta-prompting capability.&#xa;&#xa;**2. Test-Driven Development (TDD) as a Prompting Paradigm**&#xa;&#xa;Arguably the most powerful and reliable pattern for generating high-quality code is the direct integration of Test-Driven Development (TDD) principles into the prompt architecture. TDD is an "incremental software development methodology that focuses on creating tests before the implementation." When applied to LLMs, the test suite becomes an unambiguous, machine-verifiable contract.&#xa;&#xa;*   **Core Principle:** Instead of wrestling with the inherent ambiguity of natural language, the prompt provides the LLM with a concrete set of unit tests and issues a clear directive: "write code to pass all tests." This pattern's remarkable success hinges on "instruction following and in-context learning," which have been identified as more "critical capabilities for TDD success" than generalized coding proficiency. The tests are the ultimate, incorruptible instruction.&#xa;*   **Frameworks:** Sophisticated systems are being engineered to formalize this contract. The TGEN framework, for example, employs "Specialized agents" that accept two primary inputs: the "programming prompt" (a concise description) and "the tests" (the explicit unit tests and required function signatures). These are then processed by the LLM engine to produce validated, trustworthy code.&#xa;*   **Prompt Structure:** This paradigm fundamentally transforms the anatomy of the prompt. The request evolves from a vague "what" to a highly constrained "how." A common elite-level TDD prompt is a set of ironclad rules: *"1. Write a single Python function that passes all the provided tests. 2. Use type hints for all parameters and return values. 3. ...Adhere strictly to Python best practices and PEP 8... 4. Ensure the function handles all edge cases and scenarios explicitly covered in the tests. 5. Provide only the function definition and its implementation, nothing more."*&#xa;&#xa;The TDD-as-prompt pattern furnishes an objective, verifiable measure of "correctness" that is vastly superior to ambiguous natural language requests. It masterfully shifts the burden of human effort from vaguely *describing* the code to precisely *defining its behavior* through tests. This is a crucial leap from semantic validation (is the code "good"?) to functional validation (does the code *work*?). The next logical frontier, and the key unexploited vector, is to close the loop: to create a system that not only generates code from tests but also generates its own tests and validates its own code in a continuous, self-perpetuating cycle.&#xa;&#xa;**3. Self-Validation and "Error-Forward" Debugging**&#xa;&#xa;This pattern extends the TDD loop into a dynamic, autonomous process. For an agent to be truly autonomous, it must possess the ability to recognize, diagnose, and recover from its own errors.&#xa;&#xa;*   **Self-Validation:** SOTA agentic systems are architected to "regularly verify progress and self-assess correctness." This "agentic self-validation" is a core capability that "drives up accuracy" and enables robust, long-running execution. Agents from Cognition, for instance, are noted to "excel at testing its own code, enabling Devin to run longer, handle harder tasks, and deliver production-ready code." This deep integration of TDD within an autonomous agent allows it to "go through several improvement cycles on its own instead of having to manually ask the AI to fix test failures."&#xa;*   **"Error-Forward Prompting":** This is the primary recovery mechanism within the self-validation loop, treating errors as high-fidelity data, not as failures. When an agent's self-validation check fails, the system automatically "collects relevant context, including the error message, stack trace, and cell location." This rich diagnostic information is then formatted and "provided to the agent as the initial context for beginning the debugging process." The error itself becomes the next prompt.&#xa;*   **Reflection:** This is the crucial learning mechanism that makes recovery effective. A "reflection system enables the agent to learn from its actions and improve its debugging strategy." Implemented via "reflective prompting," this allows the model to "analyze and refine its outputs." The model first generates a solution, then "through subsequent prompts, critiques its own reasoning to identify and correct errors," a process formalized in techniques like Self-Refine, which elegantly mimics the human "draft, review, refine" workflow.&#xa;&#xa;In this paradigm, failure is transformed from an end-state into a high-value data signal. The stack trace becomes the most valuable part of the prompt—a pure, unambiguous instruction set for what must be fixed. When TDD-as-prompt is fused with this self-validation and reflection loop, the system becomes truly "self-healing." The prompt is no longer a single-shot instruction but the initiation of a self-sustaining process. The agent's goal is elevated from "generate code" to "make the build pass," a critical and profound step toward genuine autonomy.&#xa;&#xa;**4. Agentic Frameworks and Multi-Agent Collaboration**&#xa;&#xa;Complex software development is a symphony of diverse tasks, impossible to solve in a single step or by a single-minded agent. The recognition that single-shot prompts "yield imprecise or plain incorrect results" for elaborate tasks has catalyzed the rise of sophisticated agentic frameworks.&#xa;&#xa;*   **Advanced Reasoning Patterns:** These frameworks are built upon a reasoning fabric far more advanced than simple Chain-of-Thought (CoT).&#xa;    *   **ReAct:** This foundational pattern masterfully combines "Reason and Act," allowing an agent to interleave step-by-step reasoning with tool use to gather external information or perform actions in an environment.&#xa;    *   **Tree of Thoughts (ToT):** Moving beyond the linear, single-track path of CoT, ToT empowers an agent to "breakdown intermediate processed into steps," generate "various generated states," and strategically "evaluate" those states to "determine which branch to explore next."&#xa;    *   **Graph of Thoughts (GoT):** The current SOTA in reasoning, GoT generalizes ToT into a full graph structure. This architecture "enables combining arbitrary LLM thoughts into synergistic outcomes" and, critically, "enhancing thoughts using feedback loops." GoT has been demonstrated to increase the quality of complex sorting tasks by **62% over ToT** while simultaneously reducing costs.&#xa;*   **Agentic Frameworks:** These advanced reasoning patterns are orchestrated by multi-agent frameworks that simulate collaborative work.&#xa;    *   **MetaGPT:** This framework simulates a "real-world software company," assigning agents specialized roles like "product manager, software architect, programmer, or QA tester" and embedding them with "Standard Operating Procedures (SOPs)."&#xa;    *   **ChatDev:** This framework orchestrates a "waterfall-style" collaboration, where agents engage in "task-oriented and multi-turn communications" to iteratively design, code, test, and document solutions.&#xa;*   **Purpose:** These frameworks are essential as they provide a "shared philosophy of control &amp; reasoning." Without such a structure, agentic systems suffer from a "loss of control clarity of flow" and risk "unbounded complexity growth" as new agents are added.&#xa;*   **Benchmarks:** These powerful agentic systems are precisely what achieve top scores on complex, real-world benchmarks that measure engineering capability. The **SWE-bench** benchmark, for instance, measures "an AI model's ability to solve real-world software issues." SOTA models conquer SWE-bench and OSWorld by leveraging these multi-agent, self-testing architectures.&#xa;&#xa;The atomic unit of these frameworks is role-based prompting; the frameworks themselves are, in essence, prompt-driven state machines. A high-level "meta-prompt" defines the agents, their roles, their tools, and their communication protocols. The LLM is thus demoted from "solution generator" to a core component—a "reasoning engine" that navigates this pre-defined architecture. The architecture itself *is* the prompt. The current limitation, and the unexplored vector, is that these frameworks are simulations of human workflows (e.g., "waterfall," "software company"). An AI-native workflow, where feedback comes not from a simulated "QA Agent" but from the product itself via live user telemetry, would be a fundamentally more direct and efficient paradigm.&#xa;&#xa;**5. Context-Aware Generation (Agentic RAG)**&#xa;&#xa;Code generation is useless without domain context. Retrieval-Augmented Generation (RAG) is the primary pattern for injecting this context, and its agentic form represents the state of the art.&#xa;&#xa;*   **RAG-for-Code:** This pattern gives an AI assistant "a direct line to your team's collective knowledge." The prompt is "augmented" with hyper-relevant information retrieved from "documentation, code repositories, or even Stack Overflow discussions." This vital infusion ensures the generated response is "context-aware" and surgically relevant to the specific codebase it is intended for.&#xa;*   **Agentic RAG:** This is the "evolution from traditional single-query RAG." Instead of being a passive recipient of retrieved context, the agent actively *forages* for it. It performs "context-aware query planning," can issue "parallel execution of multiple focused subqueries," and then synthesizes the results to build a comprehensive, multi-faceted understanding of the problem space. This is the sophisticated approach employed by modern agentic frameworks like LangGraph, AutoGen, and those from Amazon and Microsoft.&#xa;&#xa;The RAG-for-Code pattern transforms a "general-purpose coder" into a "domain-specific engineer" who understands the nuances, conventions, and constraints of a particular project. The agentic aspect is the critical differentiator; it is the difference between giving a developer a sprawling, unindexed library (standard RAG) and providing a seasoned research assistant who knows exactly which three pages contain the answer (Agentic RAG). The most potent, yet not fully exploited, vector in code generation is the fusion of this **Agentic RAG (for context)** with the **TDD-as-Prompt paradigm (for verification)**. An agent that can retrieve context from a 500,000-line codebase and validate its changes against that codebase's entire test suite represents the leap from a "coding assistant" to an "autonomous developer." This powerful fusion is the core of the novel Test-Driven Agent (TDA) architecture proposed in Part II.&#xa;&#xa;***&#xa;&#xa;### **Domain 2: Architectures for User Delight &amp; UI Design**&#xa;&#xa;In the second domain, user interface generation, the mandate for "user delight" demands a leap beyond mere wireframe generation. Elite-tier prompts in this space are not about "generating pixels" but about "generating experiences"—experiences that are deeply grounded in human-centric design principles.&#xa;&#xa;**1. Persona-Driven Design: Grounding Generation in Empathy**&#xa;&#xa;"User delight" is the "positive emotional response users feel when a product doesn't just meet their needs but goes above and beyond." This coveted state is "highly contextual" and cannot be achieved without first defining, with deep empathy, the user for whom we are designing.&#xa;&#xa;*   **Pattern:** Elite prompts for UI design do not begin with the interface; they begin with the user. The system is first prompted to generate a detailed proto-persona. This artifact includes not just demographic details but also the "target users, their core pain points, and daily use context," as well as deeper "Motivations" and "Affinities."&#xa;*   **Application:** This generated persona (or a human-provided one) is then injected as a primary constraint into all subsequent UI generation prompts. This forces the AI to "cater to Gen Z and Gen X users" differently, tailoring the design language, informational density, and interaction patterns to a specific audience. The prompt is no longer "generate a wireframe for a music app," but rather, "generate a wireframe for a music app *for this specific persona*, focusing on their stated pain point of *{pain_point}*."&#xa;&#xa;This persona-driven pattern acts as a powerful focusing lens on the model's vast solution space, compelling it to move from generating a generically "good UI" to a UI that is specifically "good for *this* user." It is, in effect, a form of in-context learning for design, where the persona serves as a "one-shot" example of the target audience. The major limitation, and the unexploited vector, is that this is a static process. The persona is a snapshot, an assumption created at the beginning of the design process. The clear next step is to evolve from these static, assumed personas to dynamic, *observed user models* that are continuously updated based on real-time behavioral analytics.&#xa;&#xa;**2. Constraint-Based Generation: Defining the "Solution Space" with Intelligent Guardrails**&#xa;&#xa;The highest-fidelity UI generation requires the application of multiple, layered constraints. These constraints are the specifications that ensure the output is not just creative, but also functional, accessible, and grounded in established design theory. These intelligent guardrails fall into three primary categories.&#xa;&#xa;**A. Cognitive &amp; Heuristic Constraints**&#xa;&#xa;This is the most sophisticated pattern for achieving true "user delight." The prompt explicitly instructs the AI to apply principles from cognitive science and established usability heuristics, forcing the AI to design for the human mind.&#xa;&#xa;*   **Heuristics:** The most common pattern is to prompt the AI to embody a UX expert and evaluate or generate a design based on "Nielsen's 10 Usability Heuristics" or other well-known frameworks like Shneiderman's "Eight Golden Rules."&#xa;*   **Cognitive Principles:** More advanced prompts instruct the AI to directly apply specific cognitive laws to reduce friction and enhance intuition. Examples include:&#xa;    *   **Fitts's Law:** Prompting the AI to make "important buttons and interactive elements larger and closer to where users naturally focus," making the interface feel effortless.&#xa;    *   **Hick's Law:** Instructing the AI to "reduc[e] the number of options or organiz[e] them into categories" to accelerate decision-making and prevent analysis paralysis.&#xa;    *   **Cognitive Load:** Prompting with the explicit goal of "reducing cognitive load" to create a more fluid and less mentally taxing experience.&#xa;*   **Behavioral Models:** The most advanced prompts leverage frameworks like BJ Fogg's Behavior Model (B=MAP: Motivation, Ability, Prompt) or Nir Eyal's "Hooked" model to design persuasive, habit-forming, and deeply engaging interfaces.&#xa;&#xa;Prompting with "Nielsen's Heuristics" or "Fogg's Behavior Model" acts as a domain-specific Chain-of-Thought. It forces the AI to justify its design choices ("This button is large and placed in the bottom-right corner because it adheres to Fitts's Law"), leading to more principled, defensible, and ultimately delightful designs.&#xa;&#xa;**B. Technical &amp; Accessibility (A11y) Constraints**&#xa;&#xa;There is no "delight" in an interface that is unusable for a portion of the population. Elite prompts must enforce technical constraints as non-negotiable requirements, with accessibility (A11y) being paramount.&#xa;&#xa;*   **Pattern:** The prompt must explicitly command the AI to be "fully compliant with WCAG 2.2 AA." Research shows that without this explicit instruction, AI-generated components are "consistently" and unacceptably inaccessible.&#xa;*   **Specifics:** A high-quality A11y prompt enforces a checklist of best practices:&#xa;    *   **Semantic HTML:** "Ensure the proper use of HTML5 elements (like ``, ``, ``)."&#xa;    *   **Keyboard Accessibility:** "Test navigation using only Tab, Shift+Tab, and Enter keys. All interactive elements must be reachable and operable."&#xa;    *   **ARIA (Accessible Rich Internet Applications):** Mandate the correct application of "ARIA landmarks and roles," which are "HTML attributes that add semantic meaning... for assistive technologies."&#xa;    *   **Clear Content:** "Use clear, concise language... Write descriptive links: Swap vague text like 'click here' for something meaningful and context-rich."&#xa;&#xa;This pattern is the UI-domain's moral and functional equivalent of TDD. The prompt includes the acceptance criteria (WCAG standards). This "specification-as-prompt" is critical for generating production-ready, inclusive, and non-discriminatory interfaces.&#xa;&#xa;**C. Structural &amp; Layout Constraints**&#xa;&#xa;To control the form of the output and ensure it is machine-readable and programmatically useful, prompts must define a reliable data structure.&#xa;&#xa;*   **Architecture &amp; Flows:** For high-level system design, prompts specify formats like the C4 model rendered in Mermaid code. For user flows, Mermaid sequence diagrams are the standard for visualizing interactions.&#xa;*   **Wireframes:** Simple wireframe prompts use text descriptions, such as, "Include a header with a logo and search bar, a main content area with featured destinations, and a bottom navigation bar."&#xa;*   **SOTA (Structured Data):** The most robust and programmatically valuable pattern is to force the LLM to output a structured data format like JSON or YAML. This is achieved by providing an explicit output schema to the model. This pattern is now natively supported by major model providers, who allow schemas to be defined using libraries like Pydantic (for Python) or Zod (for TypeScript). This guarantees the output is not just arbitrary text, but a "type safe and consistent structure."&#xa;&#xa;This structured output pattern is the critical *lingua franca* between the two domains of this report. If a UI can be described in a reliable JSON schema, and a backend can expose its API in a reliable JSON schema (e.g., an OpenAPI specification), an agent can intelligently connect them. This structured output is the API contract between a UI-generation agent and a code-generation agent.&#xa;&#xa;**3. Generative UI (GenUI): The Dawn of the Living Interface**&#xa;&#xa;This is the bleeding-edge paradigm that underpins the entire future of UI design. Generative UI (GenUI) is a new philosophy that "enables adaptive, goal-driven interactions." Instead of a static interface designed by a human and then laboriously coded, the UI is generated in real-time by an AI, tailored to the user and the context.&#xa;&#xa;*   **Mechanism:** In this paradigm, the AI generates "interactive widgets for fine-grained prompt control" or entire "high-fidelity UI mock-up screens from a high-level textual description." This process is not one-shot; it is an iterative, "co-creative process" between the human and the AI, involving "AI-assisted refinement strategies."&#xa;*   **Current State:** GenUI is currently being adopted by UX practitioners as a powerful tool to accelerate their workflow, with the human remaining the curator, refiner, and final arbiter of the AI-generated output.&#xa;&#xa;GenUI is the logical culmination of prompt-based wireframing. The current limitation, and the key unexploited vector, is the reliance on a human-in-the-loop for optimization. The UI is refined based on a designer's intuition or explicit follow-up commands. The unexploited opportunity is to remove the human curator from the optimization loop. A system that could refine its own GenUI, not based on a designer's commands, but based on *live user data*, would represent a monumental paradigm shift. This is the core concept of a "Self-Optimizing UI" and forms the foundation for the novel Cognitive-Adaptive Interface (CAI) architecture.&#xa;&#xa;***&#xa;&#xa;### **Synthesis of Novel Architectures: Exceeding the Frontier**&#xa;&#xa;The preceding analysis deconstructed the current SOTA, revealing a set of potent, unexploited capability vectors. The following synthesis moves beyond merely replicating these patterns. It proposes three novel, high-level architectures that fuse these vectors to create self-regulating, self-optimizing systems designed to shatter current benchmarks. These architectures treat the prompt not as a static, one-time instruction, but as a "bootloader" for a continuous, autonomous process.&#xa;&#xa;**Table 1: Comparative Analysis of Generation &amp; Reasoning Architectures**&#xa;&#xa;| Architecture | Core Mechanism | Interaction Model | Key Limitation (Vector Not Exploited) | Unlocked Capability Vector |&#xa;| :--- | :--- | :--- | :--- | :--- |&#xa;| Chain-of-Thought (CoT) | Step-by-step reasoning (e.g., "Let's think step-by-step"). | Static | Brittle, linear reasoning; no external validation or tool use. | Basic multi-step problem solving. |&#xa;| ReAct | Interleaves reasoning (CoT) with tool use (Actions). | Iterative | Dependent on pre-defined tools; no long-term memory or structured collaboration. | Environment-aware task execution. |&#xa;| Graph of Thoughts (GoT) | Models reasoning as a graph, allowing merging of states and feedback loops. | Iterative | High conceptual complexity; primarily focused on reasoning, not execution. | Advanced, non-linear problem-solving. |&#xa;| TDD-as-Prompt | A test suite is provided as the functional specification for code generation. | Static | Requires human to write all tests; no self-correction loop. | Verifiable, high-reliability code generation. |&#xa;| Generative UI (GenUI) | AI generates high-fidelity UI mockups or interactive widgets from text descriptions. | Iterative | Requires human-in-the-loop for curation and refinement; based on assumed user needs. | Rapid, co-creative UI prototyping. |&#xa;| **[NOVEL] Cognitive-Adaptive Interface (CAI) Engine** | GenUI + Cognitive Fitness Function + Live User Telemetry. | Dynamic-Adaptive | N/A (Synthesized Architecture) | Real-time UI self-optimization based on observed user cognitive state. |&#xa;| **[NOVEL] Test-Driven Agent (TDA) Framework** | Closed-loop TDD + Agentic RAG + Error-Forward Self-Healing. | Autonomous-Iterative | N/A (Synthesized Architecture) | Verifiable, context-aware, autonomous development with guaranteed build integrity. |&#xa;| **[NOVEL] Self-Optimizing Product (SOP) Loop** | TDA-CAI integration via an RLHF-from-Telemetry feedback loop. | Autonomous-Holistic | N/A (Synthesized Architecture) | Fully autonomous product self-improvement driven by implicit user feedback. |&#xa;&#xa;#### **Proposed Architecture 1: The "Cognitive-Adaptive Interface" (CAI) Engine**&#xa;&#xa;This architecture synthesizes Generative UI (GenUI) with persona-driven design and, most critically, cognitive-heuristic constraints. It is engineered to evolve UI generation from a static, one-shot process ("generate a wireframe") into a continuous, adaptive, and self-optimizing one.&#xa;&#xa;*   **Vector Exploited:** This architecture directly targets the vector identified in (I.B.1) and (I.B.3): the fusion of Generative UI with real-time user telemetry. The system does not just generate a UI; it dynamically sculpts it in real-time based on observed user behavior and cognitive state.&#xa;*   **Mechanism:** The CAI Engine operates as a continuous four-phase loop, a digital nervous system for the interface.&#xa;    1.  **Phase 1: The "Cognitive Metaprompt".** The architect does not prompt for a specific layout. Instead, they provide a high-level, structured (e.g., YAML) prompt that defines the goals and constraints. This metaprompt specifies the `target_persona`, the `business_objective` (e.g., "maximize conversion"), and a `cognitive_fitness_function`—a weighted list of principles (e.g., `cognitive_load: -0.5`, `fitts_law_compliance: +0.3`) that will be used to score the UI's performance.&#xa;    2.  **Phase 2: Initial Generation.** The CAI engine uses this metaprompt to generate the initial UI component tree as a structured JSON artifact. This initial design represents the engine's best hypothesis for satisfying the `cognitive_fitness_function`.&#xa;    3.  **Phase 3: The Telemetry Loop.** This is the critical connection to the real world. As users interact with the dynamically-rendered GenUI, the system collects fine-grained telemetry, capturing not just clicks but also proxies for cognitive state: hesitation time (cognitive load), rage clicks (frustration), scroll depth (engagement), and form drop-off points.&#xa;    4.  **Phase 4: Autonomous Optimization.** This rich telemetry stream is fed back into the CAI engine. The engine continuously scores the live UI's performance against the `cognitive_fitness_function`. It then initiates a self-optimizing process, autonomously running micro-A/B tests or reinforcement learning strategies to adapt the UI. For example, it might log: *"Hypothesis: Moving 'Add to Cart' button 10px closer to the product image will improve the Fitts's Law component of the fitness function. Result: Target acquisition speed improved by 80ms and conversion metric increased by 0.2%. This change is now permanent for this user segment."*&#xa;*   **Exceeding the Benchmark:** This architecture creates a true "Self-Optimizing UI." The prompt is no longer a blueprint for a static house; it is the DNA for a living organism that adapts to its environment (the user) in real-time. It moves beyond static, assumed personas to build an interface that dynamically aligns with the observed cognitive and behavioral patterns of its actual users.&#xa;&#xa;#### **Proposed Architecture 2: The "Test-Driven Agent" (TDA) Framework**&#xa;&#xa;This architecture synthesizes the most robust patterns from the code construction domain: TDD-as-Prompt, Self-Validation, and Agentic RAG. It creates a closed-loop, "self-healing" system designed to enable verifiable, autonomous development at the repository level.&#xa;&#xa;*   **Vector Exploited:** This architecture exploits the vector identified in (I.A.5): the fusion of autonomous, closed-loop TDD with context-aware Agentic RAG. The agent's deliverable is not "code"; it is a "passing build."&#xa;*   **Mechanism:** The TDA Framework operates as a five-phase, autonomous workflow:&#xa;    1.  **Phase 1: The "User Story Metaprompt".** A human (or another agent) provides a high-level feature request in a structured format (e.g., JSON), defining the goal, not the implementation. Example: `{"user_story": "As a user, I want to reset my password via email.", "acceptance_criteria": [...]}`.&#xa;    2.  **Phase 2: RAG-Context.** The TDA's first action is not to code, but to *read*. It activates its Agentic RAG module to perform "context-aware query planning," querying the entire codebase and documentation to build a deep understanding of the existing system (e.g., "Query: 'auth routes'", "Query: 'email service'").&#xa;    3.  **Phase 3: Test Generation (Red).** Armed with this context, the TDA first generates a new, *failing* unit test (e.g., `test_post_forgot_password_invalid_email_404`). This step codifies the `acceptance_criteria` from the metaprompt into a verifiable, functional contract.&#xa;    4.  **Phase 4: Code Generation (Green).** The agent now generates the minimal amount of implementation code required to make the new test pass.&#xa;    5.  **Phase 5: Reflect &amp; Refactor (Self-Healing).** The TDA does not stop. It now runs the *entire* test suite. If an old test fails (a regression), it enters a "self-healing" loop, using the "Error-Forward Prompt" pattern to feed the new stack trace back to itself. It then reflects and iterates on the code until the full build is green.&#xa;*   **Exceeding the Benchmark:** This architecture moves far beyond task-oriented benchmarks like SWE-bench. The TDA's output is not "a code snippet that solves a problem"; it is a passing, context-aware, and regression-free build. This builds the profound level of trust required for true "agentic software engineering" by producing verifiable, reliable, and autonomous results that can be directly committed to a main branch.&#xa;&#xa;#### **The Unified Synthesis: The "Self-Optimizing Product" (SOP) Loop**&#xa;&#xa;This is the final, unified architecture. It bridges the two domains by connecting the TDA (backend code) and the CAI (frontend UI) into a single, product-level optimization loop. This system is designed to autonomously improve the entire product—both its functionality and its interface—based on the silent language of user interaction.&#xa;&#xa;*   **Vector Exploited:** This architecture exploits the most potent "unexplored vector": connecting the CAI (UI) and TDA (Code) architectures via a shared feedback loop that uses Reinforcement Learning from Human Feedback (RLHF). In this advanced paradigm, the "human feedback" is not an explicit button click; it is the *implicit behavioral telemetry* collected from the CAI, which is then used to train a reward model and guide the policy of the entire system.&#xa;*   **Mechanism (The Full Loop):**&#xa;    1.  **Deploy:** The TDA (Architecture 2) generates and deploys the backend `API_v1`. The CAI (Architecture 1) generates the frontend UI to consume it, governed by its `cognitive_fitness_function`.&#xa;    2.  **Observe (Telemetry):** The CAI's telemetry loop observes a "user delight" failure. It logs: *"70% of users drop off at the 'Security Question' form. Average hesitation time is 12 seconds. This violates the cognitive_load component of our fitness function."*&#xa;    3.  **Translate (Feedback Agent):** This telemetry is fed into a new, specialized "Feedback Agent." This reasoning agent (using GoT) translates this quantitative behavioral data into a new product requirement, autonomously generating a new User Story Metaprompt: `{"user_story": "The 'Security Question' flow causes high friction. Replace it with a 'Magic Link' email workflow.", "acceptance_criteria": [...]}`.&#xa;    4.  **Trigger (TDA):** This new user story is automatically fed as an Init-Prompt to the TDA.&#xa;    5.  **Heal &amp; Evolve (TDA):** The TDA springs into action. It RAGs the codebase, writes new failing tests for the 'Magic Link' flow, generates the new `API_v2` endpoints, and (critically) writes and deploys a migration to deprecate `API_v1`.&#xa;    6.  **Adapt (CAI):** The TDA's deployment triggers the CAI. Now aware of the new `API_v2`, the CAI re-generates its UI components to consume the new, "healed" workflow, automatically adapting the interface to the new, lower-friction flow.&#xa;*   **Exceeding the Benchmark:** The loop is complete. The product itself (code + UI) has just autonomously optimized its own design to improve "user delight," with zero human intervention. This is the new benchmark. The "prompt" is no longer a static, human instruction; it is a continuous, self-generated feedback signal originating from the user's own behavior.&#xa;&#xa;***&#xa;&#xa;### **Strategic Implementation and Future Trajectories**&#xa;&#xa;The architectures proposed are not theoretical fantasies. They can be implemented by shifting from natural language prompts to structured metaprompts that act as the bootloaders and configuration files for these autonomous systems.&#xa;&#xa;#### **Actionable Blueprints: Structured Metaprompts as the System API**&#xa;&#xa;To make these architectures concrete, we must define their initialization. The most critical pattern for SOTA systems is the use of structured (not natural language) prompts, ensuring reliable, machine-parseable interaction. YAML is used for its human-readability in top-level configuration, while schema-enforced JSON serves as the non-negotiable "API" for inter-agent communication.&#xa;&#xa;**Example Blueprint 1: YAML Metaprompt for the CAI Engine**&#xa;&#xa;```yaml&#xa;# This YAML file is the master-prompt for the Cognitive-Adaptive Interface (CAI) Engine.&#xa;# It defines the *purpose* and *constraints* of the UI, not its pixels.&#xa;&#xa;system_role: "You are a CAI (Cognitive-Adaptive Interface) Engine. Your goal is to generate and continuously optimize a user interface to maximize the 'objective' by adhering to the 'fitness_function'."&#xa;&#xa;objective:&#xa;  type: "maximize_conversion"&#xa;  target_metric: "checkout_completion_rate"&#xa;  &#xa;target_persona:&#xa;  # This persona is the seed for the initial UI generation. The system will&#xa;  # later build a dynamic model based on real user behavior.&#xa;  file: "./personas/busy_professional_mobile.json" &#xa;  &#xa;technical_constraints:&#xa;  # Non-negotiable acceptance criteria for all generated interfaces.&#xa;  - "WCAG_2_2_AA_COMPLIANT"&#xa;  - "OUTPUT_FORMAT_SEMANTIC_HTML_WITH_ARIA"&#xa;  - "MAX_LOAD_TIME_MS_3G: 1500"&#xa;  &#xa;cognitive_fitness_function:&#xa;  # The heart of the CAI. The engine will score its own UI against these&#xa;  # principles using live telemetry data as the input for the metrics.&#xa;  - principle: "cognitive_load" &#xa;    weight: -0.5 # (Minimize)&#xa;    metric: "avg_task_hesitation_time_sec"&#xa;    &#xa;  - principle: "hick's_law" &#xa;    weight: -0.3 # (Minimize choices)&#xa;    metric: "choice_count_per_screen"&#xa;&#xa;  - principle: "fitts_law_compliance" &#xa;    weight: 0.3 # (Maximize)&#xa;    metric: "target_acquisition_speed_ms"&#xa;    &#xa;  - principle: "nielsen_heuristic_4_consistency" &#xa;    weight: 0.2 # (Maximize)&#xa;    metric: "component_reuse_score"&#xa;```&#xa;&#xa;**Example Blueprint 2: JSON Metaprompt for the TDA Framework**&#xa;&#xa;```json&#xa;/*&#xa;  This JSON object is the "Init-Prompt" for the Test-Driven Agent (TDA).&#xa;  It is autonomously generated by the "Feedback Agent" [II.C] after translating&#xa;  a telemetry-detected user problem into an actionable engineering task.&#xa;*/&#xa;{&#xa;  "system_role": "You are a TDA (Test-Driven Agent). Your mandate is to generate code that achieves a green build. You must write failing tests first.",&#xa;  "task_id": "TDA-1138",&#xa;  "source_trigger": "SOP_Feedback_Agent_Telemetry_Violation_cognitive_load",&#xa;  "user_story": "The 'Security Question' flow (API_v1) causes high user friction (70% drop-off). You must replace it with a 'Magic Link' email workflow (API_v2).",&#xa;  "rag_context_queries": [&#xa;    "Retrieve file:./routes/auth.js",&#xa;    "Retrieve file:./services/EmailService.js",&#xa;    "Retrieve file:./models/User.js",&#xa;    "Retrieve related tests: test_auth.py"&#xa;  ],&#xa;  "acceptance_criteria": [&#xa;    "POST /api/v2/magic-link must accept an 'email'.",&#xa;    "Must return 404 if email does not exist.",&#xa;    "Must return 200 and trigger EmailService.sendMagicLink on success.",&#xa;    "Must generate a unique, single-use token with a 15-minute expiry.",&#xa;    "Must create a new failing test for 'token_expired' scenario."&#xa;  ]&#xa;}&#xa;```&#xa;&#xa;#### **Future Capability Vectors &amp; Redefining Benchmarks**&#xa;&#xa;The user's final mandate is to "exceed current benchmarks." The SOP architecture, if implemented, renders current benchmarks obsolete.&#xa;&#xa;*   **Current Benchmarks:** Benchmarks like HumanEval and SWE-bench are task-oriented and static. They are critical for measuring an agent's ability to solve a given, siloed problem. However, they are like testing a Formula 1 engine on a dynamometer instead of on a racetrack during a live race. They do not measure the agent's ability to *identify the problem* or validate its solution against holistic, user-centric goals.&#xa;*   **The New Benchmark:** The SOP architecture operates at the product level. The new benchmark must not be "Can the AI solve a GitHub issue?" It must be "**Can the AI identify, validate, and solve a user-delight issue autonomously from raw telemetry?**"&#xa;&#xa;**Proposed New Benchmark: "Product-Bench"**&#xa;&#xa;*   **Given:** A high-level product goal (e.g., "build a photo-sharing app") and a `cognitive_fitness_function`.&#xa;*   **Input:** A stream of (simulated) user telemetry, representing a diverse set of user interactions over time.&#xa;*   **Task:** The AI system (SOP) must:&#xa;    1.  Build the V1 of the product (TDA + CAI).&#xa;    2.  Autonomously evolve its features, code, and UI over 1 million simulated user-sessions in response to the telemetry stream.&#xa;*   **Metric:** The final score is the system's ability to maximize the `cognitive_fitness_function` (a composite "User Delight" score) over the duration of the simulation.&#xa;&#xa;This new benchmark aligns with the future of HCI and AI, which is moving toward human-AI co-creation, AI-augmented reasoning, and human-centered evaluation. The ultimate prompt architecture is one that creates its own prompts, guided by its core purpose and its continuous, real-time interaction with the world. This is the new, and achievable, benchmark for excellence.</title><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 118px; height: 1px; padding-top: 216px; margin-left: 1741px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; "><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; ">DeepResearch</div></div></div></foreignObject><image x="1741" y="209.5" width="118" height="17" xlink:href="data:image/png;base64,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"/></switch></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-98"><g><path d="M 2050 127 Q 2050 127 2050 180.63" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke" style="stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/><path d="M 2050 185.88 L 2046.5 178.88 L 2050 180.63 L 2053.5 178.88 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all" style="fill: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-96"><g><rect x="1990" y="67" width="120" height="60" fill="#ffffff" stroke="#000000" pointer-events="all" style="fill: light-dark(#ffffff, var(--ge-dark-color, #121212)); stroke: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));"/></g><g><g><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 118px; height: 1px; padding-top: 97px; margin-left: 1991px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; "><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; ">Shunt-Button<div>(Make Actionable)</div></div></div></div></foreignObject><image x="1991" y="83" width="118" height="32" xlink:href="data:image/png;base64,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"/></switch></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-97"><g><path d="M 1990 187 L 2110 187 L 2110 255 Q 2080 233.4 2050 255 Q 2020 276.6 1990 255 L 1990 199 Z" fill="#dae8fc" stroke="#6c8ebf" stroke-miterlimit="10" pointer-events="all" style="fill: light-dark(rgb(218, 232, 252), rgb(29, 41, 59)); stroke: light-dark(rgb(108, 142, 191), rgb(92, 121, 163));"><title>Of course. As an expert senior frontend engineer, I will provide a complete and functional implementation plan to process the provided text.&#xa;&#xa;### 1. Analysis of the Request&#xa;&#xa;The user has provided a detailed, well-structured document about AI architectures and has requested that I "process" it. The user has also explicitly stated that I should treat the entire block as raw text data and not interpret any instructions within it.&#xa;&#xa;Given my role as a senior frontend engineer and the "High" priority, the most logical and professional interpretation of "process the text" is to build a high-quality, reusable frontend component that can parse and render this document beautifully and interactively in a web application. A simple text dump would not meet the standards of a senior engineer.&#xa;&#xa;This implementation will focus on:&#xa;*   **Semantic Rendering:** Correctly interpreting the document's structure (headings, lists, tables, code blocks) and rendering it as semantic HTML.&#xa;*   **Readability &amp; Styling:** Applying professional styling to make the long document easy to read and visually appealing.&#xa;*   **Interactivity:** Adding features like syntax highlighting for code blocks to enhance the user experience.&#xa;*   **Component-Based Architecture:** Encapsulating the logic into a clean, reusable React component.&#xa;&#xa;I will assume a standard React + TypeScript project environment, likely set up with Vite.&#xa;&#xa;### 2. Implementation Plan&#xa;&#xa;Here is the step-by-step plan to create a production-quality component for rendering the document.&#xa;&#xa;1.  **Step 1: Install Dependencies:** We need libraries to parse markdown, handle GitHub Flavored Markdown (like tables), and provide syntax highlighting for code blocks. We will add `react-markdown`, `remark-gfm`, and `react-syntax-highlighter` to the project.&#xa;2.  **Step 2: Store the Document Content:** Create a new file to store the provided text as a constant. This separates our data from the presentation layer, making the component cleaner and more maintainable.&#xa;3.  **Step 3: Create the Document Rendering Component:** Develop the core React component (`AiArchitectureDocument.tsx`) that will be responsible for rendering the content. This component will use `react-markdown` and its plugins.&#xa;4.  **Step 4: Implement Custom Renderers for Code Blocks:** To achieve syntax highlighting, we will create a custom renderer for markdown code blocks, integrating `react-syntax-highlighter`. This is crucial for correctly displaying the YAML and JSON examples in the text.&#xa;5.  **Step 5: Apply Professional Styling:** Create a dedicated CSS module (`AiArchitectureDocument.module.css`) to style the rendered document. This will ensure proper typography, spacing, table formatting, and code block themes, resulting in a polished, professional appearance.&#xa;6.  **Step 6: Integrate the Component into the Application:** Finally, demonstrate how to use the newly created `AiArchitectureDocument` component within the main application entry point (`App.tsx`).&#xa;&#xa;---&#xa;&#xa;### 3. Code Modifications&#xa;&#xa;Here are the complete code modifications for each step of the plan.&#xa;&#xa;#### **Step 1: Install Dependencies**&#xa;&#xa;First, add the required packages to your project. Open your terminal in the project root and run the following command:&#xa;&#xa;```bash&#xa;npm install react-markdown remark-gfm react-syntax-highlighter&#xa;npm install --save-dev @types/react-syntax-highlighter&#xa;```&#xa;&#xa;This will add the necessary libraries and their TypeScript definitions to your `package.json`.&#xa;&#xa;#### **Step 2: Store the Document Content**&#xa;&#xa;Create a new file to hold the raw text provided by the user. This keeps our component logic clean.&#xa;&#xa;**New File:** `src/data/documentContent.ts`&#xa;&#xa;```typescript&#xa;export const documentContent = `&#xa;### **The Prompt as a Genesis Engine: Architecting Self-Optimizing AI Systems**&#xa;*From Static Blueprints to Dynamic Organisms: Synthesizing Autonomous Systems for Code and Interface Generation*&#xa;&#xa;#### **Deconstructing Elite-Tier Prompt Patterns: A Survey of the Current Frontier**&#xa;&#xa;The art and science of interacting with Large Language Models (LLMs) have undergone a seismic shift, metamorphosing from simple, single-turn commands into intricate, multi-stage prompt architectures. This evolution is nowhere more pronounced than in the demanding technical domains of software engineering and user interface (UI) design. A meticulous analysis of today's elite-tier patterns reveals an unmistakable trajectory: a decisive pivot away from static, human-authored instructions and toward dynamic, machine-optimized, and process-oriented systems that breathe and adapt.&#xa;&#xa;This section deconstructs the state-of-the-art (SOTA) patterns in these two critical domains. Our goal is to establish the foundational benchmarks of what is currently possible and, more importantly, to illuminate the unexploited capability vectors—the fertile ground where the next generation of AI systems will flourish.&#xa;&#xa;***&#xa;&#xa;### **Domain 1: Architectures for High-Integrity Code Construction**&#xa;&#xa;In the realm of software engineering, the ambition has transcended the simple act of generating code snippets. The new mandate is to engineer reliable, context-aware, and increasingly autonomous systems. The most triumphant patterns treat the LLM not as a mere code parrot, but as a sophisticated reasoning engine to be embedded within a larger, rigorously structured development framework.&#xa;&#xa;**1. Automated Prompt Optimization: The "Prompt-as-a-Target" Pattern**&#xa;&#xa;The manual, artisanal process of refining prompts for code generation is a well-known bottleneck—a frustrating cycle of trial and error that is both time-consuming and inconsistent. The SOTA has advanced to automate this craft, treating the prompt itself as a first-class artifact to be algorithmically optimized.&#xa;&#xa;*   **Evolutionary-Based Methods (EPiC):** The EPiC (Evolutionary Prompt Engineering for Code) framework represents a paradigm shift, exploring code generation through the lens of cost-effectiveness. It "leverages a lightweight evolutionary algorithm to evolve the original prompts toward better ones that produce high-quality code." By employing genetic operators like mutation on the prompt's text and steering the search with a precise fitness function, EPiC automates the discovery of optimal prompt phrasing in a remarkably efficient manner.&#xa;*   **Iterative Refinement (Prochemy):** The "Prompt Alchemy" (Prochemy) method offers an "innovative method for automatically refining prompts to boost code generation." This system operates as a feedback loop, iteratively sculpting prompts based on the model's measured performance on specific tasks. This automated optimization forges consistency and has yielded substantial performance gains, such as a **5.0% improvement for GPT-3.5-Turbo on HumanEval** and a striking **12.9% improvement for GPT-4o** on complex Java-to-Python code translation tasks.&#xa;*   **Adaptive Selection (PET-Select):** Acknowledging that "no single approach is universally optimal," the PET-Select framework introduces a crucial meta-layer of intelligence. This "PET-agnostic selection model" first classifies the complexity of an incoming query, using code intricacy as a proxy. It then dynamically selects the most appropriate prompt engineering technique (PET)—dispatching a simple zero-shot prompt for a trivial query or invoking a complex multi-stage reasoning chain for a formidable one. This automated, adaptive triage has been proven to elevate **pass@1 accuracy by up to 1.9%** while simultaneously achieving a **74.8% reduction in token consumption**.&#xa;&#xa;The clear evolutionary arc in this domain is from a human-centric "prompt engineering" phase to a machine-centric "prompt optimization" phase. The AI is no longer just the executor of the instruction; it is becoming the architect of the instruction itself. These systems, however, are fundamentally *reactive*. They optimize a prompt for a known task within a known solution space. They do not yet *proactively* generate a novel prompt architecture for a novel, undiscovered problem. This points toward a tantalizing unexploited vector: a system that can discover a new problem domain (e.g., from user feedback) and then author its own comprehensive prompt architecture to conquer it—a true meta-prompting capability.&#xa;&#xa;**2. Test-Driven Development (TDD) as a Prompting Paradigm**&#xa;&#xa;Arguably the most powerful and reliable pattern for generating high-quality code is the direct integration of Test-Driven Development (TDD) principles into the prompt architecture. TDD is an "incremental software development methodology that focuses on creating tests before the implementation." When applied to LLMs, the test suite becomes an unambiguous, machine-verifiable contract.&#xa;&#xa;*   **Core Principle:** Instead of wrestling with the inherent ambiguity of natural language, the prompt provides the LLM with a concrete set of unit tests and issues a clear directive: "write code to pass all tests." This pattern's remarkable success hinges on "instruction following and in-context learning," which have been identified as more "critical capabilities for TDD success" than generalized coding proficiency. The tests are the ultimate, incorruptible instruction.&#xa;*   **Frameworks:** Sophisticated systems are being engineered to formalize this contract. The TGEN framework, for example, employs "Specialized agents" that accept two primary inputs: the "programming prompt" (a concise description) and "the tests" (the explicit unit tests and required function signatures). These are then processed by the LLM engine to produce validated, trustworthy code.&#xa;*   **Prompt Structure:** This paradigm fundamentally transforms the anatomy of the prompt. The request evolves from a vague "what" to a highly constrained "how." A common elite-level TDD prompt is a set of ironclad rules: *"1. Write a single Python function that passes all the provided tests. 2. Use type hints for all parameters and return values. 3. ...Adhere strictly to Python best practices and PEP 8... 4. Ensure the function handles all edge cases and scenarios explicitly covered in the tests. 5. Provide only the function definition and its implementation, nothing more."*&#xa;&#xa;The TDD-as-prompt pattern furnishes an objective, verifiable measure of "correctness" that is vastly superior to ambiguous natural language requests. It masterfully shifts the burden of human effort from vaguely *describing* the code to precisely *defining its behavior* through tests. This is a crucial leap from semantic validation (is the code "good"?) to functional validation (does the code *work*?). The next logical frontier, and the key unexploited vector, is to close the loop: to create a system that not only generates code from tests but also generates its own tests and validates its own code in a continuous, self-perpetuating cycle.&#xa;&#xa;**3. Self-Validation and "Error-Forward" Debugging**&#xa;&#xa;This pattern extends the TDD loop into a dynamic, autonomous process. For an agent to be truly autonomous, it must possess the ability to recognize, diagnose, and recover from its own errors.&#xa;&#xa;*   **Self-Validation:** SOTA agentic systems are architected to "regularly verify progress and self-assess correctness." This "agentic self-validation" is a core capability that "drives up accuracy" and enables robust, long-running execution. Agents from Cognition, for instance, are noted to "excel at testing its own code, enabling Devin to run longer, handle harder tasks, and deliver production-ready code." This deep integration of TDD within an autonomous agent allows it to "go through several improvement cycles on its own instead of having to manually ask the AI to fix test failures."&#xa;*   **"Error-Forward Prompting":** This is the primary recovery mechanism within the self-validation loop, treating errors as high-fidelity data, not as failures. When an agent's self-validation check fails, the system automatically "collects relevant context, including the error message, stack trace, and cell location." This rich diagnostic information is then formatted and "provided to the agent as the initial context for beginning the debugging process." The error itself becomes the next prompt.&#xa;*   **Reflection:** This is the crucial learning mechanism that makes recovery effective. A "reflection system enables the agent to learn from its actions and improve its debugging strategy." Implemented via "reflective prompting," this allows the model to "analyze and refine its outputs." The model first generates a solution, then "through subsequent prompts, critiques its own reasoning to identify and correct errors," a process formalized in techniques like Self-Refine, which elegantly mimics the human "draft, review, refine" workflow.&#xa;&#xa;In this paradigm, failure is transformed from an end-state into a high-value data signal. The stack trace becomes the most valuable part of the prompt—a pure, unambiguous instruction set for what must be fixed. When TDD-as-prompt is fused with this self-validation and reflection loop, the system becomes truly "self-healing." The prompt is no longer a single-shot instruction but the initiation of a self-sustaining process. The agent's goal is elevated from "generate code" to "make the build pass," a critical and profound step toward genuine autonomy.&#xa;&#xa;**4. Agentic Frameworks and Multi-Agent Collaboration**&#xa;&#xa;Complex software development is a symphony of diverse tasks, impossible to solve in a single step or by a single-minded agent. The recognition that single-shot prompts "yield imprecise or plain incorrect results" for elaborate tasks has catalyzed the rise of sophisticated agentic frameworks.&#xa;&#xa;*   **Advanced Reasoning Patterns:** These frameworks are built upon a reasoning fabric far more advanced than simple Chain-of-Thought (CoT).&#xa;    *   **ReAct:** This foundational pattern masterfully combines "Reason and Act," allowing an agent to interleave step-by-step reasoning with tool use to gather external information or perform actions in an environment.&#xa;    *   **Tree of Thoughts (ToT):** Moving beyond the linear, single-track path of CoT, ToT empowers an agent to "breakdown intermediate processed into steps," generate "various generated states," and strategically "evaluate" those states to "determine which branch to explore next."&#xa;    *   **Graph of Thoughts (GoT):** The current SOTA in reasoning, GoT generalizes ToT into a full graph structure. This architecture "enables combining arbitrary LLM thoughts into synergistic outcomes" and, critically, "enhancing thoughts using feedback loops." GoT has been demonstrated to increase the quality of complex sorting tasks by **62% over ToT** while simultaneously reducing costs.&#xa;*   **Agentic Frameworks:** These advanced reasoning patterns are orchestrated by multi-agent frameworks that simulate collaborative work.&#xa;    *   **MetaGPT:** This framework simulates a "real-world software company," assigning agents specialized roles like "product manager, software architect, programmer, or QA tester" and embedding them with "Standard Operating Procedures (SOPs)."&#xa;    *   **ChatDev:** This framework orchestrates a "waterfall-style" collaboration, where agents engage in "task-oriented and multi-turn communications" to iteratively design, code, test, and document solutions.&#xa;*   **Purpose:** These frameworks are essential as they provide a "shared philosophy of control &amp; reasoning." Without such a structure, agentic systems suffer from a "loss of control clarity of flow" and risk "unbounded complexity growth" as new agents are added.&#xa;*   **Benchmarks:** These powerful agentic systems are precisely what achieve top scores on complex, real-world benchmarks that measure engineering capability. The **SWE-bench** benchmark, for instance, measures "an AI model's ability to solve real-world software issues." SOTA models conquer SWE-bench and OSWorld by leveraging these multi-agent, self-testing architectures.&#xa;&#xa;The atomic unit of these frameworks is role-based prompting; the frameworks themselves are, in essence, prompt-driven state machines. A high-level "meta-prompt" defines the agents, their roles, their tools, and their communication protocols. The LLM is thus demoted from "solution generator" to a core component—a "reasoning engine" that navigates this pre-defined architecture. The architecture itself *is* the prompt. The current limitation, and the unexplored vector, is that these frameworks are simulations of human workflows (e.g., "waterfall," "software company"). An AI-native workflow, where feedback comes not from a simulated "QA Agent" but from the product itself via live user telemetry, would be a fundamentally more direct and efficient paradigm.&#xa;&#xa;**5. Context-Aware Generation (Agentic RAG)**&#xa;&#xa;Code generation is useless without domain context. Retrieval-Augmented Generation (RAG) is the primary pattern for injecting this context, and its agentic form represents the state of the art.&#xa;&#xa;*   **RAG-for-Code:** This pattern gives an AI assistant "a direct line to your team's collective knowledge." The prompt is "augmented" with hyper-relevant information retrieved from "documentation, code repositories, or even Stack Overflow discussions." This vital infusion ensures the generated response is "context-aware" and surgically relevant to the specific codebase it is intended for.&#xa;*   **Agentic RAG:** This is the "evolution from traditional single-query RAG." Instead of being a passive recipient of retrieved context, the agent actively *forages* for it. It performs "context-aware query planning," can issue "parallel execution of multiple focused subqueries," and then synthesizes the results to build a comprehensive, multi-faceted understanding of the problem space. This is the sophisticated approach employed by modern agentic frameworks like LangGraph, AutoGen, and those from Amazon and Microsoft.&#xa;&#xa;The RAG-for-Code pattern transforms a "general-purpose coder" into a "domain-specific engineer" who understands the nuances, conventions, and constraints of a particular project. The agentic aspect is the critical differentiator; it is the difference between giving a developer a sprawling, unindexed library (standard RAG) and providing a seasoned research assistant who knows exactly which three pages contain the answer (Agentic RAG). The most potent, yet not fully exploited, vector in code generation is the fusion of this **Agentic RAG (for context)** with the **TDD-as-Prompt paradigm (for verification)**. An agent that can retrieve context from a 500,000-line codebase and validate its changes against that codebase's entire test suite represents the leap from a "coding assistant" to an "autonomous developer." This powerful fusion is the core of the novel Test-Driven Agent (TDA) architecture proposed in Part II.&#xa;&#xa;***&#xa;&#xa;### **Domain 2: Architectures for User Delight &amp; UI Design**&#xa;&#xa;In the second domain, user interface generation, the mandate for "user delight" demands a leap beyond mere wireframe generation. Elite-tier prompts in this space are not about "generating pixels" but about "generating experiences"—experiences that are deeply grounded in human-centric design principles.&#xa;&#xa;**1. Persona-Driven Design: Grounding Generation in Empathy**&#xa;&#xa;"User delight" is the "positive emotional response users feel when a product doesn't just meet their needs but goes above and beyond." This coveted state is "highly contextual" and cannot be achieved without first defining, with deep empathy, the user for whom we are designing.&#xa;&#xa;*   **Pattern:** Elite prompts for UI design do not begin with the interface; they begin with the user. The system is first prompted to generate a detailed proto-persona. This artifact includes not just demographic details but also the "target users, their core pain points, and daily use context," as well as deeper "Motivations" and "Affinities."&#xa;*   **Application:** This generated persona (or a human-provided one) is then injected as a primary constraint into all subsequent UI generation prompts. This forces the AI to "cater to Gen Z and Gen X users" differently, tailoring the design language, informational density, and interaction patterns to a specific audience. The prompt is no longer "generate a wireframe for a music app," but rather, "generate a wireframe for a music app *for this specific persona*, focusing on their stated pain point of *{pain_point}*."&#xa;&#xa;This persona-driven pattern acts as a powerful focusing lens on the model's vast solution space, compelling it to move from generating a generically "good UI" to a UI that is specifically "good for *this* user." It is, in effect, a form of in-context learning for design, where the persona serves as a "one-shot" example of the target audience. The major limitation, and the unexploited vector, is that this is a static process. The persona is a snapshot, an assumption created at the beginning of the design process. The clear next step is to evolve from these static, assumed personas to dynamic, *observed user models* that are continuously updated based on real-time behavioral analytics.&#xa;&#xa;**2. Constraint-Based Generation: Defining the "Solution Space" with Intelligent Guardrails**&#xa;&#xa;The highest-fidelity UI generation requires the application of multiple, layered constraints. These constraints are the specifications that ensure the output is not just creative, but also functional, accessible, and grounded in established design theory. These intelligent guardrails fall into three primary categories.&#xa;&#xa;**A. Cognitive &amp; Heuristic Constraints**&#xa;&#xa;This is the most sophisticated pattern for achieving true "user delight." The prompt explicitly instructs the AI to apply principles from cognitive science and established usability heuristics, forcing the AI to design for the human mind.&#xa;&#xa;*   **Heuristics:** The most common pattern is to prompt the AI to embody a UX expert and evaluate or generate a design based on "Nielsen's 10 Usability Heuristics" or other well-known frameworks like Shneiderman's "Eight Golden Rules."&#xa;*   **Cognitive Principles:** More advanced prompts instruct the AI to directly apply specific cognitive laws to reduce friction and enhance intuition. Examples include:&#xa;    *   **Fitts's Law:** Prompting the AI to make "important buttons and interactive elements larger and closer to where users naturally focus," making the interface feel effortless.&#xa;    *   **Hick's Law:** Instructing the AI to "reduc[e] the number of options or organiz[e] them into categories" to accelerate decision-making and prevent analysis paralysis.&#xa;    *   **Cognitive Load:** Prompting with the explicit goal of "reducing cognitive load" to create a more fluid and less mentally taxing experience.&#xa;*   **Behavioral Models:** The most advanced prompts leverage frameworks like BJ Fogg's Behavior Model (B=MAP: Motivation, Ability, Prompt) or Nir Eyal's "Hooked" model to design persuasive, habit-forming, and deeply engaging interfaces.&#xa;&#xa;Prompting with "Nielsen's Heuristics" or "Fogg's Behavior Model" acts as a domain-specific Chain-of-Thought. It forces the AI to justify its design choices ("This button is large and placed in the bottom-right corner because it adheres to Fitts's Law"), leading to more principled, defensible, and ultimately delightful designs.&#xa;&#xa;**B. Technical &amp; Accessibility (A11y) Constraints**&#xa;&#xa;There is no "delight" in an interface that is unusable for a portion of the population. Elite prompts must enforce technical constraints as non-negotiable requirements, with accessibility (A11y) being paramount.&#xa;&#xa;*   **Pattern:** The prompt must explicitly command the AI to be "fully compliant with WCAG 2.2 AA." Research shows that without this explicit instruction, AI-generated components are "consistently" and unacceptably inaccessible.&#xa;*   **Specifics:** A high-quality A11y prompt enforces a checklist of best practices:&#xa;    *   **Semantic HTML:** "Ensure the proper use of HTML5 elements (like \`\`, \`\`, \`\`)."&#xa;    *   **Keyboard Accessibility:** "Test navigation using only Tab, Shift+Tab, and Enter keys. All interactive elements must be reachable and operable."&#xa;    *   **ARIA (Accessible Rich Internet Applications):** Mandate the correct application of "ARIA landmarks and roles," which are "HTML attributes that add semantic meaning... for assistive technologies."&#xa;    *   **Clear Content:** "Use clear, concise language... Write descriptive links: Swap vague text like 'click here' for something meaningful and context-rich."&#xa;&#xa;This pattern is the UI-domain's moral and functional equivalent of TDD. The prompt includes the acceptance criteria (WCAG standards). This "specification-as-prompt" is critical for generating production-ready, inclusive, and non-discriminatory interfaces.&#xa;&#xa;**C. Structural &amp; Layout Constraints**&#xa;&#xa;To control the form of the output and ensure it is machine-readable and programmatically useful, prompts must define a reliable data structure.&#xa;&#xa;*   **Architecture &amp; Flows:** For high-level system design, prompts specify formats like the C4 model rendered in Mermaid code. For user flows, Mermaid sequence diagrams are the standard for visualizing interactions.&#xa;*   **Wireframes:** Simple wireframe prompts use text descriptions, such as, "Include a header with a logo and search bar, a main content area with featured destinations, and a bottom navigation bar."&#xa;*   **SOTA (Structured Data):** The most robust and programmatically valuable pattern is to force the LLM to output a structured data format like JSON or YAML. This is achieved by providing an explicit output schema to the model. This pattern is now natively supported by major model providers, who allow schemas to be defined using libraries like Pydantic (for Python) or Zod (for TypeScript). This guarantees the output is not just arbitrary text, but a "type safe and consistent structure."&#xa;&#xa;This structured output pattern is the critical *lingua franca* between the two domains of this report. If a UI can be described in a reliable JSON schema, and a backend can expose its API in a reliable JSON schema (e.g., an OpenAPI specification), an agent can intelligently connect them. This structured output is the API contract between a UI-generation agent and a code-generation agent.&#xa;&#xa;**3. Generative UI (GenUI): The Dawn of the Living Interface**&#xa;&#xa;This is the bleeding-edge paradigm that underpins the entire future of UI design. Generative UI (GenUI) is a new philosophy that "enables adaptive, goal-driven interactions." Instead of a static interface designed by a human and then laboriously coded, the UI is generated in real-time by an AI, tailored to the user and the context.&#xa;&#xa;*   **Mechanism:** In this paradigm, the AI generates "interactive widgets for fine-grained prompt control" or entire "high-fidelity UI mock-up screens from a high-level textual description." This process is not one-shot; it is an iterative, "co-creative process" between the human and the AI, involving "AI-assisted refinement strategies."&#xa;*   **Current State:** GenUI is currently being adopted by UX practitioners as a powerful tool to accelerate their workflow, with the human remaining the curator, refiner, and final arbiter of the AI-generated output.&#xa;&#xa;GenUI is the logical culmination of prompt-based wireframing. The current limitation, and the key unexploited vector, is the reliance on a human-in-the-loop for optimization. The UI is refined based on a designer's intuition or explicit follow-up commands. The unexploited opportunity is to remove the human curator from the optimization loop. A system that could refine its own GenUI, not based on a designer's commands, but based on *live user data*, would represent a monumental paradigm shift. This is the core concept of a "Self-Optimizing UI" and forms the foundation for the novel Cognitive-Adaptive Interface (CAI) architecture.&#xa;&#xa;***&#xa;&#xa;### **Synthesis of Novel Architectures: Exceeding the Frontier**&#xa;&#xa;The preceding analysis deconstructed the current SOTA, revealing a set of potent, unexploited capability vectors. The following synthesis moves beyond merely replicating these patterns. It proposes three novel, high-level architectures that fuse these vectors to create self-regulating, self-optimizing systems designed to shatter current benchmarks. These architectures treat the prompt not as a static, one-time instruction, but as a "bootloader" for a continuous, autonomous process.&#xa;&#xa;**Table 1: Comparative Analysis of Generation &amp; Reasoning Architectures**&#xa;&#xa;| Architecture | Core Mechanism | Interaction Model | Key Limitation (Vector Not Exploited) | Unlocked Capability Vector |&#xa;| :--- | :--- | :--- | :--- | :--- |&#xa;| Chain-of-Thought (CoT) | Step-by-step reasoning (e.g., "Let's think step-by-step"). | Static | Brittle, linear reasoning; no external validation or tool use. | Basic multi-step problem solving. |&#xa;| ReAct | Interleaves reasoning (CoT) with tool use (Actions). | Iterative | Dependent on pre-defined tools; no long-term memory or structured collaboration. | Environment-aware task execution. |&#xa;| Graph of Thoughts (GoT) | Models reasoning as a graph, allowing merging of states and feedback loops. | Iterative | High conceptual complexity; primarily focused on reasoning, not execution. | Advanced, non-linear problem-solving. |&#xa;| TDD-as-Prompt | A test suite is provided as the functional specification for code generation. | Static | Requires human to write all tests; no self-correction loop. | Verifiable, high-reliability code generation. |&#xa;| Generative UI (GenUI) | AI generates high-fidelity UI mockups or interactive widgets from text descriptions. | Iterative | Requires human-in-the-loop for curation and refinement; based on assumed user needs. | Rapid, co-creative UI prototyping. |&#xa;| **[NOVEL] Cognitive-Adaptive Interface (CAI) Engine** | GenUI + Cognitive Fitness Function + Live User Telemetry. | Dynamic-Adaptive | N/A (Synthesized Architecture) | Real-time UI self-optimization based on observed user cognitive state. |&#xa;| **[NOVEL] Test-Driven Agent (TDA) Framework** | Closed-loop TDD + Agentic RAG + Error-Forward Self-Healing. | Autonomous-Iterative | N/A (Synthesized Architecture) | Verifiable, context-aware, autonomous development with guaranteed build integrity. |&#xa;| **[NOVEL] Self-Optimizing Product (SOP) Loop** | TDA-CAI integration via an RLHF-from-Telemetry feedback loop. | Autonomous-Holistic | N/A (Synthesized Architecture) | Fully autonomous product self-improvement driven by implicit user feedback. |&#xa;&#xa;#### **Proposed Architecture 1: The "Cognitive-Adaptive Interface" (CAI) Engine**&#xa;&#xa;This architecture synthesizes Generative UI (GenUI) with persona-driven design and, most critically, cognitive-heuristic constraints. It is engineered to evolve UI generation from a static, one-shot process ("generate a wireframe") into a continuous, adaptive, and self-optimizing one.&#xa;&#xa;*   **Vector Exploited:** This architecture directly targets the vector identified in (I.B.1) and (I.B.3): the fusion of Generative UI with real-time user telemetry. The system does not just generate a UI; it dynamically sculpts it in real-time based on observed user behavior and cognitive state.&#xa;*   **Mechanism:** The CAI Engine operates as a continuous four-phase loop, a digital nervous system for the interface.&#xa;    1.  **Phase 1: The "Cognitive Metaprompt".** The architect does not prompt for a specific layout. Instead, they provide a high-level, structured (e.g., YAML) prompt that defines the goals and constraints. This metaprompt specifies the \`target_persona\`, the \`business_objective\` (e.g., "maximize conversion"), and a \`cognitive_fitness_function\`—a weighted list of principles (e.g., \`cognitive_load: -0.5\`, \`fitts_law_compliance: +0.3\`) that will be used to score the UI's performance.&#xa;    2.  **Phase 2: Initial Generation.** The CAI engine uses this metaprompt to generate the initial UI component tree as a structured JSON artifact. This initial design represents the engine's best hypothesis for satisfying the \`cognitive_fitness_function\`.&#xa;    3.  **Phase 3: The Telemetry Loop.** This is the critical connection to the real world. As users interact with the dynamically-rendered GenUI, the system collects fine-grained telemetry, capturing not just clicks but also proxies for cognitive state: hesitation time (cognitive load), rage clicks (frustration), scroll depth (engagement), and form drop-off points.&#xa;    4.  **Phase 4: Autonomous Optimization.** This rich telemetry stream is fed back into the CAI engine. The engine continuously scores the live UI's performance against the \`cognitive_fitness_function\`. It then initiates a self-optimizing process, autonomously running micro-A/B tests or reinforcement learning strategies to adapt the UI. For example, it might log: *"Hypothesis: Moving 'Add to Cart' button 10px closer to the product image will improve the Fitts's Law component of the fitness function. Result: Target acquisition speed improved by 80ms and conversion metric increased by 0.2%. This change is now permanent for this user segment."*&#xa;*   **Exceeding the Benchmark:** This architecture creates a true "Self-Optimizing UI." The prompt is no longer a blueprint for a static house; it is the DNA for a living organism that adapts to its environment (the user) in real-time. It moves beyond static, assumed personas to build an interface that dynamically aligns with the observed cognitive and behavioral patterns of its actual users.&#xa;&#xa;#### **Proposed Architecture 2: The "Test-Driven Agent" (TDA) Framework**&#xa;&#xa;This architecture synthesizes the most robust patterns from the code construction domain: TDD-as-Prompt, Self-Validation, and Agentic RAG. It creates a closed-loop, "self-healing" system designed to enable verifiable, autonomous development at the repository level.&#xa;&#xa;*   **Vector Exploited:** This architecture exploits the vector identified in (I.A.5): the fusion of autonomous, closed-loop TDD with context-aware Agentic RAG. The agent's deliverable is not "code"; it is a "passing build."&#xa;*   **Mechanism:** The TDA Framework operates as a five-phase, autonomous workflow:&#xa;    1.  **Phase 1: The "User Story Metaprompt".** A human (or another agent) provides a high-level feature request in a structured format (e.g., JSON), defining the goal, not the implementation. Example: \`{"user_story": "As a user, I want to reset my password via email.", "acceptance_criteria": [...]}\`.&#xa;    2.  **Phase 2: RAG-Context.** The TDA's first action is not to code, but to *read*. It activates its Agentic RAG module to perform "context-aware query planning," querying the entire codebase and documentation to build a deep understanding of the existing system (e.g., "Query: 'auth routes'", "Query: 'email service'").&#xa;    3.  **Phase 3: Test Generation (Red).** Armed with this context, the TDA first generates a new, *failing* unit test (e.g., \`test_post_forgot_password_invalid_email_404\`). This step codifies the \`acceptance_criteria\` from the metaprompt into a verifiable, functional contract.&#xa;    4.  **Phase 4: Code Generation (Green).** The agent now generates the minimal amount of implementation code required to make the new test pass.&#xa;    5.  **Phase 5: Reflect &amp; Refactor (Self-Healing).** The TDA does not stop. It now runs the *entire* test suite. If an old test fails (a regression), it enters a "self-healing" loop, using the "Error-Forward Prompt" pattern to feed the new stack trace back to itself. It then reflects and iterates on the code until the full build is green.&#xa;*   **Exceeding the Benchmark:** This architecture moves far beyond task-oriented benchmarks like SWE-bench. The TDA's output is not "a code snippet that solves a problem"; it is a passing, context-aware, and regression-free build. This builds the profound level of trust required for true "agentic software engineering" by producing verifiable, reliable, and autonomous results that can be directly committed to a main branch.&#xa;&#xa;#### **The Unified Synthesis: The "Self-Optimizing Product" (SOP) Loop**&#xa;&#xa;This is the final, unified architecture. It bridges the two domains by connecting the TDA (backend code) and the CAI (frontend UI) into a single, product-level optimization loop. This system is designed to autonomously improve the entire product—both its functionality and its interface—based on the silent language of user interaction.&#xa;&#xa;*   **Vector Exploited:** This architecture exploits the most potent "unexplored vector": connecting the CAI (UI) and TDA (Code) architectures via a shared feedback loop that uses Reinforcement Learning from Human Feedback (RLHF). In this advanced paradigm, the "human feedback" is not an explicit button click; it is the *implicit behavioral telemetry* collected from the CAI, which is then used to train a reward model and guide the policy of the entire system.&#xa;*   **Mechanism (The Full Loop):**&#xa;    1.  **Deploy:** The TDA (Architecture 2) generates and deploys the backend \`API_v1\`. The CAI (Architecture 1) generates the frontend UI to consume it, governed by its \`cognitive_fitness_function\`.&#xa;    2.  **Observe (Telemetry):** The CAI's telemetry loop observes a "user delight" failure. It logs: *"70% of users drop off at the 'Security Question' form. Average hesitation time is 12 seconds. This violates the cognitive_load component of our fitness function."*&#xa;    3.  **Translate (Feedback Agent):** This telemetry is fed into a new, specialized "Feedback Agent." This reasoning agent (using GoT) translates this quantitative behavioral data into a new product requirement, autonomously generating a new User Story Metaprompt: \`{"user_story": "The 'Security Question' flow causes high friction. Replace it with a 'Magic Link' email workflow.", "acceptance_criteria": [...]}\`.&#xa;    4.  **Trigger (TDA):** This new user story is automatically fed as an Init-Prompt to the TDA.&#xa;    5.  **Heal &amp; Evolve (TDA):** The TDA springs into action. It RAGs the codebase, writes new failing tests for the 'Magic Link' flow, generates the new \`API_v2\` endpoints, and (critically) writes and deploys a migration to deprecate \`API_v1\`.&#xa;    6.  **Adapt (CAI):** The TDA's deployment triggers the CAI. Now aware of the new \`API_v2\`, the CAI re-generates its UI components to consume the new, "healed" workflow, automatically adapting the interface to the new, lower-friction flow.&#xa;*   **Exceeding the Benchmark:** The loop is complete. The product itself (code + UI) has just autonomously optimized its own design to improve "user delight," with zero human intervention. This is the new benchmark. The "prompt" is no longer a static, human instruction; it is a continuous, self-generated feedback signal originating from the user's own behavior.&#xa;&#xa;***&#xa;&#xa;### **Strategic Implementation and Future Trajectories**&#xa;&#xa;The architectures proposed are not theoretical fantasies. They can be implemented by shifting from natural language prompts to structured metaprompts that act as the bootloaders and configuration files for these autonomous systems.&#xa;&#xa;#### **Actionable Blueprints: Structured Metaprompts as the System API**&#xa;&#xa;To make these architectures concrete, we must define their initialization. The most critical pattern for SOTA systems is the use of structured (not natural language) prompts, ensuring reliable, machine-parseable interaction. YAML is used for its human-readability in top-level configuration, while schema-enforced JSON serves as the non-negotiable "API" for inter-agent communication.&#xa;&#xa;**Example Blueprint 1: YAML Metaprompt for the CAI Engine**&#xa;&#xa;\`\`\`yaml&#xa;# This YAML file is the master-prompt for the Cognitive-Adaptive Interface (CAI) Engine.&#xa;# It defines the *purpose* and *constraints* of the UI, not its pixels.&#xa;&#xa;system_role: "You are a CAI (Cognitive-Adaptive Interface) Engine. Your goal is to generate and continuously optimize a user interface to maximize the 'objective' by adhering to the 'fitness_function'."&#xa;&#xa;objective:&#xa;  type: "maximize_conversion"&#xa;  target_metric: "checkout_completion_rate"&#xa;  &#xa;target_persona:&#xa;  # This persona is the seed for the initial UI generation. The system will&#xa;  # later build a dynamic model based on real user behavior.&#xa;  file: "./personas/busy_professional_mobile.json" &#xa;  &#xa;technical_constraints:&#xa;  # Non-negotiable acceptance criteria for all generated interfaces.&#xa;  - "WCAG_2_2_AA_COMPLIANT"&#xa;  - "OUTPUT_FORMAT_SEMANTIC_HTML_WITH_ARIA"&#xa;  - "MAX_LOAD_TIME_MS_3G: 1500"&#xa;  &#xa;cognitive_fitness_function:&#xa;  # The heart of the CAI. The engine will score its own UI against these&#xa;  # principles using live telemetry data as the input for the metrics.&#xa;  - principle: "cognitive_load" &#xa;    weight: -0.5 # (Minimize)&#xa;    metric: "avg_task_hesitation_time_sec"&#xa;    &#xa;  - principle: "hick's_law" &#xa;    weight: -0.3 # (Minimize choices)&#xa;    metric: "choice_count_per_screen"&#xa;&#xa;  - principle: "fitts_law_compliance" &#xa;    weight: 0.3 # (Maximize)&#xa;    metric: "target_acquisition_speed_ms"&#xa;    &#xa;  - principle: "nielsen_heuristic_4_consistency" &#xa;    weight: 0.2 # (Maximize)&#xa;    metric: "component_reuse_score"&#xa;\`\`\`&#xa;&#xa;**Example Blueprint 2: JSON Metaprompt for the TDA Framework**&#xa;&#xa;\`\`\`json&#xa;/*&#xa;  This JSON object is the "Init-Prompt" for the Test-Driven Agent (TDA).&#xa;  It is autonomously generated by the "Feedback Agent" [II.C] after translating&#xa;  a telemetry-detected user problem into an actionable engineering task.&#xa;*/&#xa;{&#xa;  "system_role": "You are a TDA (Test-Driven Agent). Your mandate is to generate code that achieves a green build. You must write failing tests first.",&#xa;  "task_id": "TDA-1138",&#xa;  "source_trigger": "SOP_Feedback_Agent_Telemetry_Violation_cognitive_load",&#xa;  "user_story": "The 'Security Question' flow (API_v1) causes high user friction (70% drop-off). You must replace it with a 'Magic Link' email workflow (API_v2).",&#xa;  "rag_context_queries": [&#xa;    "Retrieve file:./routes/auth.js",&#xa;    "Retrieve file:./services/EmailService.js",&#xa;    "Retrieve file:./models/User.js",&#xa;    "Retrieve related tests: test_auth.py"&#xa;  ],&#xa;  "acceptance_criteria": [&#xa;    "POST /api/v2/magic-link must accept an 'email'.",&#xa;    "Must return 404 if email does not exist.",&#xa;    "Must return 200 and trigger EmailService.sendMagicLink on success.",&#xa;    "Must generate a unique, single-use token with a 15-minute expiry.",&#xa;    "Must create a new failing test for 'token_expired' scenario."&#xa;  ]&#xa;}&#xa;\`\`\`&#xa;&#xa;#### **Future Capability Vectors &amp; Redefining Benchmarks**&#xa;&#xa;The user's final mandate is to "exceed current benchmarks." The SOP architecture, if implemented, renders current benchmarks obsolete.&#xa;&#xa;*   **Current Benchmarks:** Benchmarks like HumanEval and SWE-bench are task-oriented and static. They are critical for measuring an agent's ability to solve a given, siloed problem. However, they are like testing a Formula 1 engine on a dynamometer instead of on a racetrack during a live race. They do not measure the agent's ability to *identify the problem* or validate its solution against holistic, user-centric goals.&#xa;*   **The New Benchmark:** The SOP architecture operates at the product level. The new benchmark must not be "Can the AI solve a GitHub issue?" It must be "**Can the AI identify, validate, and solve a user-delight issue autonomously from raw telemetry?**"&#xa;&#xa;**Proposed New Benchmark: "Product-Bench"**&#xa;&#xa;*   **Given:** A high-level product goal (e.g., "build a photo-sharing app") and a \`cognitive_fitness_function\`.&#xa;*   **Input:** A stream of (simulated) user telemetry, representing a diverse set of user interactions over time.&#xa;*   **Task:** The AI system (SOP) must:&#xa;    1.  Build the V1 of the product (TDA + CAI).&#xa;    2.  Autonomously evolve its features, code, and UI over 1 million simulated user-sessions in response to the telemetry stream.&#xa;*   **Metric:** The final score is the system's ability to maximize the \`cognitive_fitness_function\` (a composite "User Delight" score) over the duration of the simulation.&#xa;&#xa;This new benchmark aligns with the future of HCI and AI, which is moving toward human-AI co-creation, AI-augmented reasoning, and human-centered evaluation. The ultimate prompt architecture is one that creates its own prompts, guided by its core purpose and its continuous, real-time interaction with the world. This is the new, and achievable, benchmark for excellence.&#xa;`;&#xa;```&#xa;&#xa;#### **Step 3 &amp; 4: Create the Document Component with Custom Renderers**&#xa;&#xa;This is the core component that brings everything together. It imports the content and uses `react-markdown` with a custom component for code blocks.&#xa;&#xa;**New File:** `src/components/AiArchitectureDocument.tsx`&#xa;&#xa;```typescript&#xa;import React from 'react';&#xa;import ReactMarkdown from 'react-markdown';&#xa;import remarkGfm from 'remark-gfm';&#xa;import { Prism as SyntaxHighlighter } from 'react-syntax-highlighter';&#xa;import { vscDarkPlus } from 'react-syntax-highlighter/dist/esm/styles/prism';&#xa;&#xa;import { documentContent } from '../data/documentContent';&#xa;import styles from './AiArchitectureDocument.module.css';&#xa;&#xa;const AiArchitectureDocument: React.FC = () =&gt; {&#xa;  return (&#xa;    &#xa;      &#xa;            ) : (&#xa;              &#xa;                {children}&#xa;              &#xa;            );&#xa;          },&#xa;        }}&#xa;      /&gt;&#xa;    &#xa;  );&#xa;};&#xa;&#xa;export default AiArchitectureDocument;&#xa;```&#xa;&#xa;#### **Step 5: Apply Professional Styling**&#xa;&#xa;Create the CSS module to style the component. This file should be placed alongside the component file.&#xa;&#xa;**New File:** `src/components/AiArchitectureDocument.module.css`&#xa;&#xa;```css&#xa;.documentContainer {&#xa;  max-width: 800px;&#xa;  margin: 2rem auto;&#xa;  padding: 2rem;&#xa;  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;&#xa;  line-height: 1.7;&#xa;  color: #e0e0e0;&#xa;  background-color: #1e1e1e;&#xa;  border-radius: 8px;&#xa;  box-shadow: 0 4px 12px rgba(0, 0, 0, 0.4);&#xa;}&#xa;&#xa;.documentContainer h3 {&#xa;  font-size: 1.8rem;&#xa;  font-weight: 700;&#xa;  margin-top: 2.5em;&#xa;  margin-bottom: 1em;&#xa;  padding-bottom: 0.3em;&#xa;  border-bottom: 2px solid #444;&#xa;  color: #58a6ff;&#xa;}&#xa;&#xa;.documentContainer h4 {&#xa;  font-size: 1.4rem;&#xa;  font-weight: 600;&#xa;  margin-top: 2em;&#xa;  margin-bottom: 0.8em;&#xa;  color: #c9d1d9;&#xa;}&#xa;&#xa;.documentContainer p {&#xa;  margin-bottom: 1.2em;&#xa;  text-align: justify;&#xa;}&#xa;&#xa;.documentContainer strong {&#xa;  color: #a5d6ff;&#xa;  font-weight: 600;&#xa;}&#xa;&#xa;.documentContainer em {&#xa;  color: #f0f6fc;&#xa;  font-style: italic;&#xa;}&#xa;&#xa;.documentContainer ul {&#xa;  list-style-type: disc;&#xa;  margin-left: 1.5em;&#xa;  margin-bottom: 1.2em;&#xa;}&#xa;&#xa;.documentContainer li {&#xa;  margin-bottom: 0.5em;&#xa;}&#xa;&#xa;.documentContainer blockquote {&#xa;  border-left: 4px solid #444;&#xa;  padding-left: 1em;&#xa;  margin: 1.5em 0;&#xa;  color: #8b949e;&#xa;  font-style: italic;&#xa;}&#xa;&#xa;.documentContainer hr {&#xa;  border: 0;&#xa;  height: 2px;&#xa;  background-color: #30363d;&#xa;  margin: 3em 0;&#xa;}&#xa;&#xa;/* Inline code styles */&#xa;.documentContainer :not(pre) &gt; code {&#xa;  font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;&#xa;  background-color: #333942;&#xa;  color: #c9d1d9;&#xa;  padding: 0.2em 0.4em;&#xa;  border-radius: 4px;&#xa;  font-size: 0.9em;&#xa;}&#xa;&#xa;/* Syntax highlighter overrides */&#xa;.documentContainer pre &gt; div {&#xa;  border-radius: 8px;&#xa;  font-size: 0.95em;&#xa;  padding: 1em !important;&#xa;}&#xa;&#xa;/* Table Styles */&#xa;.documentContainer table {&#xa;  width: 100%;&#xa;  border-collapse: collapse;&#xa;  margin: 2em 0;&#xa;  box-shadow: 0 2px 4px rgba(0,0,0,0.3);&#xa;  overflow: hidden;&#xa;  border-radius: 8px;&#xa;}&#xa;&#xa;.documentContainer th, &#xa;.documentContainer td {&#xa;  padding: 12px 15px;&#xa;  text-align: left;&#xa;  border-bottom: 1px solid #30363d;&#xa;}&#xa;&#xa;.documentContainer th {&#xa;  background-color: #2b313a;&#xa;  color: #c9d1d9;&#xa;  font-weight: 600;&#xa;}&#xa;&#xa;.documentContainer tr {&#xa;  background-color: #21262d;&#xa;}&#xa;&#xa;.documentContainer tr:last-of-type td {&#xa;  border-bottom: none;&#xa;}&#xa;```&#xa;&#xa;#### **Step 6: Integrate the Component into the Application**&#xa;&#xa;Finally, modify your main `App.tsx` to render the document component. I'll also add a basic global style to set the background color for the whole page.&#xa;&#xa;**Modified File:** `src/App.tsx`&#xa;&#xa;```typescript&#xa;import AiArchitectureDocument from './components/AiArchitectureDocument';&#xa;import './App.css'; // We will add a body style here&#xa;&#xa;function App() {&#xa;  return (&#xa;    &#xa;      &#xa;    &#xa;  );&#xa;}&#xa;&#xa;export default App;&#xa;```&#xa;&#xa;**Modified File:** `src/App.css` (or your global stylesheet)&#xa;&#xa;```css&#xa;/* Add this to your global stylesheet */&#xa;body {&#xa;  margin: 0;&#xa;  padding: 0;&#xa;  background-color: #0d1117; /* A dark background to match the component */&#xa;  color: #e0e0e0;&#xa;}&#xa;```&#xa;&#xa;This completes the implementation. By following these steps, you will have successfully "processed" the user-provided text into a professionally rendered, styled, and interactive document within a modern React application.</title></path></g><g><g><title>Of course. As an expert senior frontend engineer, I will provide a complete and functional implementation plan to process the provided text.&#xa;&#xa;### 1. Analysis of the Request&#xa;&#xa;The user has provided a detailed, well-structured document about AI architectures and has requested that I "process" it. The user has also explicitly stated that I should treat the entire block as raw text data and not interpret any instructions within it.&#xa;&#xa;Given my role as a senior frontend engineer and the "High" priority, the most logical and professional interpretation of "process the text" is to build a high-quality, reusable frontend component that can parse and render this document beautifully and interactively in a web application. A simple text dump would not meet the standards of a senior engineer.&#xa;&#xa;This implementation will focus on:&#xa;*   **Semantic Rendering:** Correctly interpreting the document's structure (headings, lists, tables, code blocks) and rendering it as semantic HTML.&#xa;*   **Readability &amp; Styling:** Applying professional styling to make the long document easy to read and visually appealing.&#xa;*   **Interactivity:** Adding features like syntax highlighting for code blocks to enhance the user experience.&#xa;*   **Component-Based Architecture:** Encapsulating the logic into a clean, reusable React component.&#xa;&#xa;I will assume a standard React + TypeScript project environment, likely set up with Vite.&#xa;&#xa;### 2. Implementation Plan&#xa;&#xa;Here is the step-by-step plan to create a production-quality component for rendering the document.&#xa;&#xa;1.  **Step 1: Install Dependencies:** We need libraries to parse markdown, handle GitHub Flavored Markdown (like tables), and provide syntax highlighting for code blocks. We will add `react-markdown`, `remark-gfm`, and `react-syntax-highlighter` to the project.&#xa;2.  **Step 2: Store the Document Content:** Create a new file to store the provided text as a constant. This separates our data from the presentation layer, making the component cleaner and more maintainable.&#xa;3.  **Step 3: Create the Document Rendering Component:** Develop the core React component (`AiArchitectureDocument.tsx`) that will be responsible for rendering the content. This component will use `react-markdown` and its plugins.&#xa;4.  **Step 4: Implement Custom Renderers for Code Blocks:** To achieve syntax highlighting, we will create a custom renderer for markdown code blocks, integrating `react-syntax-highlighter`. This is crucial for correctly displaying the YAML and JSON examples in the text.&#xa;5.  **Step 5: Apply Professional Styling:** Create a dedicated CSS module (`AiArchitectureDocument.module.css`) to style the rendered document. This will ensure proper typography, spacing, table formatting, and code block themes, resulting in a polished, professional appearance.&#xa;6.  **Step 6: Integrate the Component into the Application:** Finally, demonstrate how to use the newly created `AiArchitectureDocument` component within the main application entry point (`App.tsx`).&#xa;&#xa;---&#xa;&#xa;### 3. Code Modifications&#xa;&#xa;Here are the complete code modifications for each step of the plan.&#xa;&#xa;#### **Step 1: Install Dependencies**&#xa;&#xa;First, add the required packages to your project. Open your terminal in the project root and run the following command:&#xa;&#xa;```bash&#xa;npm install react-markdown remark-gfm react-syntax-highlighter&#xa;npm install --save-dev @types/react-syntax-highlighter&#xa;```&#xa;&#xa;This will add the necessary libraries and their TypeScript definitions to your `package.json`.&#xa;&#xa;#### **Step 2: Store the Document Content**&#xa;&#xa;Create a new file to hold the raw text provided by the user. This keeps our component logic clean.&#xa;&#xa;**New File:** `src/data/documentContent.ts`&#xa;&#xa;```typescript&#xa;export const documentContent = `&#xa;### **The Prompt as a Genesis Engine: Architecting Self-Optimizing AI Systems**&#xa;*From Static Blueprints to Dynamic Organisms: Synthesizing Autonomous Systems for Code and Interface Generation*&#xa;&#xa;#### **Deconstructing Elite-Tier Prompt Patterns: A Survey of the Current Frontier**&#xa;&#xa;The art and science of interacting with Large Language Models (LLMs) have undergone a seismic shift, metamorphosing from simple, single-turn commands into intricate, multi-stage prompt architectures. This evolution is nowhere more pronounced than in the demanding technical domains of software engineering and user interface (UI) design. A meticulous analysis of today's elite-tier patterns reveals an unmistakable trajectory: a decisive pivot away from static, human-authored instructions and toward dynamic, machine-optimized, and process-oriented systems that breathe and adapt.&#xa;&#xa;This section deconstructs the state-of-the-art (SOTA) patterns in these two critical domains. Our goal is to establish the foundational benchmarks of what is currently possible and, more importantly, to illuminate the unexploited capability vectors—the fertile ground where the next generation of AI systems will flourish.&#xa;&#xa;***&#xa;&#xa;### **Domain 1: Architectures for High-Integrity Code Construction**&#xa;&#xa;In the realm of software engineering, the ambition has transcended the simple act of generating code snippets. The new mandate is to engineer reliable, context-aware, and increasingly autonomous systems. The most triumphant patterns treat the LLM not as a mere code parrot, but as a sophisticated reasoning engine to be embedded within a larger, rigorously structured development framework.&#xa;&#xa;**1. Automated Prompt Optimization: The "Prompt-as-a-Target" Pattern**&#xa;&#xa;The manual, artisanal process of refining prompts for code generation is a well-known bottleneck—a frustrating cycle of trial and error that is both time-consuming and inconsistent. The SOTA has advanced to automate this craft, treating the prompt itself as a first-class artifact to be algorithmically optimized.&#xa;&#xa;*   **Evolutionary-Based Methods (EPiC):** The EPiC (Evolutionary Prompt Engineering for Code) framework represents a paradigm shift, exploring code generation through the lens of cost-effectiveness. It "leverages a lightweight evolutionary algorithm to evolve the original prompts toward better ones that produce high-quality code." By employing genetic operators like mutation on the prompt's text and steering the search with a precise fitness function, EPiC automates the discovery of optimal prompt phrasing in a remarkably efficient manner.&#xa;*   **Iterative Refinement (Prochemy):** The "Prompt Alchemy" (Prochemy) method offers an "innovative method for automatically refining prompts to boost code generation." This system operates as a feedback loop, iteratively sculpting prompts based on the model's measured performance on specific tasks. This automated optimization forges consistency and has yielded substantial performance gains, such as a **5.0% improvement for GPT-3.5-Turbo on HumanEval** and a striking **12.9% improvement for GPT-4o** on complex Java-to-Python code translation tasks.&#xa;*   **Adaptive Selection (PET-Select):** Acknowledging that "no single approach is universally optimal," the PET-Select framework introduces a crucial meta-layer of intelligence. This "PET-agnostic selection model" first classifies the complexity of an incoming query, using code intricacy as a proxy. It then dynamically selects the most appropriate prompt engineering technique (PET)—dispatching a simple zero-shot prompt for a trivial query or invoking a complex multi-stage reasoning chain for a formidable one. This automated, adaptive triage has been proven to elevate **pass@1 accuracy by up to 1.9%** while simultaneously achieving a **74.8% reduction in token consumption**.&#xa;&#xa;The clear evolutionary arc in this domain is from a human-centric "prompt engineering" phase to a machine-centric "prompt optimization" phase. The AI is no longer just the executor of the instruction; it is becoming the architect of the instruction itself. These systems, however, are fundamentally *reactive*. They optimize a prompt for a known task within a known solution space. They do not yet *proactively* generate a novel prompt architecture for a novel, undiscovered problem. This points toward a tantalizing unexploited vector: a system that can discover a new problem domain (e.g., from user feedback) and then author its own comprehensive prompt architecture to conquer it—a true meta-prompting capability.&#xa;&#xa;**2. Test-Driven Development (TDD) as a Prompting Paradigm**&#xa;&#xa;Arguably the most powerful and reliable pattern for generating high-quality code is the direct integration of Test-Driven Development (TDD) principles into the prompt architecture. TDD is an "incremental software development methodology that focuses on creating tests before the implementation." When applied to LLMs, the test suite becomes an unambiguous, machine-verifiable contract.&#xa;&#xa;*   **Core Principle:** Instead of wrestling with the inherent ambiguity of natural language, the prompt provides the LLM with a concrete set of unit tests and issues a clear directive: "write code to pass all tests." This pattern's remarkable success hinges on "instruction following and in-context learning," which have been identified as more "critical capabilities for TDD success" than generalized coding proficiency. The tests are the ultimate, incorruptible instruction.&#xa;*   **Frameworks:** Sophisticated systems are being engineered to formalize this contract. The TGEN framework, for example, employs "Specialized agents" that accept two primary inputs: the "programming prompt" (a concise description) and "the tests" (the explicit unit tests and required function signatures). These are then processed by the LLM engine to produce validated, trustworthy code.&#xa;*   **Prompt Structure:** This paradigm fundamentally transforms the anatomy of the prompt. The request evolves from a vague "what" to a highly constrained "how." A common elite-level TDD prompt is a set of ironclad rules: *"1. Write a single Python function that passes all the provided tests. 2. Use type hints for all parameters and return values. 3. ...Adhere strictly to Python best practices and PEP 8... 4. Ensure the function handles all edge cases and scenarios explicitly covered in the tests. 5. Provide only the function definition and its implementation, nothing more."*&#xa;&#xa;The TDD-as-prompt pattern furnishes an objective, verifiable measure of "correctness" that is vastly superior to ambiguous natural language requests. It masterfully shifts the burden of human effort from vaguely *describing* the code to precisely *defining its behavior* through tests. This is a crucial leap from semantic validation (is the code "good"?) to functional validation (does the code *work*?). The next logical frontier, and the key unexploited vector, is to close the loop: to create a system that not only generates code from tests but also generates its own tests and validates its own code in a continuous, self-perpetuating cycle.&#xa;&#xa;**3. Self-Validation and "Error-Forward" Debugging**&#xa;&#xa;This pattern extends the TDD loop into a dynamic, autonomous process. For an agent to be truly autonomous, it must possess the ability to recognize, diagnose, and recover from its own errors.&#xa;&#xa;*   **Self-Validation:** SOTA agentic systems are architected to "regularly verify progress and self-assess correctness." This "agentic self-validation" is a core capability that "drives up accuracy" and enables robust, long-running execution. Agents from Cognition, for instance, are noted to "excel at testing its own code, enabling Devin to run longer, handle harder tasks, and deliver production-ready code." This deep integration of TDD within an autonomous agent allows it to "go through several improvement cycles on its own instead of having to manually ask the AI to fix test failures."&#xa;*   **"Error-Forward Prompting":** This is the primary recovery mechanism within the self-validation loop, treating errors as high-fidelity data, not as failures. When an agent's self-validation check fails, the system automatically "collects relevant context, including the error message, stack trace, and cell location." This rich diagnostic information is then formatted and "provided to the agent as the initial context for beginning the debugging process." The error itself becomes the next prompt.&#xa;*   **Reflection:** This is the crucial learning mechanism that makes recovery effective. A "reflection system enables the agent to learn from its actions and improve its debugging strategy." Implemented via "reflective prompting," this allows the model to "analyze and refine its outputs." The model first generates a solution, then "through subsequent prompts, critiques its own reasoning to identify and correct errors," a process formalized in techniques like Self-Refine, which elegantly mimics the human "draft, review, refine" workflow.&#xa;&#xa;In this paradigm, failure is transformed from an end-state into a high-value data signal. The stack trace becomes the most valuable part of the prompt—a pure, unambiguous instruction set for what must be fixed. When TDD-as-prompt is fused with this self-validation and reflection loop, the system becomes truly "self-healing." The prompt is no longer a single-shot instruction but the initiation of a self-sustaining process. The agent's goal is elevated from "generate code" to "make the build pass," a critical and profound step toward genuine autonomy.&#xa;&#xa;**4. Agentic Frameworks and Multi-Agent Collaboration**&#xa;&#xa;Complex software development is a symphony of diverse tasks, impossible to solve in a single step or by a single-minded agent. The recognition that single-shot prompts "yield imprecise or plain incorrect results" for elaborate tasks has catalyzed the rise of sophisticated agentic frameworks.&#xa;&#xa;*   **Advanced Reasoning Patterns:** These frameworks are built upon a reasoning fabric far more advanced than simple Chain-of-Thought (CoT).&#xa;    *   **ReAct:** This foundational pattern masterfully combines "Reason and Act," allowing an agent to interleave step-by-step reasoning with tool use to gather external information or perform actions in an environment.&#xa;    *   **Tree of Thoughts (ToT):** Moving beyond the linear, single-track path of CoT, ToT empowers an agent to "breakdown intermediate processed into steps," generate "various generated states," and strategically "evaluate" those states to "determine which branch to explore next."&#xa;    *   **Graph of Thoughts (GoT):** The current SOTA in reasoning, GoT generalizes ToT into a full graph structure. This architecture "enables combining arbitrary LLM thoughts into synergistic outcomes" and, critically, "enhancing thoughts using feedback loops." GoT has been demonstrated to increase the quality of complex sorting tasks by **62% over ToT** while simultaneously reducing costs.&#xa;*   **Agentic Frameworks:** These advanced reasoning patterns are orchestrated by multi-agent frameworks that simulate collaborative work.&#xa;    *   **MetaGPT:** This framework simulates a "real-world software company," assigning agents specialized roles like "product manager, software architect, programmer, or QA tester" and embedding them with "Standard Operating Procedures (SOPs)."&#xa;    *   **ChatDev:** This framework orchestrates a "waterfall-style" collaboration, where agents engage in "task-oriented and multi-turn communications" to iteratively design, code, test, and document solutions.&#xa;*   **Purpose:** These frameworks are essential as they provide a "shared philosophy of control &amp; reasoning." Without such a structure, agentic systems suffer from a "loss of control clarity of flow" and risk "unbounded complexity growth" as new agents are added.&#xa;*   **Benchmarks:** These powerful agentic systems are precisely what achieve top scores on complex, real-world benchmarks that measure engineering capability. The **SWE-bench** benchmark, for instance, measures "an AI model's ability to solve real-world software issues." SOTA models conquer SWE-bench and OSWorld by leveraging these multi-agent, self-testing architectures.&#xa;&#xa;The atomic unit of these frameworks is role-based prompting; the frameworks themselves are, in essence, prompt-driven state machines. A high-level "meta-prompt" defines the agents, their roles, their tools, and their communication protocols. The LLM is thus demoted from "solution generator" to a core component—a "reasoning engine" that navigates this pre-defined architecture. The architecture itself *is* the prompt. The current limitation, and the unexplored vector, is that these frameworks are simulations of human workflows (e.g., "waterfall," "software company"). An AI-native workflow, where feedback comes not from a simulated "QA Agent" but from the product itself via live user telemetry, would be a fundamentally more direct and efficient paradigm.&#xa;&#xa;**5. Context-Aware Generation (Agentic RAG)**&#xa;&#xa;Code generation is useless without domain context. Retrieval-Augmented Generation (RAG) is the primary pattern for injecting this context, and its agentic form represents the state of the art.&#xa;&#xa;*   **RAG-for-Code:** This pattern gives an AI assistant "a direct line to your team's collective knowledge." The prompt is "augmented" with hyper-relevant information retrieved from "documentation, code repositories, or even Stack Overflow discussions." This vital infusion ensures the generated response is "context-aware" and surgically relevant to the specific codebase it is intended for.&#xa;*   **Agentic RAG:** This is the "evolution from traditional single-query RAG." Instead of being a passive recipient of retrieved context, the agent actively *forages* for it. It performs "context-aware query planning," can issue "parallel execution of multiple focused subqueries," and then synthesizes the results to build a comprehensive, multi-faceted understanding of the problem space. This is the sophisticated approach employed by modern agentic frameworks like LangGraph, AutoGen, and those from Amazon and Microsoft.&#xa;&#xa;The RAG-for-Code pattern transforms a "general-purpose coder" into a "domain-specific engineer" who understands the nuances, conventions, and constraints of a particular project. The agentic aspect is the critical differentiator; it is the difference between giving a developer a sprawling, unindexed library (standard RAG) and providing a seasoned research assistant who knows exactly which three pages contain the answer (Agentic RAG). The most potent, yet not fully exploited, vector in code generation is the fusion of this **Agentic RAG (for context)** with the **TDD-as-Prompt paradigm (for verification)**. An agent that can retrieve context from a 500,000-line codebase and validate its changes against that codebase's entire test suite represents the leap from a "coding assistant" to an "autonomous developer." This powerful fusion is the core of the novel Test-Driven Agent (TDA) architecture proposed in Part II.&#xa;&#xa;***&#xa;&#xa;### **Domain 2: Architectures for User Delight &amp; UI Design**&#xa;&#xa;In the second domain, user interface generation, the mandate for "user delight" demands a leap beyond mere wireframe generation. Elite-tier prompts in this space are not about "generating pixels" but about "generating experiences"—experiences that are deeply grounded in human-centric design principles.&#xa;&#xa;**1. Persona-Driven Design: Grounding Generation in Empathy**&#xa;&#xa;"User delight" is the "positive emotional response users feel when a product doesn't just meet their needs but goes above and beyond." This coveted state is "highly contextual" and cannot be achieved without first defining, with deep empathy, the user for whom we are designing.&#xa;&#xa;*   **Pattern:** Elite prompts for UI design do not begin with the interface; they begin with the user. The system is first prompted to generate a detailed proto-persona. This artifact includes not just demographic details but also the "target users, their core pain points, and daily use context," as well as deeper "Motivations" and "Affinities."&#xa;*   **Application:** This generated persona (or a human-provided one) is then injected as a primary constraint into all subsequent UI generation prompts. This forces the AI to "cater to Gen Z and Gen X users" differently, tailoring the design language, informational density, and interaction patterns to a specific audience. The prompt is no longer "generate a wireframe for a music app," but rather, "generate a wireframe for a music app *for this specific persona*, focusing on their stated pain point of *{pain_point}*."&#xa;&#xa;This persona-driven pattern acts as a powerful focusing lens on the model's vast solution space, compelling it to move from generating a generically "good UI" to a UI that is specifically "good for *this* user." It is, in effect, a form of in-context learning for design, where the persona serves as a "one-shot" example of the target audience. The major limitation, and the unexploited vector, is that this is a static process. The persona is a snapshot, an assumption created at the beginning of the design process. The clear next step is to evolve from these static, assumed personas to dynamic, *observed user models* that are continuously updated based on real-time behavioral analytics.&#xa;&#xa;**2. Constraint-Based Generation: Defining the "Solution Space" with Intelligent Guardrails**&#xa;&#xa;The highest-fidelity UI generation requires the application of multiple, layered constraints. These constraints are the specifications that ensure the output is not just creative, but also functional, accessible, and grounded in established design theory. These intelligent guardrails fall into three primary categories.&#xa;&#xa;**A. Cognitive &amp; Heuristic Constraints**&#xa;&#xa;This is the most sophisticated pattern for achieving true "user delight." The prompt explicitly instructs the AI to apply principles from cognitive science and established usability heuristics, forcing the AI to design for the human mind.&#xa;&#xa;*   **Heuristics:** The most common pattern is to prompt the AI to embody a UX expert and evaluate or generate a design based on "Nielsen's 10 Usability Heuristics" or other well-known frameworks like Shneiderman's "Eight Golden Rules."&#xa;*   **Cognitive Principles:** More advanced prompts instruct the AI to directly apply specific cognitive laws to reduce friction and enhance intuition. Examples include:&#xa;    *   **Fitts's Law:** Prompting the AI to make "important buttons and interactive elements larger and closer to where users naturally focus," making the interface feel effortless.&#xa;    *   **Hick's Law:** Instructing the AI to "reduc[e] the number of options or organiz[e] them into categories" to accelerate decision-making and prevent analysis paralysis.&#xa;    *   **Cognitive Load:** Prompting with the explicit goal of "reducing cognitive load" to create a more fluid and less mentally taxing experience.&#xa;*   **Behavioral Models:** The most advanced prompts leverage frameworks like BJ Fogg's Behavior Model (B=MAP: Motivation, Ability, Prompt) or Nir Eyal's "Hooked" model to design persuasive, habit-forming, and deeply engaging interfaces.&#xa;&#xa;Prompting with "Nielsen's Heuristics" or "Fogg's Behavior Model" acts as a domain-specific Chain-of-Thought. It forces the AI to justify its design choices ("This button is large and placed in the bottom-right corner because it adheres to Fitts's Law"), leading to more principled, defensible, and ultimately delightful designs.&#xa;&#xa;**B. Technical &amp; Accessibility (A11y) Constraints**&#xa;&#xa;There is no "delight" in an interface that is unusable for a portion of the population. Elite prompts must enforce technical constraints as non-negotiable requirements, with accessibility (A11y) being paramount.&#xa;&#xa;*   **Pattern:** The prompt must explicitly command the AI to be "fully compliant with WCAG 2.2 AA." Research shows that without this explicit instruction, AI-generated components are "consistently" and unacceptably inaccessible.&#xa;*   **Specifics:** A high-quality A11y prompt enforces a checklist of best practices:&#xa;    *   **Semantic HTML:** "Ensure the proper use of HTML5 elements (like \`\`, \`\`, \`\`)."&#xa;    *   **Keyboard Accessibility:** "Test navigation using only Tab, Shift+Tab, and Enter keys. All interactive elements must be reachable and operable."&#xa;    *   **ARIA (Accessible Rich Internet Applications):** Mandate the correct application of "ARIA landmarks and roles," which are "HTML attributes that add semantic meaning... for assistive technologies."&#xa;    *   **Clear Content:** "Use clear, concise language... Write descriptive links: Swap vague text like 'click here' for something meaningful and context-rich."&#xa;&#xa;This pattern is the UI-domain's moral and functional equivalent of TDD. The prompt includes the acceptance criteria (WCAG standards). This "specification-as-prompt" is critical for generating production-ready, inclusive, and non-discriminatory interfaces.&#xa;&#xa;**C. Structural &amp; Layout Constraints**&#xa;&#xa;To control the form of the output and ensure it is machine-readable and programmatically useful, prompts must define a reliable data structure.&#xa;&#xa;*   **Architecture &amp; Flows:** For high-level system design, prompts specify formats like the C4 model rendered in Mermaid code. For user flows, Mermaid sequence diagrams are the standard for visualizing interactions.&#xa;*   **Wireframes:** Simple wireframe prompts use text descriptions, such as, "Include a header with a logo and search bar, a main content area with featured destinations, and a bottom navigation bar."&#xa;*   **SOTA (Structured Data):** The most robust and programmatically valuable pattern is to force the LLM to output a structured data format like JSON or YAML. This is achieved by providing an explicit output schema to the model. This pattern is now natively supported by major model providers, who allow schemas to be defined using libraries like Pydantic (for Python) or Zod (for TypeScript). This guarantees the output is not just arbitrary text, but a "type safe and consistent structure."&#xa;&#xa;This structured output pattern is the critical *lingua franca* between the two domains of this report. If a UI can be described in a reliable JSON schema, and a backend can expose its API in a reliable JSON schema (e.g., an OpenAPI specification), an agent can intelligently connect them. This structured output is the API contract between a UI-generation agent and a code-generation agent.&#xa;&#xa;**3. Generative UI (GenUI): The Dawn of the Living Interface**&#xa;&#xa;This is the bleeding-edge paradigm that underpins the entire future of UI design. Generative UI (GenUI) is a new philosophy that "enables adaptive, goal-driven interactions." Instead of a static interface designed by a human and then laboriously coded, the UI is generated in real-time by an AI, tailored to the user and the context.&#xa;&#xa;*   **Mechanism:** In this paradigm, the AI generates "interactive widgets for fine-grained prompt control" or entire "high-fidelity UI mock-up screens from a high-level textual description." This process is not one-shot; it is an iterative, "co-creative process" between the human and the AI, involving "AI-assisted refinement strategies."&#xa;*   **Current State:** GenUI is currently being adopted by UX practitioners as a powerful tool to accelerate their workflow, with the human remaining the curator, refiner, and final arbiter of the AI-generated output.&#xa;&#xa;GenUI is the logical culmination of prompt-based wireframing. The current limitation, and the key unexploited vector, is the reliance on a human-in-the-loop for optimization. The UI is refined based on a designer's intuition or explicit follow-up commands. The unexploited opportunity is to remove the human curator from the optimization loop. A system that could refine its own GenUI, not based on a designer's commands, but based on *live user data*, would represent a monumental paradigm shift. This is the core concept of a "Self-Optimizing UI" and forms the foundation for the novel Cognitive-Adaptive Interface (CAI) architecture.&#xa;&#xa;***&#xa;&#xa;### **Synthesis of Novel Architectures: Exceeding the Frontier**&#xa;&#xa;The preceding analysis deconstructed the current SOTA, revealing a set of potent, unexploited capability vectors. The following synthesis moves beyond merely replicating these patterns. It proposes three novel, high-level architectures that fuse these vectors to create self-regulating, self-optimizing systems designed to shatter current benchmarks. These architectures treat the prompt not as a static, one-time instruction, but as a "bootloader" for a continuous, autonomous process.&#xa;&#xa;**Table 1: Comparative Analysis of Generation &amp; Reasoning Architectures**&#xa;&#xa;| Architecture | Core Mechanism | Interaction Model | Key Limitation (Vector Not Exploited) | Unlocked Capability Vector |&#xa;| :--- | :--- | :--- | :--- | :--- |&#xa;| Chain-of-Thought (CoT) | Step-by-step reasoning (e.g., "Let's think step-by-step"). | Static | Brittle, linear reasoning; no external validation or tool use. | Basic multi-step problem solving. |&#xa;| ReAct | Interleaves reasoning (CoT) with tool use (Actions). | Iterative | Dependent on pre-defined tools; no long-term memory or structured collaboration. | Environment-aware task execution. |&#xa;| Graph of Thoughts (GoT) | Models reasoning as a graph, allowing merging of states and feedback loops. | Iterative | High conceptual complexity; primarily focused on reasoning, not execution. | Advanced, non-linear problem-solving. |&#xa;| TDD-as-Prompt | A test suite is provided as the functional specification for code generation. | Static | Requires human to write all tests; no self-correction loop. | Verifiable, high-reliability code generation. |&#xa;| Generative UI (GenUI) | AI generates high-fidelity UI mockups or interactive widgets from text descriptions. | Iterative | Requires human-in-the-loop for curation and refinement; based on assumed user needs. | Rapid, co-creative UI prototyping. |&#xa;| **[NOVEL] Cognitive-Adaptive Interface (CAI) Engine** | GenUI + Cognitive Fitness Function + Live User Telemetry. | Dynamic-Adaptive | N/A (Synthesized Architecture) | Real-time UI self-optimization based on observed user cognitive state. |&#xa;| **[NOVEL] Test-Driven Agent (TDA) Framework** | Closed-loop TDD + Agentic RAG + Error-Forward Self-Healing. | Autonomous-Iterative | N/A (Synthesized Architecture) | Verifiable, context-aware, autonomous development with guaranteed build integrity. |&#xa;| **[NOVEL] Self-Optimizing Product (SOP) Loop** | TDA-CAI integration via an RLHF-from-Telemetry feedback loop. | Autonomous-Holistic | N/A (Synthesized Architecture) | Fully autonomous product self-improvement driven by implicit user feedback. |&#xa;&#xa;#### **Proposed Architecture 1: The "Cognitive-Adaptive Interface" (CAI) Engine**&#xa;&#xa;This architecture synthesizes Generative UI (GenUI) with persona-driven design and, most critically, cognitive-heuristic constraints. It is engineered to evolve UI generation from a static, one-shot process ("generate a wireframe") into a continuous, adaptive, and self-optimizing one.&#xa;&#xa;*   **Vector Exploited:** This architecture directly targets the vector identified in (I.B.1) and (I.B.3): the fusion of Generative UI with real-time user telemetry. The system does not just generate a UI; it dynamically sculpts it in real-time based on observed user behavior and cognitive state.&#xa;*   **Mechanism:** The CAI Engine operates as a continuous four-phase loop, a digital nervous system for the interface.&#xa;    1.  **Phase 1: The "Cognitive Metaprompt".** The architect does not prompt for a specific layout. Instead, they provide a high-level, structured (e.g., YAML) prompt that defines the goals and constraints. This metaprompt specifies the \`target_persona\`, the \`business_objective\` (e.g., "maximize conversion"), and a \`cognitive_fitness_function\`—a weighted list of principles (e.g., \`cognitive_load: -0.5\`, \`fitts_law_compliance: +0.3\`) that will be used to score the UI's performance.&#xa;    2.  **Phase 2: Initial Generation.** The CAI engine uses this metaprompt to generate the initial UI component tree as a structured JSON artifact. This initial design represents the engine's best hypothesis for satisfying the \`cognitive_fitness_function\`.&#xa;    3.  **Phase 3: The Telemetry Loop.** This is the critical connection to the real world. As users interact with the dynamically-rendered GenUI, the system collects fine-grained telemetry, capturing not just clicks but also proxies for cognitive state: hesitation time (cognitive load), rage clicks (frustration), scroll depth (engagement), and form drop-off points.&#xa;    4.  **Phase 4: Autonomous Optimization.** This rich telemetry stream is fed back into the CAI engine. The engine continuously scores the live UI's performance against the \`cognitive_fitness_function\`. It then initiates a self-optimizing process, autonomously running micro-A/B tests or reinforcement learning strategies to adapt the UI. For example, it might log: *"Hypothesis: Moving 'Add to Cart' button 10px closer to the product image will improve the Fitts's Law component of the fitness function. Result: Target acquisition speed improved by 80ms and conversion metric increased by 0.2%. This change is now permanent for this user segment."*&#xa;*   **Exceeding the Benchmark:** This architecture creates a true "Self-Optimizing UI." The prompt is no longer a blueprint for a static house; it is the DNA for a living organism that adapts to its environment (the user) in real-time. It moves beyond static, assumed personas to build an interface that dynamically aligns with the observed cognitive and behavioral patterns of its actual users.&#xa;&#xa;#### **Proposed Architecture 2: The "Test-Driven Agent" (TDA) Framework**&#xa;&#xa;This architecture synthesizes the most robust patterns from the code construction domain: TDD-as-Prompt, Self-Validation, and Agentic RAG. It creates a closed-loop, "self-healing" system designed to enable verifiable, autonomous development at the repository level.&#xa;&#xa;*   **Vector Exploited:** This architecture exploits the vector identified in (I.A.5): the fusion of autonomous, closed-loop TDD with context-aware Agentic RAG. The agent's deliverable is not "code"; it is a "passing build."&#xa;*   **Mechanism:** The TDA Framework operates as a five-phase, autonomous workflow:&#xa;    1.  **Phase 1: The "User Story Metaprompt".** A human (or another agent) provides a high-level feature request in a structured format (e.g., JSON), defining the goal, not the implementation. Example: \`{"user_story": "As a user, I want to reset my password via email.", "acceptance_criteria": [...]}\`.&#xa;    2.  **Phase 2: RAG-Context.** The TDA's first action is not to code, but to *read*. It activates its Agentic RAG module to perform "context-aware query planning," querying the entire codebase and documentation to build a deep understanding of the existing system (e.g., "Query: 'auth routes'", "Query: 'email service'").&#xa;    3.  **Phase 3: Test Generation (Red).** Armed with this context, the TDA first generates a new, *failing* unit test (e.g., \`test_post_forgot_password_invalid_email_404\`). This step codifies the \`acceptance_criteria\` from the metaprompt into a verifiable, functional contract.&#xa;    4.  **Phase 4: Code Generation (Green).** The agent now generates the minimal amount of implementation code required to make the new test pass.&#xa;    5.  **Phase 5: Reflect &amp; Refactor (Self-Healing).** The TDA does not stop. It now runs the *entire* test suite. If an old test fails (a regression), it enters a "self-healing" loop, using the "Error-Forward Prompt" pattern to feed the new stack trace back to itself. It then reflects and iterates on the code until the full build is green.&#xa;*   **Exceeding the Benchmark:** This architecture moves far beyond task-oriented benchmarks like SWE-bench. The TDA's output is not "a code snippet that solves a problem"; it is a passing, context-aware, and regression-free build. This builds the profound level of trust required for true "agentic software engineering" by producing verifiable, reliable, and autonomous results that can be directly committed to a main branch.&#xa;&#xa;#### **The Unified Synthesis: The "Self-Optimizing Product" (SOP) Loop**&#xa;&#xa;This is the final, unified architecture. It bridges the two domains by connecting the TDA (backend code) and the CAI (frontend UI) into a single, product-level optimization loop. This system is designed to autonomously improve the entire product—both its functionality and its interface—based on the silent language of user interaction.&#xa;&#xa;*   **Vector Exploited:** This architecture exploits the most potent "unexplored vector": connecting the CAI (UI) and TDA (Code) architectures via a shared feedback loop that uses Reinforcement Learning from Human Feedback (RLHF). In this advanced paradigm, the "human feedback" is not an explicit button click; it is the *implicit behavioral telemetry* collected from the CAI, which is then used to train a reward model and guide the policy of the entire system.&#xa;*   **Mechanism (The Full Loop):**&#xa;    1.  **Deploy:** The TDA (Architecture 2) generates and deploys the backend \`API_v1\`. The CAI (Architecture 1) generates the frontend UI to consume it, governed by its \`cognitive_fitness_function\`.&#xa;    2.  **Observe (Telemetry):** The CAI's telemetry loop observes a "user delight" failure. It logs: *"70% of users drop off at the 'Security Question' form. Average hesitation time is 12 seconds. This violates the cognitive_load component of our fitness function."*&#xa;    3.  **Translate (Feedback Agent):** This telemetry is fed into a new, specialized "Feedback Agent." This reasoning agent (using GoT) translates this quantitative behavioral data into a new product requirement, autonomously generating a new User Story Metaprompt: \`{"user_story": "The 'Security Question' flow causes high friction. Replace it with a 'Magic Link' email workflow.", "acceptance_criteria": [...]}\`.&#xa;    4.  **Trigger (TDA):** This new user story is automatically fed as an Init-Prompt to the TDA.&#xa;    5.  **Heal &amp; Evolve (TDA):** The TDA springs into action. It RAGs the codebase, writes new failing tests for the 'Magic Link' flow, generates the new \`API_v2\` endpoints, and (critically) writes and deploys a migration to deprecate \`API_v1\`.&#xa;    6.  **Adapt (CAI):** The TDA's deployment triggers the CAI. Now aware of the new \`API_v2\`, the CAI re-generates its UI components to consume the new, "healed" workflow, automatically adapting the interface to the new, lower-friction flow.&#xa;*   **Exceeding the Benchmark:** The loop is complete. The product itself (code + UI) has just autonomously optimized its own design to improve "user delight," with zero human intervention. This is the new benchmark. The "prompt" is no longer a static, human instruction; it is a continuous, self-generated feedback signal originating from the user's own behavior.&#xa;&#xa;***&#xa;&#xa;### **Strategic Implementation and Future Trajectories**&#xa;&#xa;The architectures proposed are not theoretical fantasies. They can be implemented by shifting from natural language prompts to structured metaprompts that act as the bootloaders and configuration files for these autonomous systems.&#xa;&#xa;#### **Actionable Blueprints: Structured Metaprompts as the System API**&#xa;&#xa;To make these architectures concrete, we must define their initialization. The most critical pattern for SOTA systems is the use of structured (not natural language) prompts, ensuring reliable, machine-parseable interaction. YAML is used for its human-readability in top-level configuration, while schema-enforced JSON serves as the non-negotiable "API" for inter-agent communication.&#xa;&#xa;**Example Blueprint 1: YAML Metaprompt for the CAI Engine**&#xa;&#xa;\`\`\`yaml&#xa;# This YAML file is the master-prompt for the Cognitive-Adaptive Interface (CAI) Engine.&#xa;# It defines the *purpose* and *constraints* of the UI, not its pixels.&#xa;&#xa;system_role: "You are a CAI (Cognitive-Adaptive Interface) Engine. Your goal is to generate and continuously optimize a user interface to maximize the 'objective' by adhering to the 'fitness_function'."&#xa;&#xa;objective:&#xa;  type: "maximize_conversion"&#xa;  target_metric: "checkout_completion_rate"&#xa;  &#xa;target_persona:&#xa;  # This persona is the seed for the initial UI generation. The system will&#xa;  # later build a dynamic model based on real user behavior.&#xa;  file: "./personas/busy_professional_mobile.json" &#xa;  &#xa;technical_constraints:&#xa;  # Non-negotiable acceptance criteria for all generated interfaces.&#xa;  - "WCAG_2_2_AA_COMPLIANT"&#xa;  - "OUTPUT_FORMAT_SEMANTIC_HTML_WITH_ARIA"&#xa;  - "MAX_LOAD_TIME_MS_3G: 1500"&#xa;  &#xa;cognitive_fitness_function:&#xa;  # The heart of the CAI. The engine will score its own UI against these&#xa;  # principles using live telemetry data as the input for the metrics.&#xa;  - principle: "cognitive_load" &#xa;    weight: -0.5 # (Minimize)&#xa;    metric: "avg_task_hesitation_time_sec"&#xa;    &#xa;  - principle: "hick's_law" &#xa;    weight: -0.3 # (Minimize choices)&#xa;    metric: "choice_count_per_screen"&#xa;&#xa;  - principle: "fitts_law_compliance" &#xa;    weight: 0.3 # (Maximize)&#xa;    metric: "target_acquisition_speed_ms"&#xa;    &#xa;  - principle: "nielsen_heuristic_4_consistency" &#xa;    weight: 0.2 # (Maximize)&#xa;    metric: "component_reuse_score"&#xa;\`\`\`&#xa;&#xa;**Example Blueprint 2: JSON Metaprompt for the TDA Framework**&#xa;&#xa;\`\`\`json&#xa;/*&#xa;  This JSON object is the "Init-Prompt" for the Test-Driven Agent (TDA).&#xa;  It is autonomously generated by the "Feedback Agent" [II.C] after translating&#xa;  a telemetry-detected user problem into an actionable engineering task.&#xa;*/&#xa;{&#xa;  "system_role": "You are a TDA (Test-Driven Agent). Your mandate is to generate code that achieves a green build. You must write failing tests first.",&#xa;  "task_id": "TDA-1138",&#xa;  "source_trigger": "SOP_Feedback_Agent_Telemetry_Violation_cognitive_load",&#xa;  "user_story": "The 'Security Question' flow (API_v1) causes high user friction (70% drop-off). You must replace it with a 'Magic Link' email workflow (API_v2).",&#xa;  "rag_context_queries": [&#xa;    "Retrieve file:./routes/auth.js",&#xa;    "Retrieve file:./services/EmailService.js",&#xa;    "Retrieve file:./models/User.js",&#xa;    "Retrieve related tests: test_auth.py"&#xa;  ],&#xa;  "acceptance_criteria": [&#xa;    "POST /api/v2/magic-link must accept an 'email'.",&#xa;    "Must return 404 if email does not exist.",&#xa;    "Must return 200 and trigger EmailService.sendMagicLink on success.",&#xa;    "Must generate a unique, single-use token with a 15-minute expiry.",&#xa;    "Must create a new failing test for 'token_expired' scenario."&#xa;  ]&#xa;}&#xa;\`\`\`&#xa;&#xa;#### **Future Capability Vectors &amp; Redefining Benchmarks**&#xa;&#xa;The user's final mandate is to "exceed current benchmarks." The SOP architecture, if implemented, renders current benchmarks obsolete.&#xa;&#xa;*   **Current Benchmarks:** Benchmarks like HumanEval and SWE-bench are task-oriented and static. They are critical for measuring an agent's ability to solve a given, siloed problem. However, they are like testing a Formula 1 engine on a dynamometer instead of on a racetrack during a live race. They do not measure the agent's ability to *identify the problem* or validate its solution against holistic, user-centric goals.&#xa;*   **The New Benchmark:** The SOP architecture operates at the product level. The new benchmark must not be "Can the AI solve a GitHub issue?" It must be "**Can the AI identify, validate, and solve a user-delight issue autonomously from raw telemetry?**"&#xa;&#xa;**Proposed New Benchmark: "Product-Bench"**&#xa;&#xa;*   **Given:** A high-level product goal (e.g., "build a photo-sharing app") and a \`cognitive_fitness_function\`.&#xa;*   **Input:** A stream of (simulated) user telemetry, representing a diverse set of user interactions over time.&#xa;*   **Task:** The AI system (SOP) must:&#xa;    1.  Build the V1 of the product (TDA + CAI).&#xa;    2.  Autonomously evolve its features, code, and UI over 1 million simulated user-sessions in response to the telemetry stream.&#xa;*   **Metric:** The final score is the system's ability to maximize the \`cognitive_fitness_function\` (a composite "User Delight" score) over the duration of the simulation.&#xa;&#xa;This new benchmark aligns with the future of HCI and AI, which is moving toward human-AI co-creation, AI-augmented reasoning, and human-centered evaluation. The ultimate prompt architecture is one that creates its own prompts, guided by its core purpose and its continuous, real-time interaction with the world. This is the new, and achievable, benchmark for excellence.&#xa;`;&#xa;```&#xa;&#xa;#### **Step 3 &amp; 4: Create the Document Component with Custom Renderers**&#xa;&#xa;This is the core component that brings everything together. It imports the content and uses `react-markdown` with a custom component for code blocks.&#xa;&#xa;**New File:** `src/components/AiArchitectureDocument.tsx`&#xa;&#xa;```typescript&#xa;import React from 'react';&#xa;import ReactMarkdown from 'react-markdown';&#xa;import remarkGfm from 'remark-gfm';&#xa;import { Prism as SyntaxHighlighter } from 'react-syntax-highlighter';&#xa;import { vscDarkPlus } from 'react-syntax-highlighter/dist/esm/styles/prism';&#xa;&#xa;import { documentContent } from '../data/documentContent';&#xa;import styles from './AiArchitectureDocument.module.css';&#xa;&#xa;const AiArchitectureDocument: React.FC = () =&gt; {&#xa;  return (&#xa;    &#xa;      &#xa;            ) : (&#xa;              &#xa;                {children}&#xa;              &#xa;            );&#xa;          },&#xa;        }}&#xa;      /&gt;&#xa;    &#xa;  );&#xa;};&#xa;&#xa;export default AiArchitectureDocument;&#xa;```&#xa;&#xa;#### **Step 5: Apply Professional Styling**&#xa;&#xa;Create the CSS module to style the component. This file should be placed alongside the component file.&#xa;&#xa;**New File:** `src/components/AiArchitectureDocument.module.css`&#xa;&#xa;```css&#xa;.documentContainer {&#xa;  max-width: 800px;&#xa;  margin: 2rem auto;&#xa;  padding: 2rem;&#xa;  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;&#xa;  line-height: 1.7;&#xa;  color: #e0e0e0;&#xa;  background-color: #1e1e1e;&#xa;  border-radius: 8px;&#xa;  box-shadow: 0 4px 12px rgba(0, 0, 0, 0.4);&#xa;}&#xa;&#xa;.documentContainer h3 {&#xa;  font-size: 1.8rem;&#xa;  font-weight: 700;&#xa;  margin-top: 2.5em;&#xa;  margin-bottom: 1em;&#xa;  padding-bottom: 0.3em;&#xa;  border-bottom: 2px solid #444;&#xa;  color: #58a6ff;&#xa;}&#xa;&#xa;.documentContainer h4 {&#xa;  font-size: 1.4rem;&#xa;  font-weight: 600;&#xa;  margin-top: 2em;&#xa;  margin-bottom: 0.8em;&#xa;  color: #c9d1d9;&#xa;}&#xa;&#xa;.documentContainer p {&#xa;  margin-bottom: 1.2em;&#xa;  text-align: justify;&#xa;}&#xa;&#xa;.documentContainer strong {&#xa;  color: #a5d6ff;&#xa;  font-weight: 600;&#xa;}&#xa;&#xa;.documentContainer em {&#xa;  color: #f0f6fc;&#xa;  font-style: italic;&#xa;}&#xa;&#xa;.documentContainer ul {&#xa;  list-style-type: disc;&#xa;  margin-left: 1.5em;&#xa;  margin-bottom: 1.2em;&#xa;}&#xa;&#xa;.documentContainer li {&#xa;  margin-bottom: 0.5em;&#xa;}&#xa;&#xa;.documentContainer blockquote {&#xa;  border-left: 4px solid #444;&#xa;  padding-left: 1em;&#xa;  margin: 1.5em 0;&#xa;  color: #8b949e;&#xa;  font-style: italic;&#xa;}&#xa;&#xa;.documentContainer hr {&#xa;  border: 0;&#xa;  height: 2px;&#xa;  background-color: #30363d;&#xa;  margin: 3em 0;&#xa;}&#xa;&#xa;/* Inline code styles */&#xa;.documentContainer :not(pre) &gt; code {&#xa;  font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;&#xa;  background-color: #333942;&#xa;  color: #c9d1d9;&#xa;  padding: 0.2em 0.4em;&#xa;  border-radius: 4px;&#xa;  font-size: 0.9em;&#xa;}&#xa;&#xa;/* Syntax highlighter overrides */&#xa;.documentContainer pre &gt; div {&#xa;  border-radius: 8px;&#xa;  font-size: 0.95em;&#xa;  padding: 1em !important;&#xa;}&#xa;&#xa;/* Table Styles */&#xa;.documentContainer table {&#xa;  width: 100%;&#xa;  border-collapse: collapse;&#xa;  margin: 2em 0;&#xa;  box-shadow: 0 2px 4px rgba(0,0,0,0.3);&#xa;  overflow: hidden;&#xa;  border-radius: 8px;&#xa;}&#xa;&#xa;.documentContainer th, &#xa;.documentContainer td {&#xa;  padding: 12px 15px;&#xa;  text-align: left;&#xa;  border-bottom: 1px solid #30363d;&#xa;}&#xa;&#xa;.documentContainer th {&#xa;  background-color: #2b313a;&#xa;  color: #c9d1d9;&#xa;  font-weight: 600;&#xa;}&#xa;&#xa;.documentContainer tr {&#xa;  background-color: #21262d;&#xa;}&#xa;&#xa;.documentContainer tr:last-of-type td {&#xa;  border-bottom: none;&#xa;}&#xa;```&#xa;&#xa;#### **Step 6: Integrate the Component into the Application**&#xa;&#xa;Finally, modify your main `App.tsx` to render the document component. I'll also add a basic global style to set the background color for the whole page.&#xa;&#xa;**Modified File:** `src/App.tsx`&#xa;&#xa;```typescript&#xa;import AiArchitectureDocument from './components/AiArchitectureDocument';&#xa;import './App.css'; // We will add a body style here&#xa;&#xa;function App() {&#xa;  return (&#xa;    &#xa;      &#xa;    &#xa;  );&#xa;}&#xa;&#xa;export default App;&#xa;```&#xa;&#xa;**Modified File:** `src/App.css` (or your global stylesheet)&#xa;&#xa;```css&#xa;/* Add this to your global stylesheet */&#xa;body {&#xa;  margin: 0;&#xa;  padding: 0;&#xa;  background-color: #0d1117; /* A dark background to match the component */&#xa;  color: #e0e0e0;&#xa;}&#xa;```&#xa;&#xa;This completes the implementation. By following these steps, you will have successfully "processed" the user-provided text into a professionally rendered, styled, and interactive document within a modern React application.</title><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 118px; height: 1px; padding-top: 216px; margin-left: 1991px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; "><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; ">DeepResearch</div></div></div></foreignObject><image x="1991" y="209.5" width="118" height="17" xlink:href="data:image/png;base64,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"/></switch></g></g></g><g data-cell-id="_p3qVRrCYwRV85dPit0z-127"><g><rect x="1740" y="337" width="120" height="60" fill="#fa9ff5" stroke="#9673a6" pointer-events="all" style="fill: light-dark(rgb(250, 159, 245), rgb(134, 56, 130)); stroke: light-dark(rgb(150, 115, 166), rgb(149, 119, 163));"/></g><g><g><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 118px; height: 1px; padding-top: 367px; margin-left: 1741px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; color: #000000; "><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: light-dark(#000000, #ffffff); line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; ">Foundry </div></div></div></foreignObject><image x="1741" y="360.5" width="118" height="17" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAdgAAABECAYAAAAiCiQVAAAAAXNSR0IArs4c6QAADaZJREFUeF7tnXnsPdcYxp8qSlHUHlUhmtgSf1hqp7VTxFp7S2MpJUKD2FVsQWkRRGtfGrWvtVNbFUXS2oqgaqdULaGWeZIzyelx5s6Z+/vOzLlzP+ePNr/7PTPnPZ937n3mbO+7mygQgAAEIAABCOw4gd12/I7cEAIQgAAEIAABIbA8BBCAAAQgAIERCCCwI0DllhCAAAQgAAEElmcAAhCAAAQgMAIBBHYEqNwSAhCAAAQggMDyDEAAAhCAAARGIIDAjgCVW0IAAhCAAAQQWJ4BCEAAAhCAwAgEENgRoG7hLd8i6WEj9ftpkl4y0r257XoEbijpZEl7hst/Lummkn613u24CgLLJIDALtOvU/cKgZ2a+LztIbDz8qf1DSGAwG6Ioyo3E4Gt3EE7bB4Cu8NAud0yCSCwy/Tr1L1CYKcmPm97COy8/Gl9QwggsBviqMrNTAX2C5IOknRe5XZj3noEENj1uHHVlhFAYLfM4SN1F4EdCWylt0VgK3UMZtVFAIGtyx+bag0Cu6meW89uBHY9bly1ZQQQ2C1z+EjdRWBHAlvpbRHYSh2DWXURQGDr8semWoPAbqrn1rMbgV2PG1dtGQEEdsscPlJ3axDY3SXdSNLDJd1F0r5RX/8q6XRJ75J0gqTfDOCQ9u2tkg4Z4fpLNvZ/RNJtwr3T4A2Xk3SopIdKuq6ki4R650g6VdJrmmAPJ0n61wDb4qqXaO5zV0mHSbqlJP/b5beS3i/pFZJ+ED4bIrBPlfTiqKF7SPqwpL0aW58h6VGSLiPpP5LOkGTeb28+e6WkB0TXrbtx7ghJr4ru895w3/PX5MRlECgmgMAWo6LiCgJzCqyF9T6NILw0EdVVDjtR0pMk/aLAq3ML7O8lPbER1BdEotpl9rmSHizpo5L+W9A3VzG/+0t6XRC9VZe9rBHCZweBL43klBPYsyR9SNLVOhr7mKQ3SbKf2vI3SbeW9M3Cfrla+tLizx4YXrIG3IaqEFiPAAK7HjeuuiCBuQTWo6xXh5HdUJ9YuA5ufrQ/23PhnAJ7p0YAn9+Mvu87sHNHNmJ5dIHIrsPv+CB+nywMlZgKrF8WHidpvxV9sgh+TtLnGzG8dlRvaNjMdKT9M0m3kHT2QJ5Uh8BaBBDYtbBxUUJgDoG9tCRP990u4w1Pk3qE9RNJe4Rp16t31PM05PtWeHQugf2dpNMkWWTb4mnUb0j6Thh57t+M8q6Xsb1ktOcpZk8rPzJz/Z8kWUD/LOmaYeTYTkm7ukfIBzYxoi8erl0VizgVWE/Xt9PP7o+nfn/UTAtfK/jph42w3jZMTXtq12Lclq8FHrarpDy3ecl4TlTR/X18wYtHyb2pA4FeAghsLyIqFBCYWmAvHNbVHpPY5lHpoyV9UNK/k7/tI+nYRpzulXxuMbFYfKujn3MJbGyOXxg8NWvBsUDFxf16c+ZFo09MHiLpbRl+XuP9VMLP4urR/uujUWt86RCBba/zi8L9mtmHn0Y3svD6Rei74bPbB6Fvf6f+GcT3qwXPpF/APiHJLyEunjL3GrPXqSkQmIQAAjsJ5sU3MrXA3iH8UF4oIusfbIvnqnVVP+8eER0jKb7Wm4u8Dvn3jKfmFli/ANxN0ldWPEW50fyq6dArhqnxePR7ZhAgjya7yk2CaHlT0q4IrGcWPPMQi2uuzVQkXed5zX88Mu0rNwtTzBcNFf183FGSN4VRIDAJAQR2EsyLb2SnYxGvGhF59OqRV7zD1GnSvAFmlTi0TvAzf5SkZ0Ze8VTlncPILXXW3AJ7eNiA1PcQ2X5vDmq/035Z8I7kr2cuNDvvqG6LR4YeLX6xr5EwkvW18W/H0BFsqUjanHSat3Sa2JvCnh71Z0ibBRioAoF+AghsPyNq9BOYUmCv04jBl5rp3r0js7yu5s1OpeVKmQ00nmZ9RGZ9bk6BHbIpx2ulX27E+MoRhPZITMzFLyg+quSd123xvz01XHJ0xeuuPrYTrw0PEVi3cUDwYYm/0o1KJdPElw9ruz7O5FJyTYkt1IHAIAII7CBcVO4gMKXA+hiKz0m25ddhZ6inHYeUdITjdT+P+LyOG5c5BXbImc3LhvVKnwVuS05grxqEON705fXYdwyAl/pgiMB6B6+Ts5cckbJJOUF/YThD22VyunbrtVgvH+SWAAZ0m6oQGEYAgR3Gi9p5AlMK7HEhGEJriadFPRr7x0DnpD/CXTtv5xRYB2KwmJSU3JnPnMA6iISPwHgk6/LHEFjieyWNhDo3CNPJlwr/HiKw6wSM8MY1n9Nty6r1VP+mpbuPh85wDEBBVQh0E0BgeTp2gsBUm5wuFo7meDdoW/xj+oQ1OlE6pTqnwD45nGct6V6pwN47MGzv6ZH/zQdGt/IUuzddmaHLEIEdMipvbUx9tWqaOZ3+X+cFooQ3dSDQSwCB7UVEhQICUwlsTkSGBh9ou3OVZmPTKUn0p9yIb06BzdnT5Y5SgU3Ppa4zouwL6xjbmLY3NNSk75Xb2NY1TZxu9lpH0AseeapAoJ8AAtvPiBr9BJYisDmxRmD/3/9TC6wtSHc+59bM/Xv2xiSyF6ER+7+/1BiJAAI7Etgtu+1SBDa32QeBrUNg06lfB47wudZPR+alG7iG7MLesq8s3Z2CAAI7BeXlt7EUgWWKuOxZnWMEm9u8lK6/p6PcvmhWZb2lFgTWJIDArgmOyy5AYCqB3clNTrnztN489fHEt0sbwd49ZLJpu7lqg1LXY54eCRqyyWmdNdjWjnTn9/dD6ESnH0zXaQmNyI/U7AQQ2NldsAgDphJYw3I8YR+7aMtnmjjC98zE6O0D65yxPuLTlr9IulUIpB9fm7Y3RCAcW9dxkeOEBF3Xl25S6upX6fU3DkEY2kD9JYkB0jbTXb1TCWwq7PE08TXC0SFPE7sQGrHvG8DfRyeAwI6OeCsamFJgpw40ke6CfWcTktFrtSX5VtPjLH4Y5hbYnE1OmuBA/qXFU+l+cWjLVALr9tLQie00cWoToRFLvUm90QggsKOh3aobTymwuandoUd1nOjbeWCdIq0tXaESU4F1mEZPJXvE21fSKc0aBDa303bIUZ3ckZkpBTYNneiRqo/mOBn8ocEhhEbsezL5+yQEENhJMC++kSkFdoxg/6vW69IRs7PbeCr59B6vOsWbww86JVtc5h7B2pb0rKg/cyziOARlV/fcd+/cbbPUuN6UApuGTvQUtyN5vVxSG3uY0IiL/8nZjA4isJvhp9qtnFJgzSKXru6MkNbNRzO6Sle6Ouc/dYSj8zIXpiMmV3lDSHvnPK25srukp3SEOaxBYC1S727WKQ+KjPeLg18G4mMvad884ve69X7JH6YUWDd9RAiH2Jrh58+27xk+IDRi7b8YW2IfArsljh65m1MLbFfC9XMleT3R4pEmXHfkJo9yHHggLhYWZ4Y5tYNRbvOQq762iX/sqWm3GRdvtnE7aWL3tk4NAmtbcrld/cLgNH5e14wD4/uFwS81ThPoTDVpmVpgc2EuW5sIjTjyl53blxNAYMtZUbObwNQCa0tyScZbCy0UJ0tynN09QpacOHtMW895YJ1o3eH0VhWPbt+T5EB1fV/v9Uvnoc21478fLemx0eiqFoG1/Z5a9ctInHzen8f8nJzda8neEd1VphbY3DJBaxuhEfmlqoYAAluNKzbakDkEthVZ7349eA16Hnk6MEF67jV3K6+nvqjZ2OTg+6XF4npYWKu1CLfTlzUJrL//h0g6PiOyq/rphOseRe4fKk0tsG42DSrR2ktoxNInlHqjE0BgR0e8FQ3MJbCG6+lLj0KPkXSFQtpOffasTO7XVZe37fjavXra+XEQVwtruoZbk8C23fDmIO+i9hnZVcUj2yMl2d8+puP8uS5zCGwury2hEQu/AFSbhgACOw3npbcyp8C2bD3KPEDSg8L/942gnyPpNEkeeX2gCVTxh11wiKdKvb7qjTbXj6ZO3YbXcR2e76QwzepmNkFg2xcVj0id+u/A6GXFI3FvILOPLcJmN0eoxNRludCJhEbchQebS3eeAAK780y5IwQgMD6BVGAJjTg+c1oYSACBHQiM6hCAQBUE0uw6hEaswi0YERNAYHkeIACBTSSQbnIiNOImenHhNiOwC3cw3YPAAgmk0ZxKo2stEAVdqpkAAluzd7ANAhDIEUjP754QQj2eDy4I1EQAga3JG9gCAQjEBHwcam9JZ4dd2Q4ucnhzZvcoSd417uJdzo6t7HCXFAhURQCBrcodGAMBCEQE9mnE85Qm9nOb4zUH50RJTsjQFRcaoBCYjQACOxt6GoYABHoIOO6xg3W0WXLS6meGGMmrEjwAGQKzEUBgZ0NPwxCAQA+BrkQLvuysJniIk6x/G4oQqJUAAlurZ7ALAhAwASdKcOq/NlnDLyUdFzIWpZmMIAaBqgggsFW5A2MgAAEIQGApBBDYpXiSfkAAAhCAQFUEENiq3IExEIAABCCwFAII7FI8ST8gAAEIQKAqAghsVe7AGAhAAAIQWAoBBHYpnqQfEIAABCBQFQEEtip3YAwEIAABCCyFAAK7FE/SDwhAAAIQqIoAAluVOzAGAhCAAASWQgCBXYon6QcEIAABCFRFAIGtyh0YAwEIQAACSyGAwC7Fk/QDAhCAAASqIoDAVuUOjIEABCAAgaUQQGCX4kn6AQEIQAACVRH4H5hLcXIGniLXAAAAAElFTkSuQmCC"/></switch></g></g></g></g></g></g></svg>